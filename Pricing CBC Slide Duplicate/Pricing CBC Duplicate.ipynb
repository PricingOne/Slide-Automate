{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"..\\general_functions\\generalFunctions.ipynb\"\n",
    "%run \"..\\Pricing CBC Slide Duplicate\\Pricing CBC Replacement Function.ipynb\"\n",
    "%run \"..\\general_functions\\Extracting Data Functions.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pptx import Presentation\n",
    "import win32com.client as win32\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "import sys \n",
    "win32c = win32.constants\n",
    "import shutil\n",
    "import os\n",
    "from win32com import client\n",
    "from pptx.util import Pt\n",
    "from pptx.enum.text import PP_ALIGN\n",
    "from pptx.chart.data import CategoryChartData,XyChartData,BubbleChartData\n",
    "import win32com.client\n",
    "from pptx.dml.color import RGBColor\n",
    "from pptx.util import Inches,Cm\n",
    "from pptx.chart.data import ChartData\n",
    "from pptx.enum.chart import XL_TICK_LABEL_POSITION\n",
    "from pptx.enum.chart import XL_LABEL_POSITION\n",
    "from win32com.client import constants as xl\n",
    "from pptx.enum.chart import XL_CHART_TYPE\n",
    "import pickle\n",
    "from pptx.enum.dml import MSO_LINE,MSO_LINE_DASH_STYLE\n",
    "import time\n",
    "import itertools\n",
    "from pptx.enum.chart import XL_AXIS_CROSSES,XL_LEGEND_POSITION\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import defaultdict \n",
    "from io import BytesIO \n",
    "import math\n",
    "from pptx.enum.shapes import MSO_SHAPE\n",
    "from pptx.oxml.xmlchemy import OxmlElement\n",
    "from pptx.enum.text import PP_ALIGN, MSO_ANCHOR\n",
    "from pptx.oxml.ns import qn\n",
    "import adodbapi\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\SophieZIMMERMANN\\Documents\\Slide-Automate\\Pricing CBC Slide Duplicate\\Pricing CBC Datasets\\Edgewell US CVS Brand data.xlsx\"\n",
    "\n",
    "\n",
    "market = []\n",
    "channel=[]\n",
    "region=['CVS Corp']\n",
    "marketsub=\" \".join(market+channel+region)\n",
    "client_manuf = [\"Edgewell\"]\n",
    "categories = [\"Manual Shave Women\"]\n",
    "\n",
    "pricingPlus = \"+15%\"\n",
    "pricingMinus = \"-10%\"\n",
    "\n",
    "colorList = [\n",
    "    RGBColor(0, 160, 151),\n",
    "    RGBColor(126, 202, 196),\n",
    "    RGBColor(0, 108, 109),\n",
    "    RGBColor(146, 208, 80),\n",
    "    RGBColor(0, 176, 80),\n",
    "    RGBColor(184, 182, 13),\n",
    "    RGBColor(0, 142, 135),   # New color close to the first and third colors\n",
    "    RGBColor(131, 218, 212)  # New color close to the second color\n",
    "]\n",
    "currency = '$' \n",
    "sign = \"before\"\n",
    "data_source = \"DATA SOURCE: Consumer Test | January 2025\"\n",
    "\n",
    "server = \"powerbi://api.powerbi.com/v1.0/myorg/Edgewell\"\n",
    "dataset_name = \"Edgewell US Dataset\"\n",
    "entity_hierarchy = [\n",
    "    (\"Region\", region),\n",
    "    (\"Channel\", channel),\n",
    "    (\"Market\", market)\n",
    "]\n",
    "hierarchy_levels = [\n",
    "    (\"Category\", categories),\n",
    "]\n",
    "\n",
    "\n",
    "path=os.path.join(os.getcwd(),\"Pricing CBC Datasets\")\n",
    "\n",
    "# Format months for DAX\n",
    "end_date = \"2024-09-01\"\n",
    "past_12_months = pd.date_range(end=end_date, periods=12, freq='ME').strftime('%b-%y').tolist()\n",
    "p12m_dax = \"{\" + \", \".join(f'\"{date}\"' for date in past_12_months) + \"}\"\n",
    "\n",
    "BrandelRun= False\n",
    "BrandSourcingRun=False\n",
    "ProductSourcingRun=False\n",
    "PERun=True\n",
    "RevenueResponseRun=False\n",
    "SERun=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PBI extract for WoB and GM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PERun: \n",
    "    client_manuf_dax = \", \".join(f'\"{x}\"' for x in client_manuf)\n",
    "    conn_str = f\"Provider=MSOLAP.8;Data Source={server};Initial Catalog={dataset_name};Timeout=600;\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for CVS Corp.\n",
      "All DataFrames saved to c:\\Users\\SophieZIMMERMANN\\Documents\\Slide-Automate\\Pricing CBC Slide Duplicate\\Pricing CBC Datasets\\Pricing_CBC.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(entity_name, area):\n",
    "    outputdic = {}\n",
    "    # Construct filter condition dynamically\n",
    "    columns = [\"Product Names WoB %\",\"Gross Margin %\"]\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "    dax_query = f\"\"\"\n",
    "    EVALUATE\n",
    "    CALCULATETABLE(\n",
    "        ADDCOLUMNS(\n",
    "            SUMMARIZE(\n",
    "                ProductNames,\n",
    "                ProductNames[ProductName]\n",
    "                ),\n",
    "            {column_exprs}\n",
    "        ),\n",
    "            ProductNames[SourceName]= \"Consumerresearchname\",\n",
    "            TREATAS(\n",
    "                {{\"{categories[0]}\"}} , \n",
    "                Products[Category]\n",
    "            ),\n",
    "            TREATAS(\n",
    "                {{{client_manuf_dax}}},\n",
    "                Products[Top Companies]\n",
    "            ),\n",
    "            TREATAS(\n",
    "                {p12m_dax},\n",
    "                Calendar[MonthYear]\n",
    "            ),\n",
    "            TREATAS(\n",
    "                {{\"{entity_name}\"}},\n",
    "                Market[{area}]\n",
    "            )\n",
    "    )  \n",
    "    \"\"\"\n",
    " \n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn:\n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(dax_query)\n",
    "                columns = [desc[0] for desc in cursor.description]\n",
    "                data = cursor.fetchall()\n",
    " \n",
    "                df = pd.DataFrame(data, columns=columns)\n",
    "                df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "                df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]\n",
    "                outputdic = df\n",
    "                print(f\"Query executed successfully for {entity_name}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name}: {e}\")\n",
    "   \n",
    "    return outputdic\n",
    " \n",
    "# Process data concurrently\n",
    "def process_dax_queries(entity_hierarchy):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "       \n",
    "        dfs_results = {}\n",
    "        futures = []\n",
    "        \n",
    "        for area, entity_list in entity_hierarchy:\n",
    "            for entity in entity_list:\n",
    "                future = executor.submit(execute_dax_query, entity, area)\n",
    "                futures.append((future, entity, area))\n",
    "\n",
    "        for future, entity, area in futures:\n",
    "            df = future.result()\n",
    "            dfs_results[(entity)] = df\n",
    "\n",
    "        # Save results\n",
    "        output_path = rf\"{path}\\Pricing_CBC.pkl\"\n",
    "        pd.to_pickle(dfs_results, output_path)\n",
    "        print(f\"All DataFrames saved to {output_path}.\")\n",
    " \n",
    "\n",
    "if PERun:\n",
    "    process_dax_queries(entity_hierarchy) \n",
    "    pbi = pd.read_pickle(\"Pricing CBC Datasets/Pricing_CBC.pkl\")\n",
    "    for key, df in pbi.items():\n",
    "        if not df.empty:\n",
    "            df.rename(columns={'Product Names WoB %':'WOB%', 'Gross Margin %':'GM%'}, inplace=True)\n",
    "            pbi[key] = df\n",
    "        else:\n",
    "            print(f\"Warning: DataFrame for {key} is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductName</th>\n",
       "      <th>WOB%</th>\n",
       "      <th>GM%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Schick Hydro Silk Ultimate Pubic Blade Refill...</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.7811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Schick Intuition Fresh Gardenia Blade Refills...</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.8492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Schick Hydro Silk Sensitive Blade Refills 4 Pack</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.8336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Schick Hydro Silk Sensitive Razor + 2 Blades</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.7502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Billie Disposable 3 Blade The Malibu 3 Pack</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.5012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Schick Hydro Silk Moisture Blade Refills 4 Pack</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.8286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Schick Intuition Sensitive Blade Refills  6 Pack</td>\n",
       "      <td>0.0879</td>\n",
       "      <td>0.8333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Schick Skintimate 4 Blade Vanilla Sugar Dispos...</td>\n",
       "      <td>0.1327</td>\n",
       "      <td>0.5138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Schick Intuition Advanced Moisture Razor + 2 B...</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.7140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Schick Quattro For Women Blade Refills 8 Pack</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.7981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Schick Hydro Silk Ultimate Pubic Skin Protecti...</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>0.6037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Schick Intuition Pure Nourishment Razor + 2 Bl...</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.7303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Schick Intuition Advanced Moisture Blade Refil...</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.8527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Billie Blade Refills 8 Pack</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.7368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Schick Intuition Pure Nourishment  Blade Refil...</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.8495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Schick Intuition Fresh Gardenia Razor + 2  Bl...</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.6704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Schick Hydro Silk Sensitive Disposable Razor 6...</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.6858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Schick Intuition Sensitive Disposable Razor 3 ...</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.6715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Billie Blade Refills 4 Pack</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>0.7580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Billie Dream Pop Razor + 2 Blades</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.4854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Billie Malibu Razor + 2 Blades</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>0.4987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Schick Intuition Lemon Berry Breeze Blade Ref...</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>0.8310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Schick Hydro Silk Sensitive Disposable Razor 3...</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>0.7432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Schick Intuition Sensitive Razor+ 2 Blades</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.7155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Schick Quattro For Women Razor + 5 Blades</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.7230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Schick Intuition Lemon Berry Breeze Razor +2 ...</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.7009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Schick Quattro For Women Blade Refills 6 Pack</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.8482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Schick Quattro For Women Razor +4 Blades</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.7512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Schick Skintimate 4-Blade Sensitive Disposable...</td>\n",
       "      <td>0.0595</td>\n",
       "      <td>0.5320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          ProductName    WOB%     GM%\n",
       "0    Schick Hydro Silk Ultimate Pubic Blade Refill...  0.0046  0.7811\n",
       "1    Schick Intuition Fresh Gardenia Blade Refills...  0.0178  0.8492\n",
       "4    Schick Hydro Silk Sensitive Blade Refills 4 Pack  0.0284  0.8336\n",
       "5        Schick Hydro Silk Sensitive Razor + 2 Blades  0.0360  0.7502\n",
       "9         Billie Disposable 3 Blade The Malibu 3 Pack  0.0146  0.5012\n",
       "10    Schick Hydro Silk Moisture Blade Refills 4 Pack  0.0264  0.8286\n",
       "11   Schick Intuition Sensitive Blade Refills  6 Pack  0.0879  0.8333\n",
       "12  Schick Skintimate 4 Blade Vanilla Sugar Dispos...  0.1327  0.5138\n",
       "13  Schick Intuition Advanced Moisture Razor + 2 B...  0.0152  0.7140\n",
       "15      Schick Quattro For Women Blade Refills 8 Pack  0.0134  0.7981\n",
       "16  Schick Hydro Silk Ultimate Pubic Skin Protecti...  0.0331  0.6037\n",
       "22  Schick Intuition Pure Nourishment Razor + 2 Bl...  0.0341  0.7303\n",
       "24  Schick Intuition Advanced Moisture Blade Refil...  0.0158  0.8527\n",
       "25                        Billie Blade Refills 8 Pack  0.0255  0.7368\n",
       "28  Schick Intuition Pure Nourishment  Blade Refil...  0.0488  0.8495\n",
       "29   Schick Intuition Fresh Gardenia Razor + 2  Bl...  0.0165  0.6704\n",
       "30  Schick Hydro Silk Sensitive Disposable Razor 6...  0.0029  0.6858\n",
       "33  Schick Intuition Sensitive Disposable Razor 3 ...  0.0238  0.6715\n",
       "35                        Billie Blade Refills 4 Pack  0.0729  0.7580\n",
       "36                  Billie Dream Pop Razor + 2 Blades  0.0359  0.4854\n",
       "37                     Billie Malibu Razor + 2 Blades  0.0502  0.4987\n",
       "39   Schick Intuition Lemon Berry Breeze Blade Ref...  0.0328  0.8310\n",
       "41  Schick Hydro Silk Sensitive Disposable Razor 3...  0.0533  0.7432\n",
       "43         Schick Intuition Sensitive Razor+ 2 Blades  0.0418  0.7155\n",
       "44          Schick Quattro For Women Razor + 5 Blades  0.0258  0.7230\n",
       "45   Schick Intuition Lemon Berry Breeze Razor +2 ...  0.0241  0.7009\n",
       "46      Schick Quattro For Women Blade Refills 6 Pack  0.0107  0.8482\n",
       "47           Schick Quattro For Women Razor +4 Blades  0.0152  0.7512\n",
       "49  Schick Skintimate 4-Blade Sensitive Disposable...  0.0595  0.5320"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pbi[marketsub]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data in Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BrandelRun:\n",
    "    sheet_name='Brand elasticity'\n",
    "    brandElasticity_ori=pd.read_excel(file_path,sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns(df):\n",
    "    column_mapping = {\n",
    "        'product': 'Product',\n",
    "        'Product': 'Product',\n",
    "        'SKU': 'Product',\n",
    "        # Add more mappings as necessary\n",
    "    }\n",
    "    \n",
    "    # Apply the column mapping\n",
    "    df.rename(columns=column_mapping, inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BrandSourcingRun:\n",
    "    plusbranding = pd.read_excel(file_path,\"Plus Brand Sourcing\").rename(columns={'Unnamed: 0': 'Product'})\n",
    "    Minusbranding = pd.read_excel(file_path,\"Minus Brand Sourcing\").rename(columns={'Unnamed: 0': 'Product'})\n",
    "    plusbrandingfair = pd.read_excel(file_path,\"Plus Brand Sourcing Fair share\").rename(columns={'Unnamed: 0': 'Product'})\n",
    "    Minusbrandingfair = pd.read_excel(file_path,\"Minus Brand Sourcing Fair share\").rename(columns={'Unnamed: 0': 'Product'})\n",
    "    Minusbrandingfair = Minusbrandingfair[[col for col in Minusbrandingfair.columns if 'Unnamed' not in col]]\n",
    "    plusbranding = normalize_columns(plusbranding)\n",
    "    Minusbranding = normalize_columns(Minusbranding)\n",
    "    plusbrandingfair = normalize_columns(plusbrandingfair)\n",
    "    Minusbrandingfair = normalize_columns(Minusbrandingfair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ProductSourcingRun: \n",
    "    plus = pd.read_excel(file_path,\"Plus Sourcing\")\n",
    "    Minus = pd.read_excel(file_path,\"Minus Sourcing\")\n",
    "    plusfair = pd.read_excel(file_path,\"Plus Sourcing Fair share\")\n",
    "    Minusfair = pd.read_excel(file_path,\"Minus Sourcing Fair share\")\n",
    "    plus = normalize_columns(plus)\n",
    "    Minus = normalize_columns(Minus)\n",
    "    plusfair = normalize_columns(plusfair)\n",
    "    Minusfair = normalize_columns(Minusfair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PERun: \n",
    "    pe = pd.read_excel(file_path,\"PE\")\n",
    "    group_list = pe['Grouping'].unique().tolist()\n",
    "    pe = normalize_columns(pe)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PERun:\n",
    "    from openpyxl import load_workbook\n",
    "    from openpyxl.utils import get_column_letter\n",
    "\n",
    "    # Load the workbook and select the sheet\n",
    "    wb = load_workbook(file_path, data_only=True)\n",
    "    sheet = wb['PE']\n",
    "    pe[\"Share P5 - Base Share\"] = pd.Series([float(0)] * len(pe))\n",
    "    pe[\"PE P5-P6\"] = pd.Series([float(0)] * len(pe))\n",
    "    # Check for yellow cells and adjust shares\n",
    "    for row in range(1, len(pe)+2):\n",
    "        for col in range(1, pe.shape[1]+ 2):\n",
    "            cell = sheet.cell(row=row, column=col)\n",
    "            if cell.fill.fgColor.rgb == 'FFFFFF00':\n",
    "                column_name = sheet.cell(1,col).value \n",
    "                col_num=int(column_name[1])\n",
    "                \n",
    "                for i in range(5,col_num-1,-1):\n",
    "                    if i == col_num:\n",
    "                        pe[f\"Share P{i} - Base Share\"][row-2] =0\n",
    "                        pe[f\"PE P{i}-P{i+1}\"][row-2]=0\n",
    "                    else:\n",
    "                        pe[f\"Share P{i} - Base Share\"][row-2] = pe[f\"Share P{i-1} - Base Share\"][row-2]\n",
    "                        pe[f\"PE P{i}-P{i+1}\"][row-2] =  pe[f\"PE P{i-1}-P{i}\"][row-2]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PERun:\n",
    "    pbi[marketsub][\"ProductName\"]=pbi[marketsub][\"ProductName\"].str.upper()\n",
    "    pbi[marketsub][\"ProductName\"] = pbi[marketsub][\"ProductName\"].apply(lambda x: ' '.join(str(x).split()))\n",
    "    pe[\"Product\"]=pe[\"Product\"].str.upper()\n",
    "    pe[\"Product\"]=pe[\"Product\"].apply(lambda x: ' '.join(str(x).split()))\n",
    "    pepbijoin = pe.join(pbi[marketsub], lsuffix=\"Product\", rsuffix=\"ProductName\")\n",
    "    pepbijoin=pd.merge(pe,pbi[marketsub][['ProductName','WOB%','GM%']], how='left', left_on='Product', right_on='ProductName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RevenueResponseRun: \n",
    "    from openpyxl import load_workbook\n",
    "\n",
    "    # Load the workbook and select the specific sheet\n",
    "    wb = load_workbook(file_path, data_only=True)\n",
    "    sheet = wb['Revenue Response']\n",
    "\n",
    "    # Create an empty color mask matrix\n",
    "    bgcol = np.empty([sheet.max_row, sheet.max_column], dtype=object, order='C')\n",
    "\n",
    "    # Cycle through all cells to get colors\n",
    "    for row in range(sheet.max_row):\n",
    "        for column in range(sheet.max_column):\n",
    "            cell = sheet.cell(row + 1, column + 1)\n",
    "            \n",
    "            # Check if the cell font color is not red (hex 'FFFF0000'), if it is, set the value to empty\n",
    "            color_in_hex_index = cell.value if cell.font.color.rgb != 'FFFF0000' else ''\n",
    "            \n",
    "            # Assign the value to the bgcol array\n",
    "            bgcol[row, column] = str(color_in_hex_index)\n",
    "\n",
    "    # Convert the bgcol array to a pandas DataFrame\n",
    "    colormask = pd.DataFrame(bgcol)\n",
    "\n",
    "    # Print the shape of the DataFrame\n",
    "    #print(colormask.shape)\n",
    "\n",
    "    # Adjust columns names and content\n",
    "    # Define ranges for slicing the DataFrame\n",
    "    if len([]) == 0:\n",
    "        SheetContentRanges = range(0, colormask.shape[0]), range(0, colormask.shape[1])\n",
    "\n",
    "    # Slice the DataFrame according to defined ranges\n",
    "    colormask = colormask.iloc[SheetContentRanges]\n",
    "\n",
    "    # Reset index and update column names\n",
    "    colormask.reset_index(drop=True, inplace=True)\n",
    "    colormask.columns = colormask.iloc[0]  # Set the first row as the header\n",
    "    colormask = colormask.iloc[1:, :]  # Remove the first row (header) and the first column\n",
    "\n",
    "    # Drop specific columns\n",
    "    colormask = colormask.drop(columns=['Select SKUs\\n(with \"x\")', 'Possible steps (d/u)', 'Base case share'])\n",
    "\n",
    "    # Display the final DataFrame\n",
    "    #print(colormask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_revenue(colormask):\n",
    "    \"\"\"\n",
    "    Clean revenue data from a DataFrame.\n",
    " \n",
    "    Parameters:\n",
    "    - colormask: The DataFrame containing revenue data.\n",
    " \n",
    "    Returns:\n",
    "    - dfList: A list of cleaned DataFrames.\n",
    "    \"\"\"\n",
    "    dfList = []  # Initialize an empty list to store cleaned DataFrames\n",
    "    colormask = colormask.loc[:, ~colormask.columns.duplicated(keep='last')]  # Remove duplicate columns\n",
    "    for i in range(1, colormask.shape[0] + 1):\n",
    "        df = colormask.iloc[i - 1:i]  # Extract a single row DataFrame\n",
    "        df = df.replace(\"\", np.nan)  # Replace empty cells with NaN\n",
    "        df.dropna(axis=1, inplace=True)  # Drop columns with NaN values\n",
    "        dfList.append(df)  # Append cleaned DataFrame to the list\n",
    "    return dfList  # Return the list of cleaned DataFrames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RevenueResponseRun: dfList = cleaning_revenue(colormask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SERun: \n",
    "    sheet_name='SE'\n",
    "    SE=pd.read_excel(file_path,sheet_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SE_clean(data):\n",
    "    new_rows = []\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        # First row: s1 and s2 \n",
    "        new_rows.append({'Product':row['Product'],\n",
    "        'Base Size': row['S1 total'], \n",
    "        'New Size': row['S2 total'],\n",
    "        'Size Change':row['size S2 - Base size'],\n",
    "        'Volume Index': row['Volume Index 2'],\n",
    "        'Value Index': row['Value Index 2'],\n",
    "        'Gross Profit':row['Gross Profit 2'],\n",
    "        'Size Elasticity': row['SE 2'], \n",
    "        'SCD PE':row['SCD PE 2'], \n",
    "        'PCD PE':row['PCD PE 2']})\n",
    "        # Second row: s1 and s3 \n",
    "        new_rows.append({'Product':row['Product'],\n",
    "        'Base Size': row['S1 total'],\n",
    "        'New Size': row['S3 total'], \n",
    "        'Size Change':row['size S3 - Base size'],\n",
    "        'Volume Index': row['Volume Index 3'],\n",
    "        'Value Index': row['Value Index 3'],\n",
    "        'Gross Profit':row['Gross Profit 3'],\n",
    "        'Size Elasticity': row['SE 3'], \n",
    "        'SCD PE':row['SCD PE 3'], \n",
    "        'PCD PE':row['PCD PE 3']})\n",
    "        \n",
    "    # Convert the list of new rows back into a DataFrame\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    new_df = new_df.dropna(thresh=new_df.shape[1] - 7).reset_index(drop=True)\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SERun: SE_cleaned = SE_clean(SE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplication Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [0,1 ,2,3,4,5 ]\n",
    "\n",
    "duplication = [(len(brandElasticity_ori.columns)+3)//6 if BrandelRun else 0,len(plusbranding.keys())-1 if BrandSourcingRun else 0,len(plus.keys())-1 if ProductSourcingRun else 0, len(group_list) if PERun else 0, colormask.shape[0] if RevenueResponseRun else 0, math.ceil(len(SE_cleaned)/20) if SERun else 0]\n",
    "section_names = [\"Brand Elasticity\" if BrandelRun else \"\",\"Brand Sourcing Analysis\" if BrandSourcingRun else 0,\"Product Sourcing Analysis\" if ProductSourcingRun else 0,\"Price Elasticity Curve\" if PERun else 0,\"Revenue Response Analysis\" if RevenueResponseRun else 0,\"Size Elasticity\" if SERun else 0]\n",
    "\n",
    "path = os.getcwd() + '//Pricing CBC base Oct 2024.pptx'\n",
    "new_pre = os.getcwd() + '//slide duplicated.pptx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "slideDuplication(index,duplication,section_names,path,new_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = Presentation(new_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BrandelRun:\n",
    "    for sli in range(duplication[0]):\n",
    "\n",
    "        start=sli*6\n",
    "        end=start+3\n",
    "        brandElasticity= brandElasticity_ori[brandElasticity_ori.columns[start:end]]\n",
    "        brandElasticity=brandElasticity.dropna()\n",
    "        \n",
    "        BrandElasticity(prs,brandElasticity,1,categories[0],position=0+sli) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BrandSourcingRun:BrandSourcingAnalysis(prs,plusbranding,Minusbranding,plusbrandingfair,Minusbrandingfair,duplication[1],position=sum(duplication[:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ProductSourcingRun:ProductSourcingAnalysis(prs,plus,Minus,plusfair,Minusfair,duplication[2],position=sum(duplication[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PERun:PriceElasticityCurve(prs, pepbijoin, group_list, duplication[3],position=sum(duplication[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RevenueResponseRun: revenue_response(prs,dfList, duplication[4],position=sum(duplication[:4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SERun: SE_Slide(prs,SE_cleaned,duplication[5],position=sum(duplication[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = str(date.today())\n",
    "outputPath=os.getcwd() + \"\\\\Pricing CBC \"+marketsub+\" output \"+today+\".pptx\"\n",
    "prs.save(outputPath)\n",
    "app = win32.Dispatch(\"PowerPoint.Application\")\n",
    "#presentation = app.Presentations.Open(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape_number_partial(shapes, text):\n",
    "    \"\"\"\n",
    "    Get the index of a shape with specific text.\n",
    "\n",
    "    Parameters:\n",
    "    - shapes (list): A list of shapes in a slide.\n",
    "    - text (str): The text to search for in the shapes.\n",
    "\n",
    "    Returns:\n",
    "    - int or None: The index of the shape if found, None otherwise.\n",
    "    \"\"\"\n",
    "    for shape_index in range(len(shapes)):\n",
    "        if shapes[shape_index].has_text_frame:  # Check if the shape has a text frame\n",
    "            if text in shapes[shape_index].text:  # Compare the shape's text with the given text\n",
    "                return shape_index  # Return the index of the shape if text matches\n",
    "    return None  # Return None if the shape with the given text is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getChartNum(shapes):\n",
    "    \"\"\"\n",
    "    Extractcharts from a collection of shapes in a PowerPoint slide.\n",
    "\n",
    "    Parameters:\n",
    "    - shapes: A collection of shapes in a PowerPoint slide.\n",
    "\n",
    "    Returns:\n",
    "    - shape_index: shape number in selecton pane\n",
    "    \"\"\"\n",
    "    shape_index = []\n",
    "    for shape_index in range(len(shapes)):\n",
    "        if shapes[shape_index].has_chart:\n",
    "            return shape_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RevenueResponseRun:  \n",
    "    sls = [sl for sl in prs.slides][sum(duplication[:4]):sum(duplication[:5])]\n",
    "    shapes = prs.slides[sum(duplication[:4])].shapes\n",
    "    subtitleNumber = get_shape_number_partial(shapes, \"Revenue Response Curve by Price Point\")\n",
    "    chartNumber = getChartNum(shapes)\n",
    "    print(chartNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RevenueResponseRun:  \n",
    "    prod_names=[i.shapes[subtitleNumber].text.split(\" | \")[1] for i in sls]\n",
    "    prod_names=list(set(prod_names))\n",
    "    len(prod_names)\n",
    "    filter_dps=pd.read_excel(file_path, sheet_name=\"PE\")\n",
    "    filter_dps=filter_dps.melt(id_vars=[\"Product\"],value_vars=[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\"])\n",
    "    filter_dps=filter_dps.groupby(\"Product\")[\"value\"].unique().reset_index()\n",
    "    filter_dps=dict(zip(filter_dps[\"Product\"],filter_dps[\"value\"]))\n",
    "    len(filter_dps.keys())\n",
    "    set(prod_names)==set(filter_dps.keys())\n",
    "    charts=[s.shapes[chartNumber] for s in sls]\n",
    "    [float(i[0].replace(currency,\"\")) for i in charts[0].chart.plots[0].categories.flattened_labels]\n",
    "    dfs=[]\n",
    "    for num,chart in enumerate(charts):\n",
    "        temp=pd.DataFrame()\n",
    "        for i in chart.chart.series:\n",
    "            temp[i.name]=i.values\n",
    "        temp[\"x_axis\"]=[float(j[0].replace(currency,\"\")) for j in chart.chart.plots[0].categories.flattened_labels]\n",
    "        prod_name=sls[num].shapes[subtitleNumber].text.split(\" | \")[1]\n",
    "        temp=temp[(temp[\"x_axis\"].isin(filter_dps[prod_name]))|(temp[\"Volume Ix\"]==100)]\n",
    "        dfs.append(temp)\n",
    "    len(dfs)       \n",
    "\n",
    "    org_dfs=[]\n",
    "    for num,chart in enumerate(charts):\n",
    "        temp=pd.DataFrame()\n",
    "        for i in chart.chart.series:\n",
    "            temp[i.name]=i.values\n",
    "        temp[\"x_axis\"]=[float(j[0].replace(currency,\"\")) for j in chart.chart.plots[0].categories.flattened_labels]\n",
    "        prod_name=sls[num].shapes[subtitleNumber].text.split(\" | \")[1]\n",
    "        org_dfs.append(temp)\n",
    "    len(org_dfs)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RevenueResponseRun:  \n",
    "  final_res=[]\n",
    "  dfs=org_dfs\n",
    "  for num_index,df in enumerate(dfs) :\n",
    "    df[\"ZeroPoint\"]=np.where((df[\"Volume Ix\"]==100),-1,np.nan)\n",
    "    df[\"ZeroPoint\"]=df[\"ZeroPoint\"].bfill()\n",
    "    df[\"ZeroPoint\"]=df[\"ZeroPoint\"].fillna(1)\n",
    "  \n",
    "\n",
    "    df[\"Value Ix delta\"]=df[\"Value Ix\"].diff() \n",
    "    df[\"Gross Profit Ix delta\"]=df[\"Gross Profit Ix\"].diff()\n",
    "\n",
    "    df[\"Value Ix delta\"]=df[\"Value Ix delta\"]*df[\"ZeroPoint\"]\n",
    "    df[\"Gross Profit Ix delta\"]=df[\"Gross Profit Ix delta\"]*df[\"ZeroPoint\"]\n",
    "\n",
    "\n",
    "\n",
    "    df[\"color\"]=np.select([(df[\"Value Ix delta\"]>0)&(df[\"Gross Profit Ix delta\"]>0)&(df[\"Value Ix\"]>100),\n",
    "                          (df[\"Value Ix delta\"]>0)&(df[\"Gross Profit Ix delta\"]<0)&(df[\"Value Ix\"]>100),\n",
    "                          (df[\"Value Ix delta\"]>0)&(df[\"Gross Profit Ix delta\"]==0)&(df[\"Value Ix\"]>100),\n",
    "                          (df[\"Value Ix delta\"]<0)&(df[\"Gross Profit Ix delta\"]>0)&(df[\"Value Ix\"]>100),\n",
    "                          (df[\"Value Ix delta\"]<0)&(df[\"Gross Profit Ix delta\"]<0)&(df[\"Value Ix\"]>100),\n",
    "                          (df[\"Value Ix delta\"]<0)&(df[\"Gross Profit Ix delta\"]==0)&(df[\"Value Ix\"]>100),\n",
    "                          (df[\"Value Ix delta\"]==0)&(df[\"Gross Profit Ix delta\"]>0)&(df[\"Value Ix\"]>100),\n",
    "                          (df[\"Value Ix delta\"]==0)&(df[\"Gross Profit Ix delta\"]<0)&(df[\"Value Ix\"]>100),\n",
    "                          (df[\"Value Ix delta\"]==0)&(df[\"Gross Profit Ix delta\"]==0)&(df[\"Value Ix\"]>100),\n",
    "                          (df[\"Value Ix delta\"]>0)&(df[\"Gross Profit Ix delta\"]>0)&(df[\"Value Ix\"]<=100),\n",
    "                          (df[\"Value Ix delta\"]>0)&(df[\"Gross Profit Ix delta\"]<0)&(df[\"Value Ix\"]<=100),\n",
    "                          (df[\"Value Ix delta\"]>0)&(df[\"Gross Profit Ix delta\"]==0)&(df[\"Value Ix\"]<=100),\n",
    "                          (df[\"Value Ix delta\"]<0)&(df[\"Gross Profit Ix delta\"]>0)&(df[\"Value Ix\"]<=100),\n",
    "                          (df[\"Value Ix delta\"]<0)&(df[\"Gross Profit Ix delta\"]<0)&(df[\"Value Ix\"]<=100),\n",
    "                          (df[\"Value Ix delta\"]<0)&(df[\"Gross Profit Ix delta\"]==0)&(df[\"Value Ix\"]<=100),\n",
    "                          (df[\"Value Ix delta\"]==0)&(df[\"Gross Profit Ix delta\"]>0)&(df[\"Value Ix\"]<=100),\n",
    "                          (df[\"Value Ix delta\"]==0)&(df[\"Gross Profit Ix delta\"]<0)&(df[\"Value Ix\"]<=100),\n",
    "                          (df[\"Value Ix delta\"]==0)&(df[\"Gross Profit Ix delta\"]==0)&(df[\"Value Ix\"]<=100)],\n",
    "                          [\n",
    "  \"Green|Profit & Revenue Increase\",\n",
    "  \"Yellow|Revenue Increase & Profit Dilution\",\n",
    "  \"Yellow|Revenue Increase & Flat Profit\",\n",
    "  \"Yellow|Revenue Dilution & Profit Increase\",\n",
    "  \"Red|Revenue & Profit Dilution\",\n",
    "  \"Red|Revenue Dilution & Flat Profit\",\n",
    "  \"Yellow|Flat Revenue & Profit Increase\",\n",
    "  \"Red|Flat Revenue & Profit Dilution\",\n",
    "  \"Yellow|Flat Revenue & Profit\",\n",
    "  \"Yellow|Profit & Revenue Increase\",\n",
    "  \"Yellow|Revenue Increase & Profit Dilution\",\n",
    "  \"Yellow|Revenue Increase & Flat Profit\",\n",
    "  \"Yellow|Revenue Dilution & Profit Increase\",\n",
    "  \"Red|Revenue & Profit Dilution\",\n",
    "  \"Red|Revenue Dilution & Flat Profit\",\n",
    "  \"Yellow|Flat Revenue & Profit Increase\",\n",
    "  \"Red|Flat Revenue & Profit Dilution\",\n",
    "  \"Yellow|Flat Revenue & Profit\",\n",
    "  ],\"\")\n",
    "    \n",
    "\n",
    "    df=org_dfs[num_index].merge(df,how=\"left\")\n",
    "\n",
    "    df=df.reset_index(drop=True)\n",
    "    df=df.iloc[1:,:]\n",
    "    df[\"color\"]=df[\"color\"].bfill()\n",
    "    df[\"grouping_same_color\"]=DetermineShapeNumber(df[\"color\"].apply(lambda x : x.split(\"|\")[0]).to_list())\n",
    "    groups=df.groupby(\"grouping_same_color\")[\"color\"].apply(lambda x : pd.Series(x).mode()[0]).reset_index()\n",
    "    df=df.drop(columns=[\"color\"]).merge(groups)\n",
    "    \n",
    "    df[\"shape_number\"]=DetermineShapeNumber(df[\"color\"].to_list())\n",
    "    df[\"color_num\"]=df[\"color\"]+\"_\"+df[\"shape_number\"].astype(str)\n",
    "    dist=df[\"color_num\"].to_list()\n",
    "    full_lenght=len(dist)\n",
    "    dist_list=[[0,0,dist[0] ]]\n",
    "    current=dist[0]\n",
    "    for i in range(len(dist)):\n",
    "      if current == dist[i]:\n",
    "        dist_list[-1][1]+=1\n",
    "      else :\n",
    "        dist_list.append([i,i+1,dist[i]])\n",
    "        current=dist[i]\n",
    "    res=[(int(round(i[0]/len(dist),2)*100),int(round(i[1]/len(dist),2)*100),i[2].split(\"_\")[0]) for i in dist_list ]  \n",
    "    final_res.append(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RevenueResponseRun:  \n",
    "    full_width=Cm(15.7)\n",
    "    left_start=Cm(2.7)\n",
    "    for num,slide in enumerate(sls):\n",
    "        for sh in final_res[num]:\n",
    "            added_shape=AddRectangle(slide,left_start + (sh[0]/100) * full_width, ((sh[1]-sh[0])/100) * full_width,sh[2] )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RevenueResponseRun:  prs.save(outputPath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
