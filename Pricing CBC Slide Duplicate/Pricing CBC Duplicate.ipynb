{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"..\\general_functions\\generalFunctions.ipynb\"\n",
    "%run \"..\\Pricing CBC Slide Duplicate\\Pricing CBC Replacement Function.ipynb\"\n",
    "%run \"..\\general_functions\\Extracting Data Functions.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pptx import Presentation\n",
    "import win32com.client as win32\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "import sys \n",
    "win32c = win32.constants\n",
    "import shutil\n",
    "import os\n",
    "from win32com import client\n",
    "from pptx.util import Pt\n",
    "from pptx.enum.text import PP_ALIGN\n",
    "from pptx.chart.data import CategoryChartData,XyChartData,BubbleChartData\n",
    "import win32com.client\n",
    "from pptx.dml.color import RGBColor\n",
    "from pptx.util import Inches,Cm\n",
    "from pptx.chart.data import ChartData\n",
    "from pptx.enum.chart import XL_TICK_LABEL_POSITION\n",
    "from pptx.enum.chart import XL_LABEL_POSITION\n",
    "from win32com.client import constants as xl\n",
    "from pptx.enum.chart import XL_CHART_TYPE\n",
    "import pickle\n",
    "from pptx.enum.dml import MSO_LINE,MSO_LINE_DASH_STYLE\n",
    "import time\n",
    "import itertools\n",
    "from pptx.enum.chart import XL_AXIS_CROSSES,XL_LEGEND_POSITION\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import defaultdict \n",
    "from io import BytesIO \n",
    "import math\n",
    "from pptx.enum.shapes import MSO_SHAPE\n",
    "from pptx.oxml.xmlchemy import OxmlElement\n",
    "from pptx.enum.text import PP_ALIGN, MSO_ANCHOR\n",
    "from pptx.oxml.ns import qn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\SophieZIMMERMANN\\Documents\\Slide-Automate\\Pricing CBC Slide Duplicate\\Pricing CBC Datasets\\Edgewell US CVS Subbrand Sector data.xlsx\"\n",
    "market = []\n",
    "channel=[]\n",
    "region=['CVS Corp']\n",
    "marketsub=\" \".join(market+channel+region)\n",
    "client_manuf = [\"Edgewell\"]\n",
    "categories = [\"Manual Shave Women\"]\n",
    "\n",
    "pricingPlus = \"+15%\"\n",
    "pricingMinus = \"-10%\"\n",
    "\n",
    "colorList = [\n",
    "    RGBColor(0, 160, 151),\n",
    "    RGBColor(126, 202, 196),\n",
    "    RGBColor(0, 108, 109),\n",
    "    RGBColor(146, 208, 80),\n",
    "    RGBColor(0, 176, 80),\n",
    "    RGBColor(184, 182, 13),\n",
    "    RGBColor(0, 142, 135),   # New color close to the first and third colors\n",
    "    RGBColor(131, 218, 212)  # New color close to the second color\n",
    "]\n",
    "currency = '$' \n",
    "sign = \"before\"\n",
    "data_source = \"DATA SOURCE: Consumer Test | January 2025\"\n",
    "f_name = os.path.join(os.path.dirname(os.getcwd()),\"Edgewell US Dataset.xlsx\")\n",
    "\n",
    "BrandelRun= False\n",
    "BrandSourcingRun=True\n",
    "ProductSourcingRun=False\n",
    "PERun=False\n",
    "RevenueResponseRun=False\n",
    "SERun=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PBI extract for WoB and GM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PERun:\n",
    "    f_path = Path.cwd()\n",
    "    excel = client.gencache.EnsureDispatch('Excel.Application')\n",
    "    excel.Visible = True  # False\n",
    "    wb = excel.Workbooks.Open(f_name)\n",
    "    ws=wb.Sheets([s.Name for s in wb.Sheets][0])\n",
    "    s_name = [s.Name for s in wb.Sheets][0]\n",
    "    pvtTable = ws.PivotTables(1)\n",
    "    #change report layout\n",
    "    pvtTable.RowAxisLayout(1)   #RowAxisLayout(1) for tabular form\n",
    "    #change pivot table style\n",
    "    #Select from Design tab, try out Medium9 or Medium3\n",
    "    pvtTable.TableStyle2 = \"pivotStyleMedium21\"\n",
    "    pvtTable.ClearTable()\n",
    "\n",
    "    pvtTable.TableRange2.Cut(ws.Range(\"A13\"))\n",
    "\n",
    "\n",
    "    fieldsNamePosition={}\n",
    "    for i in range(1,pvtTable.CubeFields.Count+1):\n",
    "        fieldsNamePosition[str(pvtTable.CubeFields(i))]=i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PERun:\n",
    "    row_list = []\n",
    "    column_list=[]\n",
    "    filter_list=['[Products].[Category]','[Time Logic].[Time Period]','[Scope].[Scope]','[Market].[Area]','[Market].[Region]','[Market].[Channel]','[Market].[Market]','[ProductNames].[SourceName]','[Products].[Top Companies]']\n",
    "    value_list=[]\n",
    "    pvtTable.ClearTable()\n",
    "    pvtTable = set_excel_fields(row_list,column_list,filter_list,value_list,pvtTable)\n",
    "\n",
    "    #Select the filter values for each filter\n",
    "    pvtTable.PivotFields('[ProductNames].[SourceName].[SourceName]').ClearAllFilters()\n",
    "    pvtTable.PivotFields('[ProductNames].[SourceName].[SourceName]').CurrentPageName = '[ProductNames].[SourceName].&[Consumerresearchname]'\n",
    "    pvtTable.PivotFields('[Products].[Top Companies].[Top Companies]').ClearAllFilters()\n",
    "    pvtTable.PivotFields('[Products].[Top Companies].[Top Companies]').CurrentPageName = f'[Products].[Top Companies].&[{client_manuf[0]}]'\n",
    "\n",
    "    pvtTable.PivotFields(\"[Products].[Category].[Category]\").ClearAllFilters()\n",
    "    pvtTable.PivotFields('[Products].[Category].[Category]').CurrentPageName = f'[Products].[Category].&[{categories[0]}]'\n",
    "\n",
    "    pvtTable.PivotFields(\"[Time Logic].[Time Period].[Time Period]\").ClearAllFilters()\n",
    "    pvtTable.PivotFields('[Time Logic].[Time Period].[Time Period]').CurrentPageName = '[Time Logic].[Time Period].&[P12M]'\n",
    "\n",
    "    if len(market)!=0:\n",
    "        pvtTable.PivotFields(\"[Market].[Market].[Market]\").ClearAllFilters()\n",
    "        pvtTable.PivotFields('[Market].[Market].[Market]').CurrentPageName = f'[Market].[Market].&[{market[0]}]'\n",
    "\n",
    "    if len(region)!=0:\n",
    "        pvtTable.PivotFields(\"[Market].[Region].[Region]\").ClearAllFilters()\n",
    "        pvtTable.PivotFields('[Market].[Region].[Region]').CurrentPageName = f'[Market].[Region].&[{region[0]}]'\n",
    "\n",
    "    if len(channel)!=0:\n",
    "        pvtTable.PivotFields(\"[Market].[Channel].[Channel]\").ClearAllFilters()\n",
    "        pvtTable.PivotFields('[Market].[Channel].[Channel]').CurrentPageName = f'[Market].[Channel].&[{channel[0]}]'\n",
    "\n",
    "    row_list = ['[ProductNames].[ProductName]']\n",
    "    column_list=[]\n",
    "    filter_list=[]\n",
    "    value_list=['[Measures].[Product Names WoB %]','[Measures].[Gross Margin %]']\n",
    "\n",
    "    pvtTable = set_excel_fields(row_list,column_list,filter_list,value_list,pvtTable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PERun:\n",
    "    Pricing_CBC ={}\n",
    "    if len(market)!=0:\n",
    "        Pricing_CBC = create_dataframe(market,Pricing_CBC,\"[Market].[Market].[Market]\",pvtTable, f'{categories[0]} | ')\n",
    "        pvtTable.PivotFields(\"[Market].[Market].[Market]\").ClearAllFilters()\n",
    "\n",
    "    if len(region)!=0:\n",
    "        Pricing_CBC = create_dataframe(region,Pricing_CBC,\"[Market].[Region].[Region]\",pvtTable, f'{categories[0]} | ')\n",
    "        pvtTable.PivotFields(\"[Market].[Region].[Region]\").ClearAllFilters()\n",
    "\n",
    "    if len(channel)!=0:\n",
    "        Pricing_CBC = create_dataframe(channel,Pricing_CBC,\"[Market].[Channel].[Channel]\",pvtTable, f'{categories[0]} | ')\n",
    "        pvtTable.PivotFields(\"[Market].[Channel].[Channel]\").ClearAllFilters()\n",
    "\n",
    "    with open('Pricing CBC Datasets/Pricing_CBC.pickle', 'wb') as handle:\n",
    "        pickle.dump(Pricing_CBC, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PERun:\n",
    "    wb.Close(False)\n",
    "    excel.Visible = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PERun:\n",
    "        pbi = pd.read_pickle(\"Pricing CBC Datasets/Pricing_CBC.pickle\")\n",
    "        for key, value in pbi.items():\n",
    "                pbi = value.iloc[12:].reset_index(drop=True)  # Adjust the dataframe to remove unnecessary rows\n",
    "                pbi.columns = pbi.iloc[0]  # Set the first row as the column headers\n",
    "                pbi = pbi.iloc[1:]  # Remove the row used for headers\n",
    "\n",
    "        pbi.rename(columns={'Product Names WoB %':'WOB%'}, inplace=True)\n",
    "        pbi.rename(columns={'Gross Margin %':'GM%'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data in Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BrandelRun:\n",
    "    sheet_name='Brand elasticity'\n",
    "    brandElasticity_ori=pd.read_excel(file_path,sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns(df):\n",
    "    column_mapping = {\n",
    "        'product': 'Product',\n",
    "        'Product': 'Product',\n",
    "        'SKU': 'Product',\n",
    "        # Add more mappings as necessary\n",
    "    }\n",
    "    \n",
    "    # Apply the column mapping\n",
    "    df.rename(columns=column_mapping, inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BrandSourcingRun:\n",
    "    plusbranding = pd.read_excel(file_path,\"Plus Brand Sourcing\").rename(columns={'Unnamed: 0': 'Product'})\n",
    "    Minusbranding = pd.read_excel(file_path,\"Minus Brand Sourcing\").rename(columns={'Unnamed: 0': 'Product'})\n",
    "    plusbrandingfair = pd.read_excel(file_path,\"Plus Brand Sourcing Fair share\").rename(columns={'Unnamed: 0': 'Product'})\n",
    "    Minusbrandingfair = pd.read_excel(file_path,\"Minus Brand Sourcing Fair share\").rename(columns={'Unnamed: 0': 'Product'})\n",
    "    Minusbrandingfair = Minusbrandingfair[[col for col in Minusbrandingfair.columns if 'Unnamed' not in col]]\n",
    "    plusbranding = normalize_columns(plusbranding)\n",
    "    Minusbranding = normalize_columns(Minusbranding)\n",
    "    plusbrandingfair = normalize_columns(plusbrandingfair)\n",
    "    Minusbrandingfair = normalize_columns(Minusbrandingfair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ProductSourcingRun: \n",
    "    plus = pd.read_excel(file_path,\"Plus Sourcing\")\n",
    "    Minus = pd.read_excel(file_path,\"Minus Sourcing\")\n",
    "    plusfair = pd.read_excel(file_path,\"Plus Sourcing Fair share\")\n",
    "    Minusfair = pd.read_excel(file_path,\"Minus Sourcing Fair share\")\n",
    "    plus = normalize_columns(plus)\n",
    "    Minus = normalize_columns(Minus)\n",
    "    plusfair = normalize_columns(plusfair)\n",
    "    Minusfair = normalize_columns(Minusfair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PERun: \n",
    "    pe = pd.read_excel(file_path,\"PE\")\n",
    "    group_list = pe['Grouping'].unique().tolist()\n",
    "    pe = normalize_columns(pe)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PERun:\n",
    "    from openpyxl import load_workbook\n",
    "    from openpyxl.utils import get_column_letter\n",
    "\n",
    "    # Load the workbook and select the sheet\n",
    "    wb = load_workbook(file_path, data_only=True)\n",
    "    sheet = wb['PE']\n",
    "    pe[\"Share P5 - Base Share\"] = pd.Series([float(0)] * len(pe))\n",
    "    pe[\"PE P5-P6\"] = pd.Series([float(0)] * len(pe))\n",
    "    # Check for yellow cells and adjust shares\n",
    "    for row in range(1, len(pe)+2):\n",
    "        for col in range(1, pe.shape[1]+ 2):\n",
    "            cell = sheet.cell(row=row, column=col)\n",
    "            if cell.fill.fgColor.rgb == 'FFFFFF00':\n",
    "                column_name = sheet.cell(1,col).value \n",
    "                col_num=int(column_name[1])\n",
    "                \n",
    "                for i in range(5,col_num-1,-1):\n",
    "                    if i == col_num:\n",
    "                        pe[f\"Share P{i} - Base Share\"][row-2] =0\n",
    "                        pe[f\"PE P{i}-P{i+1}\"][row-2]=0\n",
    "                    else:\n",
    "                        pe[f\"Share P{i} - Base Share\"][row-2] = pe[f\"Share P{i-1} - Base Share\"][row-2]\n",
    "                        pe[f\"PE P{i}-P{i+1}\"][row-2] =  pe[f\"PE P{i-1}-P{i}\"][row-2]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PERun:\n",
    "    pbi[\"ProductName\"]=pbi[\"ProductName\"].str.upper()\n",
    "    pe[\"Product\"]=pe[\"Product\"].str.upper()\n",
    "    pepbijoin = pe.join(pbi, lsuffix=\"Product\", rsuffix=\"ProductName\")\n",
    "    pepbijoin=pd.merge(pe,pbi[['ProductName','WOB%','GM%']], how='left', left_on='Product', right_on='ProductName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RevenueResponseRun: \n",
    "    from openpyxl import load_workbook\n",
    "\n",
    "    # Load the workbook and select the specific sheet\n",
    "    wb = load_workbook(file_path, data_only=True)\n",
    "    sheet = wb['Revenue Response']\n",
    "\n",
    "    # Create an empty color mask matrix\n",
    "    bgcol = np.empty([sheet.max_row, sheet.max_column], dtype=object, order='C')\n",
    "\n",
    "    # Cycle through all cells to get colors\n",
    "    for row in range(sheet.max_row):\n",
    "        for column in range(sheet.max_column):\n",
    "            cell = sheet.cell(row + 1, column + 1)\n",
    "            \n",
    "            # Check if the cell font color is not red (hex 'FFFF0000'), if it is, set the value to empty\n",
    "            color_in_hex_index = cell.value if cell.font.color.rgb != 'FFFF0000' else ''\n",
    "            \n",
    "            # Assign the value to the bgcol array\n",
    "            bgcol[row, column] = str(color_in_hex_index)\n",
    "\n",
    "    # Convert the bgcol array to a pandas DataFrame\n",
    "    colormask = pd.DataFrame(bgcol)\n",
    "\n",
    "    # Print the shape of the DataFrame\n",
    "    #print(colormask.shape)\n",
    "\n",
    "    # Adjust columns names and content\n",
    "    # Define ranges for slicing the DataFrame\n",
    "    if len([]) == 0:\n",
    "        SheetContentRanges = range(0, colormask.shape[0]), range(0, colormask.shape[1])\n",
    "\n",
    "    # Slice the DataFrame according to defined ranges\n",
    "    colormask = colormask.iloc[SheetContentRanges]\n",
    "\n",
    "    # Reset index and update column names\n",
    "    colormask.reset_index(drop=True, inplace=True)\n",
    "    colormask.columns = colormask.iloc[0]  # Set the first row as the header\n",
    "    colormask = colormask.iloc[1:, :]  # Remove the first row (header) and the first column\n",
    "\n",
    "    # Drop specific columns\n",
    "    colormask = colormask.drop(columns=['Select SKUs\\n(with \"x\")', 'Possible steps (d/u)', 'Base case share'])\n",
    "\n",
    "    # Display the final DataFrame\n",
    "    #print(colormask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_revenue(colormask):\n",
    "    \"\"\"\n",
    "    Clean revenue data from a DataFrame.\n",
    " \n",
    "    Parameters:\n",
    "    - colormask: The DataFrame containing revenue data.\n",
    " \n",
    "    Returns:\n",
    "    - dfList: A list of cleaned DataFrames.\n",
    "    \"\"\"\n",
    "    dfList = []  # Initialize an empty list to store cleaned DataFrames\n",
    "    colormask = colormask.loc[:, ~colormask.columns.duplicated(keep='last')]  # Remove duplicate columns\n",
    "    for i in range(1, colormask.shape[0] + 1):\n",
    "        df = colormask.iloc[i - 1:i]  # Extract a single row DataFrame\n",
    "        df = df.replace(\"\", np.nan)  # Replace empty cells with NaN\n",
    "        df.dropna(axis=1, inplace=True)  # Drop columns with NaN values\n",
    "        dfList.append(df)  # Append cleaned DataFrame to the list\n",
    "    return dfList  # Return the list of cleaned DataFrames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RevenueResponseRun: dfList = cleaning_revenue(colormask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SERun: \n",
    "    sheet_name='SE'\n",
    "    SE=pd.read_excel(file_path,sheet_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SE_clean(data):\n",
    "    new_rows = []\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        # First row: s1 and s2 \n",
    "        new_rows.append({'Product':row['Product'],\n",
    "        'Base Size': row['S1 total'], \n",
    "        'New Size': row['S2 total'],\n",
    "        'Size Change':row['size S2 - Base size'],\n",
    "        'Volume Index': row['Volume Index 2'],\n",
    "        'Value Index': row['Value Index 2'],\n",
    "        'Gross Profit':row['Gross Profit 2'],\n",
    "        'Size Elasticity': row['SE 2'], \n",
    "        'SCD PE':row['SCD PE 2'], \n",
    "        'PCD PE':row['PCD PE 2']})\n",
    "        # Second row: s1 and s3 \n",
    "        new_rows.append({'Product':row['Product'],\n",
    "        'Base Size': row['S1 total'],\n",
    "        'New Size': row['S3 total'], \n",
    "        'Size Change':row['size S3 - Base size'],\n",
    "        'Volume Index': row['Volume Index 3'],\n",
    "        'Value Index': row['Value Index 3'],\n",
    "        'Gross Profit':row['Gross Profit 3'],\n",
    "        'Size Elasticity': row['SE 3'], \n",
    "        'SCD PE':row['SCD PE 3'], \n",
    "        'PCD PE':row['PCD PE 3']})\n",
    "        \n",
    "    # Convert the list of new rows back into a DataFrame\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    new_df = new_df.dropna(thresh=new_df.shape[1] - 7).reset_index(drop=True)\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SERun: SE_cleaned = SE_clean(SE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplication Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [0,1 ,2,3,4,5 ]\n",
    "\n",
    "duplication = [(len(brandElasticity_ori.columns)+3)//6 if BrandelRun else 0,len(plusbranding.keys())-1 if BrandSourcingRun else 0,len(plus.keys())-1 if ProductSourcingRun else 0, len(group_list) if PERun else 0, colormask.shape[0] if RevenueResponseRun else 0, math.ceil(len(SE_cleaned)/20) if SERun else 0]\n",
    "section_names = [\"Brand Elasticity\" if BrandelRun else \"\",\"Brand Sourcing Analysis\" if BrandSourcingRun else 0,\"Product Sourcing Analysis\" if ProductSourcingRun else 0,\"Price Elasticity Curve\" if PERun else 0,\"Revenue Response Analysis\" if RevenueResponseRun else 0,\"Size Elasticity\" if SERun else 0]\n",
    "\n",
    "path = os.getcwd() + '//Pricing CBC base Oct 2024.pptx'\n",
    "new_pre = os.getcwd() + '//slide duplicated.pptx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "slideDuplication(index,duplication,section_names,path,new_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = Presentation(new_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BrandelRun:\n",
    "    for sli in range(duplication[0]):\n",
    "\n",
    "        start=sli*6\n",
    "        end=start+3\n",
    "        brandElasticity= brandElasticity_ori[brandElasticity_ori.columns[start:end]]\n",
    "        brandElasticity=brandElasticity.dropna()\n",
    "        \n",
    "        BrandElasticity(prs,brandElasticity,1,categories[0],position=0+sli) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BrandSourcingRun:BrandSourcingAnalysis(prs,plusbranding,Minusbranding,plusbrandingfair,Minusbrandingfair,duplication[1],position=sum(duplication[:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ProductSourcingRun:ProductSourcingAnalysis(prs,plus,Minus,plusfair,Minusfair,duplication[2],position=sum(duplication[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PERun:PriceElasticityCurve(prs, pepbijoin, group_list, duplication[3],position=sum(duplication[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RevenueResponseRun: revenue_response(prs,dfList, duplication[4],position=sum(duplication[:4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SERun: SE_Slide(prs,SE_cleaned,duplication[5],position=sum(duplication[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = str(date.today())\n",
    "outputPath=os.getcwd() + \"\\\\Pricing CBC \"+marketsub+\" output \"+today+\".pptx\"\n",
    "prs.save(outputPath)\n",
    "app = win32.Dispatch(\"PowerPoint.Application\")\n",
    "#presentation = app.Presentations.Open(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape_number_partial(shapes, text):\n",
    "    \"\"\"\n",
    "    Get the index of a shape with specific text.\n",
    "\n",
    "    Parameters:\n",
    "    - shapes (list): A list of shapes in a slide.\n",
    "    - text (str): The text to search for in the shapes.\n",
    "\n",
    "    Returns:\n",
    "    - int or None: The index of the shape if found, None otherwise.\n",
    "    \"\"\"\n",
    "    for shape_index in range(len(shapes)):\n",
    "        if shapes[shape_index].has_text_frame:  # Check if the shape has a text frame\n",
    "            if text in shapes[shape_index].text:  # Compare the shape's text with the given text\n",
    "                return shape_index  # Return the index of the shape if text matches\n",
    "    return None  # Return None if the shape with the given text is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getChartNum(shapes):\n",
    "    \"\"\"\n",
    "    Extractcharts from a collection of shapes in a PowerPoint slide.\n",
    "\n",
    "    Parameters:\n",
    "    - shapes: A collection of shapes in a PowerPoint slide.\n",
    "\n",
    "    Returns:\n",
    "    - shape_index: shape number in selecton pane\n",
    "    \"\"\"\n",
    "    shape_index = []\n",
    "    for shape_index in range(len(shapes)):\n",
    "        if shapes[shape_index].has_chart:\n",
    "            return shape_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RevenueResponseRun:  \n",
    "    sls = [sl for sl in prs.slides][sum(duplication[:4]):sum(duplication[:5])]\n",
    "    shapes = prs.slides[sum(duplication[:4])].shapes\n",
    "    subtitleNumber = get_shape_number_partial(shapes, \"Revenue Response Curve by Price Point\")\n",
    "    chartNumber = getChartNum(shapes)\n",
    "    print(chartNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RevenueResponseRun:  \n",
    "    prod_names=[i.shapes[subtitleNumber].text.split(\" | \")[1] for i in sls]\n",
    "    prod_names=list(set(prod_names))\n",
    "    len(prod_names)\n",
    "    filter_dps=pd.read_excel(file_path, sheet_name=\"PE\")\n",
    "    filter_dps=filter_dps.melt(id_vars=[\"Product\"],value_vars=[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\"])\n",
    "    filter_dps=filter_dps.groupby(\"Product\")[\"value\"].unique().reset_index()\n",
    "    filter_dps=dict(zip(filter_dps[\"Product\"],filter_dps[\"value\"]))\n",
    "    len(filter_dps.keys())\n",
    "    set(prod_names)==set(filter_dps.keys())\n",
    "    charts=[s.shapes[chartNumber] for s in sls]\n",
    "    [float(i[0].replace(currency,\"\")) for i in charts[0].chart.plots[0].categories.flattened_labels]\n",
    "    dfs=[]\n",
    "    for num,chart in enumerate(charts):\n",
    "        temp=pd.DataFrame()\n",
    "        for i in chart.chart.series:\n",
    "            temp[i.name]=i.values\n",
    "        temp[\"x_axis\"]=[float(j[0].replace(currency,\"\")) for j in chart.chart.plots[0].categories.flattened_labels]\n",
    "        prod_name=sls[num].shapes[subtitleNumber].text.split(\" | \")[1]\n",
    "        temp=temp[(temp[\"x_axis\"].isin(filter_dps[prod_name]))|(temp[\"Volume Ix\"]==100)]\n",
    "        dfs.append(temp)\n",
    "    len(dfs)       \n",
    "\n",
    "    org_dfs=[]\n",
    "    for num,chart in enumerate(charts):\n",
    "        temp=pd.DataFrame()\n",
    "        for i in chart.chart.series:\n",
    "            temp[i.name]=i.values\n",
    "        temp[\"x_axis\"]=[float(j[0].replace(currency,\"\")) for j in chart.chart.plots[0].categories.flattened_labels]\n",
    "        prod_name=sls[num].shapes[subtitleNumber].text.split(\" | \")[1]\n",
    "        org_dfs.append(temp)\n",
    "    len(org_dfs)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RevenueResponseRun:  \n",
    "  final_res=[]\n",
    "  dfs=org_dfs\n",
    "  for num_index,df in enumerate(dfs) :\n",
    "    df[\"ZeroPoint\"]=np.where((df[\"Volume Ix\"]==100),-1,np.nan)\n",
    "    df[\"ZeroPoint\"]=df[\"ZeroPoint\"].bfill()\n",
    "    df[\"ZeroPoint\"]=df[\"ZeroPoint\"].fillna(1)\n",
    "  \n",
    "\n",
    "    df[\"Value Ix delta\"]=df[\"Value Ix\"].diff() \n",
    "    df[\"Gross Profit Ix delta\"]=df[\"Gross Profit Ix\"].diff()\n",
    "\n",
    "    df[\"Value Ix delta\"]=df[\"Value Ix delta\"]*df[\"ZeroPoint\"]\n",
    "    df[\"Gross Profit Ix delta\"]=df[\"Gross Profit Ix delta\"]*df[\"ZeroPoint\"]\n",
    "\n",
    "\n",
    "\n",
    "    df[\"color\"]=np.select([(df[\"Value Ix delta\"]>0)&(df[\"Gross Profit Ix delta\"]>0)&(df[\"Value Ix\"]>100),\n",
    "                          (df[\"Value Ix delta\"]>0)&(df[\"Gross Profit Ix delta\"]<0)&(df[\"Value Ix\"]>100),\n",
    "                          (df[\"Value Ix delta\"]>0)&(df[\"Gross Profit Ix delta\"]==0)&(df[\"Value Ix\"]>100),\n",
    "                          (df[\"Value Ix delta\"]<0)&(df[\"Gross Profit Ix delta\"]>0)&(df[\"Value Ix\"]>100),\n",
    "                          (df[\"Value Ix delta\"]<0)&(df[\"Gross Profit Ix delta\"]<0)&(df[\"Value Ix\"]>100),\n",
    "                          (df[\"Value Ix delta\"]<0)&(df[\"Gross Profit Ix delta\"]==0)&(df[\"Value Ix\"]>100),\n",
    "                          (df[\"Value Ix delta\"]==0)&(df[\"Gross Profit Ix delta\"]>0)&(df[\"Value Ix\"]>100),\n",
    "                          (df[\"Value Ix delta\"]==0)&(df[\"Gross Profit Ix delta\"]<0)&(df[\"Value Ix\"]>100),\n",
    "                          (df[\"Value Ix delta\"]==0)&(df[\"Gross Profit Ix delta\"]==0)&(df[\"Value Ix\"]>100),\n",
    "                          (df[\"Value Ix delta\"]>0)&(df[\"Gross Profit Ix delta\"]>0)&(df[\"Value Ix\"]<=100),\n",
    "                          (df[\"Value Ix delta\"]>0)&(df[\"Gross Profit Ix delta\"]<0)&(df[\"Value Ix\"]<=100),\n",
    "                          (df[\"Value Ix delta\"]>0)&(df[\"Gross Profit Ix delta\"]==0)&(df[\"Value Ix\"]<=100),\n",
    "                          (df[\"Value Ix delta\"]<0)&(df[\"Gross Profit Ix delta\"]>0)&(df[\"Value Ix\"]<=100),\n",
    "                          (df[\"Value Ix delta\"]<0)&(df[\"Gross Profit Ix delta\"]<0)&(df[\"Value Ix\"]<=100),\n",
    "                          (df[\"Value Ix delta\"]<0)&(df[\"Gross Profit Ix delta\"]==0)&(df[\"Value Ix\"]<=100),\n",
    "                          (df[\"Value Ix delta\"]==0)&(df[\"Gross Profit Ix delta\"]>0)&(df[\"Value Ix\"]<=100),\n",
    "                          (df[\"Value Ix delta\"]==0)&(df[\"Gross Profit Ix delta\"]<0)&(df[\"Value Ix\"]<=100),\n",
    "                          (df[\"Value Ix delta\"]==0)&(df[\"Gross Profit Ix delta\"]==0)&(df[\"Value Ix\"]<=100)],\n",
    "                          [\n",
    "  \"Green|Profit & Revenue Increase\",\n",
    "  \"Yellow|Revenue Increase & Profit Dilution\",\n",
    "  \"Yellow|Revenue Increase & Flat Profit\",\n",
    "  \"Yellow|Revenue Dilution & Profit Increase\",\n",
    "  \"Red|Revenue & Profit Dilution\",\n",
    "  \"Red|Revenue Dilution & Flat Profit\",\n",
    "  \"Yellow|Flat Revenue & Profit Increase\",\n",
    "  \"Red|Flat Revenue & Profit Dilution\",\n",
    "  \"Yellow|Flat Revenue & Profit\",\n",
    "  \"Yellow|Profit & Revenue Increase\",\n",
    "  \"Yellow|Revenue Increase & Profit Dilution\",\n",
    "  \"Yellow|Revenue Increase & Flat Profit\",\n",
    "  \"Yellow|Revenue Dilution & Profit Increase\",\n",
    "  \"Red|Revenue & Profit Dilution\",\n",
    "  \"Red|Revenue Dilution & Flat Profit\",\n",
    "  \"Yellow|Flat Revenue & Profit Increase\",\n",
    "  \"Red|Flat Revenue & Profit Dilution\",\n",
    "  \"Yellow|Flat Revenue & Profit\",\n",
    "  ],\"\")\n",
    "    \n",
    "\n",
    "    df=org_dfs[num_index].merge(df,how=\"left\")\n",
    "\n",
    "    df=df.reset_index(drop=True)\n",
    "    df=df.iloc[1:,:]\n",
    "    df[\"color\"]=df[\"color\"].bfill()\n",
    "    df[\"grouping_same_color\"]=DetermineShapeNumber(df[\"color\"].apply(lambda x : x.split(\"|\")[0]).to_list())\n",
    "    groups=df.groupby(\"grouping_same_color\")[\"color\"].apply(lambda x : pd.Series(x).mode()[0]).reset_index()\n",
    "    df=df.drop(columns=[\"color\"]).merge(groups)\n",
    "    \n",
    "    df[\"shape_number\"]=DetermineShapeNumber(df[\"color\"].to_list())\n",
    "    df[\"color_num\"]=df[\"color\"]+\"_\"+df[\"shape_number\"].astype(str)\n",
    "    dist=df[\"color_num\"].to_list()\n",
    "    full_lenght=len(dist)\n",
    "    dist_list=[[0,0,dist[0] ]]\n",
    "    current=dist[0]\n",
    "    for i in range(len(dist)):\n",
    "      if current == dist[i]:\n",
    "        dist_list[-1][1]+=1\n",
    "      else :\n",
    "        dist_list.append([i,i+1,dist[i]])\n",
    "        current=dist[i]\n",
    "    res=[(int(round(i[0]/len(dist),2)*100),int(round(i[1]/len(dist),2)*100),i[2].split(\"_\")[0]) for i in dist_list ]  \n",
    "    final_res.append(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RevenueResponseRun:  \n",
    "    full_width=Cm(15.7)\n",
    "    left_start=Cm(2.7)\n",
    "    for num,slide in enumerate(sls):\n",
    "        for sh in final_res[num]:\n",
    "            added_shape=AddRectangle(slide,left_start + (sh[0]/100) * full_width, ((sh[1]-sh[0])/100) * full_width,sh[2] )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RevenueResponseRun:  prs.save(outputPath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
