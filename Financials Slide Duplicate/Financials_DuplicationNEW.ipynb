{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"..\\general_functions\\generalFunctions.ipynb\"\n",
    "%run \"..\\Financials Slide Duplicate\\Financials Replacement Function.ipynb\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries & reading pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "themePath = os.getcwd()+\"\\Theme1.thmx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_manuf = [\"Bel\"]\n",
    "client_brands = [\"Kiri\",\"La Vache Qui Rit\",\"Boursin\"]\n",
    "decimals = 2\n",
    "sign = \"After\"\n",
    "currency = 'â‚¬'\n",
    "currency = ' '+ currency if sign.lower() == 'after' else  currency + ' '\n",
    "prodORitem = \"Item\"\n",
    "categories = [\"Total Fromage\"]\n",
    "sectors = [\"Soft Cheese\",\"Aperitif\"]\n",
    "segments = [\"Enfant\",\"Frais A Tartiner\",\"Salade\"]\n",
    "subsegments= []\n",
    "subcategories= []\n",
    "\n",
    "national = False\n",
    "customareas= \"\"\n",
    "areas = [\"RETAILER\"]\n",
    "\n",
    "regions_RET  = [\"Carrefour\",\"Intermarche\"]\n",
    "channels_RET = []\n",
    "market_RET = []\n",
    "\n",
    "regions_CHAN = []\n",
    "channels_CHAN = []\n",
    "market_CHAN = []\n",
    " \n",
    "regions_REG = []\n",
    "channels_REG = []\n",
    "market_REG = []\n",
    " \n",
    "regions_CUST = []\n",
    "channels_CUST = []\n",
    "market_CUST = []\n",
    "\n",
    "\n",
    "\n",
    "data_source = \"DATA SOURCE: Client P&L\"\n",
    "\n",
    "end_date = \"2025-08-01\"\n",
    "\n",
    "OpenEditData=True\n",
    "ManufOrTopC =\"Top Companies\"\n",
    "BrandOrTopB=\"Top Brands\"\n",
    "\n",
    "percent = 1000000\n",
    "percentstr=\"'000 000\"\n",
    "### OpenEditData is a parameter (run open excel cell or not )\n",
    "OpenEditData=True\n",
    "slides_Period=\"P3M\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "national = ['National'] if \"NATIONAL\" in areas else []\n",
    "retailers = regions_RET + channels_RET + market_RET\n",
    "channels = regions_CHAN + channels_CHAN + market_CHAN\n",
    "regions = regions_REG + channels_REG + market_REG\n",
    "cust = regions_CUST + channels_CUST + market_CUST\n",
    "area=national+retailers+channels+regions+cust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleaa\\Documents\\Slide-Automate\\Financials Slide Duplicate\\Financials Datasets NewEX\\\n"
     ]
    }
   ],
   "source": [
    "loaded_data = {}\n",
    "\n",
    "datasets_path = os.getcwd()+\"\\\\\"\"Financials Datasets NewEX\"\"\\\\\"\n",
    "print(datasets_path)\n",
    "\n",
    "datasets = os.listdir(datasets_path)\n",
    "for dataset in datasets:\n",
    "    file_path = os.path.join(datasets_path, dataset)\n",
    "    with open(file_path, 'rb') as handle:\n",
    "        globals()[dataset.split('.')[0]] = pd.read_pickle(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacement functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide1: Mix Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_brand_P12M_dfs={}\n",
    "for k in brands_client_dfs.keys():\n",
    "    t=brands_client_dfs[k].copy()\n",
    "    t=t[:-1]\n",
    "    t['Value Sales IYA'] = t['Value Sales IYA'].astype(float).fillna(-199)\n",
    "    t=t.fillna(0)\n",
    "    t = t[t['Net Sales'].astype(float) >= 1000]\n",
    "    total= t[(t['Top Brands'].str.contains( ' Total')) & ~(t['Top Brands'].isin(['Grand Total','All Others Total'])) & ~(t['Top Brands'].isin([i+' Total' for i in client_brands]))]\n",
    "    if not t.empty and len(t['Top Brands']) != 1:\n",
    "        modified_brand_P12M_dfs[k]=t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Market "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_RET_CHAN_POS(dataframes,regions, channels, markets):\n",
    "    modified_regions = {}\n",
    "    modified_channels = {}\n",
    "    modified_markets = {}\n",
    "    dya = {}\n",
    "\n",
    "    for k in dataframes.keys():\n",
    "        t = dataframes[k].copy()\n",
    "        t = t[t[\"Net Sales\"].astype(float)>=1000]\n",
    "        t['Value Sales IYA'] =t['Value Sales IYA'].astype(float).fillna(-199) \n",
    "\n",
    "        level_check = set([\"Region\", \"Channel\", \"Market\"])\n",
    "        existant_cols = list(set(t.columns)&level_check)\n",
    "\n",
    "        decider_dic = {\"Region\": regions, \"Channel\":channels, \"Market\":markets}\n",
    "        grand_tot = t[t[t.columns[0]] == 'Grand Total'] \n",
    "        dya[k] = grand_tot\n",
    "\n",
    "        if len(existant_cols) == 1:\n",
    "            df = t[t[t.columns[0]].isin(decider_dic[existant_cols[0]])]\n",
    "            if not df.empty:\n",
    "                if df.columns[0] == \"Region\":\n",
    "                    modified_regions[k] = df\n",
    "                if df.columns[0] == \"Channel\":\n",
    "                    modified_channels[k] = df\n",
    "                if df.columns[0] == \"Market\":\n",
    "                    modified_markets[k] = df\n",
    "\n",
    "        elif len(existant_cols) == 2:\n",
    "            levels_rank = {\"Region\":1, \"Channel\":2, \"Market\":3}\n",
    "            existant_cols = sorted(existant_cols, key=lambda x: levels_rank[x])\n",
    "            t_child = t[t[existant_cols[1]].isin(decider_dic[existant_cols[1]])].drop(columns = [existant_cols[0]])\n",
    "            t_parent = t[t[existant_cols[0]].isin([i + \" Total\" for i in decider_dic[existant_cols[0]]])].drop(columns = [existant_cols[1]])\n",
    "            t_parent[existant_cols[0]] = t_parent[existant_cols[0]].str.replace(\" Total\", \"\").str.strip()\n",
    "            for df in [t_child, t_parent]:\n",
    "                if not df.empty:\n",
    "                    if df.columns[0] == \"Region\":\n",
    "                        modified_regions[k] = df\n",
    "                    if df.columns[0] == \"Channel\":\n",
    "                        modified_channels[k] = df\n",
    "                    if df.columns[0] == \"Market\":\n",
    "                        modified_markets[k] = df\n",
    "                        \n",
    "            print(k,df)\n",
    "            \n",
    "\n",
    "        else:\n",
    "            levels_rank = {\"Region\":1, \"Channel\":2, \"Market\":3}\n",
    "            existant_cols = sorted(existant_cols, key=lambda x: levels_rank[x])\n",
    "            t_market = t[t[existant_cols[2]].isin(decider_dic[existant_cols[2]])].drop(columns = [existant_cols[0],existant_cols[1]])\n",
    "            t_channel = t[t[existant_cols[1]].isin([i + \" Total\" for i in decider_dic[existant_cols[1]]])].drop(columns = [existant_cols[0],existant_cols[2]])\n",
    "            t_channel[existant_cols[1]] = t_channel[existant_cols[1]].str.replace(\" Total\", \"\").str.strip()\n",
    "            t_region = t[t[existant_cols[0]].isin([i + \" Total\" for i in decider_dic[existant_cols[0]]])].drop(columns = [existant_cols[1],existant_cols[2]])\n",
    "            t_region[existant_cols[0]] = t_region[existant_cols[0]].str.replace(\" Total\", \"\").str.strip()\n",
    "            if not t_region.empty:\n",
    "                modified_regions[k] = t_region\n",
    "            if not t_channel.empty:\n",
    "                modified_channels[k] = t_channel\n",
    "            if not t_market.empty:\n",
    "                modified_markets[k] = t_market\n",
    "            \n",
    "    return modified_regions, modified_channels, modified_markets, dya\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_retailer_regions = {}\n",
    "modified_retailer_channels = {}\n",
    "modified_retailer_markets = {}\n",
    "\n",
    "modified_channels_regions = {}\n",
    "modified_channels_channels = {}\n",
    "modified_channels_markets = {}\n",
    "\n",
    "modified_region_regions = {}\n",
    "modified_region_channels = {}\n",
    "modified_region_markets = {}\n",
    "\n",
    "modified_cust_regions = {}\n",
    "modified_cust_channels = {}\n",
    "modified_cust_markets = {}\n",
    "\n",
    "dya_retailer={}\n",
    "dya_channel={}\n",
    "dya_region={}\n",
    "dya_cust = {}\n",
    "\n",
    "#**********Retailer*********\n",
    "if len(retailers)!=0:\n",
    "    modified_retailer_regions, modified_retailer_channels, modified_retailer_markets, dya_retailer = process_RET_CHAN_POS(retailers_P12M_dfs, regions_RET, channels_RET, market_RET)\n",
    "# *********Channels**********\n",
    "if len(channels)!=0:\n",
    "    modified_channels_regions, modified_channels_channels, modified_channels_markets, dya_channel = process_RET_CHAN_POS(channel_P12M_dfs, regions_CHAN, channels_CHAN, market_CHAN)\n",
    "# *********Regions**********\n",
    "if len(regions)!=0:\n",
    "    modified_region_regions, modified_region_channels, modified_region_markets, dya_region = process_RET_CHAN_POS(region_P12M_dfs, regions_REG, channels_REG, market_REG)\n",
    "#********POS****************\n",
    "if len(cust)!=0: \n",
    "    modified_cust_regions, modified_cust_channels, modified_cust_markets, dya_cust = process_RET_CHAN_POS(cust_P12M_dfs, regions_CUST, channels_CUST, market_CUST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Sector/Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MixAnalysisCleaning(inputdic):\n",
    "    modifieddic={}\n",
    "    for k in inputdic.keys():\n",
    "        t=inputdic[k].copy()\n",
    "        t=t[:-1]\n",
    "        t['Value Sales IYA'] =t['Value Sales IYA'].astype(float).fillna(-199)\n",
    "        t=t.fillna(0)\n",
    "        t=t[t[\"Net Sales\"]>=1000]\n",
    "        if not t.empty:\n",
    "            modifieddic[k]=t\n",
    "    return modifieddic   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)!=0:\n",
    "    modified_sectors_P12M_mix_analysis_dfs=MixAnalysisCleaning(Sector_P12M_client_dfs)\n",
    "if len(segments)!=0:\n",
    "    modified_segment_P12M_mix_analysis_dfs=MixAnalysisCleaning(Segment_P12M_client_dfs)\n",
    "if len(subsegments)!=0:\n",
    "    modified_subsegment_P12M_mix_analysis_dfs=MixAnalysisCleaning(SubSegment_P12M_client_dfs)\n",
    "if len(subcategories)!=0:\n",
    "    modified_subcategory_P12M_mix_analysis_dfs=MixAnalysisCleaning(SubCategory_P12M_client_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide2: Trade Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TradeMarginCleaning(inputdic,scope=\"\"):\n",
    "    modifieddic={}\n",
    "    for k in inputdic.keys():\n",
    "        t = inputdic[k].copy()\n",
    "        t[scope] = t[scope].replace('Grand Total', 'Total')\n",
    "        t=t.replace(np.nan,0)\n",
    "        if not t.empty:\n",
    "            modifieddic[k]=t\n",
    "    return modifieddic   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)!=0:\n",
    "    modified_sector_Trade_Margin_dfs=TradeMarginCleaning(Sector_P12M_client_dfs,scope=\"Sector\")\n",
    "if len(segments)!=0:\n",
    "    modified_segment_Trade_Margin_dfs=TradeMarginCleaning(Segment_P12M_client_dfs,scope=\"Segment\")\n",
    "\n",
    "if len(subsegments)!=0:\n",
    "    modified_subsegment_Trade_Margin_dfs=TradeMarginCleaning(SubSegment_P12M_client_dfs,scope=\"SubSegment\")\n",
    "\n",
    "if len(subcategories)!=0:\n",
    "    modified_subcategory_Trade_Margin_dfs=TradeMarginCleaning(SubCategory_P12M_client_dfs,scope=\"SubCategory\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sector KPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(data, Scope =\"Sector\"):\n",
    "    final ={}\n",
    "    for key, df in data.items():\n",
    "        df.fillna(0,inplace = True)\n",
    "        df = df.reset_index(drop=True)\n",
    "        df =df[df['Net Sales'] > 1000]\n",
    "\n",
    "        df = df[~df[Scope].str.contains('Grand Total', case=False)]\n",
    "        if df.shape[0] !=0:\n",
    "            if 'National' in key:\n",
    "                new_key = key.split(' | ')[0] + ' | ' + key.split(' | ')[2] +' | ' + key.split(' | ')[1]\n",
    "            else:\n",
    "                new_key = key\n",
    "            final[new_key] = df\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(data1,data2, Scope = \"Sector\"):\n",
    "    final = {}\n",
    "    for key in modified_sector_P12M.keys():\n",
    "        if key in modified_sector_P3M.keys():\n",
    "            final[key] = pd.merge(data1[key], data2[key], on = Scope, suffixes= (\"_P12M\", \"_P3M\"))\n",
    "            df = final[key]\n",
    "            df = df[~df[Scope].str.contains('Total', case=False)]\n",
    "            df =df[df['Net Sales_P3M'] > 1000]\n",
    "            \n",
    "            df = df.sort_values('Rate of Sales_P3M', ascending=False).reset_index(drop =True)\n",
    "            \n",
    "            \n",
    "            if df.shape[0]>0:\n",
    "                final[key] = df\n",
    "            \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_sector_P12M = {}\n",
    "modified_sector_P3M ={}\n",
    "merged_data_sector ={}\n",
    "if len(sectors)!=0:\n",
    "    modified_sector_P12M  = clean(Sector_P12M_client_dfs, \"Sector\")\n",
    "    modified_sector_P3M  = clean(Sector_P3M_client_dfs, \"Sector\")\n",
    "    merged_data_sector = merge_data(modified_sector_P12M,modified_sector_P3M, \"Sector\")\n",
    "\n",
    "\n",
    "modified_segment_P12M ={}\n",
    "modified_segment_P3M ={}\n",
    "merged_data_segment ={}\n",
    "if len(segments)!=0:\n",
    "    modified_segment_P12M  = clean(Segment_P12M_client_dfs, \"Segment\")\n",
    "    modified_segment_P3M  = clean(Segment_P3M_client_dfs, \"Segment\")\n",
    "    merged_data_segment = merge_data(modified_segment_P12M,modified_segment_P3M, \"Segment\")\n",
    "\n",
    "modified_subsegment_P12M ={}\n",
    "modified_subsegment_P3M ={}\n",
    "merged_data_subsegment ={}\n",
    "if len(subsegments)!=0:\n",
    "    modified_subsegment_P12M  = clean(SubSegment_P12M_client_dfs, \"SubSegment\")\n",
    "    modified_subsegment_P3M  = clean(SubSegment_P3M_client_dfs, \"SubSegment\")\n",
    "    merged_data_subsegment = merge_data(modified_subsegment_P12M,modified_subsegment_P3M, \"SubSegment\")\n",
    "\n",
    "modified_subcategory_P12M = {}\n",
    "modified_subcategory_P3M ={}\n",
    "merged_data_subcategory ={}\n",
    "if len(subcategories)!=0:\n",
    "    modified_subcategory_P12M  = clean(SubCategory_P12M_client_dfs, \"SubCategory\")\n",
    "    modified_subcategory_P3M  = clean(SubCategory_P3M_client_dfs, \"SubCategory\")\n",
    "    merged_data_subcategory = merge_data(modified_subcategory_P12M,modified_subcategory_P3M, \"SubCategory\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide 4: SKU KPIs Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By_Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_product_P12M_dfs={}\n",
    "modified_product_P3M_dfs={}\n",
    "modified_product_dfs = {}\n",
    "\n",
    "#P3M\n",
    "for k in product_P3M_dfs.keys():\n",
    "    t=product_P3M_dfs[k].copy()\n",
    "    t=t[:-1]\n",
    "    t['Top Brands']=t['Top Brands'].ffill()\n",
    "    t = t[~t[\"Top Brands\"].str.contains(' Total')]\n",
    "    df = t[t['Top Brands'].isin(client_brands)]\n",
    "    df = df.fillna(0)\n",
    "    df = df[df['Net Sales'] > 1000]\n",
    "    if not df.empty:\n",
    "        modified_product_P3M_dfs[k] = df\n",
    "\n",
    "#P12M\n",
    "for k in product_P12M_dfs.keys():\n",
    "    t=product_P12M_dfs[k].copy()\n",
    "    t=t[:-1]\n",
    "    t['Top Brands']=t['Top Brands'].ffill()\n",
    "    t = t[~t[\"Top Brands\"].str.contains(' Total')]\n",
    "    df = t[t['Top Brands'].isin(client_brands)]\n",
    "    df = df.fillna(0)\n",
    "    df['Net Sales'] = df['Net Sales'].astype(float)\n",
    "    df = df[df['Net Sales'] > 1000]\n",
    "    if not df.empty:\n",
    "        modified_product_P12M_dfs[k] = df\n",
    "\n",
    "\n",
    "missing_keys = [k for k in modified_product_P12M_dfs.keys() if k not in modified_product_P3M_dfs]\n",
    "for k in missing_keys:\n",
    "    modified_product_P3M_dfs[k] = pd.DataFrame(columns=modified_product_P12M_dfs[k].columns)\n",
    "\n",
    "for k in modified_product_P12M_dfs.keys():\n",
    "    p12m_df = modified_product_P12M_dfs[k].copy()\n",
    "    p12m_df = p12m_df.nlargest(15, 'Net Sales')\n",
    "    p3m_df = modified_product_P3M_dfs[k].copy()\n",
    "    comb = pd.merge(p12m_df,p3m_df, how = 'left',on = [\"Top Brands\",f'{prodORitem}'], suffixes = (\"_P12M\", \"_P3M\"))\n",
    "    comb = comb.sort_values(by=f'{prodORitem} Sales Rate_P3M', ascending=False)\n",
    "    # Compute Sales Rate Ix\n",
    "    first_value = comb[f'{prodORitem} Sales Rate_P3M'].iloc[0]\n",
    "    comb['Sales Rate Ix'] = (comb[f'{prodORitem} Sales Rate_P3M'] / first_value)\n",
    "    modified_product_dfs[k] = comb.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By_Brand \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_brand_product_P3M_dfs={}\n",
    "modified_brand_product_P12M_dfs={}\n",
    "modified_brand_product_dfs={}\n",
    "\n",
    "###P3M\n",
    "for k in modified_product_P3M_dfs.keys():\n",
    "        t = modified_product_P3M_dfs[k].copy()\n",
    "        for brand in client_brands:\n",
    "            df = t[t['Top Brands'] == brand]\n",
    "            new_key = f\"{brand} | {k}\"\n",
    "            parts = [part.strip() for part in new_key.split('|') if f'{client_manuf[0]}' not in part]\n",
    "            new_key = ' | '.join(parts)\n",
    "            if not df.empty :\n",
    "                modified_brand_product_P3M_dfs[new_key] = df  \n",
    "\n",
    "\n",
    "###P12M    \n",
    "for k in modified_product_P12M_dfs.keys():\n",
    "        t = modified_product_P12M_dfs[k].copy()\n",
    "        for brand in client_brands:\n",
    "            df = t[t['Top Brands'] == brand]\n",
    "            new_key = f\"{brand} | {k}\"\n",
    "            parts = [part.strip() for part in new_key.split('|') if f'{client_manuf[0]}' not in part]\n",
    "            new_key = ' | '.join(parts)\n",
    "            if not df.empty :\n",
    "                modified_brand_product_P12M_dfs[new_key] = df    \n",
    "\n",
    "\n",
    "missing_keys = [k for k in modified_brand_product_P12M_dfs.keys() if k not in modified_brand_product_P3M_dfs]\n",
    "for k in missing_keys:\n",
    "    modified_brand_product_P3M_dfs[k] = pd.DataFrame(columns=modified_brand_product_P12M_dfs[k].columns)\n",
    "\n",
    "for k in modified_brand_product_P12M_dfs.keys():\n",
    "    p12m_df = modified_brand_product_P12M_dfs[k].copy()\n",
    "    p12m_df = p12m_df.nlargest(15, 'Net Sales')\n",
    "    p3m_df = modified_brand_product_P3M_dfs[k].copy()\n",
    "    comb = pd.merge(p12m_df,p3m_df, how = 'left',on = [\"Top Brands\",f'{prodORitem}'], suffixes = (\"_P12M\", \"_P3M\"))\n",
    "    \n",
    "    comb = comb.sort_values(by=f'{prodORitem} Sales Rate_P3M', ascending=False)\n",
    "    # Compute Sales Rate Ix\n",
    "    first_value = comb[f'{prodORitem} Sales Rate_P3M'].iloc[0]\n",
    "    comb['Sales Rate Ix'] = (comb[f'{prodORitem} Sales Rate_P3M'] / first_value)\n",
    "    modified_brand_product_dfs[k] = comb.fillna(0)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide 5_Mix Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixMatrixClean(data):\n",
    "    final ={}\n",
    "    for key, val in data.items():\n",
    "        df=val.copy()\n",
    "        if df.shape[0] !=0:\n",
    "            if 'National' in key:\n",
    "                new_key = ' | '.join([key.split(' | ')[0],key.split(' | ')[2],key.split(' | ')[1]])\n",
    "            else:\n",
    "                new_key = key\n",
    "\n",
    "            df.fillna(0,inplace = True)\n",
    "            df['Source'] = new_key.split(' | ')[2]\n",
    "\n",
    "            final[new_key] = df.sort_values(by='Value Sales',ascending=False)\n",
    "    #         final[new_key] = df.sort_values(by='Value Sales',ascending=False)\n",
    "    sortOrder=final[new_key][final[new_key].columns[0]].unique()\n",
    "\n",
    "    # print(sortOrder,final[new_key].columns[0])\n",
    "    for key,val in final.items():\n",
    "        val['order']=val[val.columns[0]].replace(dict(zip(sortOrder,range(len(sortOrder)))))\n",
    "        final[key]=val\n",
    "\n",
    "\n",
    "\n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)!=0:\n",
    "    sector_P12M_modified = mixMatrixClean(Sector_P12M_client_dfs)\n",
    "if len(segments)!=0:\n",
    "    segment_P12M_modified = mixMatrixClean(Segment_P12M_client_dfs)\n",
    "if len(subcategories)!=0:\n",
    "    subCat_P12M_modified = mixMatrixClean(SubCategory_P12M_client_dfs)\n",
    "if len(subsegments)!=0:\n",
    "    subSeg_P12M_modified = mixMatrixClean(SubSegment_P12M_client_dfs)\n",
    "    \n",
    "    \n",
    "secRetailerDf,segRetailerDf,subCatRetailerDf,subSegRetailerDf,brandsRetailerDf={},{},{},{},{}\n",
    "secChannelDf,segChannelDf,subCatChannelDf,subSegChannelDf,brandsChannelDf={},{},{},{},{}\n",
    "secRegionDf,segRegionDf,subCatRegionDf,subSegRegionDf,brandsRegionDf={},{},{},{},{}\n",
    "secCustDf,segCustDf,subCatCustDf,subSegCustDf,brandsCustDf={},{},{},{},{}\n",
    "\n",
    "for key,retailerList in {'region':['National'] if national else []+regions_RET,'channel':['National'] if national else []+channels_RET,'market':['National'] if national else []+market_RET}.items():\n",
    "    if len(sectors)!=0:secRetailerDf[key] = {key: sector_P12M_modified[key] for key in sector_P12M_modified.keys()  if (key.split(' | ')[2] in retailerList)}\n",
    "    if len(segments)!=0:segRetailerDf[key] = {key: segment_P12M_modified[key] for key in segment_P12M_modified.keys()  if (key.split(' | ')[2] in retailerList)}\n",
    "    if len(subcategories)!=0:subCatRetailerDf[key] = {key: subCat_P12M_modified[key] for key in subCat_P12M_modified.keys()  if (key.split(' | ')[2] in retailerList)}\n",
    "    if len(subsegments)!=0:subSegRetailerDf[key] = {key: subSeg_P12M_modified[key] for key in subSeg_P12M_modified.keys()  if (key.split(' | ')[2] in retailerList)}\n",
    "\n",
    "for key,channelList in {'region':['National'] if national else []+regions_CHAN,'channel':['National'] if national else []+channels_CHAN,'market':['National'] if national else []+market_CHAN}.items():\n",
    "    if len(sectors)!=0:secChannelDf[key] = {key: sector_P12M_modified[key] for key in sector_P12M_modified.keys()  if (key.split(' | ')[2] in channelList)}\n",
    "    if len(segments)!=0:segChannelDf[key] = {key: segment_P12M_modified[key] for key in segment_P12M_modified.keys()  if (key.split(' | ')[2] in channelList)}\n",
    "    if len(subcategories)!=0:subCatChannelDf[key] = {key: subCat_P12M_modified[key] for key in subCat_P12M_modified.keys()  if (key.split(' | ')[2] in channelList)}\n",
    "    if len(subsegments)!=0:subSegChannelDf[key] = {key: subSeg_P12M_modified[key] for key in subSeg_P12M_modified.keys()  if (key.split(' | ')[2] in channelList)}\n",
    "\n",
    "for key,regionList in {'region':['National'] if national else []+regions_REG,'channel':['National'] if national else []+channels_REG,'market':['National'] if national else []+market_REG}.items():\n",
    "    if len(sectors)!=0:secRegionDf[key] = {key: sector_P12M_modified[key] for key in sector_P12M_modified.keys()  if (key.split(' | ')[2] in regionList)}\n",
    "    if len(segments)!=0:segRegionDf[key] = {key: segment_P12M_modified[key] for key in segment_P12M_modified.keys()  if (key.split(' | ')[2] in regionList)}\n",
    "    if len(subcategories)!=0:subCatRegionDf[key] = {key: subCat_P12M_modified[key] for key in subCat_P12M_modified.keys()  if (key.split(' | ')[2] in regionList)}\n",
    "    if len(subsegments)!=0:subSegRegionDf[key] = {key: subSeg_P12M_modified[key] for key in subSeg_P12M_modified.keys()  if (key.split(' | ')[2] in regionList)}\n",
    "\n",
    "for key,custList in {'region':['National'] if national else []+regions_CUST,'channel':['National'] if national else []+channels_CUST,'market':['National'] if national else []+market_CUST}.items():\n",
    "    if len(sectors)!=0:secCustDf[key] = {key: sector_P12M_modified[key] for key in sector_P12M_modified.keys()  if (key.split(' | ')[2] in custList)}\n",
    "    if len(segments)!=0:segCustDf[key] = {key: segment_P12M_modified[key] for key in segment_P12M_modified.keys()  if (key.split(' | ')[2] in custList)}\n",
    "    if len(subcategories)!=0:subCatCustDf[key] = {key: subCat_P12M_modified[key] for key in subCat_P12M_modified.keys()  if (key.split(' | ')[2] in custList)}\n",
    "    if len(subsegments)!=0:subSegCustDf[key] = {key: subSeg_P12M_modified[key] for key in subSeg_P12M_modified.keys()  if (key.split(' | ')[2] in custList)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "secRetailerClient,segRetailerClient,subCatRetailerClient,subSegRetailerClient={},{},{},{}\n",
    "secChannelClient,segChannelClient,subCatChannelClient,subSegChannelClient={},{},{},{}\n",
    "secRegionClient,segRegionClient,subCatRegionClient,subSegRegionClient={},{},{},{}\n",
    "secCustClient,segCustClient,subCatCustClient,subSegCustClient={},{},{},{}\n",
    "\n",
    "\n",
    "def clientAgg(dic):\n",
    "\n",
    "    clients={}\n",
    "    for marketLevel in ['region','channel','market']:\n",
    "        for manuf in client_manuf:\n",
    "            keys = [dic[marketLevel][key] for key in dic[marketLevel].keys() if manuf in key.split(' | ')]\n",
    "            if keys:\n",
    "                clients[manuf+' | '+marketLevel]=pd.concat(keys).reset_index(drop = True)\n",
    "    return clients\n",
    "\n",
    "if len(sectors)!=0:secRetailerClient = clientAgg(secRetailerDf)\n",
    "if len(segments)!=0:segRetailerClient = clientAgg(segRetailerDf)\n",
    "if len(subcategories)!=0:subCatRetailerClient = clientAgg(subCatRetailerDf)\n",
    "if len(subsegments)!=0:subSegRetailerClient = clientAgg(subSegRetailerDf)\n",
    "\n",
    "if len(sectors)!=0:secChannelClient = clientAgg(secChannelDf)\n",
    "if len(segments)!=0:segChannelClient = clientAgg(segChannelDf)\n",
    "if len(subcategories)!=0:subCatChannelClient = clientAgg(subCatChannelDf)\n",
    "if len(subsegments)!=0:subSegChannelClient = clientAgg(subSegChannelDf)\n",
    "\n",
    "if len(sectors)!=0:secRegionClient = clientAgg(secRegionDf)\n",
    "if len(segments)!=0:segRegionClient = clientAgg(segRegionDf)\n",
    "if len(subcategories)!=0:subCatRegionClient = clientAgg(subCatRegionDf)\n",
    "if len(subsegments)!=0:subSegRegionClient = clientAgg(subSegRegionDf)\n",
    "\n",
    "if len(sectors)!=0:secCustClient = clientAgg(secCustDf)\n",
    "if len(segments)!=0:segCustClient = clientAgg(segCustDf)\n",
    "if len(subcategories)!=0:subCatCustClient = clientAgg(subCatCustDf)\n",
    "if len(subsegments)!=0:subSegCustClient = clientAgg(subSegCustDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0, 0, 0)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retailerDuplication = sum([len(secRetailerClient)+len(segRetailerClient)+len(subCatRetailerClient)+len(subSegRetailerClient)])\n",
    "channelDuplication = sum([len(secChannelClient)+len(segChannelClient)+len(subCatChannelClient)+len(subSegChannelClient)])\n",
    "regionDuplication = sum([len(secRegionClient)+len(segRegionClient)+len(subCatRegionClient)+len(subSegRegionClient)])\n",
    "custDuplication = sum([len(secCustClient)+len(segCustClient)+len(subCatCustClient)+len(subSegCustClient)])\n",
    "retailerDuplication,channelDuplication,regionDuplication,custDuplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillMissingValue(dfToFill):\n",
    "    for key,val in dfToFill.items():\n",
    "        colToFill = val.columns[0]\n",
    "        uniqueValue = val[~val[colToFill].str.contains('Total')][colToFill].unique()\n",
    "        dfLis = []\n",
    "        for source in val['Source'].unique():\n",
    "            df = val[val.Source==source]\n",
    "            missingValue = list(set(uniqueValue) - set(df[~df[colToFill].str.contains('Total')][colToFill].unique()))\n",
    "            missingValue = pd.DataFrame({colToFill: missingValue,'Source':source})\n",
    "            val = pd.concat([val, missingValue]).replace(np.nan,0).reset_index(drop=True)\n",
    "            \n",
    "        ## Value Identifier on the avg or national value for the color schema on replacement\n",
    "        if 'National' in val['Source'].unique():\n",
    "            val['Net Total'] = val[(val.Source=='National')&(val[colToFill].str.contains('Total'))]['Net Sales/Kg'].iloc[0]\n",
    "            val['GM Total'] = val[(val.Source=='National')&(val[colToFill].str.contains('Total'))]['Gross Margin %'].iloc[0]\n",
    "        else:\n",
    "            val['Net Total'] = val[(val[colToFill].str.contains('Total'))]['Net Sales/Kg'].sum()/val[(val[colToFill].str.contains('Total'))]['Net Sales/Kg'].count()\n",
    "            val['GM Total'] = val[(val[colToFill].str.contains('Total'))]['Gross Margin %'].sum()/val[(val[colToFill].str.contains('Total'))]['Gross Margin %'].count()\n",
    "        dfToFill[key]=val\n",
    "        \n",
    "    return dfToFill\n",
    "                            \n",
    "retailerDic = {'Sec':secRetailerClient,'Seg':segRetailerClient,'SubSeg':subSegRetailerClient,'SubCat':subCatRetailerClient}\n",
    "channelDic = {'Sec':secChannelClient,'Seg':segChannelClient,'SubSeg':subSegChannelClient,'SubCat':subCatChannelClient}\n",
    "regionDic = {'Sec':secRegionClient,'Seg':segRegionClient,'SubSeg':subSegRegionClient,'SubCat':subCatRegionClient}\n",
    "custDic = {'Sec':secCustClient,'Seg':segCustClient,'SubSeg':subSegCustClient,'SubCat':subCatCustClient}\n",
    "\n",
    "for key,val in retailerDic.items():\n",
    "    retailerDic[key] = fillMissingValue(val)\n",
    "for key,val in channelDic.items():\n",
    "    channelDic[key] = fillMissingValue(val)\n",
    "for key,val in regionDic.items():\n",
    "    regionDic[key] = fillMissingValue(val)\n",
    "for key,val in custDic.items():\n",
    "    custDic[key] = fillMissingValue(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLide6: MixMatrix ByBrand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixMatrixbybrandClean(data):\n",
    "    final = {}\n",
    "    for key, val in data.items():\n",
    "        df = val.copy()       \n",
    "        if df.shape[0] != 0:\n",
    "            new_key = key\n",
    "            df.fillna(0, inplace=True)\n",
    "            df['Source'] = new_key.split(' | ')[1]\n",
    "            # Sort the DataFrame by 'Value Sales'\n",
    "            final[new_key] = df.sort_values(by='Value Sales', ascending=False)\n",
    "            # Generate sort order based on sorted unique values of the first column\n",
    "            sortOrder = final[new_key][final[new_key].columns[0]].unique()\n",
    "            # Apply the sort order to the current DataFrame\n",
    "            final[new_key]['order'] = final[new_key][final[new_key].columns[0]].replace(dict(zip(sortOrder, range(len(sortOrder)))))\n",
    " \n",
    "    return final\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillMissingValue(dfToFill):\n",
    "    for key,val in dfToFill.items():\n",
    "        colToFill = val.columns[0]\n",
    "        uniqueValue = val[~val[colToFill].str.contains('Total')][colToFill].unique()\n",
    "        dfLis = []\n",
    "        for source in val['Source'].unique():\n",
    "            df = val[val.Source==source]\n",
    "            missingValue = list(set(uniqueValue) - set(df[~df[colToFill].str.contains('Total')][colToFill].unique()))\n",
    "            missingValue = pd.DataFrame({colToFill: missingValue,'Source':source})\n",
    "            val = pd.concat([val, missingValue]).replace(np.nan,0).reset_index(drop=True)\n",
    "            \n",
    "        ## Value Identifier on the avg or national value for the color schema on replacement\n",
    "            val['Net Total'] = val[(val[colToFill].str.contains('Total'))]['Net Sales/Kg'].sum()/val[(val[colToFill].str.contains('Total'))]['Net Sales/Kg'].count()\n",
    "            val['GM Total'] = val[(val[colToFill].str.contains('Total'))]['Gross Margin %'].sum()/val[(val[colToFill].str.contains('Total'))]['Gross Margin %'].count()\n",
    "        dfToFill[key]=val\n",
    "        \n",
    "    return dfToFill\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat,sec,seg,subseg,subcat \n",
    "secbrand,segbrand,subsegbrand,subcatbrand = {},{},{},{}\n",
    "for key in brands_client_dfs.keys():\n",
    "    key_split = key.split(' | ')\n",
    "    if len(sectors) != 0 and len(key_split) > 2 and key_split[1] in sectors or key_split[1] in categories  :secbrand[key] = brands_client_dfs[key]\n",
    "    if len(segments) != 0 and len(key_split) > 2 and key_split[1] in segments or key_split[1] in categories:segbrand[key] = brands_client_dfs[key]\n",
    "    if len(subsegments) != 0 and len(key_split) > 2 and key_split[1] in subsegments or key_split[1] in categories:subsegbrand[key] = brands_client_dfs[key]\n",
    "    if len(subcategories) != 0 and len(key_split) > 2 and key_split[1] in subcategories or key_split[1] in categories:subcatbrand[key] = brands_client_dfs[key]\n",
    " \n",
    "if len(sectors) != 0:\n",
    "        sec_dfclean=mixMatrixbybrandClean(secbrand)\n",
    "        sectorbybrand=fillMissingValue(sec_dfclean)\n",
    "if len(segments) != 0:\n",
    "        seg_dfclean=mixMatrixbybrandClean(segbrand)\n",
    "        segmentbybrand=fillMissingValue(seg_dfclean)\n",
    "\n",
    "if len(subsegments) != 0: \n",
    "        subseg_dfclean=mixMatrixbybrandClean(subsegbrand)\n",
    "        subsegmentbybrand=fillMissingValue(subseg_dfclean)\n",
    "\n",
    "if len(subcategories) != 0:\n",
    "       subcat_dfclean=mixMatrixbybrandClean(subcatbrand)\n",
    "       subcategorybybrand=fillMissingValue(subcat_dfclean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatdf(dic,area):\n",
    "    final = {}\n",
    "    for key_part in area:\n",
    "        aligned_dfs = []\n",
    "\n",
    "        # Filter and align DataFrames for the current area\n",
    "        for key, df in dic.items():\n",
    "            key_parts = key.split(\" | \")  # Split key into parts based on \" | \"\n",
    "            if key_part in key_parts:  # Check if the key includes the area (e.g., \"NATIONAL\")\n",
    "                # Set 'Top Brands' as index for alignment, reindex to ensure all brands are present\n",
    "                area_brands = pd.concat([df['Top Brands'] for key, df in dic.items() if key_part in key]).unique()\n",
    "                aligned_df = df.set_index('Top Brands').reindex(area_brands).reset_index()\n",
    "                aligned_df['Source'] = aligned_df['Source'].ffill()  # Track the source of the data\n",
    "                aligned_df = aligned_df.fillna(0)  # Fill missing values with 0\n",
    "                aligned_df.rename(columns={\"Top Brands\": client_manuf[0]}, inplace=True)\n",
    "                aligned_dfs.append(aligned_df)\n",
    "\n",
    "        if aligned_dfs:  # Ensure there's at least one DataFrame to concatenate\n",
    "            final_df = pd.concat(aligned_dfs, ignore_index=True)\n",
    "            final[key_part] = final_df  # Store the concatenated DataFrame in the final dictionary\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)!=0:\n",
    "    secfinaldic=concatdf(sectorbybrand,area)\n",
    "if len(segments)!=0:\n",
    "    segfinaldic=concatdf(segmentbybrand,area)\n",
    "if len(subsegments)!=0:\n",
    "    subsegfinaldic=concatdf(subsegmentbybrand,area)\n",
    "if len(subcategories)!=0:\n",
    "    subcatfinaldic=concatdf(subcategorybybrand,area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide7:Sector Spending Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Spending Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanProducts(data):\n",
    "    final ={}\n",
    "    for key, df in data.items():\n",
    "        df['Top Brands'] = df['Top Brands'].replace(0, np.nan)\n",
    "        df['Top Brands'] = df['Top Brands'].fillna(method = 'ffill')\n",
    "        df = df[~df['Top Brands'].str.contains('Total', case=False)]\n",
    "        df.fillna(0,inplace = True)\n",
    "        df = df[df['Net Sales']>1000]\n",
    "        df = df.sort_values(by= 'Net Sales', ascending=False)\n",
    "        df =df.head(12)\n",
    "        df = df.reset_index(drop=True)\n",
    "        if df.shape[0] !=0:\n",
    "            if 'National' in key:\n",
    "                new_key = key.split(' | ')[0] + ' | ' + key.split(' | ')[2] +' | ' + key.split(' | ')[1]\n",
    "            else:\n",
    "                new_key = key\n",
    "            final[new_key] = df\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_products_p12m = cleanProducts(product_P12M_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_products_p12m_brand ={}\n",
    "for key, df in modified_brand_product_P12M_dfs.items():\n",
    "    df['Top Brands'] = df['Top Brands'].replace(0, np.nan)\n",
    "    df['Top Brands'] = df['Top Brands'].fillna(method = 'ffill')\n",
    "    df = df[~df['Top Brands'].str.contains('Total', case=False)]\n",
    "    df.fillna(0,inplace = True)\n",
    "    df = df[df['Net Sales']>1000]\n",
    "    df = df[df['Top Brands'].isin(client_brands)]\n",
    "    df = df.sort_values(by= 'Net Sales', ascending=False)\n",
    "    df =df.head(12)\n",
    "    df = df.reset_index(drop=True)\n",
    "    if df.shape[0] !=0:\n",
    "        if 'National' in key:\n",
    "            new_key = key.split(' | ')[0] + ' | ' + key.split(' | ')[2] +' | ' + key.split(' | ')[1]\n",
    "        else:\n",
    "            new_key = key\n",
    "        modified_products_p12m_brand[new_key] = df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKU Profitability Slide 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "###P12M\n",
    "modified_product_sec_seg_P12M_dfs = {}\n",
    "\n",
    "for k in product_P12M_dfs.keys():\n",
    "    t=product_P12M_dfs[k].copy()\n",
    "    t=t[:-1]\n",
    "    t['Value Sales IYA'] =t['Value Sales IYA'].astype(float).fillna(-199)\n",
    "    t['Net Sales'] =t['Net Sales'].astype(float).fillna(0)\n",
    "    t['Net Sales/Kg'] =t['Net Sales/Kg'].astype(float).fillna(0)\n",
    "\n",
    "    t['Gross Margin %'] =t['Gross Margin %'].astype(float).fillna(0)\n",
    "\n",
    "    t['Top Brands']=t['Top Brands'].ffill()\n",
    "    total= t[(t['Top Brands'].str.contains( ' Total')) & ~(t['Top Brands'].isin(['Grand Total','All Others Total'])) & ~(t['Top Brands'].isin([i+' Total' for i in client_brands]))]\n",
    "    df = t[t['Top Brands'].isin(client_brands)]\n",
    "    df[f'{prodORitem} Sales Rate'] = df[f'{prodORitem} Sales Rate'].fillna(0)\n",
    "    df = df[df['Net Sales'] >= 1000]\n",
    "    if (not df.empty):\n",
    "        modified_product_sec_seg_P12M_dfs[k] = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide9: Trade margin table vs Competition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By client and competitor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_df_excluding_total(df, Inscope=\"\"):\n",
    "    df = df.fillna(0)\n",
    "    total_row = df[df[f'{ManufOrTopC}'] == 'Total']\n",
    "    df = df[df[f'{ManufOrTopC}'] != 'Total']\n",
    "    df = df.sort_values(by=[Inscope], ascending=[True]).reset_index(drop=True)\n",
    "    df = pd.concat([df, total_row]).reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def split_client_copetitor(dictionary,client_dictionary,competitor_dictionary,Inscope=\"\"):\n",
    "    for k in dictionary.keys():\n",
    "        t = dictionary[k].copy()\n",
    "        t=t[:-1]\n",
    "        t[Inscope]=t[Inscope].fillna(t[f'{ManufOrTopC}'])\n",
    "        t['Net Sales'] = t['Net Sales'].astype(float)\n",
    "        total_entries = t[(t[f'{ManufOrTopC}'].str.contains(' Total')) & ~(t[f'{ManufOrTopC}'].isin(['Grand Total',\"All Others Total\"])) & ~(t[f'{ManufOrTopC}'].isin([i+' Total' for i in client_manuf]))]\n",
    "        total_entries['Value Share'] = total_entries['Value Share'].astype(float)\n",
    "        total_entries = total_entries.nlargest(1,columns=\"Value Share\")    \n",
    "        comp_lis = list(total_entries[f'{ManufOrTopC}'].str.replace(\" Total\",'').str.strip())\n",
    "        print(comp_lis)\n",
    "        dc = (t[t[f'{ManufOrTopC}'].isin(client_manuf) | t[f'{ManufOrTopC}'].isin([i + \" Total\" for i in client_manuf])]).replace([i + \" Total\" for i in client_manuf],\"Total\")\n",
    "        df = (t[t[f'{ManufOrTopC}'].isin(comp_lis) | t[f'{ManufOrTopC}'].isin([i + \" Total\" for i in comp_lis])]).replace([i + \" Total\" for i in comp_lis],\"Total\")\n",
    "        \n",
    "        dc = dc[dc['Net Sales'] > 1000]\n",
    "        unique_scope = dc[Inscope].unique().tolist()\n",
    "\n",
    "        df = df[df[Inscope].isin(unique_scope)]\n",
    "\n",
    "        for subcat in unique_scope:\n",
    "            print(subcat)\n",
    "            if (subcat not in df[Inscope].values) & (subcat!=\"\"):\n",
    "                df = pd.concat([df, pd.DataFrame({f'{ManufOrTopC}': [df[f'{ManufOrTopC}'].unique()[0]], Inscope: [subcat]})])\n",
    "\n",
    "\n",
    "        dc = sort_df_excluding_total(dc, Inscope)\n",
    "        df = sort_df_excluding_total(df, Inscope)\n",
    "\n",
    "        if not dc.empty:\n",
    "            client_dictionary[k]=dc\n",
    "        if not df.empty:\n",
    "            competitor_dictionary[k]=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mdd']\n",
      "Soft Cheese\n",
      "Aperitif\n",
      "Alternative Vegetale\n",
      "Total\n",
      "['Mdd']\n",
      "Soft Cheese\n",
      "Aperitif\n",
      "Alternative Vegetale\n",
      "Total\n",
      "['Mdd']\n",
      "Frais A Tartiner\n",
      "Aperitif\n",
      "Enfant\n",
      "Alternative Vegetale\n",
      "Salade\n",
      "Total\n",
      "['Mdd']\n",
      "Frais A Tartiner\n",
      "Aperitif\n",
      "Enfant\n",
      "Alternative Vegetale\n",
      "Salade\n",
      "Total\n"
     ]
    }
   ],
   "source": [
    "####Sector_Cleaning \n",
    "client_manuf_sector_dfs_new = {}\n",
    "top_competitor_manuf_sector_dfs_new = {}\n",
    "if len(sectors)!=0:\n",
    "    split_client_copetitor(manuf_Sector_dfs,client_manuf_sector_dfs_new,top_competitor_manuf_sector_dfs_new,Inscope=\"Sector\")\n",
    "\n",
    "####Segment_Cleaning\n",
    "client_manuf_segment_dfs_new = {}\n",
    "top_competitor_manuf_segment_dfs_new = {}\n",
    "if len(segments)!=0:\n",
    "    split_client_copetitor(manuf_Segment_dfs,client_manuf_segment_dfs_new,top_competitor_manuf_segment_dfs_new,Inscope=\"Segment\")\n",
    "\n",
    "####SubSegment_Cleaning\n",
    "client_manuf_subsegment_dfs_new = {}\n",
    "top_competitor_manuf_subsegment_dfs_new = {}\n",
    "if len(subsegments)!=0:\n",
    "    split_client_copetitor(manuf_SubSegment_dfs,client_manuf_subsegment_dfs_new,top_competitor_manuf_subsegment_dfs_new,Inscope=\"SubSegment\")\n",
    "\n",
    "####SubCategory_Cleaning\n",
    "client_manuf_subcategory_dfs_new = {}\n",
    "top_competitor_manuf_subcategory_dfs_new = {}\n",
    "if len(subcategories)!=0:\n",
    "    split_client_copetitor(manuf_SubCategory_dfs,client_manuf_subcategory_dfs_new,top_competitor_manuf_subcategory_dfs_new,Inscope=\"SubCategory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# duplication part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [\n",
    "    *[0]*((1 if len(client_brands)>1 and len(modified_brand_P12M_dfs)>0 else 0)+(1 if len(modified_retailer_regions)>0 else 0)+(1 if len(modified_retailer_channels)>0 else 0)+(1 if len(modified_retailer_markets)>0 else 0)\n",
    "          +(1 if len(modified_channels_regions)>0 else 0)+(1 if len(modified_channels_channels)>0 else 0)+(1 if len(modified_channels_markets)>0 else 0)\n",
    "          +(1 if len(modified_region_regions)>0 else 0)+(1 if len(modified_region_channels)>0 else 0)+(1 if len(modified_region_markets)>0 else 0)\n",
    "          +(1 if len(modified_cust_regions)>0 else 0)+(1 if len(modified_cust_channels)>0 else 0)+(1 if len(modified_cust_markets)>0 else 0)\n",
    "          +(1 if sectors else 0)+(1 if segments else 0)+(1 if subsegments else 0)+(1 if subcategories else 0)+(1 if len(client_brands)>1 else 0)),\n",
    "    *[1]*((1 if sectors else 0)+(1 if segments else 0)+(1 if subsegments else 0)+(1 if subcategories else 0)),\n",
    "#     *[2]*((1 if sectors else 0)+(1 if segments else 0)+(1 if subsegments else 0)+(1 if subcategories else 0)),\n",
    "    *[3]*((1 if len(client_brands)>=1 else 0)+(1 if len(client_brands)>=1 else 0)),\n",
    "    *[4]*((1 if retailerDuplication !=0 else 0)+(1 if channelDuplication !=0 else 0 )+(1 if regionDuplication !=0 else 0 )+(1 if custDuplication !=0 else 0 )),\n",
    "    *[5]*((1 if sectors else 0)+(1 if segments else 0)+(1 if subsegments else 0)+(1 if subcategories else 0)),\n",
    "    *[6]*((1 if sectors else 0)+(1 if segments else 0)+(1 if subsegments else 0)+(1 if subcategories else 0)),\n",
    "    *[7]*(1 if len(client_brands)>=1 else 0),\n",
    "    *[8]*( 1 if len(client_brands)>=1 else 0),\n",
    "    *[9]*((1 if sectors else 0)+(1 if segments else 0)+(1 if subsegments else 0)+(1 if subcategories else 0))\n",
    "    ]\n",
    "\n",
    "# slide 0\n",
    "duplication_1=[(len(modified_brand_P12M_dfs.keys()) if len(client_brands)>1 else 0)]\n",
    "duplication_2 = [len(modified_retailer_regions.keys()) if len(regions_RET)>0 else 0, len(modified_retailer_channels.keys()) if len(channels_RET)>0 else 0, len(modified_retailer_markets.keys()) if len(market_RET)>0 else 0,\n",
    "                 len(modified_channels_regions.keys()) if len(regions_CHAN)>0 else 0, len(modified_channels_channels.keys()) if len(channels_CHAN)>0 else 0, len(modified_channels_markets.keys()) if len(market_CHAN) >0 else 0,\n",
    "                 len(modified_region_regions.keys()) if len(regions_REG)>0 else 0, (len(modified_region_channels.keys()) if len(channels_REG)>0 else 0), len(modified_region_markets.keys()) if len(market_REG)>0 else 0,\n",
    "                 len(modified_cust_regions.keys()) if len(regions_CUST)>0 else 0, (len(modified_cust_channels.keys()) if len(channels_CUST)>0 else 0), len(modified_cust_markets.keys()) if len(market_CUST)>0 else 0] \n",
    "\n",
    "duplication_3 = [(len(modified_sectors_P12M_mix_analysis_dfs.keys()) if len(sectors)>0 else 0), (len(modified_segment_P12M_mix_analysis_dfs.keys()) if len(segments)>0 else 0), (len(modified_subsegment_P12M_mix_analysis_dfs) if subsegments else 0), (len(modified_subcategory_P12M_mix_analysis_dfs) if len(subcategories)>0 else 0)]\n",
    "\n",
    "duplication_4 = [len(modified_product_sec_seg_P12M_dfs.keys()) if len(client_brands)>1 else 0]\n",
    "\n",
    "# Slide 1\n",
    "duplication_5 = [(len(modified_sector_Trade_Margin_dfs.keys()) if len(sectors)!=0 else 0), (len(modified_segment_Trade_Margin_dfs.keys()) if len(segments)!=0 else 0), (len(modified_subsegment_Trade_Margin_dfs) if len(subsegments)!=0 else 0), (len(modified_subcategory_Trade_Margin_dfs) if len(subcategories)!=0 else 0)]\n",
    "\n",
    "# Slide 2\n",
    "# duplication_6 = [(len(merged_data_sector.keys()) if len(sectors)!=0 else 0), (len(merged_data_segment.keys()) if len(segments)!=0 else 0), (len(merged_data_subsegment) if len(subsegments)!=0 else 0), (len(merged_data_subcategory) if len(subcategories)!=0 else 0)]\n",
    "\n",
    "# Slide 3\n",
    "duplication_7 = [len(modified_product_dfs.keys()),len(modified_brand_product_dfs.keys())]\n",
    "# Slide 4\n",
    "duplication_8 = [retailerDuplication,channelDuplication,regionDuplication,custDuplication]\n",
    "\n",
    "# Slide 5\n",
    "duplication_9=[(len(secfinaldic.keys())if len(sectors)!=0 else 0),(len(segfinaldic.keys())if len(segments)!=0 else 0),(len(subsegfinaldic.keys())if len(subsegments)!=0 else 0),(len(subcatfinaldic.keys())if len(subcategories)!=0 else 0)]\n",
    "\n",
    "# Slide 5\n",
    "duplication_10 = [(len(modified_sector_P12M.keys()) if len(sectors)!=0 else 0), (len(modified_segment_P12M.keys()) if len(segments)!=0 else 0), (len(modified_subsegment_P12M) if len(subsegments)!=0 else 0), (len(modified_subcategory_P12M) if len(subcategories)!=0 else 0)]\n",
    "\n",
    "# Slide 6\n",
    "duplication_11 = [len(modified_products_p12m)+ len(modified_products_p12m_brand)]\n",
    "\n",
    "# Slide 7 \n",
    "duplication_12 = [len(modified_product_P12M_dfs) + len(modified_brand_product_P12M_dfs)]\n",
    "\n",
    "# Slide 8\n",
    "duplication_13 = [(len(client_manuf_sector_dfs_new.keys()) if len(sectors)!=0 else 0), (len(client_manuf_segment_dfs_new.keys()) if len(segments)!=0 else 0), (len(client_manuf_subsegment_dfs_new) if len(subsegments)!=0 else 0), (len(client_manuf_subcategory_dfs_new) if len(subcategories)!=0 else 0)]\n",
    "\n",
    "\n",
    "duplication = duplication_1 + duplication_2 + duplication_3 + duplication_4 + duplication_5 + duplication_7 + duplication_8+duplication_9 + duplication_10+ duplication_11+duplication_12+duplication_13 #+ duplication_6\n",
    "duplication = [item for item in duplication if item !=0]\n",
    "\n",
    "section_1 = ([\"Mix Analysis by brand\"] if len(client_brands)>1 and  len(modified_brand_P12M_dfs)>0 else [])\n",
    "section_2 = ([\"Mix Analysis by Retailer for Region\"] if len(modified_retailer_regions)!=0 else [])+ ([\"Mix Analysis by Retailer for Channel\"] if len(modified_retailer_channels)!=0 else [])+ ([\"Mix Analysis by Retailer for Market\"] if len(modified_retailer_markets)!=0 else [])+([\"Mix Analysis by Channel for Region\"] if len(modified_channels_regions)!=0 else [])+ ([\"Mix Analysis by Channel for Channel\"] if len(modified_channels_channels)!=0 else [])+ ([\"Mix Analysis by Channel for Market\"] if len(modified_channels_markets)!=0 else [])+([f\"Mix Analysis by Region for Region\"] if len(modified_region_regions)!=0 else [])+ ([f\"Mix Analysis by Region for Channel\"] if len(modified_region_channels)!=0 else [])+ ([f\"Mix Analysis by Region for Market\"] if len(modified_region_markets)!=0 else [])+([f\"Mix Analysis by {customareas} for Region\"] if len(modified_cust_regions)!=0 else [])+ ([f\"Mix Analysis by {customareas} for Channel\"] if len(modified_cust_channels)!=0 else [])+ ([f\"Mix Analysis by {customareas} for Market\"] if len(modified_cust_markets)!=0 else [])\n",
    "section_3 = ([\"Mix Analysis by Sector\"] if len(sectors)!=0 else [])+ ([\"Mix Analysis by Segment\"] if len(segments)!=0 else [])+ ([\"Mix Analysis by SubSegment\"] if len(subsegments)!=0 else [])+ ([\"Mix Analysis by SubCategory\"] if len(subcategories)!=0 else [])\n",
    "section_4 = [\"Mix Analysis by\"+ f'{prodORitem}' if len(client_brands)>1 else []]\n",
    "\n",
    "section_5 = ([\"Trade Margin Analysis by Sector\"] if len(sectors)!=0 else [])+ ([\"Trade Margin Analysis by Segment\"] if len(segments)!=0 else [])+ ([\"Trade Margin Analysis by SubSegment\"] if len(subsegments)!=0 else [])+([\"Trade Margin Analysis by SubCategory\"] if len(subcategories)!=0 else [])\n",
    "\n",
    "# section_6 = ([\"Sector KPI\"] if len(sectors)!=0 else [])+ ([\"Segment KPI\"] if len(segments)!=0 else [])+ ([\"SubSegment KPI\"] if len(subsegments)!=0 else [])+ ([\"SubCategory KPI\"] if len(subcategories)!=0 else [])\n",
    "\n",
    "section_7 = (\"SKU KPIs Summary By Manufacturer\" if len(client_brands)>=1 else [],\"SKU KPIs Summary By Brand\" if len(client_brands)>=1 else [])\n",
    "\n",
    "section_8 = ['Mix Matrix By Retailer'if retailerDuplication != 0 else[] ,'Mix Matrix By Channel'if channelDuplication != 0 else[],'Mix Matrix By Region'if regionDuplication != 0 else[],'Mix Matrix By Custom Region'if custDuplication != 0 else[]]#,*section_names_slide4]#*section_names_slide3,*section_names_slide4]\n",
    "\n",
    "section_9=[\"Mix Matrix By Brands by Sector\" if len(sectors)!=0 else [],\"Mix Matrix By Brands by Segment\" if len(segments)!=0 else [],\"Mix Matrix By Brands by SubSegment\"if len(subsegments)!=0 else [],\"Mix Matrix By Brands by SubCategory\"if len(subcategories)!=0 else []]\n",
    "\n",
    "section_10 = ([\"Sector Spending Pool\"] if len(sectors)!=0 else [])+ ([\"Segment Spending Pool\"] if len(segments)!=0 else [])+ ([\"SubSegment Spending Pool\"] if len(subsegments)!=0 else [])+ ([\"SubCategory Spending Pool\"] if len(subcategories)!=0 else [])\n",
    "\n",
    "section_11 = ([\"Product Spending Pool\"] if len(client_brands)>=1 else [])\n",
    "\n",
    "section_12 = [(\"SKU Profitability\" if len(client_brands)>=1 else [])]\n",
    "\n",
    "section_13 = ([\"Trade Margin Table By Sector\"] if len(sectors)!=0 else [])+ ([\"Trade Margin Table By Segment\"] if len(segments)!=0 else [])+ ([\"Trade Margin Table By SubSegment\"] if len(subsegments)!=0 else [])+ ([\"Trade Margin Table By SubCategory\"] if len(subcategories)!=0 else [])\n",
    "\n",
    "section_names = [*section_1 , *section_2 , *section_3 , *section_4 , *section_5  , *section_7 , *section_8, *section_9 , *section_10 , *section_11,*section_12,*section_13]#, *section_6\n",
    "\n",
    "section_names = [item for item in section_names if item !=[]]\n",
    " \n",
    "\n",
    "path = os.getcwd() + \"\\Financials base.pptx\"\n",
    "new_pre = os.getcwd() + '\\Financials Slide Duplicate.pptx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 1, 3, 3, 4, 5, 5, 6, 6, 7, 8, 9, 9]\n",
      "[10, 6, 2, 2, 12, 2, 2, 12, 24, 2, 2, 2, 2, 2, 36, 36, 2, 2]\n",
      "['Mix Analysis by brand', 'Mix Analysis by Retailer for Region', 'Mix Analysis by Sector', 'Mix Analysis by Segment', 'Mix Analysis byItem', 'Trade Margin Analysis by Sector', 'Trade Margin Analysis by Segment', 'SKU KPIs Summary By Manufacturer', 'SKU KPIs Summary By Brand', 'Mix Matrix By Retailer', 'Mix Matrix By Brands by Sector', 'Mix Matrix By Brands by Segment', 'Sector Spending Pool', 'Segment Spending Pool', 'Product Spending Pool', 'SKU Profitability', 'Trade Margin Table By Sector', 'Trade Margin Table By Segment']\n",
      "18\n",
      "18\n",
      "18\n",
      "158\n"
     ]
    }
   ],
   "source": [
    "print(index)\n",
    "print(duplication)\n",
    "print(section_names)\n",
    "print(len(index))\n",
    "print(len(duplication))\n",
    "print(len(section_names))\n",
    "print(sum(duplication))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pythoncom\n",
    "import win32com.client as win32\n",
    " \n",
    "def slideDuplication(index=[0,1], duplication=[1,1], section_names=[''], path='', new_pre=''):\n",
    "    \"\"\"\n",
    "    Duplicate slides in a PowerPoint presentation, show live, then save & close.\n",
    " \n",
    "    Parameters:\n",
    "    - index (list): List of slide indices (0-based) to duplicate.\n",
    "    - duplication (list): List specifying the number of times each slide should be duplicated.\n",
    "    - section_names (list): List of names for sections to be added.\n",
    "    - path (str): Path to the PowerPoint presentation file.\n",
    "    - new_pre (str): Path to save the duplicated presentation.\n",
    " \n",
    "    Returns:\n",
    "    - str: A message indicating success or failure.\n",
    "    \"\"\"\n",
    "    if not (len(index) == len(duplication) == len(section_names)):\n",
    "        return 'The Index list must have the same length as Duplication and Section names'\n",
    " \n",
    "    lis = []\n",
    " \n",
    "    app = win32.Dispatch(\"PowerPoint.Application\")\n",
    "    app.Visible = True  # âœ… Show PowerPoint window\n",
    "    presentation = app.Presentations.Open(path, WithWindow=True)  # âœ… Open with window\n",
    " \n",
    "    try:\n",
    "        for i in range(len(index)):\n",
    "            if isinstance(index[i], list):\n",
    "                for num_duplicate in range(duplication[i]):\n",
    "                    for k in index[i]:\n",
    "                        slide = presentation.Slides.Item(k + 1)  # 0-based â†’ COM 1-based\n",
    "                        duplicated_slide = slide.Duplicate()\n",
    "                        duplicated_slide.MoveTo(presentation.Slides.Count)\n",
    "                lis.append(presentation.Slides.Count + 1 - (duplication[i] * len(index[i])))\n",
    "            else:\n",
    "                slide = presentation.Slides.Item(index[i] + 1)\n",
    "                for num_duplicate in range(duplication[i]):\n",
    "                    duplicated_slide = slide.Duplicate()\n",
    "                    duplicated_slide.MoveTo(presentation.Slides.Count)\n",
    "                lis.append(presentation.Slides.Count + 1 - duplication[i])\n",
    " \n",
    "        # Add sections\n",
    "        for j in range(len(lis)):\n",
    "            if duplication[j] != 0:\n",
    "                presentation.SectionProperties.AddBeforeSlide(lis[j], section_names[j])\n",
    " \n",
    "        # Remove default first section\n",
    "        if presentation.SectionProperties.Count > 0:\n",
    "            presentation.SectionProperties.Delete(1, True)\n",
    " \n",
    "        # Save new file\n",
    "        presentation.SaveAs(new_pre)\n",
    "        msg = f\"Presentation saved to {new_pre}\"\n",
    " \n",
    "    finally:\n",
    "        # âœ… Close presentation & PowerPoint\n",
    "        presentation.Close()\n",
    "        app.Quit()\n",
    " \n",
    "    return msg\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Presentation saved to c:\\\\Users\\\\aleaa\\\\Documents\\\\Slide-Automate\\\\Financials Slide Duplicate\\\\Financials Slide Duplicate.pptx'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slideDuplication(index,duplication,section_names,path,new_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_position(end):\n",
    "    return sum(duplication[i] * (1 if isinstance(index[i], int) else len(index[i])) for i in range(end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = Presentation(new_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0\n",
    "if len(client_brands)>1 and len(modified_brand_P12M_dfs) >0:\n",
    "    Mixanalysis(prs,modified_brand_P12M_dfs,duplication[p],Inscop='Brand',position = calculate_position(p),label_col='Top Brands')\n",
    "    p+=1\n",
    "if len(regions_RET)!=0:\n",
    "    Mixanalysis(prs,modified_retailer_regions,duplication[p],Inscop='Retailer',position = calculate_position(p),label_col='Region')\n",
    "    p+=1\n",
    "if len(channels_RET)!=0:\n",
    "    Mixanalysis(prs,modified_retailer_channels,duplication[p],Inscop='Retailer',position = calculate_position(p),label_col='Channel')\n",
    "    p+=1\n",
    "if len(market_RET)!=0 and len(modified_retailer_markets)>0:\n",
    "    Mixanalysis(prs,modified_retailer_markets,duplication[p],Inscop='Retailer',position = calculate_position(p),label_col='Market')\n",
    "    p+=1\n",
    "\n",
    "if len(regions_CHAN)!=0:\n",
    "    Mixanalysis(prs,modified_channels_regions,duplication[p],Inscop='Channel',position = calculate_position(p),label_col='Region')\n",
    "    p+=1\n",
    "if len(channels_CHAN)!=0:\n",
    "    Mixanalysis(prs,modified_channels_channels,duplication[p],Inscop='Channel',position = calculate_position(p),label_col='Channel')\n",
    "    p+=1\n",
    "if len(market_CHAN)!=0:\n",
    "    Mixanalysis(prs,modified_channels_markets,duplication[p],Inscop='Channel',position = calculate_position(p),label_col='Market')\n",
    "    p+=1\n",
    "\n",
    "if len(regions_REG)!=0:\n",
    "    Mixanalysis(prs,modified_region_regions,duplication[p],Inscop='Region',position = calculate_position(p),label_col='Region')\n",
    "    p+=1\n",
    "if len(channels_REG)!=0:\n",
    "    Mixanalysis(prs,modified_region_channels,duplication[p],Inscop='Region',position = calculate_position(p),label_col='Channel')\n",
    "    p+=1\n",
    "if len(market_REG)!=0 and len(modified_region_markets)>0:\n",
    "    Mixanalysis(prs,modified_region_markets,duplication[p],Inscop='Region',position = calculate_position(p),label_col='Market')\n",
    "    p+=1\n",
    "\n",
    "\n",
    "if len(regions_CUST)!=0:\n",
    "    Mixanalysis(prs,modified_cust_regions,duplication[p],Inscop=f\"{customareas}\",position = calculate_position(p),label_col='Region')\n",
    "    p+=1\n",
    "if len(channels_CUST)!=0:\n",
    "    Mixanalysis(prs,modified_cust_channels,duplication[p],Inscop=f\"{customareas}\",position = calculate_position(p),label_col='Channel')\n",
    "    p+=1\n",
    "if len(market_CUST)!=0 and len(modified_cust_markets)>0:\n",
    "    Mixanalysis(prs,modified_cust_markets,duplication[p],Inscop=f\"{customareas}\",position = calculate_position(p),label_col='Market')\n",
    "    p+=1\n",
    "\n",
    "\n",
    "if len(sectors)!=0:\n",
    "    Mixanalysis(prs,modified_sectors_P12M_mix_analysis_dfs,duplication[p],Inscop='Sector',position = calculate_position(p),label_col='Sector')\n",
    "    p+=1\n",
    "if len(segments)!=0:         \n",
    "    Mixanalysis(prs,modified_segment_P12M_mix_analysis_dfs,duplication[p],Inscop=\"Segment\",position = calculate_position(p),label_col=\"Segment\")\n",
    "    p+=1\n",
    "if len(subsegments)!=0:\n",
    "    Mixanalysis(prs,modified_subsegment_P12M_mix_analysis_dfs,duplication[p],Inscop=\"SubSegment\",position = calculate_position(p),label_col=\"SubSegment\")\n",
    "    p+=1\n",
    "if len(subcategories)!=0:\n",
    "    Mixanalysis(prs,modified_subcategory_P12M_mix_analysis_dfs,duplication[p],Inscop=\"SubCategory\",position = calculate_position(p),label_col=\"SubCategory\")\n",
    "    p+=1\n",
    "if len(client_brands)>1:\n",
    "    Mixanalysis(prs,modified_product_sec_seg_P12M_dfs,duplication[p],Inscop=f'{prodORitem}',position = calculate_position(p),label_col=f'{prodORitem}')\n",
    "    p+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)!=0:\n",
    "    TradeMargin(prs,modified_sector_Trade_Margin_dfs,duplication[p],position = calculate_position(p),InScope='Sector')\n",
    "    p+=1\n",
    "if len(segments)!=0:\n",
    "    TradeMargin(prs,modified_segment_Trade_Margin_dfs,duplication[p],position = calculate_position(p),InScope=\"Segment\")\n",
    "    p+=1\n",
    "if len(subsegments)!=0:\n",
    "    TradeMargin(prs,modified_subsegment_Trade_Margin_dfs,duplication[p],position = calculate_position(p),InScope=\"SubSegment\")\n",
    "    p+=1\n",
    "if len(subcategories)!=0:\n",
    "    TradeMargin(prs,modified_subcategory_Trade_Margin_dfs,duplication[p],position = calculate_position(p),InScope=\"SubCategory\")\n",
    "    p+=1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(sectors)!=0:\n",
    "#     sectorKPI(prs, merged_data_sector, duplication[p], position=calculate_position(p),Scope= \"Sector\")\n",
    "#     p+=1\n",
    "# if len(segments)!=0:\n",
    "#     sectorKPI(prs, merged_data_segment, duplication[p], position=calculate_position(p),Scope= \"Segment\")\n",
    "#     p+=1\n",
    "\n",
    "# if len(subsegments)!=0:\n",
    "#     sectorKPI(prs, merged_data_subsegment, duplication[p], position=calculate_position(p),Scope= \"SubSegment\")\n",
    "#     p+=1\n",
    "\n",
    "# if len(subcategories)!=0:\n",
    "#     sectorKPI(prs, merged_data_subcategory, duplication[p], position=calculate_position(p),Scope= \"SubCategory\") \n",
    "#     p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(client_brands)>1:\n",
    "\n",
    "SkuKpis(prs,modified_product_dfs,duplication[p],position = calculate_position(p))\n",
    "p+=1\n",
    "SkuKpis(prs,modified_brand_product_dfs,duplication[p],position = calculate_position(p))\n",
    "p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "# mixMatrix(prs,secretailerTotal,position = 0)\n",
    "pos = calculate_position(p)\n",
    "if retailerDuplication!=0:\n",
    "    for key,val in retailerDic.items():\n",
    "        if val:\n",
    "            mixMatrix(prs,val,position = pos)\n",
    "            print(pos)\n",
    "\n",
    "            pos +=len(retailerDic[key].keys())\n",
    "\n",
    "    p+=1        \n",
    "if channelDuplication!=0:\n",
    "    for key,val in channelDic.items():\n",
    "        if val:\n",
    "            mixMatrix(prs,val,position = pos)\n",
    "            pos +=len(channelDic[key].keys())\n",
    "    p+=1       \n",
    "\n",
    "if regionDuplication!=0:\n",
    "    for key,val in regionDic.items():\n",
    "        if val:\n",
    "            mixMatrix(prs,val,position = pos)\n",
    "            pos +=len(regionDic[key].keys())\n",
    "    p+=1\n",
    "\n",
    "if custDuplication!=0:\n",
    "    for key,val in custDic.items():\n",
    "        if val:\n",
    "            mixMatrix(prs,val,position = pos)\n",
    "            pos +=len(custDic[key].keys())\n",
    "    p+=1        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = calculate_position(p)\n",
    "if len(sectors)!=0:\n",
    "    mixMatrix(prs,secfinaldic,position = calculate_position(p),slideby=\"bybrand\")\n",
    "    p+=1\n",
    "if len(segments)!=0:\n",
    "    mixMatrix(prs,segfinaldic,position = calculate_position(p),slideby=\"bybrand\")\n",
    "    p+=1\n",
    "if len(subsegments)!=0:\n",
    "    mixMatrix(prs,subsegfinaldic,position = calculate_position(p),slideby=\"bybrand\")\n",
    "    p+=1\n",
    "if len(subcategories)!=0:\n",
    "    mixMatrix(prs,subcatfinaldic,position = calculate_position(p),slideby=\"bybrand\")\n",
    "    p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = calculate_position(p)\n",
    "if len(sectors)!=0:\n",
    "    sectorSpendingPool(prs, modified_sector_P12M,duplication[p], position =calculate_position(p),Scope= \"Sector\")\n",
    "    p+=1\n",
    "\n",
    "if len(segments)!=0:\n",
    "    sectorSpendingPool(prs, modified_segment_P12M,duplication[p], position =calculate_position(p),Scope=\"Segment\")\n",
    "    p+=1\n",
    "\n",
    "if len(subsegments)!=0:\n",
    "    sectorSpendingPool(prs, modified_subsegment_P12M,duplication[p], position =calculate_position(p),Scope=\"SubSegment\")\n",
    "    p+=1\n",
    "\n",
    "if len(subcategories)!=0:\n",
    "    sectorSpendingPool(prs, modified_subcategory_P12M,duplication[p], position =calculate_position(p),Scope= \"SubCategory\")\n",
    "    p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(client_brands)>1:\n",
    "\n",
    "combinedmanufbranddfpool=modified_products_p12m\n",
    "combinedmanufbranddfpool.update(modified_products_p12m_brand)\n",
    "productSpendingPool(prs,combinedmanufbranddfpool, duplication[p], position= calculate_position(p))\n",
    "p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(client_brands)>1:\n",
    "combinedmanufbranddf=modified_product_P12M_dfs\n",
    "combinedmanufbranddf.update(modified_brand_product_P12M_dfs)\n",
    "SKUProfitability(prs,combinedmanufbranddf,duplication[p],position = calculate_position(p))\n",
    "p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)!=0:\n",
    "    TradeMarginTable(prs,client_manuf_sector_dfs_new,top_competitor_manuf_sector_dfs_new,duplication[p],position = calculate_position(p),Inscope=\"Sector\")\n",
    "    p+=1\n",
    "if len(segments)!=0:  \n",
    "    TradeMarginTable(prs,client_manuf_segment_dfs_new,top_competitor_manuf_segment_dfs_new,duplication[p],position = calculate_position(p),Inscope=\"Segment\")\n",
    "    p+=1\n",
    "if len(subsegments)!=0:  \n",
    "    TradeMarginTable(prs,client_manuf_subsegment_dfs_new,top_competitor_manuf_subsegment_dfs_new,duplication[p],position = calculate_position(p),Inscope=\"SubSegment\")\n",
    "    p+=1   \n",
    "if len(subcategories)!=0:  \n",
    "    TradeMarginTable(prs,client_manuf_subcategory_dfs_new,top_competitor_manuf_subcategory_dfs_new,duplication[p],position = calculate_position(p),Inscope=\"SubCategory\")\n",
    "    p+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath=os.getcwd() +\"\\\\FinalOutput\"+f\"\\\\Financials_Output_{datetime.today().strftime(\"%d-%m\")}.pptx\"\n",
    "prs.save(outputPath)\n",
    "app = win32.Dispatch(\"PowerPoint.Application\")\n",
    "presentation = app.Presentations.Open(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=os.getcwd() +\"\\\\FinalOutput\"+f\"\\\\Financials_Output_{datetime.today().strftime(\"%d-%m\")}.pptx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_chart_data_in_excel(pptx_path, output_pptx_path=None, OpenEditData=True):\n",
    "    \"\"\"Open PowerPoint, detect charts, and (optionally) open their Excel data workbooks.\"\"\"\n",
    "    if not OpenEditData:\n",
    "        print(\"Stopping the script as 'OpenEditData' is set to False.\")\n",
    "        return None\n",
    "\n",
    "    # pythoncom.CoInitialize()\n",
    "\n",
    "    powerpoint = safe_dispatch(\"PowerPoint.Application\")\n",
    "    powerpoint.DisplayAlerts = False\n",
    "\n",
    "    excel = safe_dispatch(\"Excel.Application\")\n",
    "    excel.Visible = False\n",
    "    excel.DisplayAlerts = False\n",
    "\n",
    "    workbooks = []\n",
    "\n",
    "    # Open the PowerPoint file (hidden window)\n",
    "    ppt_pres = powerpoint.Presentations.Open(pptx_path, WithWindow=False)\n",
    "\n",
    "    try:\n",
    "        for slide in ppt_pres.Slides:\n",
    "            slide_index = slide.SlideIndex\n",
    "            for shape in slide.Shapes:\n",
    "                if getattr(shape, \"HasChart\", False):\n",
    "                    chart = shape.Chart\n",
    "                    if chart.ChartType in [15, -4169]:\n",
    "                        try:\n",
    "                            chart_data = chart.ChartData\n",
    "                            workbook = chart_data.Workbook\n",
    "                            workbook.Application.Visible = False\n",
    "                            workbooks.append(workbook)\n",
    "                            print(f\"Slide {slide_index}: Found chart with workbook: {workbook.FullName}\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Slide {slide_index}: Failed to open chart data â†’ {e}\")\n",
    "\n",
    "        if output_pptx_path:\n",
    "            ppt_pres.SaveAs(output_pptx_path)\n",
    "\n",
    "        # return presentation object so slideDuplication can use it\n",
    "        return ppt_pres\n",
    "\n",
    "    finally:\n",
    "        for wb in workbooks:\n",
    "            try:\n",
    "                wb.Close(SaveChanges=False)\n",
    "            except Exception:\n",
    "                pass\n",
    "        # pythoncom.CoUninitialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slide 1: Found chart with workbook: Book1\n",
      "Slide 2: Found chart with workbook: Book1\n",
      "Slide 3: Found chart with workbook: Book1\n",
      "Slide 4: Found chart with workbook: Book1\n",
      "Slide 5: Found chart with workbook: Book1\n",
      "Slide 6: Found chart with workbook: Book1\n",
      "Slide 7: Found chart with workbook: Book1\n",
      "Slide 8: Found chart with workbook: Book1\n",
      "Slide 9: Found chart with workbook: Book1\n",
      "Slide 10: Found chart with workbook: Book1\n",
      "Slide 11: Found chart with workbook: Book1\n",
      "Slide 12: Found chart with workbook: Book1\n",
      "Slide 13: Found chart with workbook: Book1\n",
      "Slide 14: Found chart with workbook: Book1\n",
      "Slide 15: Found chart with workbook: Book1\n",
      "Slide 16: Found chart with workbook: Book1\n",
      "Slide 17: Found chart with workbook: Book1\n",
      "Slide 18: Found chart with workbook: Book1\n",
      "Slide 19: Found chart with workbook: Book1\n",
      "Slide 20: Found chart with workbook: Book1\n",
      "Slide 21: Found chart with workbook: Book1\n",
      "Slide 22: Found chart with workbook: Book1\n",
      "Slide 23: Found chart with workbook: Book1\n",
      "Slide 24: Found chart with workbook: Book1\n",
      "Slide 25: Found chart with workbook: Book1\n",
      "Slide 26: Found chart with workbook: Book1\n",
      "Slide 27: Found chart with workbook: Book1\n",
      "Slide 28: Found chart with workbook: Book1\n",
      "Slide 29: Found chart with workbook: Book1\n",
      "Slide 30: Found chart with workbook: Book1\n",
      "Slide 31: Found chart with workbook: Book1\n",
      "Slide 32: Found chart with workbook: Book1\n",
      "Slide 119: Found chart with workbook: Book1\n",
      "Slide 120: Found chart with workbook: Book1\n",
      "Slide 121: Found chart with workbook: Book1\n",
      "Slide 122: Found chart with workbook: Book1\n",
      "Slide 123: Found chart with workbook: Book1\n",
      "Slide 124: Found chart with workbook: Book1\n",
      "Slide 125: Found chart with workbook: Book1\n",
      "Slide 126: Found chart with workbook: Book1\n",
      "Slide 127: Found chart with workbook: Book1\n",
      "Slide 128: Found chart with workbook: Book1\n",
      "Slide 129: Found chart with workbook: Book1\n",
      "Slide 130: Found chart with workbook: Book1\n",
      "Slide 131: Found chart with workbook: Book1\n",
      "Slide 132: Found chart with workbook: Book1\n",
      "Slide 133: Found chart with workbook: Book1\n",
      "Slide 134: Found chart with workbook: Book1\n",
      "Slide 135: Found chart with workbook: Book1\n",
      "Slide 136: Found chart with workbook: Book1\n",
      "Slide 137: Found chart with workbook: Book1\n",
      "Slide 138: Found chart with workbook: Book1\n",
      "Slide 139: Found chart with workbook: Book1\n",
      "Slide 140: Found chart with workbook: Book1\n",
      "Slide 141: Found chart with workbook: Book1\n",
      "Slide 142: Found chart with workbook: Book1\n",
      "Slide 143: Found chart with workbook: Book1\n",
      "Slide 144: Found chart with workbook: Book1\n",
      "Slide 145: Found chart with workbook: Book1\n",
      "Slide 146: Found chart with workbook: Book1\n",
      "Slide 147: Found chart with workbook: Book1\n",
      "Slide 148: Found chart with workbook: Book1\n",
      "Slide 149: Found chart with workbook: Book1\n",
      "Slide 150: Found chart with workbook: Book1\n",
      "Slide 151: Found chart with workbook: Book1\n",
      "Slide 152: Found chart with workbook: Book1\n",
      "Slide 153: Found chart with workbook: Book1\n",
      "Slide 154: Found chart with workbook: Book1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<win32com.gen_py.None.Presentation>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "pptx_path = outputPath  # Replace with the actual path to your PPTX file\n",
    "output_pptx_path=final\n",
    "open_chart_data_in_excel(pptx_path,output_pptx_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
