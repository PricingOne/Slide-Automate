{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c351613a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d30ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%run \"{os.path.dirname(os.getcwd())}\\general_functions\\generalFunctions.ipynb\" #container\n",
    "\n",
    "%run \"{os.path.dirname(os.getcwd())}\\general_functions\\Extracting Data Functions.ipynb\" # container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e491377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'parameters.xlsx'\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Construct the full path to the file\n",
    "f_path = os.path.join(current_dir, filename)\n",
    "print(f_path)\n",
    "#xls = pd.ExcelFile(f_path)\n",
    "parm = pd.read_excel(f_path, sheet_name='Financials')\n",
    "fields = dict(zip(parm['Field'],parm['Value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69273d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import adodbapi\n",
    "import pandas as pd\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dd375a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ee25ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = \"powerbi://api.powerbi.com/v1.0/myorg/\"+ fields['server']\n",
    "dataset_name = fields['f_name']\n",
    "f_name = os.getcwd()+\"/\"+fields['f_name']+\".xlsx\"\n",
    "\n",
    "client_manuf = list(set(fields['client_manuf'].split(','))-set(['']))\n",
    "client_brands = list(set(fields['client_brands'].split(','))-set(['']))\n",
    "\n",
    "ManufOrTopC = fields['ManufOrTopC']\n",
    "BrandOrTopB = fields['BrandOrTopB']\n",
    "\n",
    "decimals = fields['decimals']\n",
    "sign = fields['sign']\n",
    "currency = fields['currency']\n",
    "currency = ' '+ currency if sign.lower() == 'after' else  currency + ' ' \n",
    "\n",
    "prodORitem=fields[\"prodORitem\"]\n",
    "categories = list(set(fields['categories'].split(','))-set(['']))\n",
    "sectors=list(set(fields['sectors'].split(','))-set(['']))\n",
    "segments=list(set(fields['segments'].split(','))-set(['']))\n",
    "subsegments=list(set(fields['subsegments'].split(','))-set(['']))\n",
    "subcategories=list(set(fields['subcategories'].split(','))-set(['']))\n",
    "\n",
    "national=fields['national']\n",
    "customareas=fields['customareas']\n",
    "print(fields['customareas'])\n",
    "if pd.isna(customareas):\n",
    "    customareas = ''\n",
    "areas = list(set(fields['areas'].split(','))-set(['']))+[customareas]\n",
    "areas = [a for a in areas if a != '']\n",
    "\n",
    "regions_RET = list(set(fields['regions_RET'].split(','))-set(['']))\n",
    "channels_RET = list(set(fields['channels_RET'].split(','))-set(['']))\n",
    "market_RET=list(set(fields['market_RET'].split(','))-set(['']))\n",
    "\n",
    "regions_CHAN=list(set(fields['regions_CHAN'].split(','))-set(['']))\n",
    "channels_CHAN=list(set(fields['channels_CHAN'].split(','))-set(['']))\n",
    "market_CHAN=list(set(fields['market_CHAN'].split(','))-set(['']))\n",
    "\n",
    "regions_CUST=list(set(fields['regions_CUST'].split(','))-set(['']))\n",
    "channels_CUST=list(set(fields['channels_CUST'].split(','))-set(['']))\n",
    "market_CUST=list(set(fields['market_CUST'].split(','))-set(['']))\n",
    "\n",
    "data_source=fields['data_source']\n",
    "\n",
    "years=list(set(fields['years'].split(','))-set(['']))\n",
    "years = {int(y) for y in fields['years'].split(',') if y}\n",
    "end_date=fields['end_date']\n",
    "\n",
    "brands_only=fields['brands_only']\n",
    "National=[\"NATIONAL\"]if national else []\n",
    "\n",
    "\n",
    "client_brands,ManufOrTopC,decimals,sign,currency,prodORitem,categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518195e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = regions_RET + regions_CHAN + regions_CUST\n",
    "channels = channels_RET + channels_CHAN + channels_CUST\n",
    "markets = market_RET + market_CHAN + market_CUST\n",
    "\n",
    "entity_hierarchy = [\n",
    "    (\"NATIONAL\",\"Area\",National),\n",
    "    (\"RETAILER\",\"Region\", regions_RET),\n",
    "    (\"RETAILER\",\"Channel\", channels_RET),\n",
    "    (\"RETAILER\",\"Market\", market_RET),\n",
    "    \n",
    "    (\"CHANNEL\",\"Region\", regions_CHAN),\n",
    "    (\"CHANNEL\",\"Channel\", channels_CHAN),\n",
    "    (\"CHANNEL\",\"Market\", market_CHAN),\n",
    "    \n",
    "    (\"REGION\",\"Region\", regions_REG),\n",
    "    (\"REGION\",\"Channel\", channels_REG),\n",
    "    (\"REGION\",\"Market\", market_REG),\n",
    "    \n",
    "    (f\"{customareas}\",\"Region\", regions_CUST),\n",
    "    (f\"{customareas}\",\"Channel\", channels_CUST),\n",
    "    (f\"{customareas}\",\"Market\", market_CUST)\n",
    "]\n",
    "entity_hierarchy = [\n",
    "    item for item in entity_hierarchy\n",
    "    if len(item) == 3 and item[2]  # item[2] is the entity list\n",
    "]\n",
    "\n",
    "hierarchy_levels = [\n",
    "    (\"Category\", categories),\n",
    "    (\"Sector\", sectors),\n",
    "    (\"Segment\", segments),\n",
    "    (\"SubSegment\", subsegments),\n",
    "    (\"SubCategory\", subcategories)\n",
    "]\n",
    "\n",
    "direct_parent = {\"Sector\":list(zip([\"Category\"]*len(categories),categories))\n",
    "                ,\"Segment\":list(zip([\"Sector\"]*len(sectors),sectors))\n",
    "                #,\"SubSegment\":list(zip([\"Segment\"]*len(sectors),sectors))\n",
    "                #,\"SubCategory\":list(zip([\"Segment\"]*len(segments),segments))\n",
    "                } \n",
    "\n",
    "# past_12_months = pd.date_range(end=end_date, periods=12, freq='ME').strftime('%b-%y').tolist()\n",
    "# past_3_months = pd.date_range(end=end_date, periods=3, freq='ME').strftime('%b-%y').tolist()\n",
    "# past_6_months = pd.date_range(end=end_date, periods=6, freq='ME').strftime('%b-%y').tolist()\n",
    "# p12m_dax = \"{\" + \", \".join(f'\"{date}\"' for date in past_12_months) + \"}\"\n",
    "# p3m_dax = \"{\" + \", \".join(f'\"{date}\"' for date in past_3_months) + \"}\"\n",
    "# p6m_dax = \"{\" + \", \".join(f'\"{date}\"' for date in past_6_months) + \"}\"\n",
    "\n",
    "# slides_Period=\"P3M\"\n",
    "# period=p12m_dax if slides_Period==\"P12M\" else p3m_dax if slides_Period==\"P3M\" else p6m_dax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29dccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_str = f\"Provider=MSOLAP.8;Data Source={server};Initial Catalog={dataset_name};\"\n",
    "path=os.path.join(os.getcwd(),\"Financials Datasets Test\")\n",
    "\n",
    "past_12_months = pd.date_range(end=end_date, periods=12, freq='ME').strftime('%b-%y').tolist()\n",
    "past_3_months = pd.date_range(end=end_date, periods=3, freq='ME').strftime('%b-%y').tolist()\n",
    "past_6_months = pd.date_range(end=end_date, periods=6, freq='ME').strftime('%b-%y').tolist()\n",
    "p12m_dax = \"{\" + \", \".join(f'\"{date}\"' for date in past_12_months) + \"}\"\n",
    "p3m_dax = \"{\" + \", \".join(f'\"{date}\"' for date in past_3_months) + \"}\"\n",
    "p6m_dax = \"{\" + \", \".join(f'\"{date}\"' for date in past_6_months) + \"}\"\n",
    "\n",
    "slides_Period=fields['slides_Period']\n",
    "period=p12m_dax if slides_Period==\"P12M\" else p3m_dax if slides_Period==\"P3M\" else p6m_dax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93db4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provider=MSOLAP.8;Data Source=powerbi://api.powerbi.com/v1.0/myorg/Groupe Bel;Initial Catalog=Bel France Dataset;\n"
     ]
    }
   ],
   "source": [
    "# client_manuf = [\"Bel\"]\n",
    "# client_brands = [\"Kiri\",\"La Vache Qui Rit\",\"Boursin\"]\n",
    "# decimals = 2\n",
    "# sign = \"After\"\n",
    "# currency = 'â‚¬'\n",
    "# currency = ' '+ currency if sign.lower() == 'after' else  currency + ' '\n",
    "# prodORitem = \"Item\"\n",
    "# categories = [\"Total Fromage\"]\n",
    "# sectors = [\"Soft Cheese\",\"Aperitif\"]\n",
    "# segments = [\"Enfant\",\"Frais A Tartiner\",\"Salade\"]\n",
    "# subsegments= []\n",
    "# subcategories= []\n",
    " \n",
    "# national = False\n",
    "# customareas= \"\"\n",
    "# areas = [\"RETAILER\"]\n",
    "\n",
    "# regions_RET  = [\"Carrefour\",\"Intermarche\"]\n",
    "# channels_RET = []\n",
    "# market_RET = []\n",
    "\n",
    "# regions_CHAN = [\"NICOLAS\"]\n",
    "# channels_CHAN = [\"NICOLAS QCN\",\"NICOLAS VCN\",\"NICOLAS QCT\",\"NICOLAS QCA\",\"NICOLAS CCP\"]\n",
    "# market_CHAN = []\n",
    " \n",
    "# regions_REG = []\n",
    "# channels_REG = [\"NICOLAS IDF\",\"NICOLAS PAC\",\"NICOLAS RHO\",\"NICOLAS AQU\",\"NICOLAS EST\"]\n",
    "# market_REG = []\n",
    " \n",
    "# regions_CUST = []\n",
    "# channels_CUST = []\n",
    "# market_CUST = []\n",
    "\n",
    "\n",
    "# data_source = \"DATA SOURCE: Client P&L\"\n",
    "# ManufOrTopC =\"Top Companies\"\n",
    "# BrandOrTopB=\"Top Brands\"\n",
    "# end_date = \"2025-08-01\"\n",
    "\n",
    "# National=[\"NATIONAL\"]if national else[]\n",
    "\n",
    "# entity_hierarchy = [\n",
    "#     (\"NATIONAL\",\"Area\",National),\n",
    "#     (\"RETAILER\",\"Region\", regions_RET),\n",
    "#     (\"RETAILER\",\"Channel\", channels_RET),\n",
    "#     (\"RETAILER\",\"Market\", market_RET),\n",
    "    \n",
    "#     (\"CHANNEL\",\"Region\", regions_CHAN),\n",
    "#     (\"CHANNEL\",\"Channel\", channels_CHAN),\n",
    "#     (\"CHANNEL\",\"Market\", market_CHAN),\n",
    "    \n",
    "#     (\"REGION\",\"Region\", regions_REG),\n",
    "#     (\"REGION\",\"Channel\", channels_REG),\n",
    "#     (\"REGION\",\"Market\", market_REG),\n",
    "    \n",
    "#     (f\"{customareas}\",\"Region\", regions_CUST),\n",
    "#     (f\"{customareas}\",\"Channel\", channels_CUST),\n",
    "#     (f\"{customareas}\",\"Market\", market_CUST)\n",
    "# ]\n",
    "# entity_hierarchy = [\n",
    "#     item for item in entity_hierarchy\n",
    "#     if len(item) == 3 and item[2]  # item[2] is the entity list\n",
    "# ]\n",
    "\n",
    "# hierarchy_levels = [\n",
    "#     (\"Category\", categories),\n",
    "#     (\"Sector\", sectors),\n",
    "#     (\"Segment\", segments),\n",
    "#     (\"SubSegment\", subsegments),\n",
    "#     (\"SubCategory\", subcategories)\n",
    "# ]\n",
    "\n",
    "# direct_parent = {\"Sector\":list(zip([\"Category\"]*len(categories),categories))\n",
    "#                 ,\"Segment\":list(zip([\"Sector\"]*len(sectors),sectors))\n",
    "#                 #,\"SubSegment\":list(zip([\"Segment\"]*len(sectors),sectors))\n",
    "#                 #,\"SubCategory\":list(zip([\"Segment\"]*len(segments),segments))\n",
    "#                 } \n",
    "# server = \"powerbi://api.powerbi.com/v1.0/myorg/Groupe Bel\"\n",
    "# dataset_name = \"Bel France Dataset\"\n",
    "# conn_str = f\"Provider=MSOLAP.8;Data Source={server};Initial Catalog={dataset_name};\"\n",
    "\n",
    "# print(conn_str)\n",
    "# path=os.path.join(os.getcwd(),\"Financials Datasets NewEX\")\n",
    "\n",
    "# past_12_months = pd.date_range(end=end_date, periods=12, freq='ME').strftime('%b-%y').tolist()\n",
    "# past_3_months = pd.date_range(end=end_date, periods=3, freq='ME').strftime('%b-%y').tolist()\n",
    "# past_6_months = pd.date_range(end=end_date, periods=6, freq='ME').strftime('%b-%y').tolist()\n",
    "# p12m_dax = \"{\" + \", \".join(f'\"{date}\"' for date in past_12_months) + \"}\"\n",
    "# p3m_dax = \"{\" + \", \".join(f'\"{date}\"' for date in past_3_months) + \"}\"\n",
    "# p6m_dax = \"{\" + \", \".join(f'\"{date}\"' for date in past_6_months) + \"}\"\n",
    "\n",
    "# slides_Period=\"P3M\"\n",
    "# period=p12m_dax if slides_Period==\"P12M\" else p3m_dax if slides_Period==\"P3M\" else p6m_dax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae80ffbf",
   "metadata": {},
   "source": [
    "### Slide 67(brands_client_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22cd52d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Frais A Tartiner Carrefour.\n",
      "Query executed successfully for Aperitif Carrefour.\n",
      "Query executed successfully for Enfant Carrefour.\n",
      "Query executed successfully for Soft Cheese Carrefour.\n",
      "Query executed successfully for Salade Carrefour.\n",
      "Query executed successfully for Total Fromage Carrefour.\n",
      "Query executed successfully for Soft Cheese Intermarche.\n",
      "Query executed successfully for Total Fromage Intermarche.\n",
      "Query executed successfully for Aperitif Intermarche.\n",
      "Query executed successfully for Frais A Tartiner Intermarche.\n",
      "Query executed successfully for Salade Intermarche.\n",
      "Query executed successfully for Enfant Intermarche.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def execute_dax_query(BrandorManuf,entity_name, area,market, hierby, entity_type):\n",
    "    outputdic = {}\n",
    "    columns=[\"Gross Margin %\",\"Gross Margin % IYA\",\"Gross Profit\",\"Net Sales\",\"Net Sales/Kg\",\"Net Sales/Kg IYA\",\"Volume Sales\",\"Trade Margin %\",\"Trade Profit\",\"Trade Profit/Kg\",\"Av Price/KG\",\"Value Sales IYA\",\"Value Sales\",\"Total WoB %\"]\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    dax_query = f\"\"\"\n",
    "    EVALUATE\n",
    "    CALCULATETABLE(\n",
    "        SUMMARIZE(\n",
    "            Products,\n",
    "            Products[{BrandorManuf}],  \n",
    "            {column_exprs}\n",
    "        ),\n",
    "        Products[Category] = \"{categories[0]}\",\n",
    "        Products[{ManufOrTopC}] = \"{client_manuf[0]}\",\n",
    "        \n",
    "        Products[{hierby}] = \"{entity_type}\",\n",
    "        TREATAS(\n",
    "            {period},\n",
    "            Calendar[MonthYear]\n",
    "        ),\n",
    "        FILTER('Market', 'Market'[Area] = \"{area}\"),\n",
    "    \n",
    "        TREATAS(\n",
    "            {{\"{entity_name}\"}},\n",
    "            Market[{market}]\n",
    "        ),\n",
    "        FILTER(\n",
    "            'Scope', \n",
    "            'Scope'[Scope] = \"{hierby}\"   \n",
    "        )\n",
    "    )   \n",
    "    \"\"\"\n",
    "    grandtotal_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                VALUES(Products[{hierby}]),  -- dummy base just to return a single row\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            Products[{ManufOrTopC}] = \"{client_manuf[0]}\",\n",
    "            \n",
    "            Products[{hierby}] = \"{entity_type}\",\n",
    "            TREATAS(\n",
    "                {period},\n",
    "                Calendar[MonthYear] \n",
    "            ),\n",
    "            FILTER('Market', 'Market'[Area] = \"{area}\"),\n",
    "            TREATAS(\n",
    "                {{\"{entity_name}\"}},\n",
    "                Market[{market}]\n",
    "            ),\n",
    "            FILTER(\n",
    "                'Scope', \n",
    "                'Scope'[Scope] = \"{hierby}\"   \n",
    "            )\n",
    "        )   \n",
    "    \"\"\"\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "                \n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(grandtotal_query)\n",
    "            grandtotal_columns = [desc[0] for desc in cursor.description]\n",
    "            grandtotal_data = cursor.fetchall()        \n",
    "                    \n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "            df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]\n",
    "        \n",
    "            dt = pd.DataFrame([grandtotal_data[0]], columns=[col.replace(']', '').split('[')[-1] for col in grandtotal_columns])\n",
    "            dt[df.columns[0]] = 'Grand Total'            \n",
    "            df = pd.concat([df, dt], ignore_index=True)\n",
    "            df = df.iloc[:, :-1]\n",
    "\n",
    "            \n",
    "            outputdic[f\"{client_manuf[0]} | {entity_type} | {entity_name}\"] = df\n",
    "            print(f\"Query executed successfully for {entity_type} {entity_name}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_type} {entity_name}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_type} {entity_name}: {e}\")\n",
    "    return outputdic\n",
    "\n",
    "# List of all entities to process\n",
    "\n",
    "brands_client_dfs = {}\n",
    "# **Threaded Execution**\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    futures = []\n",
    "    for area,market, entity_list in entity_hierarchy:\n",
    "        for entity in entity_list:\n",
    "            for hierby, hier_values in hierarchy_levels:\n",
    "                    for value in hier_values:\n",
    "                        futures.append(executor.submit(execute_dax_query, f\"{BrandOrTopB}\",entity, area,market,hierby, value))\n",
    "               \n",
    "    # Wait for all tasks to complete\n",
    "    for future in futures:\n",
    "        result=future.result()\n",
    "        brands_client_dfs.update(result)\n",
    "\n",
    "pd.to_pickle(brands_client_dfs, os.path.join(path,\"brands_client_dfs.pkl\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad6a863",
   "metadata": {},
   "source": [
    "### Slide 68 & 69 & 71 & 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0f86d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Enfant Intermarche.\n",
      "Query executed successfully for Total Fromage Intermarche.\n",
      "Query executed successfully for Aperitif Intermarche.\n",
      "Query executed successfully for Soft Cheese Intermarche.\n",
      "Query executed successfully for Aperitif Carrefour.\n",
      "Query executed successfully for Soft Cheese Carrefour.\n",
      "Query executed successfully for Total Fromage Carrefour.\n",
      "Query executed successfully for Enfant Carrefour.\n",
      "Query executed successfully for Frais A Tartiner Carrefour.\n",
      "Query executed successfully for Salade Carrefour.\n",
      "Query executed successfully for Frais A Tartiner Intermarche.\n",
      "Query executed successfully for Salade Intermarche.\n",
      "All DataFrames saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Financials Slide Duplicate\\Financials Datasets NewEX\\Sector_P12M_client_dfs.pkl.\n",
      "Query executed successfully for Enfant Intermarche.\n",
      "Query executed successfully for Total Fromage Intermarche.\n",
      "Query executed successfully for Aperitif Intermarche.\n",
      "Query executed successfully for Soft Cheese Intermarche.\n",
      "Query executed successfully for Aperitif Carrefour.\n",
      "Query executed successfully for Enfant Carrefour.\n",
      "Query executed successfully for Total Fromage Carrefour.\n",
      "Query executed successfully for Soft Cheese Carrefour.\n",
      "Query executed successfully for Salade Intermarche.\n",
      "Query executed successfully for Salade Carrefour.\n",
      "Query executed successfully for Frais A Tartiner Intermarche.\n",
      "Query executed successfully for Frais A Tartiner Carrefour.\n",
      "All DataFrames saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Financials Slide Duplicate\\Financials Datasets NewEX\\Segment_P12M_client_dfs.pkl.\n",
      "Query executed successfully for Soft Cheese Carrefour.\n",
      "Query executed successfully for Aperitif Carrefour.\n",
      "Query executed successfully for Total Fromage Carrefour.\n",
      "Query executed successfully for Enfant Carrefour.\n",
      "Query executed successfully for Soft Cheese Intermarche.\n",
      "Query executed successfully for Enfant Intermarche.\n",
      "Query executed successfully for Total Fromage Intermarche.\n",
      "Query executed successfully for Aperitif Intermarche.\n",
      "Query executed successfully for Frais A Tartiner Intermarche.\n",
      "Query executed successfully for Frais A Tartiner Carrefour.\n",
      "Query executed successfully for Salade Carrefour.\n",
      "Query executed successfully for Salade Intermarche.\n",
      "All DataFrames saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Financials Slide Duplicate\\Financials Datasets NewEX\\Sector_P3M_client_dfs.pkl.\n",
      "Query executed successfully for Soft Cheese Carrefour.\n",
      "Query executed successfully for Aperitif Carrefour.\n",
      "Query executed successfully for Aperitif Intermarche.\n",
      "Query executed successfully for Total Fromage Intermarche.\n",
      "Query executed successfully for Enfant Intermarche.\n",
      "Query executed successfully for Soft Cheese Intermarche.\n",
      "Query executed successfully for Total Fromage Carrefour.\n",
      "Query executed successfully for Enfant Carrefour.\n",
      "Query executed successfully for Frais A Tartiner Carrefour.\n",
      "Query executed successfully for Frais A Tartiner Intermarche.\n",
      "Query executed successfully for Salade Carrefour.\n",
      "Query executed successfully for Salade Intermarche.\n",
      "All DataFrames saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Financials Slide Duplicate\\Financials Datasets NewEX\\Segment_P3M_client_dfs.pkl.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def execute_dax_query(BrandorManuf,entity_name, area,market, hierby, entity_type,Monthyear,ke):\n",
    "    outputdic = {}\n",
    "\n",
    "    columns=[\"Value Sales\",\"Value Sales IYA\",\"Trade Margin %\",\"Trade Margin % DYA\",\"Net Sales\",\"Net Sales/Kg\",\"Gross Profit/Kg\",\"Gross Margin %\",\"Trade Profit IYA\",\"VSOD IYA\",\"Av Price/KG\",\"VAT/Kg\",\"Total COGS/Kg\",\"Trade Profit/Kg\",\"Rate of Sales\",\"WD\",\"Total WoB %\"]\n",
    "\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    dax_query = f\"\"\"\n",
    "    EVALUATE\n",
    "    CALCULATETABLE(\n",
    "        SUMMARIZE(\n",
    "            Products,\n",
    "            Products[{ke}], \n",
    "            {column_exprs}            \n",
    "        ),\n",
    "        Products[Category] = \"{categories[0]}\",\n",
    "        Products[{ManufOrTopC}] = \"{client_manuf[0]}\",\n",
    "\n",
    "        TREATAS(\n",
    "            {Monthyear},\n",
    "            Calendar[MonthYear]\n",
    "        ),\n",
    "        FILTER('Market', 'Market'[Area] = \"{area}\"),\n",
    "    \n",
    "        TREATAS(\n",
    "            {{\"{entity_name}\"}},\n",
    "            Market[{market}]\n",
    "        ),\n",
    "        FILTER(\n",
    "            'Scope', \n",
    "            'Scope'[Scope] = \"Category\"   \n",
    "        )\n",
    "    )   \n",
    "    \"\"\"\n",
    "    grandtotal_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                VALUES(Products[Category]),  -- dummy base just to return a single row\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            Products[{ManufOrTopC}] = \"{client_manuf[0]}\",\n",
    "            TREATAS(\n",
    "                {Monthyear},\n",
    "                Calendar[MonthYear]\n",
    "            ),\n",
    "            FILTER('Market', 'Market'[Area] = \"{area}\"),\n",
    "            TREATAS(\n",
    "                {{\"{entity_name}\"}},\n",
    "                Market[{market}]\n",
    "            ),\n",
    "            FILTER(\n",
    "                'Scope', \n",
    "                'Scope'[Scope] = \"Category\"   \n",
    "            )\n",
    "        )   \n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "                \n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(grandtotal_query)\n",
    "            grandtotal_columns = [desc[0] for desc in cursor.description]\n",
    "            grandtotal_data = cursor.fetchall()        \n",
    "                    \n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "            df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]\n",
    "        \n",
    "            dt = pd.DataFrame([grandtotal_data[0]], columns=[col.replace(']', '').split('[')[-1] for col in grandtotal_columns])\n",
    "            dt[df.columns[0]] = 'Grand Total'            \n",
    "            df = pd.concat([df, dt], ignore_index=True)\n",
    "            df = df.iloc[:, :-1]\n",
    "\n",
    "            \n",
    "            outputdic[f\"{categories[0]} | {client_manuf[0]} | {entity_name}\"] = df\n",
    "            print(f\"Query executed successfully for {entity_type} {entity_name}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_type} {entity_name}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_type} {entity_name}: {e}\")\n",
    "    return outputdic\n",
    "\n",
    "# List of all entities to process\n",
    "\n",
    "brands_client_dfs = {}\n",
    "def process_dax_queries(entity_hierarchy, hierarchy_levels,Monthyear):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = []\n",
    "        dfs_results = {} \n",
    "        futures = {}\n",
    "        ordered_keys=[]\n",
    "        for ke, val in direct_parent.items():\n",
    "            for hierby, hier_values in hierarchy_levels:\n",
    "                for value in hier_values:\n",
    "                    for area,market, entity_list in entity_hierarchy:\n",
    "                        for entity in entity_list:\n",
    "                            key =  f\"{client_manuf[0]} | {value} | {entity}\"\n",
    "                            ordered_keys.append(key) \n",
    "                            future = executor.submit(execute_dax_query, f\"{BrandOrTopB}\", entity, area,market, hierby, value,Monthyear,ke)\n",
    "                            futures[future] = key\n",
    "\n",
    "\n",
    "            temp_results = {}\n",
    "            for future in as_completed(futures):\n",
    "                key = futures[future]\n",
    "                result = future.result()\n",
    "                dfs_results.update(result)\n",
    "\n",
    "\n",
    "            # Insert results in original order\n",
    "            for key in ordered_keys:\n",
    "                if key in temp_results:\n",
    "                    dfs_results[key] = temp_results[key]\n",
    "            if  Monthyear== p12m_dax:\n",
    "                filename =  f\"{ke}_P12M_client_dfs.pkl\"\n",
    "            else:\n",
    "                filename =  f\"{ke}_P3M_client_dfs.pkl\"\n",
    "\n",
    "            output_file = f\"{path}\\\\{filename}\"\n",
    "            with open(output_file, \"wb\") as f:\n",
    "                pd.to_pickle(dfs_results, f)\n",
    "            \n",
    "            print(f\"All DataFrames saved to {output_file}.\")\n",
    "\n",
    "\n",
    "process_dax_queries(entity_hierarchy, hierarchy_levels,p12m_dax)\n",
    "process_dax_queries(entity_hierarchy, hierarchy_levels,p3m_dax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b30c399",
   "metadata": {},
   "source": [
    "### Slide 70 &73 &74(Product P12M &P3M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94f14e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Aperitif Intermarche.\n",
      "Query executed successfully for Total Fromage Intermarche.\n",
      "Query executed successfully for Enfant Intermarche.\n",
      "Query executed successfully for Enfant Carrefour.\n",
      "Query executed successfully for Total Fromage Carrefour.\n",
      "Query executed successfully for Aperitif Carrefour.\n",
      "Query executed successfully for Soft Cheese Intermarche.\n",
      "Query executed successfully for Soft Cheese Carrefour.\n",
      "Query executed successfully for Frais A Tartiner Carrefour.\n",
      "Query executed successfully for Salade Carrefour.\n",
      "Query executed successfully for Salade Intermarche.\n",
      "Query executed successfully for Frais A Tartiner Intermarche.\n",
      "All DataFrames saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Financials Slide Duplicate\\Financials Datasets NewEX\\product_P12M_dfs.pkl.\n",
      "Query executed successfully for Total Fromage Carrefour.\n",
      "Query executed successfully for Aperitif Carrefour.\n",
      "Query executed successfully for Aperitif Intermarche.\n",
      "Query executed successfully for Enfant Intermarche.\n",
      "Query executed successfully for Enfant Carrefour.\n",
      "Query executed successfully for Total Fromage Intermarche.\n",
      "Query executed successfully for Soft Cheese Intermarche.\n",
      "Query executed successfully for Soft Cheese Carrefour.\n",
      "Query executed successfully for Salade Carrefour.\n",
      "Query executed successfully for Frais A Tartiner Intermarche.\n",
      "Query executed successfully for Frais A Tartiner Carrefour.\n",
      "Query executed successfully for Salade Intermarche.\n",
      "All DataFrames saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Financials Slide Duplicate\\Financials Datasets NewEX\\product_P3M_dfs.pkl.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def execute_dax_query(BrandorManuf,entity_name, area,market, hierby, entity_type,Monthyear):\n",
    "    outputdic = {}\n",
    "    columns=[\"WD\",\"Gross Profit/Unit\",\"VAT/Unit\",\"Net Sales\",\"Net Sales/Kg\",\"Net Sales/Unit\",\"Gross Margin %\",\"Trade Margin %\",\"Trade Profit/Unit\",\"Av Price/Unit\",\"Total COGS/Unit\",f\"{prodORitem} Sales Rate\",\"Value Sales IYA\"]\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    dax_query = f\"\"\"\n",
    "    EVALUATE\n",
    "    CALCULATETABLE(\n",
    "        SUMMARIZE(\n",
    "            Products,\n",
    "            Products[{BrandorManuf}], \n",
    "            Products[{prodORitem}], \n",
    "            {column_exprs}            \n",
    "        ),\n",
    "        Products[Category] = \"{categories[0]}\",\n",
    "        Products[{ManufOrTopC}] = \"{client_manuf[0]}\",\n",
    "\n",
    "        Products[{hierby}] = \"{entity_type}\",\n",
    "        TREATAS(\n",
    "            {Monthyear},\n",
    "            Calendar[MonthYear]\n",
    "        ),\n",
    "        FILTER('Market', 'Market'[Area] = \"{area}\"),\n",
    "        TREATAS(\n",
    "            {{\"{entity_name}\"}},\n",
    "            Market[{market}]\n",
    "        ),\n",
    "        FILTER(\n",
    "            'Scope', \n",
    "            'Scope'[Scope] = \"{hierby}\"   \n",
    "        )\n",
    "    )   \n",
    "    \"\"\"\n",
    "    grandtotal_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                VALUES(Products[{hierby}]),  -- dummy base just to return a single row\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            Products[{ManufOrTopC}] = \"{client_manuf[0]}\",\n",
    "            Products[{hierby}] = \"{entity_type}\",\n",
    "            TREATAS(\n",
    "                {Monthyear},\n",
    "                Calendar[MonthYear]\n",
    "            ),\n",
    "            FILTER('Market', 'Market'[Area] = \"{area}\"),\n",
    "            TREATAS(\n",
    "                {{\"{entity_name}\"}},\n",
    "                Market[{market}]\n",
    "            ),\n",
    "            FILTER(\n",
    "                'Scope', \n",
    "                'Scope'[Scope] = \"{hierby}\"   \n",
    "            )\n",
    "        )   \n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "                \n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(grandtotal_query)\n",
    "            grandtotal_columns = [desc[0] for desc in cursor.description]\n",
    "            grandtotal_data = cursor.fetchall()        \n",
    "                    \n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "            df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]\n",
    "        \n",
    "            dt = pd.DataFrame([grandtotal_data[0]], columns=[col.replace(']', '').split('[')[-1] for col in grandtotal_columns])\n",
    "            dt[df.columns[0]] = 'Grand Total'            \n",
    "            df = pd.concat([df, dt], ignore_index=True)\n",
    "            df = df.iloc[:, :-1]\n",
    "\n",
    "            \n",
    "            outputdic[f\"{client_manuf[0]} | {entity_type} | {entity_name}\"] = df\n",
    "            print(f\"Query executed successfully for {entity_type} {entity_name}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_type} {entity_name}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_type} {entity_name}: {e}\")\n",
    "    return outputdic\n",
    "\n",
    "# List of all entities to process\n",
    "\n",
    "brands_client_dfs = {}\n",
    "def process_dax_queries(entity_hierarchy, hierarchy_levels,Monthyear):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = []\n",
    "        dfs_results = {} \n",
    "        futures = {}\n",
    "        ordered_keys=[]\n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "            for value in hier_values:\n",
    "                for area,market, entity_list in entity_hierarchy:\n",
    "                    for entity in entity_list:\n",
    "                        key =  f\"{client_manuf[0]} | {value} | {entity}\"\n",
    "                        ordered_keys.append(key)  # <-- Add this line\n",
    "                        future = executor.submit(execute_dax_query, f\"{BrandOrTopB}\", entity, area,market,hierby, value,Monthyear)\n",
    "                        futures[future] = key\n",
    "\n",
    "\n",
    "        temp_results = {}\n",
    "        for future in as_completed(futures):\n",
    "            key = futures[future]\n",
    "            result = future.result()\n",
    "            dfs_results.update(result)\n",
    "\n",
    "\n",
    "        # Insert results in original order\n",
    "        for key in ordered_keys:\n",
    "            if key in temp_results:\n",
    "                dfs_results[key] = temp_results[key]\n",
    "        if  Monthyear== p12m_dax:\n",
    "            filename =  f\"product_P12M_dfs.pkl\"\n",
    "        else:\n",
    "            filename =  f\"product_P3M_dfs.pkl\"\n",
    "\n",
    "        output_file = f\"{path}\\\\{filename}\"\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            pd.to_pickle(dfs_results, f)\n",
    "        \n",
    "        print(f\"All DataFrames saved to {output_file}.\")\n",
    "\n",
    "\n",
    "process_dax_queries(entity_hierarchy, hierarchy_levels,p12m_dax)\n",
    "process_dax_queries(entity_hierarchy, hierarchy_levels,p3m_dax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff321a9e",
   "metadata": {},
   "source": [
    "### DataFrames_By Markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdeeb5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Market[Region]']\n",
      "Query executed successfully for Segment | ['Market[Region]'].\n",
      "Query executed successfully for Segment | ['Market[Region]'].\n",
      "Query executed successfully for Category | ['Market[Region]'].\n",
      "Query executed successfully for Segment | ['Market[Region]'].\n",
      "Query executed successfully for Sector | ['Market[Region]'].\n",
      "Query executed successfully for Sector | ['Market[Region]'].\n",
      "Query executed successfully for Category | ['Market[Region]'].\n",
      "Query executed successfully for Segment | ['Market[Region]'].\n",
      "Query executed successfully for Sector | ['Market[Region]'].\n",
      "Query executed successfully for Segment | ['Market[Region]'].\n",
      "Query executed successfully for Segment | ['Market[Region]'].\n",
      "Query executed successfully for Sector | ['Market[Region]'].\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(hierby, Monthyear, area, entity_type=None, row_field=None):\n",
    "    outputdic = {}\n",
    "    key = f\"{client_manuf[0]} | {entity_type}\"\n",
    "\n",
    "    columns = [\n",
    "        \"Gross Margin %\", \"Gross Margin % IYA\", 'Net Sales',\n",
    "        \"Net Sales/Kg\", \"Net Sales/Kg IYA\", \"Value Sales IYA\"\n",
    "    ]\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "    if isinstance(row_field, list):\n",
    "        row_field_str = \", \".join(col.replace(\"'\", \"\").replace('\"', \"\") for col in row_field)\n",
    "    else:\n",
    "        row_field_str = row_field\n",
    "    row_field_frist = row_field if isinstance(row_field, str) else row_field[0]\n",
    "        \n",
    "    # print(row_field_frist)\n",
    "\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(Market, {row_field_str}),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            \n",
    "            TREATAS({Monthyear}, Calendar[MonthYear]),\n",
    "            FILTER(Products, Products[Category] = \"{categories[0]}\"),\n",
    "            FILTER(Products, Products[{ManufOrTopC}] = \"{client_manuf[0]}\"),\n",
    "            FILTER(Products, Products[{hierby}] = \"{entity_type}\"),\n",
    "            Filter(Market,Market[Area]=\"{area}\"),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    parent_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(Market, {row_field_frist}),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            \n",
    "            TREATAS({Monthyear}, Calendar[MonthYear]),\n",
    "            FILTER(Products, Products[Category] = \"{categories[0]}\"),\n",
    "            FILTER(Products, Products[{ManufOrTopC}] = \"{client_manuf[0]}\"),\n",
    "            FILTER(Products, Products[{hierby}] = \"{entity_type}\"),\n",
    "            Filter(Market,Market[Area]=\"{area}\"),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"Category\")\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    grandtotal_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                VALUES(Products[Category]),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            Products[{ManufOrTopC}] = \"{client_manuf[0]}\",\n",
    "            Products[{hierby}] = \"{entity_type}\",\n",
    "            TREATAS({Monthyear}, Calendar[MonthYear]),\n",
    "            Filter(Market,Market[Area]=\"{area}\"),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            result_columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "        \n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(parent_query)\n",
    "            parent_columns = [desc[0] for desc in cursor.description]\n",
    "            parenttotal = cursor.fetchall()   \n",
    "            \n",
    "\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(grandtotal_query)\n",
    "            grandtotal_columns = [desc[0] for desc in cursor.description]\n",
    "            grandtotal_data = cursor.fetchall()\n",
    "\n",
    "\n",
    "\n",
    "        df = pd.DataFrame(data, columns=result_columns)\n",
    "        df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "        df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]\n",
    "        \n",
    "        parenttotal_df = pd.DataFrame(parenttotal, columns=parent_columns)\n",
    "        parenttotal_df.columns = parenttotal_df.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "        parenttotal_df = parenttotal_df.loc[~(parenttotal_df.select_dtypes(include='number') == 0).all(axis=1)]\n",
    "\n",
    "        if parenttotal_df.shape[1] > 0:\n",
    "            parenttotal_df.iloc[:, 0] = parenttotal_df.iloc[:, 0].astype(str) +\" Total\" \n",
    "   \n",
    "        # if parenttotal_df.empty:\n",
    "        #     outputdic[key] = parenttotal_df\n",
    "        #     return outputdic\n",
    "        # if not parenttotal_df.empty:\n",
    "        #     df = pd.concat([parenttotal_df, df], ignore_index=True)\n",
    "    \n",
    "\n",
    "        if grandtotal_data:\n",
    "            dt = pd.DataFrame([grandtotal_data[0]], columns=[col.replace(']', '').split('[')[-1] for col in grandtotal_columns])\n",
    "            dt[df.columns[0]] = 'Grand Total'\n",
    "            df = pd.concat([df, dt], ignore_index=True)\n",
    "            df = df.iloc[:, :-1]  # Remove duplicate column if needed\n",
    "       \n",
    "        df =pd.concat([df,parenttotal_df],ignore_index=True)\n",
    "        # print(df.columns)\n",
    "        outputdic[key] = df\n",
    "        print(f\"Query executed successfully for {hierby} | {row_field}.\")\n",
    "\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {hierby} {entity_type} | {row_field}: {db_error}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "def process_dax_queries(hierarchy_levels, Monthyear, area, row_list):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "            dfs_results = {}\n",
    "            futures = [\n",
    "                executor.submit(execute_dax_query, hierby, Monthyear, area, value, row_list)\n",
    "                for hierby, hier_values in hierarchy_levels\n",
    "                for value in hier_values\n",
    "            ]\n",
    "                 \n",
    "            for future in as_completed(futures):\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    dfs_results.update(result)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing query: {e}\")\n",
    "\n",
    "            if area == \"RETAILER\":\n",
    "                if Monthyear==p12m_dax:\n",
    "                    filename = \"retailers_P12M_dfs.pkl\"\n",
    "                else:\n",
    "                    filename = \"retailers_P3M_dfs.pkl\"\n",
    "            elif area == \"CHANNEL\":\n",
    "                if Monthyear==p12m_dax:\n",
    "                    filename = \"channel_P12M_dfs.pkl\"\n",
    "                else:    \n",
    "                    filename = \"channel_P3M_dfs.pkl\"\n",
    "            \n",
    "            elif area == \"REGION\":\n",
    "                if Monthyear==p12m_dax:\n",
    "                    filename = \"region_P12M_dfs.pkl\"\n",
    "                else:    \n",
    "                    filename = \"region_P3M_dfs.pkl\"\n",
    "                    \n",
    "            elif area == customareas:\n",
    "                if Monthyear==p12m_dax:\n",
    "                    filename = \"cust_P12M_dfs.pkl\"\n",
    "                else:    \n",
    "                    filename = \"cust_P3M_dfs.pkl\"\n",
    "                    \n",
    "            else:\n",
    "                filename = f\"{area.lower()}_dfs.pkl\"\n",
    "\n",
    "            output_file = f\"{path}\\\\{filename}\"\n",
    "            with open(output_file, \"wb\") as f:\n",
    "                pd.to_pickle(dfs_results, f)\n",
    "\n",
    "            # print(f\"Saved DataFrames for {row_field} to {output_file}.\")\n",
    "\n",
    "\n",
    "# Final Calls\n",
    "if \"RETAILER\" in areas:\n",
    "    RET_list = []\n",
    "    if regions_RET: RET_list.append('Market[Region]')\n",
    "    if channels_RET: RET_list.append('Market[Channel]')\n",
    "    if market_RET: RET_list.append('Market[Market]')\n",
    "    print(RET_list)\n",
    "    process_dax_queries(hierarchy_levels, p12m_dax, \"RETAILER\", RET_list)\n",
    "    process_dax_queries(hierarchy_levels, p3m_dax, \"RETAILER\", RET_list)\n",
    "\n",
    "    \n",
    "\n",
    "if \"CHANNEL\" in areas:\n",
    "    CHA_list = []\n",
    "    if regions_CHAN: CHA_list.append('Market[Region]')\n",
    "    if channels_CHAN: CHA_list.append('Market[Channel]')\n",
    "    if market_CHAN: CHA_list.append('Market[Market]')\n",
    "    process_dax_queries(hierarchy_levels, p12m_dax, \"CHANNEL\", CHA_list)\n",
    "    process_dax_queries(hierarchy_levels, p3m_dax, \"CHANNEL\", CHA_list)\n",
    "    \n",
    "if \"REGION\" in areas:\n",
    "    REG_list = []\n",
    "    if regions_REG: REG_list.append('Market[Region]')\n",
    "    if channels_REG: REG_list.append('Market[Channel]')\n",
    "    if market_REG: REG_list.append('Market[Market]')\n",
    "    process_dax_queries(hierarchy_levels, p12m_dax, \"REGION\", REG_list)\n",
    "    process_dax_queries(hierarchy_levels, p3m_dax, \"REGION\", REG_list)\n",
    "        \n",
    "\n",
    "if customareas in areas:\n",
    "    CUST_list = []\n",
    "    if regions_CUST: CUST_list.append('Market[Region]')\n",
    "    if channels_CUST: CUST_list.append('Market[Channel]')\n",
    "    if market_CUST: CUST_list.append('Market[Market]')\n",
    "    process_dax_queries(hierarchy_levels, p12m_dax, customareas, CUST_list)\n",
    "    process_dax_queries(hierarchy_levels, p3m_dax, customareas, CUST_list)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305c0d4b",
   "metadata": {},
   "source": [
    "### Slide 75(Manuf_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c23447cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Soft Cheese Carrefour.\n",
      "Query executed successfully for Enfant Carrefour.\n",
      "Query executed successfully for Total Fromage Carrefour.\n",
      "Query executed successfully for Aperitif Carrefour.\n",
      "Query executed successfully for Aperitif Intermarche.\n",
      "Query executed successfully for Total Fromage Intermarche.\n",
      "Query executed successfully for Soft Cheese Intermarche.\n",
      "Query executed successfully for Enfant Intermarche.\n",
      "Query executed successfully for Frais A Tartiner Intermarche.\n",
      "Query executed successfully for Salade Intermarche.\n",
      "Query executed successfully for Salade Carrefour.\n",
      "Query executed successfully for Frais A Tartiner Carrefour.\n",
      "All DataFrames saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Financials Slide Duplicate\\Financials Datasets NewEX\\manuf_Sector_dfs.\n",
      "Query executed successfully for Enfant Carrefour.\n",
      "Query executed successfully for Aperitif Carrefour.\n",
      "Query executed successfully for Total Fromage Carrefour.\n",
      "Query executed successfully for Soft Cheese Carrefour.\n",
      "Query executed successfully for Soft Cheese Intermarche.\n",
      "Query executed successfully for Enfant Intermarche.\n",
      "Query executed successfully for Aperitif Intermarche.\n",
      "Query executed successfully for Total Fromage Intermarche.\n",
      "Query executed successfully for Salade Carrefour.\n",
      "Query executed successfully for Frais A Tartiner Carrefour.\n",
      "Query executed successfully for Salade Intermarche.\n",
      "Query executed successfully for Frais A Tartiner Intermarche.\n",
      "All DataFrames saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Financials Slide Duplicate\\Financials Datasets NewEX\\manuf_Segment_dfs.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(entity_name, area,market, hierby, entity_type, ke):\n",
    "    outputdic = {}\n",
    "    \n",
    "    columns = [\n",
    "        \"Volume Sales\", \"Value Share\", \"Value Sales\", \"Value Sales IYA\", \"Trade Margin %\",\n",
    "        \"Net Sales\", \"Net Sales/Kg\", \"Gross Profit/Kg\", \"Gross Margin %\", \"Gross to Net IYA\",\n",
    "        \"VSOD IYA\", \"Av Price/KG\", \"VAT/Kg\", \"Total COGS/Kg\", \"Trade Profit/Kg\",\n",
    "        \"Rate of Sales\", \"WD\", \"Total WoB %\", \"Trade Profit\", \"Gross Profit\"\n",
    "    ]\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    base_filters = f\"\"\"\n",
    "        Products[Category] = \"{categories[0]}\",\n",
    "        TREATAS({period}, Calendar[MonthYear]),\n",
    "        FILTER('Market', 'Market'[Area] = \"{area}\"),\n",
    "        TREATAS({{ \"{entity_name}\" }}, Market[{market}]),\n",
    "        FILTER('Scope', 'Scope'[Scope] = \"Category\")\n",
    "    \"\"\"\n",
    "\n",
    "    dax_query = f\"\"\"\n",
    "    EVALUATE\n",
    "    CALCULATETABLE(\n",
    "        SUMMARIZE(\n",
    "            Products,\n",
    "            Products[{ManufOrTopC}], \n",
    "            Products[{ke}], \n",
    "            {column_exprs}\n",
    "        ),\n",
    "        {base_filters}\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    totalcol_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                VALUES(Products[{ManufOrTopC}]), \n",
    "                {column_exprs}\n",
    "            ),\n",
    "            {base_filters}\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    grandtotal_query = f\"\"\"\n",
    "    EVALUATE\n",
    "    CALCULATETABLE(\n",
    "        ADDCOLUMNS(\n",
    "            VALUES(Products[Category]),\n",
    "            {column_exprs}\n",
    "        ),\n",
    "        {base_filters}\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Main Data\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns_out = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "        df = pd.DataFrame(data, columns=columns_out)\n",
    "        df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "        df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]\n",
    "\n",
    "        # Total by entity\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(totalcol_query)\n",
    "            totalcol_columns = [desc[0] for desc in cursor.description]\n",
    "            totalcol_data = cursor.fetchall()\n",
    "        maintotal_df = pd.DataFrame(totalcol_data, columns=totalcol_columns)\n",
    "        maintotal_df.columns = maintotal_df.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "        maintotal_df = maintotal_df.loc[~(maintotal_df.select_dtypes(include='number') == 0).all(axis=1)]\n",
    "\n",
    "        maintotal_df[\"Top Companies\"] = maintotal_df[\"Top Companies\"].astype(str) + \" Total\"\n",
    "\n",
    "        # Grand total\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(grandtotal_query)\n",
    "            grandtotal_columns = [desc[0] for desc in cursor.description]\n",
    "            grandtotal_data = cursor.fetchall()\n",
    "        dt = pd.DataFrame([grandtotal_data[0]], columns=[col.replace(']', '').split('[')[-1] for col in grandtotal_columns])\n",
    "        dt[df.columns[0]] = 'Grand Total'\n",
    "\n",
    "        # Combine all\n",
    "        df_with_totals = pd.concat([maintotal_df, dt], ignore_index=True)\n",
    "        \n",
    "        df= pd.concat([df, df_with_totals], ignore_index=True)\n",
    "        df = df.iloc[:, :-1]\n",
    "\n",
    "        outputdic[f\"{categories[0]} | {entity_name}\"] = df\n",
    "        \n",
    "        print(f\"Query executed successfully for {entity_type} {entity_name}.\")\n",
    "\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_type} {entity_name}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_type} {entity_name}: {e}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "def process_dax_queries(entity_hierarchy, hierarchy_levels):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        for ke, val in direct_parent.items():\n",
    "            futures = {}\n",
    "            ordered_keys = []\n",
    "            for hierby, hier_values in hierarchy_levels:\n",
    "                for value in hier_values:\n",
    "                    for area,market, entity_list in entity_hierarchy:\n",
    "                        for entity in entity_list:\n",
    "                            key = f\"{categories[0]} | {entity}\"\n",
    "                            ordered_keys.append(key)\n",
    "                            future = executor.submit(execute_dax_query, entity, area,market,hierby, value, ke)\n",
    "                            futures[future] = key\n",
    "\n",
    "            temp_results = {}\n",
    "            for future in as_completed(futures):\n",
    "                key = futures[future]\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    temp_results.update(result)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to process {key}: {e}\")\n",
    "\n",
    "            dfs_results = {}\n",
    "            for key in ordered_keys:\n",
    "                if key in temp_results:\n",
    "                    dfs_results[key] = temp_results[key]\n",
    "\n",
    "            filename = f\"manuf_{ke}_dfs\"\n",
    "            output_file = f\"{path}\\\\{filename}\"\n",
    "            with open(output_file, \"wb\") as f:\n",
    "                pd.to_pickle(dfs_results, f)\n",
    "\n",
    "            print(f\"All DataFrames saved to {output_file}.\")\n",
    "process_dax_queries(entity_hierarchy, hierarchy_levels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "710d5d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = {}\n",
    "datasets_path =os.getcwd()+\"\\\\Financials Datasets NewEX\\\\\"\n",
    "datasets = os.listdir(datasets_path)\n",
    "for d in datasets:\n",
    "    with open(datasets_path+d, 'rb') as handle:\n",
    "        globals()[d.split('.')[0]] = pd.read_pickle(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226556b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a905818a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
