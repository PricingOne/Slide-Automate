{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "15a454f5-c4e1-460c-a27d-40aa00dfcac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"..\\general_functions\\generalFunctions.ipynb\"\n",
    "%run \"..\\Promotion Slide Duplicate\\Promotion Replacement Function.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6999d128",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06b6fbff-4bd3-4c15-8d5d-f3b65886bc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_type = False\n",
    "\n",
    "normalized = True\n",
    "national = False \n",
    "\n",
    "display_share = False  # True if Available\n",
    "feature_share = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ff0039",
   "metadata": {},
   "outputs": [],
   "source": [
    "ManufOrTopC =\"Top Companies\" \n",
    "BrandOrTopB = \"Top Brands\"\n",
    "\n",
    "client_manuf = [\"Edgewell\"]\n",
    "client_brands = [\"Hawaiian Tropic\", \"Banana Boat\", \"Beauty Care\"]\n",
    "decimals = 2\n",
    "sign = \"Before\"\n",
    "currency = '$'\n",
    "currency = ' '+ currency if sign.lower() == 'after' else  currency + ' '\n",
    "\n",
    "categories = [\"Sun Care\"]\n",
    "sectors = [\"Sunscreen\",\"Banded Pack\",\"Tanning\",\"After Sun\"]\n",
    "segments = [\"Sunscreen Adults\", \"Sunscreen Baby\", \"Sunscreen Kids\"]\n",
    "subsegments= [\"Sunscreen Cosmetics\", \"Sunscreen Derma\", \"Sunscreen Sport\"]\n",
    "subcategories= [\"No Spray Crema\", \"No Spray Liquido\", \"No Spray Gel\", \"No Spray Fluido\", \"Spray Liquido\"]\n",
    "\n",
    "customareas='AUTOS SCANNING'\n",
    "national = False\n",
    "areas = [\"RETAILER\", \"CHANNEL\", f\"{customareas}\"]\n",
    " \n",
    "regions_RET  = [\"Walmart\"]\n",
    "channels_RET = [\"Walmart Supercenter\", \"Bodega Aurrera\", \"Walmart Express\",\t\"Mi Bodega\"]\n",
    "market_RET = []\n",
    " \n",
    "regions_CHAN = [\"Canal Moderno\"]\n",
    "channels_CHAN = []\n",
    "market_CHAN = []\n",
    " \n",
    "regions_CUST = [\"Autos Scanning\"]\n",
    "channels_CUST = []\n",
    "market_CUST = []\n",
    "\n",
    "data_source = \"DATA SOURCE: Trade Panel/Retailer Data | April  2025\"\n",
    "years = ['2023', '2024','2025']\n",
    "\n",
    "subcatg_parent = \"Segment\"\n",
    "subcatg_parent_list = segments\n",
    "percent = 1000\n",
    "percentstr=\"'000\"\n",
    "\n",
    "\n",
    "\n",
    "# Add one month to the original ending date (YYYY-MM-01)\n",
    "start_date = \"2022-02-01\"\t\n",
    "end_date = \"2025-05-01\"\n",
    "prodORitem = \"SKU\"\n",
    "\n",
    "\n",
    "# Guidline Promo Columns ex :Volume Uplift >>> \"[Measures].[Volume Uplift IYA]\" using filter_dictionary_keys(fieldsNamePosition, 'Volume Upli')\n",
    "#promo_col = ['[Measures].[Straight Discount 10-20 Sales]','[Measures].[Straight Discount 20-30 Sales]', '[Measures].[Straight Discount 30-40 Sales]','[Measures].[Straight Discount 40+ Sales]']\n",
    "promo_col = []\n",
    "selectedBrands = client_brands \n",
    "marketList = regions_RET + channels_RET + market_RET + regions_CHAN + channels_CHAN + market_CHAN \n",
    "notInScope = []\n",
    "OpenEditData=True\n",
    "direct_parent = {\"Sector\":\"Category\",\n",
    "                \"Segment\":\"Sector\",\n",
    "                \"SubSegment\":\"Segment\", \n",
    "                \"SubCategory\":\"Segment\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d93407ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# max_total_size = {\n",
    "#         'Rossmann | Male Shaving': 7.76779931984066,\n",
    "#         'Rossmann | Male Dispo': 9.39896018537874,\n",
    "#         'Rossmann | Male System': 7.07098834397453,\n",
    "#         'Rossmann | Male Blades': 7.66470415775729,\n",
    "#         'Rossmann | Male Razor': 4.18256105457904\n",
    "#         }\n",
    "\n",
    "# custom_colors = [\n",
    "#     RGBColor(91, 159, 153),    # Darker teal\n",
    "#     RGBColor(131, 199, 193),   # Brighter medium teal\n",
    "#     RGBColor(168, 216, 212),   # Original light teal\n",
    "#     RGBColor(198, 236, 232),   # Very light teal\n",
    "#     RGBColor(111, 179, 173),\n",
    "#     RGBColor(121, 189, 183)\n",
    "#]\n",
    "# custom_colors = [\n",
    "#     RGBColor(111, 179, 173),  \n",
    "#     RGBColor(121, 189, 183),  \n",
    "#     RGBColor(168, 216, 212),  \n",
    "#     RGBColor(178, 226, 222), \n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a8ab5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Scope = {\n",
    "    \"Category\": categories,\n",
    "    \"Sector\": sectors,\n",
    "    \"Segment\": segments,\n",
    "    \"Subsegment\": subsegments,\n",
    "    \"Subcategory\": subcategories\n",
    "}\n",
    "suffixes = [\"Category\", \"Sector\", \"Segment\",'SubSegment', 'SubCategory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0373cd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DetectHeader(df):\n",
    "  # df = df.replace( np.nan, 0)\n",
    "  vals=df.values\n",
    "  vals=list(map(lambda x : all([type(i)==str for i in x ]),vals))\n",
    "  # print(vals)\n",
    "  break_point=0\n",
    "  for i,v in enumerate(vals):\n",
    "    if v:\n",
    "      break_point=i\n",
    "      # print(break_point)\n",
    "      break  \n",
    "  df.columns=df.iloc[break_point]\n",
    "  df=df.iloc[break_point+1:,:]\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71fd5a3",
   "metadata": {},
   "source": [
    "## Reading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "461dc096-382d-4c3b-91c1-8610a7cd684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = {}\n",
    "datasets_path = os.getcwd()+\"/Promotion Datasets/\"\n",
    "datasets = os.listdir(datasets_path)\n",
    "for d in datasets:\n",
    "    with open(datasets_path+d, 'rb') as handle:\n",
    "        globals()[d.split('.')[0]] = pd.read_pickle(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3163ddce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Sun Care | Walmart', 'Sun Care | Walmart Supercenter', 'Sun Care | Bodega Aurrera', 'Sun Care | Walmart Express', 'Sun Care | Mi Bodega', 'Sun Care | Canal Moderno', 'Sun Care | Autos Scanning'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sector_client_VSOD.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b3e2c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "marketList = regions_RET + channels_RET + market_RET + regions_CHAN + channels_CHAN + market_CHAN + regions_CUST + channels_CUST + market_CUST\n",
    "categoryList=categories +sectors+segments+subsegments+subcategories\n",
    "defaults = {\n",
    "    'Sun Care':\t140,\n",
    "    'Banana Boat': 220,\n",
    "    'Hawaiian Tropic': 260,\n",
    "    'Nivea': 150,\n",
    "    'Caribbean Beach': 160\n",
    "}\n",
    "diff_market_value = {\n",
    "}\n",
    " \n",
    "def totalsize (lis,defaultdic,diffmarketdic=[],cat1=False) :\n",
    "    if cat1:\n",
    "        max_total_size = {\n",
    "        f\"{category} | {market}\": diff_market_value.get(market.upper(), {}).get(category, defaults[category])\n",
    "        for market in marketList\n",
    "        for category in defaults\n",
    "    }\n",
    "    else:\n",
    "        max_total_size = {\n",
    "        f\"{market} | {category}\": diff_market_value.get(market.upper(), {}).get(category, defaults[category])\n",
    "        for market in marketList\n",
    "        for category in defaults\n",
    "    }    \n",
    "    return max_total_size  \n",
    " \n",
    "max_total_size=totalsize(categoryList,defaults,diff_market_value,cat1=True)\n",
    "       \n",
    " \n",
    "custom_colors = [\n",
    "    RGBColor(91, 159, 153),    # Darker teal\n",
    "    RGBColor(131, 199, 193),   # Brighter medium teal\n",
    "    RGBColor(168, 216, 212),   # Original light teal\n",
    "    RGBColor(198, 236, 232),   # Very light teal\n",
    "    RGBColor(111, 179, 173),\n",
    "    RGBColor(121, 189, 183)\n",
    "]\n",
    "# custom_colors = [\n",
    "#     RGBColor(111, 179, 173),  \n",
    "#     RGBColor(121, 189, 183),  \n",
    "#     RGBColor(168, 216, 212),  \n",
    "#     RGBColor(178, 226, 222),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acb1f42",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d9ab22-4ebf-4b74-8859-4cad1e38a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaningData(data):\n",
    "    \"\"\"\n",
    "    Clean and preprocess data in a dictionary of DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "    - data (dict): Dictionary containing DataFrames.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Dictionary containing cleaned DataFrames.\n",
    "    \"\"\"\n",
    "    cleaned_data = {}\n",
    "    \n",
    "    # Iterate over each key-value pair in the input dictionary\n",
    "    for key in data:\n",
    "      \n",
    "        df=DetectHeader(data[key])\n",
    "        # Set column names and skip the first row\n",
    "        if  df.columns.isna().any():\n",
    "            continue\n",
    "        # Perform specific cleaning operations based on the DataFrame columns and key\n",
    "        if df.shape[0] > 0 and not 'National' in key:\n",
    "            if f'{BrandOrTopB}' in df.columns and f'{prodORitem}' in df.columns:\n",
    "                df[f'{BrandOrTopB}'] = df[f'{BrandOrTopB}'].fillna(method='ffill')\n",
    "                df[f'{prodORitem}'].fillna('', inplace=True)\n",
    "                df.fillna(0, inplace=True)\n",
    "                df[f'{BrandOrTopB}'] = df[f'{BrandOrTopB}'].apply(lambda x: 'Grand Total' if 'Grand Total' in x else x.replace('Total', '').strip())\n",
    "                df = df.reset_index(drop=True)\n",
    "            \n",
    "            elif f'{BrandOrTopB}' in df.columns:\n",
    "                df[f'{BrandOrTopB}'] = df[f'{BrandOrTopB}'].fillna(method='ffill')\n",
    "                #df.fillna(0, inplace=True)\n",
    "                if normalized:\n",
    "                    df.loc[:,~ df.columns.isin(['VSOD IYA','Value Uplift Normalized IYA'])] = df.loc[:,~ df.columns.isin(['VSOD IYA','Value Uplift Normalized IYA'])].fillna(0)\n",
    "                    df['Promo Value Uplift vs YA'] = np.where(df['Value Uplift Normalized IYA'].isna(), None, df['Value Uplift Normalized IYA'] - 1)\n",
    "                else:\n",
    "                    df.loc[:, df.columns.isin(['VSOD IYA','Value Uplift IYA'])] = df.loc[:, df.columns.isin(['VSOD IYA','Value Uplift IYA'])].fillna(0)\n",
    "                    df['Promo Value Uplift vs YA'] = np.where(df['Value Uplift IYA'].isna(), None, df['Value Uplift IYA'] - 1)\n",
    "               \n",
    "                df['VSOD Evaluation vs YA'] = np.where(df['VSOD IYA'].isna(), None, df['VSOD IYA'] - 1)\n",
    "\n",
    "                df[f'{BrandOrTopB}'] = df[f'{BrandOrTopB}'].apply(lambda x: 'Grand Total' if 'Grand Total' in x else x.replace('Total', '').strip())\n",
    "                df = df[~df[f'{BrandOrTopB}'].str.contains('Total', case=False)]\n",
    "                df = df[df['Total Size'] == 0].reset_index(drop=True)\n",
    "\n",
    "       \n",
    "                \n",
    "            elif 'End of Week' in df.columns and f'{prodORitem}' in df.columns:\n",
    "                df[f'{prodORitem}'] = df[f'{prodORitem}'].fillna(method='ffill')\n",
    "                if normalized:\n",
    "                    df = df[(df['Value Uplift (v. base) Normalized'] >= 0)]\n",
    "                else:\n",
    "                    df = df[(df['Value Uplift (v. base)'] >= 0)]\n",
    "                df = df[(df['End of Week'].str.contains('2024|2025')) & (df['End of Week'].notna())]\n",
    "                df['End of Week'] = pd.to_datetime(df['End of Week'])\n",
    "                new_start=(datetime.strptime(end_date, \"%Y-%m-%d\") - relativedelta(months=12)).strftime(\"%Y-%m-%d\")\n",
    "                df = df[(df['End of Week'] >= new_start) & (df['End of Week'] <= end_date)]\n",
    "                df = df[~df[f'{prodORitem}'].str.contains('Total', case=False)].reset_index(drop=True)\n",
    "                df = df[df['Promo Sales'] > 1000]\n",
    "                if normalized:\n",
    "                    df = df.dropna(subset=['Value Uplift (v. base) Normalized'])\n",
    "                    df =  df[df['Value Uplift (v. base) Normalized']<10]\n",
    "                else:\n",
    "                    df = df.dropna(subset=['Value Uplift (v. base)'])\n",
    "                    df = df[df['Value Uplift (v. base']<10]\n",
    "                df.fillna(0, inplace=True)\n",
    "                df = df.reset_index(drop=True)\n",
    "                \n",
    "            elif 'End of Week' in df.columns:\n",
    "                df['End of Week'] = df['End of Week'].astype(str)\n",
    "                df = df[~df['End of Week'].str.contains('Total', case=False)].reset_index(drop=True)\n",
    "                df['End of Week'] = pd.to_datetime(df['End of Week'])\n",
    "                df['End of Week'] = df['End of Week'].dt.strftime(\"%d-%b-%y\")\n",
    "                df = df[(df['End of Week'].str.contains('-22|-23|-24|Jan-25')) & (df['End of Week'].notna())]\n",
    "                df['End of Week'] = pd.to_datetime(df['End of Week'])\n",
    "                df = df[(df['End of Week'] >= start_date) & (df['End of Week'] <= end_date)]\n",
    "                df = df.dropna()\n",
    "                \n",
    "            elif 'Grand Total' in df.columns:\n",
    "                if 'Sector' == df.columns[1]:\n",
    "                    df[direct_parent[\"Sector\"]].fillna(method='ffill', inplace= True)\n",
    "                    df['Sector'] = df['Sector'].replace(0, np.nan)\n",
    "                    df['Sector'].fillna(method='ffill', inplace=True)\n",
    "                    df['Sector'] = df.apply(lambda row: row[direct_parent[\"Sector\"]] if 'Total' in row[direct_parent[\"Sector\"]] and row[direct_parent[\"Sector\"]] != categories[0] else row['Sector'], axis=1)\n",
    "\n",
    "                elif 'Segment' == df.columns[1]:\n",
    "                    df['Segment'] = df['Segment'].replace(0, np.nan)  \n",
    "                    df[direct_parent[\"Segment\"]].fillna(method='ffill', inplace= True)          \n",
    "                    df['Segment'] = df.apply(lambda row: row[direct_parent[\"Segment\"]] if 'Total' in row[direct_parent[\"Segment\"]] and row[direct_parent[\"Segment\"]] != categories[0] else row['Segment'], axis=1)\n",
    "                    df['Segment'].fillna(method='ffill', inplace=True)\n",
    "                elif 'SubSegment' == df.columns[1]:\n",
    "                    df['SubSegment'] = df['SubSegment'].replace(0, np.nan)\n",
    "                    df[direct_parent[\"SubSegment\"]].fillna(method='ffill', inplace= True)          \n",
    "                    df['SubSegment'] = df.apply(lambda row: row[direct_parent[\"SubSegment\"]] if 'Total' in row[direct_parent[\"SubSegment\"]] and row[direct_parent[\"SubSegment\"]] != categories[0] else row['SubSegment'], axis=1)\n",
    "                    df['SubSegment'].fillna(method='ffill', inplace=True)\n",
    "                elif 'SubCategory' == df.columns[1]:\n",
    "                    df['SubCategory'] = df['SubCategory'].replace(0, np.nan)\n",
    "                    df[direct_parent[\"SubCategory\"]].fillna(method='ffill', inplace= True)          \n",
    "                    df['SubCategory'] = df.apply(lambda row: row[direct_parent[\"SubCategory\"]] if 'Total' in row[direct_parent[\"SubCategory\"]] and row[direct_parent[\"SubCategory\"]] != categories[0] else row['SubCategory'], axis=1)\n",
    "                    df['SubCategory'].fillna(method='ffill', inplace=True)\n",
    "                df = df.reset_index(drop=True)\n",
    "        df.fillna(0, inplace=True)\n",
    "            # Check if the key matches specific categories and modify the key accordingly\n",
    "        if key.split(' | ')[0] in categories and len(key.split(' | ')) == 3:\n",
    "                modified_key = key.split(' | ')[1] + ' | ' + key.split(' | ')[2] + ' | ' + key.split(' | ')[0]\n",
    "                if df.shape[0] > 0:\n",
    "                    cleaned_data[modified_key] = df\n",
    "        else:\n",
    "                if df.shape[0] > 0:\n",
    "                    cleaned_data[key] = df\n",
    "    \n",
    "    return cleaned_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df05b63b-986d-473b-9a40-ef7798a932ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaningdata_with_grand_total(data):\n",
    "    \"\"\"\n",
    "    Clean and preprocess data in a dictionary of DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "    - data (dict): Dictionary containing DataFrames.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Dictionary containing cleaned DataFrames.\n",
    "    \"\"\"\n",
    "    cleaningdata_with_grand_total = {}\n",
    "    \n",
    "    # Iterate over each key-value pair in the input dictionary\n",
    "    for key in data:\n",
    "   \n",
    "        df=DetectHeader(data[key])\n",
    "\n",
    "        if df.shape[0] > 0 and not 'National' in key:\n",
    "            if f'{BrandOrTopB}' in df.columns and f'{prodORitem}' in df.columns:\n",
    "                df[f'{BrandOrTopB}'] = df[f'{BrandOrTopB}'].fillna(method='ffill')\n",
    "                df[f'{prodORitem}'].fillna('', inplace=True)\n",
    "                df.fillna(0, inplace=True)\n",
    "                df[f'{BrandOrTopB}'] = df[f'{BrandOrTopB}'].apply(lambda x: 'Grand Total' if 'Grand Total' in x else x.replace('Total', '').strip())\n",
    "            \n",
    "            elif f'{BrandOrTopB}' in df.columns:\n",
    "                df[f'{BrandOrTopB}'] = df[f'{BrandOrTopB}'].fillna(method='ffill')\n",
    "                if normalized:\n",
    "                    df.loc[:,~ df.columns.isin(['VSOD IYA','Value Uplift Normalized IYA'])] = df.loc[:,~ df.columns.isin(['VSOD IYA','Value Uplift Normalized IYA'])].fillna(0)\n",
    "                    df['Promo Value Uplift vs YA'] = np.where(df['Value Uplift Normalized IYA'].isna(), None, df['Value Uplift Normalized IYA'] - 1)\n",
    "                else:\n",
    "                    df.loc[:, df.columns.isin(['VSOD IYA','Value Uplift IYA'])] = df.loc[:, df.columns.isin(['VSOD IYA','Value Uplift IYA'])].fillna(0)\n",
    "                    df['Promo Value Uplift vs YA'] = np.where(df['Value Uplift IYA'].isna(), None, df['Value Uplift IYA'] - 1)\n",
    "               \n",
    "                df['VSOD Evaluation vs YA'] = np.where(df['VSOD IYA'].isna(), None, df['VSOD IYA'] - 1)\n",
    "                df[f'{BrandOrTopB}'] = df[f'{BrandOrTopB}'].apply(lambda x: 'Grand Total' if 'Grand Total' in x else x.replace('Total', '').strip())\n",
    "                #df = df[~df[f'{BrandOrTopB}'].str.contains('Total', case=False)]\n",
    "                df = df[df['Total Size'] == 0].reset_index(drop=True)\n",
    "\n",
    "            elif 'End of Week' in df.columns and f'{prodORitem}' in df.columns:\n",
    "                df[f'{prodORitem}'] = df[f'{prodORitem}'].fillna(method='ffill')\n",
    "                df = df[(df['End of Week'].str.contains('2023|2024')) & (df['End of Week'].notna())]\n",
    "                df['End of Week'] = pd.to_datetime(df['End of Week'])\n",
    "                df = df[(df['End of Week'] >= start_date) & (df['End of Week'] <= end_date)]\n",
    "                df = df[~df[f'{prodORitem}'].str.contains('Total', case=False)].reset_index(drop=True)\n",
    "                \n",
    "                df = df[df['Promo Sales'] > 1000]\n",
    "                if normalized:\n",
    "                    df = df.dropna(subset=['Value Uplift (v. base) Normalized'])\n",
    "                else:\n",
    "                    df = df.dropna(subset=['Value Uplift (v. base)'])\n",
    "                df.fillna(0, inplace=True)\n",
    "                df = df.reset_index(drop=True)\n",
    "                \n",
    "            elif 'End of Week' in df.columns:\n",
    "                df['End of Week'] = df['End of Week'].astype(str)\n",
    "                df = df[~df['End of Week'].str.contains('Total', case=False)].reset_index(drop=True)\n",
    "                df['End of Week'] = pd.to_datetime(df['End of Week'])\n",
    "                df['End of Week'] = df['End of Week'].dt.strftime(\"%d-%b-%y\")\n",
    "                df = df[(df['End of Week'].str.contains('-21|-22|-23|Jan-24')) & (df['End of Week'].notna())]\n",
    "                df['End of Week'] = pd.to_datetime(df['End of Week'])\n",
    "                df = df[(df['End of Week'] >= start_date) & (df['End of Week'] <= end_date)]\n",
    "                df = df.dropna()\n",
    "                \n",
    "            elif 'Grand Total' in df.columns:\n",
    "                df['Sector'].fillna(method='ffill', inplace=True)\n",
    "                df.fillna(0, inplace=True)\n",
    "            \n",
    "            # Check if the key matches specific categories and modify the key accordingly\n",
    "            if key.split(' | ')[0] in categories and len(key.split(' | ')) == 3:\n",
    "                modified_key = key.split(' | ')[1] + ' | ' + key.split(' | ')[2] + ' | ' + key.split(' | ')[0]\n",
    "                if df.shape[0] > 0:\n",
    "                    cleaningdata_with_grand_total[modified_key] = df\n",
    "            else:\n",
    "                if df.shape[0] > 0:\n",
    "                    cleaningdata_with_grand_total[key] = df\n",
    "    \n",
    "    return cleaningdata_with_grand_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc586ee-696d-43bb-b763-ecfe53252dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning13New(data):\n",
    "    \"\"\"\n",
    "    Clean and process data for specific brands and regions.\n",
    "\n",
    "    Parameters:\n",
    "    - data (dict): Dictionary containing raw data.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Dictionary containing cleaned and processed data.\n",
    "    \"\"\"\n",
    "    data_cleaned = {}\n",
    "    \n",
    "    # Define maximum total size for each combination of product type and region\n",
    "    \n",
    "    for key, df in data.items():\n",
    "        # Skip processing if the region is 'NATIONAL' or 'National'\n",
    "        if 'NATIONAL' in areas or 'National' in key:\n",
    "            continue\n",
    "        new_data = []\n",
    "        # Skip first 12 rows as they are headers and metadata\n",
    "        # df = df.iloc[12:]\n",
    "        df=DetectHeader(data[key])\n",
    "        \n",
    "        # # Set columns names based on the first row, and skip the first row\n",
    "        # df.columns = df.iloc[0]\n",
    "        # df = df.iloc[1:]\n",
    "        # Fill missing values in 'Top Brands' column with the previous non-null value\n",
    "        df[f'{BrandOrTopB}'].fillna(method='ffill', inplace=True)\n",
    "        # Filter out rows where 'Top Brands' is 'Grand Total' or 'Other'\n",
    "        df = df[(df[f'{BrandOrTopB}'] != 'Grand Total') & (df[f'{BrandOrTopB}'] != 'Other')]\n",
    "        # Remove 'GR' suffix from 'Total Size' and convert it to integer\n",
    "        df['Total Size'] = df['Total Size'].str.extract('(\\d+)', expand=False)\n",
    "        df.fillna('0',inplace=True)\n",
    "        df['Total Size'] = df['Total Size'].astype(int)\n",
    "        # Sort data by 'Value Share' in descending order\n",
    "        df = df.sort_values(by='Value Share', ascending=False).reset_index(drop=True)\n",
    "        for i, brand in enumerate(df[f'{BrandOrTopB}'].unique()):\n",
    "            # Determine the product key based on the first two elements of the key\n",
    "            product_key = key.split('|')[0] + '|' + key.split('|')[1]\n",
    "            # Get the maximum total size for the product key, if it exists\n",
    "            max_size = max_total_size.get(product_key, None)\n",
    "            # Filter rows for the current brand and check if total size is within the maximum allowed size\n",
    "            if max_size is not None:\n",
    "                brand_df = df[(df[f'{BrandOrTopB}'] == brand) & (df['Total Size'] <= max_size)]\n",
    "            else:\n",
    "                brand_df = pd.DataFrame()\n",
    "            # Calculate recruitment ratio if the brand has data and total size is greater than zero\n",
    "            #brand_total = df[(df['Top Brands'] == brand + ' Total')]['Promo Value'].values\n",
    "            brand_total = df[(df[f'{BrandOrTopB}'].str.strip() == (brand + ' Total').strip())]['Promo Value'].values\n",
    "\n",
    "            if not brand_df.empty and brand_total.size > 0 and brand_total[0] > 0:\n",
    "                brand_sum = brand_df['Promo Value'].sum() / brand_total[0]\n",
    "                new_data.append({f'{BrandOrTopB}': brand, 'Recruitment': brand_sum, 'Consumption': 1 - brand_sum, 'Value Share': df['Value Share'][i], 'SUM':brand_df['Promo Value'].sum()})\n",
    "        # Create a new DataFrame with cleaned data\n",
    "        new = pd.DataFrame(new_data)\n",
    "        new.fillna(0, inplace=True)\n",
    "        \n",
    "        # Add cleaned data to the dictionary if it contains non-zero rows\n",
    "        if new.shape[0] != 0:\n",
    "            data_cleaned[key] = new\n",
    "        \n",
    "    return data_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07630d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def VSOD_Clean(VSOD_Data):\n",
    "#     \"\"\"\n",
    "#     Clean and preprocess VSOD data in a dictionary of DataFrames.\n",
    "\n",
    "#     Parameters:\n",
    "#     - VSOD_Data (dict): Dictionary containing VSOD DataFrames.\n",
    "\n",
    "#     Returns:\n",
    "#     - dict: Dictionary containing cleaned VSOD DataFrames.\n",
    "#     \"\"\"\n",
    "#     VSOD_cleaned = {}\n",
    "#     for key in VSOD_Data:\n",
    " \n",
    "#         df=DetectHeader(VSOD_Data[key])\n",
    "#         # Fill NaN values with 0\n",
    "#         # print(key)\n",
    "#         if 'Sector' == df.columns[1]:\n",
    "#             df[direct_parent[\"Sector\"]] = df[direct_parent[\"Sector\"]].replace(0, np.nan)\n",
    "#             df[direct_parent[\"Sector\"]].fillna(method='ffill', inplace = True)\n",
    "#             df['Sector'] = df['Sector'].replace(0, np.nan)\n",
    "#             df['Sector'] = df.apply(lambda row: row[direct_parent[\"Sector\"]] if 'Total' in row[direct_parent[\"Sector\"]] and row[direct_parent[\"Sector\"]] != categories[0] else row['Sector'], axis=1)\n",
    "#             df = df[~(df[direct_parent[\"Sector\"]].str.contains(r'\\btotal\\b', case=False) & \n",
    "#                     (df[direct_parent[\"Sector\"]] != categories[0])) | \n",
    "#                     df[direct_parent[\"Sector\"]].str.contains(r'\\bGrand\\b', case=False)].reset_index(drop=True)\n",
    "#             df['Sector'].fillna(method='ffill', inplace=True)\n",
    "#             df.fillna(0, inplace=True)\n",
    "#         df = df.reset_index(drop=True)\n",
    "#         if df.shape[0] > 0:\n",
    "#             VSOD_cleaned[key] = df\n",
    "#     return VSOD_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd7a1182-ecdd-40a8-8d9e-a110ad873ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VSOD_Clean(VSOD_Data):\n",
    "    \"\"\"\n",
    "    Clean and preprocess VSOD data in a dictionary of DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "    - VSOD_Data (dict): Dictionary containing VSOD DataFrames.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Dictionary containing cleaned VSOD DataFrames.\n",
    "    \"\"\"\n",
    "    VSOD_cleaned = {}\n",
    "    for key in VSOD_Data:\n",
    " \n",
    "        df=DetectHeader(VSOD_Data[key])\n",
    "        # Fill NaN values with 0\n",
    "        # print(key)\n",
    "        if 'Sector' == df.columns[1]:\n",
    "            df[direct_parent[\"Sector\"]] = df[direct_parent[\"Sector\"]].replace(0, np.nan)\n",
    "            df[direct_parent[\"Sector\"]].fillna(method='ffill', inplace = True)\n",
    "            df['Sector'] = df['Sector'].replace(0, np.nan)\n",
    "            df['Sector'] = df.apply(lambda row: row[direct_parent[\"Sector\"]] if 'Total' in row[direct_parent[\"Sector\"]] and row[direct_parent[\"Sector\"]] != categories[0] else row['Sector'], axis=1)\n",
    "            df = df[~(df[direct_parent[\"Sector\"]].str.contains(r'\\bGrand\\b', case=False))].reset_index(drop=True)\n",
    "            df['Sector'].fillna(method='ffill', inplace=True)\n",
    "            \n",
    "        elif 'Segment' == df.columns[1]:\n",
    "            df[direct_parent[\"Segment\"]].fillna(method='ffill', inplace=True)\n",
    "            df['Segment'] = df['Segment'].replace(0, np.nan)\n",
    "            # df=df[~df['Sector'].str.contains(r'\\btotal\\b', case=False) | df['Sector'].str.contains(r'\\bGrand\\b', case=False)].reset_index(drop=True)\n",
    "            df['Segment'] = df.apply(lambda row: row[direct_parent[\"Segment\"]] if 'Total' in row[direct_parent[\"Segment\"]] and row[direct_parent[\"Segment\"]] != categories[0] else row['Segment'], axis=1)\n",
    "            df = df[~(df[direct_parent[\"Segment\"]].str.contains(r'\\bGrand\\b', case=False))].reset_index(drop=True)\n",
    "            df['Segment'].fillna(method='ffill', inplace=True)    \n",
    "        elif 'SubSegment' == df.columns[1]:\n",
    "            df['SubSegment'] = df['SubSegment'].replace(0, np.nan)\n",
    "            df[direct_parent[\"SubSegment\"]].fillna(method='ffill', inplace=True)\n",
    "            # df=df[~df['Segment'].str.contains(r'\\btotal\\b', case=False) | df['Segment'].str.contains(r'\\bGrand\\b', case=False)].reset_index(drop=True)\n",
    "            df['SubSegment'] = df.apply(lambda row: row[direct_parent[\"SubSegment\"]] if 'Total' in row[direct_parent[\"SubSegment\"]] and row[direct_parent[\"SubSegment\"]] != categories[0] else row['SubSegment'], axis=1)\n",
    "            df = df[~(df[direct_parent[\"SubSegment\"]].str.contains(r'\\bGrand\\b', case=False))].reset_index(drop=True)\n",
    "            df['SubSegment'].fillna(method='ffill', inplace=True)\n",
    "        elif 'SubCategory' == df.columns[1]:\n",
    "            df['SubCategory'] = df['SubCategory'].replace(0, np.nan)\n",
    "            df[direct_parent[\"SubCategory\"]].fillna(method='ffill', inplace=True)\n",
    "            # df=df[~df['Segment'].str.contains(r'\\btotal\\b', case=False) | df['Segment'].str.contains(r'\\bGrand\\b', case=False)].reset_index(drop=True)\n",
    "            df['SubCategory'] = df.apply(lambda row: row[direct_parent[\"SubCategory\"]] if 'Total' in row[direct_parent[\"SubCategory\"]] and row[direct_parent[\"SubCategory\"]] != categories[0] else row['SubCategory'], axis=1)\n",
    "            df = df[~(df[direct_parent[\"SubCategory\"]].str.contains(r'\\bGrand\\b', case=False))].reset_index(drop=True)\n",
    "            df['SubCategory'].fillna(method='ffill', inplace=True)\n",
    "        df.fillna(0, inplace=True)\n",
    "        df = df.reset_index(drop=True)\n",
    "        if df.shape[0] > 0:\n",
    "            VSOD_cleaned[key] = df\n",
    "    return VSOD_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d32522c1-88ce-4f84-b71c-4e777b408673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging(VSODClient_Cleaned, VSODCleaned, col):\n",
    "    \"\"\"\n",
    "    Merge two dictionaries of DataFrames based on a common column.\n",
    "\n",
    "    Parameters:\n",
    "    - VSODClient_Cleaned (dict): Dictionary containing cleaned VSOD client DataFrames.\n",
    "    - VSODCleaned (dict): Dictionary containing cleaned VSOD DataFrames.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Dictionary containing merged DataFrames.\n",
    "    \"\"\"\n",
    "    merged_dict = {}\n",
    "    for key in VSODClient_Cleaned:\n",
    "        # Merge DataFrames based on 'Sector' column\n",
    "        #merged_df = pd.merge(VSODCleaned[key], VSODClient_Cleaned[key], on=col, how='left')\n",
    "        merged_df = pd.merge(VSODClient_Cleaned[key],VSODCleaned[key], on=col, how='left')\n",
    "        #merged_df = merged_df.dropna(subset=['Grand Total'])\n",
    "        merged_df['Grand Total'] = merged_df['Grand Total'].fillna(0)\n",
    "        merged_df = merged_df.fillna(0)\n",
    "        if merged_df.shape[0]>0:\n",
    "            merged_dict[key] = merged_df     \n",
    "    return merged_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7caef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified_promotionBrandsP12M_display = cleaningData(display_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1c2b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_promotionBrandsP12M = cleaningData(promotions_brands_P12M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77d32fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_promotionBrandsP12M_total = cleaningdata_with_grand_total(promotions_brands_P12M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ad3da6e-fb47-4873-b875-bd146d89d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_promotionProductsP12M = cleaningData(promotions_products_P12M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5159e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_promotionProductsP12M_updated = {}\n",
    "for key, df in modified_promotionProductsP12M.items():\n",
    "    df = df.copy()\n",
    "    df = df[df[f'{prodORitem}'] != '']\n",
    "    df = df[df['Promo Sales'] >= 10000]\n",
    "    df = df.sort_values(by='Promo Value', ascending=False).reset_index(drop=True)\n",
    "    if not df.empty:\n",
    "        modified_promotionProductsP12M_updated[key] = df\n",
    "modified_promotionProductsP12M_volumeuplift = modified_promotionProductsP12M_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b40a1e66-80f4-4dd0-9af8-a1a4e1cdc795",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_promotionEndOfWeek = cleaningData(promotions_EndOfWeek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c86f6a2a-90f7-40b1-8f9f-723f5578455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_valueUplift = cleaningData(value_uplift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3253f1fa-b573-493b-b3c6-d825cee538f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning13New(data):\n",
    "    \"\"\"\n",
    "    Clean and process data for specific brands and regions.\n",
    "\n",
    "    Parameters:\n",
    "    - data (dict): Dictionary containing raw data.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Dictionary containing cleaned and processed data.\n",
    "    \"\"\"\n",
    "    data_cleaned = {}\n",
    "    \n",
    "    # Define maximum total size for each combination of product type and region\n",
    "    \n",
    "    for key, df in data.items():\n",
    "        # Skip processing if the region is 'NATIONAL' or 'National'\n",
    "        if 'NATIONAL' in areas or 'National' in key:\n",
    "            continue\n",
    "        \n",
    "        new_data = []\n",
    "        \n",
    "        # Skip first 12 rows as they are headers and metadata\n",
    "        # df = df.iloc[12:]\n",
    "        df=DetectHeader(data[key])\n",
    "        \n",
    "        # # Set columns names based on the first row, and skip the first row\n",
    "        # df.columns = df.iloc[0]\n",
    "        # df = df.iloc[1:]\n",
    "        \n",
    "        # Fill missing values in 'Top Brands' column with the previous non-null value\n",
    "        df[f'{BrandOrTopB}'].fillna(method='ffill', inplace=True)\n",
    "        \n",
    "        # Filter out rows where 'Top Brands' is 'Grand Total' or 'Other'\n",
    "        df = df[(df[f'{BrandOrTopB}'] != 'Grand Total') & (df[f'{BrandOrTopB}'] != 'Other')]\n",
    "        # Remove 'GR' suffix from 'Total Size' and convert it to integer\n",
    "        df['Total Size'] = df['Total Size'].str.extract('(\\d+)', expand=False)\n",
    "        df.fillna('0',inplace=True)\n",
    "        df['Total Size'] = df['Total Size'].astype(int)\n",
    "        # Sort data by 'Value Share' in descending order\n",
    "        df = df.sort_values(by='Value Share', ascending=False).reset_index(drop=True)\n",
    "        for i, brand in enumerate(df[f'{BrandOrTopB}'].unique()):\n",
    "            # Split and strip both parts of the key\n",
    "            part1 = key.split('|')[0].strip()\n",
    "            part2 = key.split('|')[1].strip()\n",
    "\n",
    "            # Determine the product key with cleaned parts\n",
    "            if part1 == categories[0]:\n",
    "                product_key = f\"{part2} | {part1}\"\n",
    "            else:\n",
    "                product_key = f\"{part1} | {part2}\"\n",
    "\n",
    "            # Get the maximum total size for the product key, if it exists\n",
    "            max_size = max_total_size.get(product_key, None)\n",
    "            # print(product_key, max_size)\n",
    "\n",
    "            # print(product_key)\n",
    "            # Get the maximum total size for the product key, if it exists\n",
    "            # max_size = max_total_size.get(product_key, None)\n",
    "            # print(product_key,max_size)\n",
    "            # Filter rows for the current brand and check if total size is within the maximum allowed size\n",
    "            if max_size is not None:\n",
    "                \n",
    "                brand_df = df[(df[f'{BrandOrTopB}'] == brand) & (df['Total Size'] <= max_size)]\n",
    "            else:\n",
    "                brand_df = pd.DataFrame()\n",
    "                \n",
    "            # Calculate recruitment ratio if the brand has data and total size is greater than zero\n",
    "            #brand_total = df[(df['Top Brands'] == brand + ' Total')]['Promo Value'].values\n",
    "            brand_total = df[(df[f'{BrandOrTopB}'].str.strip() == (brand + ' Total').strip())]['Promo Value'].values\n",
    "\n",
    "            if not brand_df.empty and brand_total.size > 0 and brand_total[0] > 0:\n",
    "                brand_sum = brand_df['Promo Value'].sum() / brand_total[0]\n",
    "                new_data.append({f'{BrandOrTopB}': brand, 'Recruitment': brand_sum, 'Consumption': 1 - brand_sum, 'Value Share': df['Value Share'][i], 'SUM':brand_df['Promo Value'].sum()})\n",
    "        \n",
    "        # Create a new DataFrame with cleaned data\n",
    "        new = pd.DataFrame(new_data)\n",
    "        new.fillna(0, inplace=True)\n",
    "        \n",
    "        # Add cleaned data to the dictionary if it contains non-zero rows\n",
    "        if new.shape[0] != 0:\n",
    "            data_cleaned[key] = new\n",
    "        \n",
    "    return data_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1997b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newModifiedBrands = cleaning13New(promotions_brands_P12M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "586375bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging(VSODClient_Cleaned, VSODCleaned, col):\n",
    "    \"\"\"\n",
    "    Merge two dictionaries of DataFrames based on a common column.\n",
    "\n",
    "    Parameters:\n",
    "    - VSODClient_Cleaned (dict): Dictionary containing cleaned VSOD client DataFrames.\n",
    "    - VSODCleaned (dict): Dictionary containing cleaned VSOD DataFrames.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Dictionary containing merged DataFrames.\n",
    "    \"\"\"\n",
    "    merged_dict = {}\n",
    "    for key in VSODClient_Cleaned:\n",
    "        # Merge DataFrames based on 'Sector' column\n",
    "        #merged_df = pd.merge(VSODCleaned[key], VSODClient_Cleaned[key], on=col, how='left')\n",
    "        merged_df = pd.merge(VSODClient_Cleaned[key],VSODCleaned[key], on=col, how='left')\n",
    "        #merged_df = merged_df.dropna(subset=['Grand Total'])\n",
    "        merged_df['Grand Total'] = merged_df['Grand Total'].fillna(0)\n",
    "        merged_df = merged_df.fillna(0)\n",
    "        if merged_df.shape[0]>0:\n",
    "            merged_dict[key] = merged_df     \n",
    "    return merged_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5376db1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sun Care | Walmart':                         Segment                  SubCategory  VSOD  \\\n",
      "0              After Sun Adults                 No Spray Gel  0.04   \n",
      "1        After Sun Adults Total       After Sun Adults Total  0.04   \n",
      "2         Sunscreen | Sunscreen        Sunscreen | Sunscreen  1.00   \n",
      "3   Sunscreen | Sunscreen Total  Sunscreen | Sunscreen Total  1.00   \n",
      "4              Sunscreen Adults               No Spray Crema  0.55   \n",
      "5              Sunscreen Adults              No Spray Fluido  0.22   \n",
      "6              Sunscreen Adults             No Spray Liquido  0.53   \n",
      "7              Sunscreen Adults              No Spray Locion  0.18   \n",
      "8              Sunscreen Adults                Spray Liquido  0.50   \n",
      "9              Sunscreen Adults                 Spray Locion  0.66   \n",
      "10       Sunscreen Adults Total       Sunscreen Adults Total  0.52   \n",
      "11               Sunscreen Baby              No Spray Locion  0.19   \n",
      "12         Sunscreen Baby Total         Sunscreen Baby Total  0.18   \n",
      "13               Sunscreen Kids               No Spray Crema  0.60   \n",
      "14               Sunscreen Kids             No Spray Liquido  0.72   \n",
      "15               Sunscreen Kids              No Spray Locion  0.53   \n",
      "16               Sunscreen Kids             No Spray Roll-On  0.01   \n",
      "17               Sunscreen Kids                 Spray Locion  0.40   \n",
      "18         Sunscreen Kids Total         Sunscreen Kids Total  0.52   \n",
      "19               Tanning Adults               No Spray Crema  0.00   \n",
      "20               Tanning Adults                 Spray Aceite  0.21   \n",
      "21               Tanning Adults                Spray Liquido  0.30   \n",
      "22         Tanning Adults Total         Tanning Adults Total  0.18   \n",
      "\n",
      "    Banana Boat  Beauty Care  Hawaiian Tropic  Grand Total  \n",
      "0          0.00         0.00             0.10         0.04  \n",
      "1          0.00         0.00             0.10         0.04  \n",
      "2          1.00         0.00             0.00         1.00  \n",
      "3          1.00         0.00             0.00         1.00  \n",
      "4          0.60         0.00             0.50         0.55  \n",
      "5          0.22         0.00             0.00         0.22  \n",
      "6          0.59         0.49             0.51         0.53  \n",
      "7          0.18         0.00             0.00         0.18  \n",
      "8          0.55         0.00             0.44         0.50  \n",
      "9          0.66         0.00             0.00         0.66  \n",
      "10         0.56         0.49             0.50         0.52  \n",
      "11         0.19         0.00             0.00         0.19  \n",
      "12         0.18         0.00             0.00         0.18  \n",
      "13         0.60         0.00             0.00         0.60  \n",
      "14         0.00         0.00             0.72         0.72  \n",
      "15         0.53         0.00             0.00         0.53  \n",
      "16         0.01         0.00             0.00         0.01  \n",
      "17         0.40         0.00             0.00         0.40  \n",
      "18         0.51         0.00             0.72         0.52  \n",
      "19         0.00         0.00             0.00         0.00  \n",
      "20         0.18         0.00             0.23         0.21  \n",
      "21         0.00         0.00             0.30         0.30  \n",
      "22         0.18         0.00             0.18         0.18  , 'Sun Care | Walmart Supercenter':                         Segment                  SubCategory  VSOD  \\\n",
      "0              After Sun Adults                 No Spray Gel  0.03   \n",
      "1        After Sun Adults Total       After Sun Adults Total  0.03   \n",
      "2         Sunscreen | Sunscreen        Sunscreen | Sunscreen  1.00   \n",
      "3   Sunscreen | Sunscreen Total  Sunscreen | Sunscreen Total  1.00   \n",
      "4              Sunscreen Adults               No Spray Crema  0.56   \n",
      "5              Sunscreen Adults              No Spray Fluido  0.26   \n",
      "6              Sunscreen Adults             No Spray Liquido  0.51   \n",
      "7              Sunscreen Adults              No Spray Locion  0.07   \n",
      "8              Sunscreen Adults                Spray Liquido  0.49   \n",
      "9              Sunscreen Adults                 Spray Locion  0.67   \n",
      "10       Sunscreen Adults Total       Sunscreen Adults Total  0.51   \n",
      "11               Sunscreen Baby              No Spray Locion  0.19   \n",
      "12         Sunscreen Baby Total         Sunscreen Baby Total  0.18   \n",
      "13               Sunscreen Kids               No Spray Crema  0.41   \n",
      "14               Sunscreen Kids             No Spray Liquido  1.00   \n",
      "15               Sunscreen Kids              No Spray Locion  0.50   \n",
      "16               Sunscreen Kids             No Spray Roll-On  0.01   \n",
      "17               Sunscreen Kids                 Spray Locion  0.36   \n",
      "18         Sunscreen Kids Total         Sunscreen Kids Total  0.43   \n",
      "19               Tanning Adults               No Spray Crema  0.00   \n",
      "20               Tanning Adults                 Spray Aceite  0.16   \n",
      "21               Tanning Adults                Spray Liquido  0.30   \n",
      "22         Tanning Adults Total         Tanning Adults Total  0.13   \n",
      "\n",
      "    Banana Boat  Beauty Care  Hawaiian Tropic  Grand Total  \n",
      "0          0.00         0.00             0.07         0.03  \n",
      "1          0.00         0.00             0.07         0.03  \n",
      "2          1.00         0.00             0.00         1.00  \n",
      "3          1.00         0.00             0.00         1.00  \n",
      "4          0.60         0.00             0.52         0.56  \n",
      "5          0.26         0.00             0.00         0.26  \n",
      "6          0.57         0.49             0.49         0.51  \n",
      "7          0.07         0.00             0.00         0.07  \n",
      "8          0.55         0.00             0.44         0.49  \n",
      "9          0.67         0.00             0.00         0.67  \n",
      "10         0.54         0.49             0.49         0.51  \n",
      "11         0.19         0.00             0.00         0.19  \n",
      "12         0.18         0.00             0.00         0.18  \n",
      "13         0.41         0.00             0.00         0.41  \n",
      "14         0.00         0.00             1.00         1.00  \n",
      "15         0.50         0.00             0.00         0.50  \n",
      "16         0.01         0.00             0.00         0.01  \n",
      "17         0.36         0.00             0.00         0.36  \n",
      "18         0.43         0.00             1.00         0.43  \n",
      "19         0.00         0.00             0.00         0.00  \n",
      "20         0.03         0.00             0.23         0.16  \n",
      "21         0.00         0.00             0.30         0.30  \n",
      "22         0.03         0.00             0.17         0.13  , 'Sun Care | Bodega Aurrera':                    Segment             SubCategory  VSOD  Banana Boat  \\\n",
      "0         After Sun Adults            No Spray Gel  0.01         0.01   \n",
      "1   After Sun Adults Total  After Sun Adults Total  0.01         0.01   \n",
      "2         Sunscreen Adults          No Spray Crema  0.55         0.62   \n",
      "3         Sunscreen Adults        No Spray Liquido  0.59         0.66   \n",
      "4         Sunscreen Adults         No Spray Locion  0.27         0.27   \n",
      "5         Sunscreen Adults           Spray Liquido  0.48         0.56   \n",
      "6         Sunscreen Adults            Spray Locion  0.65         0.65   \n",
      "7   Sunscreen Adults Total  Sunscreen Adults Total  0.55         0.60   \n",
      "8           Sunscreen Kids          No Spray Crema  0.86         0.86   \n",
      "9           Sunscreen Kids        No Spray Liquido  0.71         0.00   \n",
      "10          Sunscreen Kids         No Spray Locion  0.55         0.55   \n",
      "11          Sunscreen Kids            Spray Locion  0.50         0.50   \n",
      "12    Sunscreen Kids Total    Sunscreen Kids Total  0.64         0.62   \n",
      "13          Tanning Adults            Spray Aceite  0.41         0.91   \n",
      "14          Tanning Adults           Spray Liquido  1.00         0.00   \n",
      "15    Tanning Adults Total    Tanning Adults Total  0.41         0.91   \n",
      "\n",
      "    Beauty Care  Hawaiian Tropic  Grand Total  \n",
      "0           0.0             0.00         0.01  \n",
      "1           0.0             0.00         0.01  \n",
      "2           0.0             0.49         0.55  \n",
      "3           0.5             0.56         0.59  \n",
      "4           0.0             0.00         0.27  \n",
      "5           0.0             0.25         0.48  \n",
      "6           0.0             0.00         0.65  \n",
      "7           0.5             0.51         0.55  \n",
      "8           0.0             0.00         0.86  \n",
      "9           0.0             0.71         0.71  \n",
      "10          0.0             0.00         0.55  \n",
      "11          0.0             0.00         0.50  \n",
      "12          0.0             0.71         0.64  \n",
      "13          0.0             0.23         0.41  \n",
      "14          0.0             1.00         1.00  \n",
      "15          0.0             0.23         0.41  , 'Sun Care | Walmart Express':                    Segment             SubCategory  VSOD  Banana Boat  \\\n",
      "0         After Sun Adults            No Spray Gel  0.24         0.00   \n",
      "1   After Sun Adults Total  After Sun Adults Total  0.24         0.00   \n",
      "2         Sunscreen Adults          No Spray Crema  0.51         0.51   \n",
      "3         Sunscreen Adults        No Spray Liquido  0.48         0.39   \n",
      "4         Sunscreen Adults         No Spray Locion  0.63         0.63   \n",
      "5         Sunscreen Adults           Spray Liquido  0.67         0.57   \n",
      "6         Sunscreen Adults            Spray Locion  0.60         0.60   \n",
      "7   Sunscreen Adults Total  Sunscreen Adults Total  0.54         0.53   \n",
      "8           Sunscreen Kids          No Spray Crema  0.81         0.81   \n",
      "9           Sunscreen Kids         No Spray Locion  0.54         0.54   \n",
      "10          Sunscreen Kids            Spray Locion  0.93         0.93   \n",
      "11    Sunscreen Kids Total    Sunscreen Kids Total  0.74         0.74   \n",
      "12          Tanning Adults            Spray Aceite  0.23         0.46   \n",
      "13          Tanning Adults           Spray Liquido  0.23         0.00   \n",
      "14    Tanning Adults Total    Tanning Adults Total  0.23         0.46   \n",
      "\n",
      "    Beauty Care  Hawaiian Tropic  Grand Total  \n",
      "0          0.00             0.24         0.24  \n",
      "1          0.00             0.24         0.24  \n",
      "2          0.00             0.51         0.51  \n",
      "3          0.54             0.49         0.48  \n",
      "4          0.00             0.00         0.63  \n",
      "5          0.00             0.74         0.67  \n",
      "6          0.00             0.00         0.60  \n",
      "7          0.54             0.54         0.54  \n",
      "8          0.00             0.00         0.81  \n",
      "9          0.00             0.00         0.54  \n",
      "10         0.00             0.00         0.93  \n",
      "11         0.00             0.00         0.74  \n",
      "12         0.00             0.18         0.23  \n",
      "13         0.00             0.23         0.23  \n",
      "14         0.00             0.17         0.23  , 'Sun Care | Mi Bodega':                   Segment             SubCategory  VSOD  Banana Boat  \\\n",
      "0        Sunscreen Adults          No Spray Crema  0.51         0.55   \n",
      "1        Sunscreen Adults        No Spray Liquido  0.56         0.42   \n",
      "2        Sunscreen Adults         No Spray Locion  0.43         0.43   \n",
      "3  Sunscreen Adults Total  Sunscreen Adults Total  0.52         0.55   \n",
      "4          Sunscreen Kids         No Spray Locion  0.60         0.60   \n",
      "5    Sunscreen Kids Total    Sunscreen Kids Total  0.60         0.60   \n",
      "6          Tanning Adults            Spray Aceite  0.40         0.67   \n",
      "7    Tanning Adults Total    Tanning Adults Total  0.40         0.67   \n",
      "\n",
      "   Hawaiian Tropic  Grand Total  \n",
      "0             0.47         0.51  \n",
      "1             0.57         0.56  \n",
      "2             0.00         0.43  \n",
      "3             0.51         0.52  \n",
      "4             0.00         0.60  \n",
      "5             0.00         0.60  \n",
      "6             0.00         0.40  \n",
      "7             0.00         0.40  , 'Sun Care | Canal Moderno':                                     Segment  \\\n",
      "0                          After Sun Adults   \n",
      "1                          After Sun Adults   \n",
      "2                          After Sun Adults   \n",
      "3                    After Sun Adults Total   \n",
      "4                     Sunscreen | Sunscreen   \n",
      "5               Sunscreen | Sunscreen Total   \n",
      "6         Sunscreen | Sunscreen | Sunscreen   \n",
      "7   Sunscreen | Sunscreen | Sunscreen Total   \n",
      "8                          Sunscreen Adults   \n",
      "9                          Sunscreen Adults   \n",
      "10                         Sunscreen Adults   \n",
      "11                         Sunscreen Adults   \n",
      "12                         Sunscreen Adults   \n",
      "13                         Sunscreen Adults   \n",
      "14                         Sunscreen Adults   \n",
      "15                         Sunscreen Adults   \n",
      "16                         Sunscreen Adults   \n",
      "17                         Sunscreen Adults   \n",
      "18                         Sunscreen Adults   \n",
      "19                         Sunscreen Adults   \n",
      "20                         Sunscreen Adults   \n",
      "21                         Sunscreen Adults   \n",
      "22                         Sunscreen Adults   \n",
      "23                         Sunscreen Adults   \n",
      "24                   Sunscreen Adults Total   \n",
      "25                           Sunscreen Baby   \n",
      "26                           Sunscreen Baby   \n",
      "27                           Sunscreen Baby   \n",
      "28                     Sunscreen Baby Total   \n",
      "29                           Sunscreen Kids   \n",
      "30                           Sunscreen Kids   \n",
      "31                           Sunscreen Kids   \n",
      "32                           Sunscreen Kids   \n",
      "33                           Sunscreen Kids   \n",
      "34                           Sunscreen Kids   \n",
      "35                           Sunscreen Kids   \n",
      "36                           Sunscreen Kids   \n",
      "37                           Sunscreen Kids   \n",
      "38                           Sunscreen Kids   \n",
      "39                     Sunscreen Kids Total   \n",
      "40                           Tanning Adults   \n",
      "41                           Tanning Adults   \n",
      "42                           Tanning Adults   \n",
      "43                           Tanning Adults   \n",
      "44                           Tanning Adults   \n",
      "45                           Tanning Adults   \n",
      "46                     Tanning Adults Total   \n",
      "\n",
      "                                SubCategory  VSOD  Banana Boat  Beauty Care  \\\n",
      "0                            No Spray Crema  0.01         0.00         0.00   \n",
      "1                              No Spray Gel  0.01         0.01         0.00   \n",
      "2                          No Spray Liquido  0.00         0.00         0.00   \n",
      "3                    After Sun Adults Total  0.01         0.01         0.00   \n",
      "4                     Sunscreen | Sunscreen  0.00         0.00         0.00   \n",
      "5               Sunscreen | Sunscreen Total  0.00         0.00         0.00   \n",
      "6         Sunscreen | Sunscreen | Sunscreen  0.00         0.00         0.00   \n",
      "7   Sunscreen | Sunscreen | Sunscreen Total  0.00         0.00         0.00   \n",
      "8                           No Spray Aceite  0.01         0.00         0.00   \n",
      "9                            No Spray Crema  0.01         0.03         0.00   \n",
      "10                          No Spray Fluido  0.00         0.00         0.00   \n",
      "11                             No Spray Gel  0.01         0.00         0.00   \n",
      "12                       No Spray Gel-Crema  0.00         0.00         0.00   \n",
      "13                         No Spray Liquido  0.02         0.02         0.01   \n",
      "14                          No Spray Locion  0.01         0.01         0.00   \n",
      "15                         No Spray Roll-On  0.02         0.02         0.00   \n",
      "16                           No Spray Serum  0.01         0.00         0.00   \n",
      "17                           No Spray Stick  0.00         0.00         0.00   \n",
      "18                                    Spray  0.00         0.00         0.00   \n",
      "19                             Spray Aceite  0.01         0.00         0.00   \n",
      "20                              Spray Crema  0.01         0.00         0.00   \n",
      "21                                Spray Gel  0.01         0.00         0.00   \n",
      "22                            Spray Liquido  0.02         0.01         0.00   \n",
      "23                             Spray Locion  0.02         0.02         0.00   \n",
      "24                   Sunscreen Adults Total  0.01         0.02         0.01   \n",
      "25                           No Spray Crema  0.03         0.00         0.00   \n",
      "26                          No Spray Locion  0.02         0.03         0.00   \n",
      "27                             Spray Locion  0.01         0.00         0.00   \n",
      "28                     Sunscreen Baby Total  0.02         0.03         0.00   \n",
      "29                           No Spray Crema  0.01         0.01         0.00   \n",
      "30                             No Spray Gel  0.02         0.00         0.00   \n",
      "31                       No Spray Gel-Crema  0.02         0.00         0.00   \n",
      "32                         No Spray Liquido  0.02         0.06         0.00   \n",
      "33                          No Spray Locion  0.02         0.02         0.00   \n",
      "34                         No Spray Roll-On  0.01         0.01         0.00   \n",
      "35                             Spray Aceite  0.00         0.00         0.00   \n",
      "36                              Spray Crema  0.01         0.00         0.00   \n",
      "37                            Spray Liquido  0.02         0.00         0.00   \n",
      "38                             Spray Locion  0.02         0.02         0.00   \n",
      "39                     Sunscreen Kids Total  0.01         0.02         0.00   \n",
      "40                          No Spray Aceite  0.02         0.00         0.00   \n",
      "41                           No Spray Crema  0.02         0.00         0.00   \n",
      "42                         No Spray Liquido  0.03         0.00         0.00   \n",
      "43                          No Spray Locion  0.00         0.00         0.00   \n",
      "44                             Spray Aceite  0.01         0.02         0.00   \n",
      "45                            Spray Liquido  0.02         0.00         0.00   \n",
      "46                     Tanning Adults Total  0.02         0.02         0.00   \n",
      "\n",
      "    Hawaiian Tropic  Grand Total  \n",
      "0              0.00         0.00  \n",
      "1              0.01         0.01  \n",
      "2              1.00         1.00  \n",
      "3              0.01         0.01  \n",
      "4              0.00         0.00  \n",
      "5              0.00         0.00  \n",
      "6              0.00         0.00  \n",
      "7              0.00         0.00  \n",
      "8              0.00         0.00  \n",
      "9              0.02         0.02  \n",
      "10             0.00         0.00  \n",
      "11             0.00         0.00  \n",
      "12             0.00         0.00  \n",
      "13             0.02         0.02  \n",
      "14             0.00         0.01  \n",
      "15             0.00         0.02  \n",
      "16             0.00         0.00  \n",
      "17             0.00         0.00  \n",
      "18             0.00         0.00  \n",
      "19             0.00         0.00  \n",
      "20             0.00         0.00  \n",
      "21             0.00         0.00  \n",
      "22             0.01         0.01  \n",
      "23             0.00         0.02  \n",
      "24             0.02         0.02  \n",
      "25             0.04         0.04  \n",
      "26             0.00         0.03  \n",
      "27             0.00         0.00  \n",
      "28             0.04         0.03  \n",
      "29             0.00         0.01  \n",
      "30             0.00         0.00  \n",
      "31             0.00         0.00  \n",
      "32             0.01         0.01  \n",
      "33             0.00         0.02  \n",
      "34             0.00         0.01  \n",
      "35             0.00         0.00  \n",
      "36             0.00         0.00  \n",
      "37             0.00         0.00  \n",
      "38             0.00         0.02  \n",
      "39             0.01         0.02  \n",
      "40             0.00         0.00  \n",
      "41             0.01         0.01  \n",
      "42             0.00         0.00  \n",
      "43             0.00         0.00  \n",
      "44             0.01         0.01  \n",
      "45             0.02         0.02  \n",
      "46             0.01         0.01  , 'Sun Care | Autos Scanning':                                     Segment  \\\n",
      "0                          After Sun Adults   \n",
      "1                          After Sun Adults   \n",
      "2                          After Sun Adults   \n",
      "3                          After Sun Adults   \n",
      "4                    After Sun Adults Total   \n",
      "5                     Sunscreen | After Sun   \n",
      "6               Sunscreen | After Sun Total   \n",
      "7                     Sunscreen | Sunscreen   \n",
      "8               Sunscreen | Sunscreen Total   \n",
      "9         Sunscreen | Sunscreen | Sunscreen   \n",
      "10  Sunscreen | Sunscreen | Sunscreen Total   \n",
      "11                         Sunscreen Adults   \n",
      "12                         Sunscreen Adults   \n",
      "13                         Sunscreen Adults   \n",
      "14                         Sunscreen Adults   \n",
      "15                         Sunscreen Adults   \n",
      "16                         Sunscreen Adults   \n",
      "17                         Sunscreen Adults   \n",
      "18                         Sunscreen Adults   \n",
      "19                         Sunscreen Adults   \n",
      "20                         Sunscreen Adults   \n",
      "21                         Sunscreen Adults   \n",
      "22                         Sunscreen Adults   \n",
      "23                         Sunscreen Adults   \n",
      "24                         Sunscreen Adults   \n",
      "25                         Sunscreen Adults   \n",
      "26                         Sunscreen Adults   \n",
      "27                   Sunscreen Adults Total   \n",
      "28                           Sunscreen Baby   \n",
      "29                           Sunscreen Baby   \n",
      "30                           Sunscreen Baby   \n",
      "31                           Sunscreen Baby   \n",
      "32                           Sunscreen Baby   \n",
      "33                           Sunscreen Baby   \n",
      "34                     Sunscreen Baby Total   \n",
      "35                           Sunscreen Kids   \n",
      "36                           Sunscreen Kids   \n",
      "37                           Sunscreen Kids   \n",
      "38                           Sunscreen Kids   \n",
      "39                           Sunscreen Kids   \n",
      "40                           Sunscreen Kids   \n",
      "41                           Sunscreen Kids   \n",
      "42                           Sunscreen Kids   \n",
      "43                           Sunscreen Kids   \n",
      "44                           Sunscreen Kids   \n",
      "45                           Sunscreen Kids   \n",
      "46                     Sunscreen Kids Total   \n",
      "47                           Tanning Adults   \n",
      "48                           Tanning Adults   \n",
      "49                           Tanning Adults   \n",
      "50                           Tanning Adults   \n",
      "51                           Tanning Adults   \n",
      "52                           Tanning Adults   \n",
      "53                     Tanning Adults Total   \n",
      "\n",
      "                                SubCategory  VSOD  Banana Boat  Beauty Care  \\\n",
      "0                            No Spray Crema  0.03         0.00         0.00   \n",
      "1                              No Spray Gel  0.03         0.03         0.00   \n",
      "2                          No Spray Liquido  0.00         0.00         0.00   \n",
      "3                           No Spray Locion  0.00         0.00         0.00   \n",
      "4                    After Sun Adults Total  0.03         0.03         0.00   \n",
      "5                     Sunscreen | After Sun  0.00         0.00         0.00   \n",
      "6               Sunscreen | After Sun Total  0.00         0.00         0.00   \n",
      "7                     Sunscreen | Sunscreen  0.00         0.00         0.00   \n",
      "8               Sunscreen | Sunscreen Total  0.00         0.00         0.00   \n",
      "9         Sunscreen | Sunscreen | Sunscreen  0.00         0.00         0.00   \n",
      "10  Sunscreen | Sunscreen | Sunscreen Total  0.00         0.00         0.00   \n",
      "11                          No Spray Aceite  0.02         0.00         0.00   \n",
      "12                           No Spray Crema  0.04         0.07         0.00   \n",
      "13                          No Spray Fluido  0.04         0.00         0.00   \n",
      "14                             No Spray Gel  0.07         0.00         0.00   \n",
      "15                       No Spray Gel-Crema  0.08         0.00         0.00   \n",
      "16                         No Spray Liquido  0.06         0.07         0.02   \n",
      "17                          No Spray Locion  0.04         0.05         0.00   \n",
      "18                         No Spray Roll-On  0.03         0.03         0.00   \n",
      "19                           No Spray Serum  0.05         0.00         0.00   \n",
      "20                           No Spray Stick  0.01         0.00         0.00   \n",
      "21                                    Spray  0.01         0.00         0.00   \n",
      "22                             Spray Aceite  0.06         0.00         0.00   \n",
      "23                              Spray Crema  0.07         0.09         0.00   \n",
      "24                                Spray Gel  0.07         0.00         0.00   \n",
      "25                            Spray Liquido  0.04         0.04         0.00   \n",
      "26                             Spray Locion  0.04         0.04         0.00   \n",
      "27                   Sunscreen Adults Total  0.05         0.06         0.02   \n",
      "28                           No Spray Crema  0.05         0.00         0.00   \n",
      "29                          No Spray Fluido  0.03         0.00         0.00   \n",
      "30                         No Spray Liquido  0.05         0.00         0.00   \n",
      "31                          No Spray Locion  0.04         0.05         0.00   \n",
      "32                                    Spray  0.01         0.00         0.00   \n",
      "33                             Spray Locion  0.03         0.00         0.00   \n",
      "34                     Sunscreen Baby Total  0.04         0.05         0.00   \n",
      "35                           No Spray Crema  0.02         0.04         0.00   \n",
      "36                             No Spray Gel  0.06         0.00         0.00   \n",
      "37                       No Spray Gel-Crema  0.14         0.00         0.00   \n",
      "38                         No Spray Liquido  0.07         0.19         0.00   \n",
      "39                          No Spray Locion  0.06         0.05         0.00   \n",
      "40                         No Spray Roll-On  0.03         0.03         0.00   \n",
      "41                                    Spray  0.00         0.00         0.00   \n",
      "42                             Spray Aceite  0.01         0.00         0.00   \n",
      "43                              Spray Crema  0.05         0.00         0.00   \n",
      "44                            Spray Liquido  0.06         0.05         0.00   \n",
      "45                             Spray Locion  0.05         0.05         0.00   \n",
      "46                     Sunscreen Kids Total  0.04         0.05         0.00   \n",
      "47                          No Spray Aceite  0.04         0.00         0.00   \n",
      "48                           No Spray Crema  0.05         0.00         0.00   \n",
      "49                         No Spray Liquido  0.06         0.00         0.00   \n",
      "50                          No Spray Locion  0.01         0.00         0.00   \n",
      "51                             Spray Aceite  0.04         0.04         0.00   \n",
      "52                            Spray Liquido  0.03         0.00         0.00   \n",
      "53                     Tanning Adults Total  0.04         0.04         0.00   \n",
      "\n",
      "    Hawaiian Tropic  Grand Total  \n",
      "0              0.00         0.00  \n",
      "1              0.04         0.03  \n",
      "2              1.00         1.00  \n",
      "3              0.00         0.00  \n",
      "4              0.04         0.03  \n",
      "5              0.00         0.00  \n",
      "6              0.00         0.00  \n",
      "7              0.00         0.00  \n",
      "8              0.00         0.00  \n",
      "9              0.00         0.00  \n",
      "10             0.00         0.00  \n",
      "11             0.00         0.00  \n",
      "12             0.06         0.06  \n",
      "13             0.00         0.00  \n",
      "14             0.00         0.00  \n",
      "15             0.00         0.00  \n",
      "16             0.06         0.06  \n",
      "17             0.00         0.05  \n",
      "18             0.00         0.03  \n",
      "19             0.00         0.00  \n",
      "20             0.00         0.00  \n",
      "21             0.00         0.00  \n",
      "22             0.00         0.00  \n",
      "23             0.00         0.08  \n",
      "24             0.00         0.00  \n",
      "25             0.03         0.04  \n",
      "26             0.00         0.04  \n",
      "27             0.06         0.06  \n",
      "28             0.11         0.11  \n",
      "29             0.00         0.00  \n",
      "30             0.00         0.00  \n",
      "31             0.00         0.05  \n",
      "32             0.00         0.00  \n",
      "33             0.00         0.00  \n",
      "34             0.10         0.06  \n",
      "35             0.00         0.04  \n",
      "36             0.00         0.00  \n",
      "37             0.00         0.00  \n",
      "38             0.03         0.04  \n",
      "39             0.00         0.05  \n",
      "40             0.00         0.03  \n",
      "41             0.00         0.00  \n",
      "42             0.00         0.00  \n",
      "43             0.00         0.00  \n",
      "44             0.00         0.05  \n",
      "45             0.00         0.05  \n",
      "46             0.03         0.05  \n",
      "47             0.00         0.00  \n",
      "48             0.03         0.03  \n",
      "49             0.00         0.00  \n",
      "50             0.00         0.00  \n",
      "51             0.04         0.04  \n",
      "52             0.04         0.04  \n",
      "53             0.04         0.04  }\n"
     ]
    }
   ],
   "source": [
    "if len(sectors) >0:\n",
    "    a = VSOD_Clean(Sector_VSOD)\n",
    "    if len(Sector_client_VSOD) >0:\n",
    "        b = cleaningData(Sector_client_VSOD)\n",
    "        sect_vsod_merged = merging(b,a, col=[direct_parent[\"Sector\"],'Sector'])\n",
    "    else:\n",
    "        sect_vsod_merged = a\n",
    "    c = cleaningData(Sector_manuf_VSOD)\n",
    "    for key in sect_vsod_merged:\n",
    "        merged_df = pd.merge(sect_vsod_merged[key], c[key], on=[direct_parent[\"Sector\"],'Sector'], how='left')\n",
    "        if merged_df.shape[0]>0:\n",
    "            sect_vsod_merged[key] = merged_df    \n",
    "\n",
    "if len(segments) >0:\n",
    "    a = VSOD_Clean(Segment_VSOD)\n",
    "    if len(Segment_client_VSOD) > 0:\n",
    "        b = cleaningData(Segment_client_VSOD)\n",
    "        seg_vsod_merged = merging(a,b, col=[direct_parent[\"Segment\"],'Segment'])\n",
    "    else:\n",
    "        seg_vsod_merged = a\n",
    "    \n",
    "    c = cleaningData(Segment_manuf_VSOD)\n",
    "    for key in seg_vsod_merged:\n",
    "        # Merge DataFrames based on 'Sector' column\n",
    "        merged_df = pd.merge(seg_vsod_merged[key], c[key], on=[direct_parent[\"Segment\"],'Segment'], how='left')\n",
    "        merged_df = merged_df.fillna(0)\n",
    "        if merged_df.shape[0]>0:\n",
    "            seg_vsod_merged[key] = merged_df    \n",
    "\n",
    "if len(subsegments) >0:\n",
    "    a = VSOD_Clean(SubSegment_VSOD)\n",
    "    if len(SubSegment_client_VSOD) > 0 :\n",
    "        b = cleaningData(SubSegment_client_VSOD)\n",
    "        subseg_vsod_merged = merging(a,b, col=[direct_parent[\"SubSegment\"],'SubSegment'])\n",
    "    else:\n",
    "        subseg_vsod_merged = a\n",
    "    c = cleaningData(SubSegment_manuf_VSOD)\n",
    "    for key in subseg_vsod_merged:\n",
    "        # Merge DataFrames based on 'Sector' column\n",
    "        merged_df = pd.merge(subseg_vsod_merged[key], c[key], on=[direct_parent[\"SubSegment\"],'SubSegment'], how='left')\n",
    "        merged_df = merged_df.fillna(0)\n",
    "        if merged_df.shape[0]>0:\n",
    "            subseg_vsod_merged[key] = merged_df    \n",
    "\n",
    "if len(subcategories) >0:\n",
    "    a = VSOD_Clean(SubCategory_VSOD)\n",
    "    # print(a)\n",
    "    if len(SubCategory_client_VSOD) > 0 :\n",
    "        b = cleaningData(SubCategory_client_VSOD)\n",
    "        subcat_vsod_merged = merging(a,b, col=[direct_parent[\"SubCategory\"],'SubCategory'])\n",
    "        print(subcat_vsod_merged)\n",
    "    else:\n",
    "        subcat_vsod_merged = a\n",
    "    c = cleaningData(SubCategory_manuf_VSOD)\n",
    "    for key in subcat_vsod_merged:\n",
    "        # Merge DataFrames based on 'Sector' column\n",
    "        merged_df = pd.merge(subcat_vsod_merged[key], c[key], on=[direct_parent[\"SubCategory\"],'SubCategory'], how='left')\n",
    "        merged_df = merged_df.fillna(0)\n",
    "        if merged_df.shape[0]>0:\n",
    "            subcat_vsod_merged[key] = merged_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44deeac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Sun Care | Walmart', 'Sun Care | Walmart Supercenter', 'Sun Care | Bodega Aurrera', 'Sun Care | Walmart Express', 'Sun Care | Mi Bodega', 'Sun Care | Canal Moderno', 'Sun Care | Autos Scanning'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subseg_vsod_merged.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f75fd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitkeys(dic, lis, parent,clientlist):\n",
    "    \"\"\"\n",
    "    Splits the keys of a dictionary into new keys based on unique values in a specified column.\n",
    "    Parameters:\n",
    "    dic (dict): The input dictionary with DataFrames as values.\n",
    "    lis (list): A list of sector names to filter by (if needed).\n",
    "    parent (str): The column name used for splitting (e.g., 'Sector').\n",
    "    \n",
    "    Returns:\n",
    "    dict: A new dictionary with updated keys and filtered DataFrames.\n",
    "    \"\"\"\n",
    "    splitvsod = {}\n",
    "    for key in dic.keys():\n",
    "        for key in dic.keys():\n",
    "            s = dic[key].copy()        \n",
    "            for value in s[parent].unique():\n",
    "                if isinstance(value, str) and not value.endswith(\"Total\"):\n",
    "                    new_key = f\"{key} | {value}\" \n",
    "                    filtered_df = s[s[parent].isin([value, f\"{value} Total\"])] \n",
    "                    \n",
    "                    for cli in clientlist:\n",
    "                        needed_col = [filtered_df.columns[0],filtered_df.columns[1],\"VSOD\",cli] \n",
    "                       \n",
    "                        existing_cols = [col for col in needed_col if col in filtered_df.columns]\n",
    "                        if existing_cols:  # Only try to filter if there are valid columns\n",
    "                            filtered_dfnew = filtered_df[existing_cols]\n",
    "                            splitvsod[new_key + \" | \" + cli] = filtered_dfnew\n",
    "                        else:\n",
    "                            print(f\"Warning: None of the columns in {needed_col} found in DataFrame.\")\n",
    "\n",
    "    keys_to_remove = [\n",
    "        k for k in splitvsod.keys() \n",
    "        if k.split(\" | \")[-2] not in lis\n",
    "    ]\n",
    "    for k in keys_to_remove:\n",
    "        del splitvsod[k]\n",
    "    return splitvsod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e97a11db",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=client_brands+client_manuf\n",
    "if len(sectors)!=0:\n",
    "    sect_vsod_merged=splitkeys(sect_vsod_merged,categories,parent=direct_parent['Sector'],clientlist=client)\n",
    "if len(segments)!=0:\n",
    "    seg_vsod_merged=splitkeys(seg_vsod_merged,sectors,parent=direct_parent['Segment'],clientlist=client)\n",
    "if len(subsegments)!=0:\n",
    "    subseg_vsod_merged=splitkeys(subseg_vsod_merged,segments,parent=direct_parent['SubSegment'],clientlist=client)\n",
    "if len(subcategories)!=0:\n",
    "    subcat_vsod_merged=splitkeys(subcat_vsod_merged,segments,parent=direct_parent['SubCategory'],clientlist=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e5ca402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector</th>\n",
       "      <th>Segment</th>\n",
       "      <th>VSOD</th>\n",
       "      <th>Edgewell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>After Sun</td>\n",
       "      <td>After Sun Adults</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After Sun Total</td>\n",
       "      <td>After Sun Total</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sector           Segment  VSOD  Edgewell\n",
       "0        After Sun  After Sun Adults  0.03      0.03\n",
       "1  After Sun Total   After Sun Total  0.03      0.03"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_vsod_merged['Sun Care | Autos Scanning | After Sun | Edgewell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b271ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors):\n",
    "    sect_vsod_count =0\n",
    "    for key,df in sect_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                sect_vsod_count +=1\n",
    "    sect_vsod_count = sect_vsod_count *len(categories)\n",
    " \n",
    "if len(segments):\n",
    "    seg_vsod_count =0\n",
    "    for key,df in seg_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                seg_vsod_count +=1\n",
    "    #seg_vsod_count = seg_vsod_count * len(sectors) \n",
    "    seg_vsod_count = seg_vsod_count           \n",
    " \n",
    "if len(subsegments) >0:\n",
    "    subseg_vsod_count =0\n",
    "    for key,df in subseg_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                subseg_vsod_count +=1\n",
    "    #subseg_vsod_count =subseg_vsod_count *len(segments)\n",
    "    subseg_vsod_count = subseg_vsod_count\n",
    " \n",
    "if len(subcategories) >0:\n",
    "    subcat_vsod_count =0\n",
    "    for key,df in subcat_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                subcat_vsod_count +=1\n",
    "    #subcat_vsod_count = subcat_vsod_count * len(subsegments)\n",
    "    subcat_vsod_count = subcat_vsod_count\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd04ba3-5570-4ad4-8d61-252872480a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "promotionsBrandSortedTotalFinal = {}\n",
    "promotionsBrandSortedTotal = dfSort(modified_promotionBrandsP12M, client_brands, f\"{BrandOrTopB}\", num=8, salesCol='Promo Value')\n",
    "\n",
    "for key, df in promotionsBrandSortedTotal.items():\n",
    "    # Step 1: Get client brands first\n",
    "    df_client = selectClientBrands(df, f'{BrandOrTopB}', 'Promo Value')\n",
    "    df_remaining = df[~df[f'{BrandOrTopB}'].isin(client_brands)]\n",
    "\n",
    "    # Step 2: Combine client brands and top non-client brands\n",
    "    number_of_brands_needed = max(6 - len(df_client), 0)\n",
    "    df_top = df_remaining.sort_values(by='Promo Value', ascending=False).head(number_of_brands_needed)\n",
    "    df_combined = pd.concat([df_client, df_top], ignore_index=True)\n",
    "    \n",
    "    # Step 3: Apply filtering\n",
    "    df_combined = df_combined[~df_combined[f'{BrandOrTopB}'].str.contains('Others', case=False, na=False)]\n",
    "    df_combined = df_combined[~df_combined[f'{BrandOrTopB}'].str.contains('Grand Total', case=False, na=False)]\n",
    "    df_combined = df_combined[df_combined['Value Share'] > 0.01]\n",
    "\n",
    "    # Step 4: If fewer than 6 brands remain, add more from df_remaining\n",
    "    existing_brands = df_combined[f'{BrandOrTopB}'].tolist()\n",
    "    if df_combined.shape[0] < 6:\n",
    "        df_filler = df_remaining[~df_remaining[f'{BrandOrTopB}'].isin(existing_brands)]\n",
    "        df_filler = df_filler[~df_filler[f'{BrandOrTopB}'].str.contains('Others|Grand Total', case=False, na=False)]\n",
    "        df_filler = df_filler[df_filler['Value Share'] > 0.01]\n",
    "        df_filler = df_filler.sort_values(by='Promo Value', ascending=False).head(6 - df_combined.shape[0])\n",
    "        df_combined = pd.concat([df_combined, df_filler], ignore_index=True)\n",
    "\n",
    "    # Step 5: Sort final list\n",
    "    df_combined = df_combined.sort_values(by='Promo Value', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Step 6: Cast types and store result if valid\n",
    "    if df_combined.shape[0] > 0:\n",
    "        df_combined['VSOD Evaluation vs YA'] = df_combined['VSOD Evaluation vs YA'].astype(float)\n",
    "        df_combined['Promo Value Uplift vs YA'] = df_combined['Promo Value Uplift vs YA'].astype(float)\n",
    "        promotionsBrandSortedTotalFinal[key] = df_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66555e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "promotionsBrandNOTSortedTotalFinal={}\n",
    "promotionsBrandNOTSortedTotalFinal=dfSort(modified_promotionBrandsP12M, client_brands, f\"{BrandOrTopB}\", num=8,salesCol='Promo Value')\n",
    "for key,df in modified_promotionBrandsP12M.items():\n",
    "     df = df.sort_values(by='Promo Value', ascending=False).reset_index(drop=True)\n",
    "     df = df[~df[f'{BrandOrTopB}'].str.contains('Others', case=False)]\n",
    "     df = df[~df[f'{BrandOrTopB}'].str.contains('Grand Total', case=False)]\n",
    "     df = df[df['Value Share'] > 0.01]\n",
    "     df['VSOD Evaluation vs YA'] = df['VSOD Evaluation vs YA'].astype(float)\n",
    "     df['Promo Value Uplift vs YA'] = df['Promo Value Uplift vs YA'].astype(float)\n",
    "     if df.shape[0] >0:\n",
    "          promotionsBrandNOTSortedTotalFinal[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75e0e42f-2500-4d43-9ed2-2b5ac567a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedBrands_og = selectedBrands\n",
    "selectedBrands= selectedBrands + [\"Grand Total\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab470824-4116-42ea-b87c-150650a1d61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "promotionsBrandsSelected={key:modified_promotionBrandsP12M_total[key][modified_promotionBrandsP12M_total[key][f'{BrandOrTopB}'].isin(selectedBrands)].sort_values(by='Promo Value',ascending=False) for key in modified_promotionBrandsP12M_total.keys()   if all(cat != key.split(' | ')[0] for cat in categories)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deb8699",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in promotionsBrandsSelected:\n",
    "    # Identify the Grand Total row (adjust this if necessary to match your data)\n",
    "    grand_total_row = promotionsBrandsSelected[key].loc[promotionsBrandsSelected[key][f'{BrandOrTopB}'] == 'Grand Total']\n",
    "    # Remove the Grand Total row from the dataframe\n",
    "    sorted_df = promotionsBrandsSelected[key].loc[promotionsBrandsSelected[key][f'{BrandOrTopB}'] != 'Grand Total']\n",
    "    # Concatenate the Grand Total row to the top of the dataframe\n",
    "    promotionsBrandsSelected[key] = pd.concat([grand_total_row, sorted_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea88f768",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedBrands = selectedBrands_og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4a6ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not including client brands\n",
    "promotionsNotBrandsSelected = {\n",
    "    key: modified_promotionBrandsP12M_total[key][\n",
    "        ~modified_promotionBrandsP12M_total[key][f'{BrandOrTopB}'].isin(selectedBrands)\n",
    "    ].sort_values(by='Value Share', ascending=False)\n",
    "    for key in modified_promotionBrandsP12M_total.keys()\n",
    "    if all(cat != key.split(' | ')[0] for cat in categories)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabcdd35-a8e6-4667-8efe-17c5dea262ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatAttribute(dic, marketList):\n",
    "    \"\"\"\n",
    "    This function takes a dictionary of DataFrames and a list of markets, and concatenates\n",
    "    the DataFrames by adding a 'SOURCE' column to each DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    dic (dict): A dictionary where keys are strings in the format 'market | source', and\n",
    "                values are DataFrames containing market data.\n",
    "    marketList (list): A list of market names (strings).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are market names and values are concatenated DataFrames\n",
    "          with an added 'SOURCE' column.\n",
    "    \"\"\"\n",
    "    # Initialize a defaultdict to store the resulting DataFrames\n",
    "    marketDic = defaultdict(list)\n",
    "    \n",
    "    # Iterate through the list of markets\n",
    "    for market in marketList:\n",
    "        # Iterate through the items in the dictionary\n",
    "        for key, value in dic.items():\n",
    "            # Check if the market name matches the key's market part\n",
    "            if market == key.split(' | ')[0]:\n",
    "                # Extract the source part from the key and assign it to the 'SOURCE' column\n",
    "                value['SOURCE'] = list(set(key.split(' | ')) - set([market]))[0]\n",
    "                value = value[value['Value Share'] >0.01]\n",
    "                value = value[~value[f'{BrandOrTopB}'].str.contains('Other')].reset_index(drop=True)\n",
    "            \n",
    "                # Only include rows where 'SOURCE' is not 'National'\n",
    "                if (value['SOURCE'] != 'National').all():\n",
    "                    marketDic[market].append(value)\n",
    "\n",
    "        # Concatenate all DataFrames in the list for each market\n",
    "        if len(marketDic[market]) != 0:\n",
    "            marketDic[market] = pd.concat(marketDic[market])\n",
    "    \n",
    "    return marketDic\n",
    "\n",
    "def fillingMissingBrands(dic):\n",
    "    \"\"\"\n",
    "    This function fills in missing brands for each market and source combination in the\n",
    "    provided dictionary of DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "    dic (dict): A dictionary where keys are market names and values are DataFrames\n",
    "                containing market data with 'Top Brands' and 'SOURCE' columns.\n",
    "\n",
    "    Returns:\n",
    "    dict: The input dictionary with missing brands filled in each DataFrame.\n",
    "    \"\"\"\n",
    "    # Iterate through the dictionary items\n",
    "    for key, value in dic.items():\n",
    "        # Get the unique list of top brands in the DataFrame\n",
    "        brandList = value[f'{BrandOrTopB}'].unique().tolist()\n",
    "        # Iterate through the unique sources in the DataFrame\n",
    "        for source in value['SOURCE'].unique():\n",
    "            # Check if the number of unique brands for the source is less than the total unique brands\n",
    "            if value[value['SOURCE'] == source][f'{BrandOrTopB}'].nunique() != len(brandList):\n",
    "                # Find the missing brands for the source\n",
    "                missingBrand = list(set(brandList) - set(value[value['SOURCE'] == source][f'{BrandOrTopB}'].unique()))\n",
    "                # Create a DataFrame for the missing brands with the current source\n",
    "                missingBrand = pd.DataFrame({f'{BrandOrTopB}': missingBrand, 'SOURCE': source}).explode(f'{BrandOrTopB}')\n",
    "                # Concatenate the missing brands DataFrame with the original DataFrame\n",
    "                value = pd.concat([value, missingBrand]).replace(np.nan, 0).reset_index(drop=True)\n",
    "        # Update the dictionary with the filled DataFrame\n",
    "        dic[key] = value\n",
    "    \n",
    "    return dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5825f852-d5a8-4717-863c-60bce7831474",
   "metadata": {},
   "outputs": [],
   "source": [
    "promotionsBrandsWithMarket=concatAttribute(promotionsBrandsSelected,marketList)\n",
    "promotionsBrandsWithMarket = fillingMissingBrands(promotionsBrandsWithMarket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "993b4af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "promotionsNotBrandsWithMarket=concatAttribute(promotionsNotBrandsSelected,marketList)\n",
    "promotionsNotBrandsWithMarket = fillingMissingBrands(promotionsNotBrandsWithMarket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "762fb5e2-0b4d-442f-9531-040980af3115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_market(data, Scope):\n",
    "    final = {}\n",
    "    for k, df in data.items():\n",
    "        for key, value in Scope.items():\n",
    "            for v in value:\n",
    "                new_key = k + ' | ' + v\n",
    "                if new_key not in final:\n",
    "                    df_market = df[df['SOURCE'].isin(value)]\n",
    "                    if df_market.shape[0] > 0:\n",
    "                        final[new_key] = df_market\n",
    "                    break  # stop checking once we use one valid value\n",
    "    return final    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2a003a6-6da6-495c-a2d9-a9b0af5a7a88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newpromotionsBrandsWithMarket = split_market(promotionsBrandsWithMarket,Scope)\n",
    "newpromotionsNotBrandsWithMarket = split_market(promotionsNotBrandsWithMarket,Scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e045f79-110e-4cb8-b237-b514151b9c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "def concatAttributeNew(sorted):\n",
    "    \"\"\"\n",
    "    This function takes a dictionary of DataFrames sorted by keys and concatenates the DataFrames\n",
    "    based on specified categories, sectors, and segments. It adds a 'SOURCE' column to each DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    sorted (dict): A dictionary where keys are strings in the format 'category | sector | segment | brand',\n",
    "                   and values are DataFrames containing market data.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are the categories, sectors, and segments, and values are concatenated DataFrames\n",
    "          with an added 'SOURCE' column.\n",
    "    \"\"\"\n",
    "    # Create a unique list of all category/sector/segment/subsegment/subcategory values\n",
    "    all_keys = list(dict.fromkeys(categories + sectors + segments + subsegments + subcategories))\n",
    "    # all_keys = all_keys[:-1]  # Exclude last if needed (e.g., due to Edgewell issue)\n",
    "\n",
    "    marketDic = defaultdict(list)\n",
    "    concatenatedDic = {}\n",
    "\n",
    "    for i in all_keys:\n",
    "        if i in concatenatedDic:\n",
    "            continue  # already handled this key\n",
    "\n",
    "        for key, value in sorted.items():\n",
    "            if i in key:\n",
    "                parts = key.split(' | ')\n",
    "                # Decide which part of the key to use as SOURCE\n",
    "                markets = parts[1] if i in categories else parts[0]\n",
    "\n",
    "                # Copy and modify to avoid changing original data\n",
    "                df = value.copy()\n",
    "                df['SOURCE'] = markets\n",
    "                marketDic[i].append(df)\n",
    "\n",
    "        if marketDic[i]:\n",
    "            concatenatedDic[i] = pd.concat(marketDic[i], ignore_index=True)\n",
    "\n",
    "    return concatenatedDic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "28e29be2-2f65-4603-8858-1087e008b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "concated = concatAttributeNew(modified_promotionBrandsP12M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3ee231f-9b67-4eef-ad0a-ae6e7d75eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(modified_promotionProductsP12M):\n",
    "    cleaned_data = {}\n",
    "    for key in modified_promotionProductsP12M:\n",
    "        df = modified_promotionProductsP12M[key]\n",
    "        df = df[df[f'{prodORitem}'] != '']\n",
    "        df=df.sort_values(by=['Promo Share'], ascending=False)\n",
    "        # Filter and sort the DataFrame\n",
    "        df['cumulative promo share'] = df['Promo Share'].cumsum()\n",
    "        df = df[df['Discount Depth (%)'] >= 0.05]\n",
    "        df = df[df['VSOD'] >= 0.05]\n",
    "        df = df[df['cumulative promo share'] <= 0.8]\n",
    "        df = df.sort_values(by='Incr Value', ascending=False).reset_index(drop=True)\n",
    "        df = df.head(50)\n",
    "        df['index'] = str(df.index + 1)\n",
    "        df = df.reset_index(drop=True)\n",
    "        if df.shape[0] >0:\n",
    "            cleaned_data[key] = df\n",
    "        #else:\n",
    "            #print(key)\n",
    "    return cleaned_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b8c6fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_modified_promotionProductsP12M = filter_data(modified_promotionProductsP12M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df8ceaa-7083-4015-8ccb-6202d9ac4aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_Top(modified_promotionProductsP12M):\n",
    "    cleaned_data = {}\n",
    "    for key in modified_promotionProductsP12M:\n",
    "        combined_df = pd.DataFrame() \n",
    "        for client in client_brands:\n",
    "            \n",
    "            df = modified_promotionProductsP12M[key]\n",
    "            # Filter the DataFrame for the current client brand\n",
    "            df = df[df[f'{prodORitem}'] != '']\n",
    "            df = df[df[f'{BrandOrTopB}'] == client]\n",
    "            df = df.sort_values(by=f'{BrandOrTopB}')\n",
    "            df['Promo Share'] = pd.to_numeric(df['Promo Share'], errors='coerce')\n",
    "            df['cumulative promo share'] = df.groupby(f'{BrandOrTopB}')['Promo Share'].cumsum()\n",
    "            df = df[df['cumulative promo share'] <= 0.8]\n",
    "\n",
    "            df = df[df['Discount Depth (%)'] >= 0.05]\n",
    "            df = df[df['VSOD'] >= 0.05]\n",
    "            if df.shape[0] >0:\n",
    "                combined_df = pd.concat([combined_df, df])\n",
    "                combined_df = combined_df.sort_values(by='Incr Value', ascending=False).head(20).reset_index(drop=True)\n",
    "        if combined_df.shape[0] > 0:\n",
    "            cleaned_data[key] = combined_df.reset_index(drop=True)  # Store the combined DataFrame for the current key\n",
    "                \n",
    "    return cleaned_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ec81127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified_promotionProductsP12M_updated = {}\n",
    "# for key, df in modified_promotionProductsP12M.items():\n",
    "#     df = df.copy()\n",
    "#     df = df[df['Product'] != '']\n",
    "#     df = df[df['Promo Sales'] >= 10000]\n",
    "#     df = df.sort_values(by='Promo Value', ascending=False).reset_index(drop=True)\n",
    "#     if not df.empty:\n",
    "#         modified_promotionProductsP12M_updated[key] = df\n",
    "# modified_promotionProductsP12M = modified_promotionProductsP12M_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0241c3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_Bot(modified_promotionProductsP12M):\n",
    "    cleaned_data = {}\n",
    "    for key in modified_promotionProductsP12M:\n",
    "        combined_df = pd.DataFrame() \n",
    "        for client in client_brands:\n",
    "            df = modified_promotionProductsP12M[key]\n",
    "            # Filter the DataFrame for the current client brand\n",
    "            df = df[df[f'{prodORitem}'] != '']\n",
    "            df = df[df[f'{BrandOrTopB}'] == client]\n",
    "            df = df.sort_values(by=f'{BrandOrTopB}')\n",
    "            df['Promo Share'] = pd.to_numeric(df['Promo Share'], errors='coerce')\n",
    "            df['cumulative promo share'] = df.groupby(f'{BrandOrTopB}')['Promo Share'].cumsum()\n",
    "            df = df[df['Discount Depth (%)'] >= 0.05]\n",
    "            df = df[df['VSOD'] >= 0.05]\n",
    "            if df.shape[0] >0:\n",
    "                combined_df = pd.concat([combined_df, df])\n",
    "                combined_df = combined_df.sort_values(by='Incr Value', ascending=False).tail(20).reset_index(drop=True)\n",
    "                combined_df = combined_df.sort_values(by ='Incr Value', ascending= True).reset_index(drop=True)\n",
    "        if combined_df.shape[0] > 0:\n",
    "            cleaned_data[key] = combined_df.reset_index(drop=True)  # Store the combined DataFrame for the current key\n",
    "    return cleaned_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d5316486-6b68-430c-963f-11df7ef98c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top20clientonly = filter_data_Top(modified_promotionProductsP12M)\n",
    "\n",
    "bottom20clientonly = filter_data_Bot(modified_promotionProductsP12M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e9198-c36a-4544-8a00-92a1e2ab89cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promotionsEndOfWeekCleaning(promotions_EndOfWeek, notInScope, col=f'{BrandOrTopB}'):\n",
    "    \"\"\"\n",
    "    Clean promotions end of week data.\n",
    "\n",
    "    Parameters:\n",
    "    promotions_EndOfWeek (dict): Dictionary containing promotions end of week data.\n",
    "    notInScope (list): List of items not in scope to be excluded.\n",
    "    col (str): Column name to check for filtering. Default is 'Top Brands'.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary containing cleaned promotions end of week data.\n",
    "    \"\"\"\n",
    "    # Initialize an empty dictionary to store cleaned promotions end of week data\n",
    "    promotionsEndOfWeek = {}\n",
    "    # Iterate over items in promotions_EndOfWeek dictionary\n",
    "    for key, value in promotions_EndOfWeek.items():\n",
    "        # Make a copy of the dataframe to avoid modifying the original data\n",
    "        df = value.copy()\n",
    "        # Check if the dataframe is not empty\n",
    "        if df.shape[0] != 0:\n",
    "            # Modify the key to match the desired format if applicable\n",
    "            modified_key = key\n",
    "            if key.split(' | ')[0] in categories and len(key.split(' | ')) == 3:\n",
    "                modified_key = key.split(' | ')[1] + ' | ' + key.split(' | ')[2] + ' | ' + key.split(' | ')[0]\n",
    "            # Check if the key contains any item from the notInScope list\n",
    "            # If not, add the dataframe to the cleaned dictionary after filtering out 'Grand Total' rows\n",
    "            flag = False if any(element in modified_key for element in notInScope) else True\n",
    "            if flag:\n",
    "                promotionsEndOfWeek[modified_key] = df[df[col] != 'Grand Total'].reset_index(drop=True).replace(np.nan, 0)\n",
    "        else:\n",
    "            print(key, ' Is empty')\n",
    "    \n",
    "    return promotionsEndOfWeek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3bdd031-7086-48bc-b9b6-d9e09be82bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod=cleaningData(promotions_EndOfWeek)\n",
    "promotionsEndOfWeekCleaned=promotionsEndOfWeekCleaning(mod,notInScope,col='End of Week')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e7408ac-109a-48e1-83ee-1f3acda454ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandMarket = list(set([key.split(' | ')[0]+' | '+key.split(' | ')[1] for key in promotionsEndOfWeekCleaned]))\n",
    "brandMarketCategory = [key for key in promotionsEndOfWeekCleaned.keys() if any(cat in key.split(' | ')[-1] for cat in categories )]\n",
    "if len(sectors) != 0:\n",
    "    brandMarketSector = [key for key in promotionsEndOfWeekCleaned.keys() if any(cat == key.split(' | ')[-1] for cat in sectors )]\n",
    "if len(segments) != 0:\n",
    "    brandMarketSegment = [key for key in promotionsEndOfWeekCleaned.keys() if any(cat == key.split(' | ')[-1] for cat in segments )]\n",
    "if len(subsegments) != 0:\n",
    "    brandMarketSubSegment = [key for key in promotionsEndOfWeekCleaned.keys() if any(cat == key.split(' | ')[-1] for cat in subsegments )]\n",
    "if len(subcategories) != 0:\n",
    "    brandMarketSubCategory = [key for key in promotionsEndOfWeekCleaned.keys() if any(cat == key.split(' | ')[-1] for cat in subcategories )]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "33070cde-4b18-410c-bf87-00d132014a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeDates(dfList, promotionsEndOfWeekCleaned):\n",
    "    \"\"\"\n",
    "    Complete dates for each dataframe in dfList based on promotionsEndOfWeekCleaned.\n",
    "\n",
    "    Parameters:\n",
    "    dfList (list): List of dataframe keys.\n",
    "    promotionsEndOfWeekCleaned (dict): Dictionary containing cleaned promotions end of week data.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Tuple containing EndOfWeekcompletDate (dictionary), dfGroup (list), and dic (dictionary).\n",
    "    \"\"\"\n",
    "    # Create a list of unique brand-category combinations\n",
    "    brandCatList = sorted(set(key.split(' | ')[0] + ' | ' + key.split(' | ')[2] for key in dfList))\n",
    "    \n",
    "    # Initialize dictionaries and lists\n",
    "    EndOfWeekcompletDate = {}\n",
    "    dfGroup = []\n",
    "    dic = defaultdict(int)\n",
    "    \n",
    "    # Count occurrences of each brand-category combination\n",
    "    for key in brandCatList:\n",
    "        for name in dfList:\n",
    "            if (key.split(' | ')[0] == name.split(' | ')[0]) and (key.split(' | ')[1] == name.split(' | ')[2]):\n",
    "                dic[key] += 1\n",
    "                \n",
    "    # Iterate over unique brand-category combinations\n",
    "    for name in dic.keys():\n",
    "        # Get dataframe keys associated with the current brand-category combination\n",
    "        dfName = [key for key in dfList if name == (key.split(' | ')[0] + ' | ' + key.split(' | ')[2])]\n",
    "        \n",
    "        # Extract unique dates from all associated dataframes\n",
    "        uniqueDates = pd.concat([promotionsEndOfWeekCleaned[key] for key in dfName])[['End of Week']].drop_duplicates()\n",
    "        if uniqueDates.shape[0] > 0:\n",
    "            # Initialize dictionary for complete dates for each dataframe\n",
    "            dfCompleteDates = {}\n",
    "            \n",
    "            # Add dataframe keys to the group list\n",
    "            dfGroup.append(dfName)\n",
    "            \n",
    "            # Populate EndOfWeekcompletDate dictionary with dataframes merged on unique dates\n",
    "            for key in dfName:\n",
    "                EndOfWeekcompletDate[key] = pd.merge(uniqueDates, promotionsEndOfWeekCleaned[key], how='left').replace(np.nan, 0).sort_values(by='End of Week').reset_index(drop = True)\n",
    "    return EndOfWeekcompletDate, dfGroup, dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "26bde262-eab5-4afc-ab44-9c3658cb974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(categories) != 0:\n",
    "    dfCategory,catGroup,catDuplication=completeDates(brandMarketCategory,promotionsEndOfWeekCleaned)\n",
    "if len(sectors) != 0:\n",
    "    dfSector,secGroup,secDuplication=completeDates(brandMarketSector,promotionsEndOfWeekCleaned)\n",
    "if len(segments) != 0:\n",
    "    dfSegment,segGroup,segDuplication=completeDates(brandMarketSegment,promotionsEndOfWeekCleaned)\n",
    "if len(subsegments) != 0:\n",
    "    dfSubSegment,subsegGroup,subsegDuplication=completeDates(brandMarketSubSegment,promotionsEndOfWeekCleaned)\n",
    "if len(subcategories) != 0:\n",
    "    dfSubCategory,subcatGroup,subcatDuplication=completeDates(brandMarketSubCategory,promotionsEndOfWeekCleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4108f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors):\n",
    "    sect_vsod_count =0\n",
    "    for key,df in sect_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                sect_vsod_count +=1\n",
    "    sect_vsod_count = sect_vsod_count *len(categories)\n",
    " \n",
    "if len(segments):\n",
    "    seg_vsod_count =0\n",
    "    for key,df in seg_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                seg_vsod_count +=1\n",
    "    #seg_vsod_count = seg_vsod_count * len(sectors) \n",
    "    seg_vsod_count = seg_vsod_count           \n",
    " \n",
    "if len(subsegments) >0:\n",
    "    subseg_vsod_count =0\n",
    "    for key,df in subseg_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                subseg_vsod_count +=1\n",
    "    #subseg_vsod_count =subseg_vsod_count *len(segments)\n",
    "    subseg_vsod_count = subseg_vsod_count\n",
    " \n",
    "if len(subcategories) >0:\n",
    "    subcat_vsod_count =0\n",
    "    for key,df in subcat_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                subcat_vsod_count +=1\n",
    "    #subcat_vsod_count = subcat_vsod_count * len(subsegments)\n",
    "    subcat_vsod_count = subcat_vsod_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "18bd063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(subsegments) != 0:\n",
    "#     fourth_key, fourth_value = next(iter(subsegDuplication.items()))\n",
    "    \n",
    "#     # Check if the key is not in the other segment list\n",
    "#     if fourth_key not in segments:\n",
    "#         PromoRet.update({fourth_key: fourth_value})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "43c6f94a-d00f-46ad-9011-678073e6bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PromoRet ={}\n",
    "if len(categories)!=0:\n",
    "    first_key, first_value = next(iter(catDuplication.items()))\n",
    "    PromoRet.update({first_key: first_value})\n",
    "if len(sectors)!=0:\n",
    "    sec_key, sec_value = next(iter(secDuplication.items()))\n",
    "    PromoRet.update({sec_key:sec_value})\n",
    "if len(segments)!=0:\n",
    "    third_key, third_value = next(iter(segDuplication.items()))\n",
    "    PromoRet.update({third_key: third_value})\n",
    "if len(subsegments)!=0:\n",
    "    fourth_key, fourth_value = next(iter(subsegDuplication.items()))\n",
    "    PromoRet.update({fourth_key:fourth_value})\n",
    "if len(subcategories)!=0:\n",
    "    fifth_key, fifth_value = next(iter(subcatDuplication.items()))\n",
    "    PromoRet.update({fifth_key:fifth_value })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c094ecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PromoSalesTypes_data = {}\n",
    "# for key, df in modified_promotionBrandsP12M.items():\n",
    "#     df = df[~df['Top Brands'].str.contains('Others', case=False)]\n",
    "#     df = df[~df['Top Brands'].str.contains('Grand Total', case=False)]\n",
    "#     df = df[df['Value Share'] > 0.01]\n",
    "#     df = df[df['Promo Value'] > 0]\n",
    "#     # Select client brands and additional brands needed to make 10 brands\n",
    "#     df_client = selectClientBrands(modified_promotionBrandsP12M[key],'Top Brands', 'Value Share')\n",
    "#     number_of_brands_needed = max(10 - len(df_client),0)\n",
    "#     df = df[~df['Top Brands'].isin(client_brands)]\n",
    "#     df = df.sort_values(by='Value Share', ascending=False).head(number_of_brands_needed)\n",
    "#     # Concatenate client brands and additional brands\n",
    "#     df = pd.concat([df_client, df], ignore_index=True)\n",
    "#     df = df[df['Promo Value'] > 0]\n",
    "#     df = df.reset_index(drop=True)\n",
    "#     if df.shape[0]:\n",
    "#         modified_promotionBrandsP12M[key] =df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a728a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "PromoSalesTypes_data = {}\n",
    "for key, df in brands_promo_type.items():\n",
    "    df = DetectHeader(df)\n",
    "    df[f'{BrandOrTopB}'] = df[f'{BrandOrTopB}'].ffill()\n",
    "    df[\"Promo Sales\"] = pd.to_numeric(df[\"Promo Sales\"], errors=\"coerce\").fillna(0)\n",
    "    df[\"Value Share\"] = pd.to_numeric(df[\"Value Share\"], errors=\"coerce\").fillna(0)\n",
    "    df = df[df['Promo Type'].notna()]\n",
    "    brand_totals = df.groupby(f\"{BrandOrTopB}\")['Promo Sales'].sum()\n",
    "\n",
    "    # df[\"Base Brand\"] = df[\"Top Brands\"].str.replace(\" Total\", \"\", regex=False)\n",
    "    # brand_totals = df[df[\"Top Brands\"].str.endswith(\"Total\")].set_index(\"Base Brand\")[\"Promo Sales\"].to_dict()\n",
    "    df[\"Brand Total Sales\"] = df[f\"{BrandOrTopB}\"].map(brand_totals)\n",
    "    df[\"% Promo Sales\"] = df[\"Promo Sales\"] / df[\"Brand Total Sales\"]\n",
    "\n",
    "    df = df[~df[f'{BrandOrTopB}'].str.contains('Others|Grand Total', case=False)]\n",
    "    df = df[df['Value Share'] > 0.01]\n",
    "    df = df[df['Promo Sales'] > 0]\n",
    "    # Select client brands and additional brands needed to make 10 brands\n",
    "    df_client = selectClientBrands(brands_promo_type[key],f'{BrandOrTopB}', 'Value Share')\n",
    "    comp_brand = df[~df[f'{BrandOrTopB}'].isin(cb for cb in client_brands)].drop_duplicates(f\"{BrandOrTopB}\")\n",
    "    if not df_client.empty:\n",
    "        comp_brand = comp_brand.nlargest(10-df_client[f\"{BrandOrTopB}\"].nunique(), \"Value Share\")[f\"{BrandOrTopB}\"].to_list()\n",
    "        # Concatenate client brands and additional brands\n",
    "        df = df[df[f\"{BrandOrTopB}\"].isin(comp_brand + client_brands)]\n",
    "        df = df.reset_index(drop=True)\n",
    "        df = df.sort_values(\"Value Share\", ascending=False).reset_index(drop=True)\n",
    "        # print(comp_brand)\n",
    "        if df.shape[0]:\n",
    "            PromoSalesTypes_data[key] =df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b23654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = os.getcwd() + '//Promotion base Oct 2024.pptx'\n",
    "# prs = Presentation(path)\n",
    "# slide = prs.slides[12]\n",
    "# brands = list(dataa['Top Brands'].unique())\n",
    "# promotype = dataa['Promo Type'].unique().tolist()\n",
    "# tables, charts = createTableAndChart(slide.shapes)\n",
    "# # Update table with category data\n",
    "# table = tables[0].table\n",
    "# num_rows_to_remove = len(table.rows) - len(brands)\n",
    "# #table_height = 3.88\n",
    "# table = removeRowFromTable(table, num_rows_to_remove, rowToExclude=0)\n",
    "# for row_number, row in enumerate(table.rows, start=0):\n",
    "#     for column_num, cell in enumerate(row.cells):\n",
    "#         if column_num == 0:\n",
    "#             cell.text = str(brands[row_number])\n",
    "#             set_cell_font(cell, 'Nexa Bold', 9)\n",
    "#             cell.text_frame.paragraphs[0].alignment = PP_ALIGN.LEFT\n",
    "# chart = charts[0].chart\n",
    "# chart_data = CategoryChartData()\n",
    "# chart_data.categories = brands\n",
    "# for promo_type in promotype:\n",
    "#     brand_values = {brand: 0 for brand in brands}\n",
    "    \n",
    "#     promo_data = dataa[dataa['Promo Type'] == promo_type]\n",
    "#     for _, row in promo_data.iterrows():\n",
    "#         brand_values[row['Top Brands']] = row['% Promo Sales']\n",
    "#     series_values = [value if value != 0 else None for value in [brand_values[brand] for brand in brands]]\n",
    "\n",
    "#     if any(value is not None for value in series_values):\n",
    "#         chart_data.add_series(promo_type, series_values)\n",
    "\n",
    "\n",
    "# chart.replace_data(chart_data)\n",
    "# chart.chart_style = 3\n",
    "# for i, series in enumerate(chart.series):\n",
    "#     fill = series.format.fill\n",
    "#     fill.solid()\n",
    "#     fill.fore_color.rgb = custom_colors[i]\n",
    "\n",
    "# outputPath=os.getcwd() + \"\\\\Promotion EdgeWell test.pptx\"\n",
    "# prs.save(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "88c1ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lis = []\n",
    "cat_lis = []\n",
    "if categories:\n",
    "    for i in range(len(catGroup)):\n",
    "        cat_lis += genrateIndexList(catGroup[i], chartIndex=14, chartCount=4)[0]\n",
    "    final_lis.append(cat_lis)\n",
    "else:\n",
    "    final_lis.append([])\n",
    "\n",
    "sec_lis = []\n",
    "if sectors:\n",
    "    for i in range(len(secGroup)):\n",
    "        sec_lis += genrateIndexList(secGroup[i], chartIndex=14, chartCount=4)[0]\n",
    "    final_lis.append(sec_lis)\n",
    "else:\n",
    "    final_lis.append([])\n",
    "\n",
    "seg_lis=[]\n",
    "if segments:\n",
    "    for i in range(len(segGroup)):\n",
    "        seg_lis += genrateIndexList(segGroup[i], chartIndex=14, chartCount=4)[0]\n",
    "    final_lis.append(seg_lis)\n",
    "\n",
    "else:\n",
    "    final_lis.append([])\n",
    "\n",
    "subseg_lis =[]\n",
    "if subsegments:\n",
    "    for i in range(len(subsegGroup)):\n",
    "        subseg_lis +=  genrateIndexList(subsegGroup[i], chartIndex=14, chartCount=4)[0]\n",
    "    final_lis.append(subseg_lis)\n",
    "else:\n",
    "    final_lis.append([])\n",
    "\n",
    "subcat_lis =[]\n",
    "if subcategories:\n",
    "    for i in range(len(subcatGroup)):\n",
    "        subcat_lis +=  genrateIndexList(subcatGroup[i], chartIndex=14, chartCount=4)[0]\n",
    "    final_lis.append(subcat_lis)\n",
    "else:\n",
    "    final_lis.append([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd4fa9",
   "metadata": {},
   "source": [
    "### New Slide 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "15c05226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = Sector_MonthYear['Boots']\n",
    "# d = DetectHeader(d).reset_index(drop=True)\n",
    "# d['Sector'] = d['Sector'].fillna(method = 'ffill')\n",
    "# d = d[~d['Sector'].str.contains('Total', case=False)].reset_index(drop=True)\n",
    "# d['year'] = pd.to_datetime(d['MonthYear'], format='%b-%y').dt.year\n",
    "# #yearly_avg_sales = d.groupby(['year', 'Sector'])['Value Sales'].mean().reset_index(drop=True) \n",
    "# yearly_avg_sales = d.groupby(['year', 'Sector'])['Value Sales'].transform('mean').reset_index(drop=True) \n",
    "\n",
    "# print(yearly_avg_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b59236",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b0c9e1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MonthYear_clean(data,column):\n",
    "    month_year_data={}\n",
    "    for key,df in data.items():\n",
    "        df=DetectHeader(data[key]).reset_index(drop=True)\n",
    "        df[column] = df[column].fillna(method = 'ffill')\n",
    "        df = df[~((df[column].str.contains('Total', case=False)) & (df[column] != categories[0]))].reset_index(drop=True)\n",
    "\n",
    "        # df = df[~df[column].str.contains('Total', case=False)].reset_index(drop=True)\n",
    "        df['year'] = pd.to_datetime(df['MonthYear'], format='%b-%y').dt.year\n",
    "        df['year'] = df['year'].astype(int)\n",
    "\n",
    "        # Convert 'Month' column to datetime\n",
    "        df['Month_dt'] = pd.to_datetime(df['MonthYear'], format=\"%b-%y\")\n",
    "\n",
    "        # Convert start date string to datetime\n",
    "        start_date_dt = pd.to_datetime(start_date)\n",
    "\n",
    "        # Filter the DataFrame\n",
    "        df = df[df['Month_dt'] >= start_date_dt]\n",
    "\n",
    "        # Drop the helper column if needed\n",
    "        df = df.drop(columns=['Month_dt'])\n",
    "        yearly_avg_sales = df.groupby(['year', column])['Value Sales'].transform('mean').reset_index(drop=True) \n",
    "        yearly_avg_sales = yearly_avg_sales.replace(0, float('nan'))\n",
    "        \n",
    "        # Calculate 'Sales index' and handle NaN values gracefully\n",
    "        df['Sales index'] = (df['Value Sales'] / yearly_avg_sales * 100).fillna(0).astype(int)\n",
    "        # df['Sales index'] = (df['Value Sales'] / yearly_avg_sales * 100).astype(int)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if df.shape[0]>0:\n",
    "            # if column =='Sector':\n",
    "            #     newkey =key\n",
    "            #     month_year_data[newkey] = df\n",
    "            # elif column == 'Segment':\n",
    "            #     newkey= key.split(' | ')[0] + ' | ' + segments[-1]\n",
    "            #     month_year_data[newkey] = df\n",
    "            # elif column == 'SubSegment':\n",
    "            #     newkey= key.split(' | ')[0] + ' | ' + subsegments[-1]\n",
    "            #     month_year_data[newkey] = df\n",
    "            # else:\n",
    "            #     newkey= key.split(' | ')[0] + ' | ' + subcategories[-1]\n",
    "            month_year_data[key] = df\n",
    "    return month_year_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "800863e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sector_MonthYear = {\n",
    "    f\"{key} | {categories[0]}\": value for key, value in Sector_MonthYear.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "db1737be",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_month_year=MonthYear_clean(Category_MonthYear,column='Category')\n",
    "sector_month_year = MonthYear_clean(Sector_MonthYear,column='Sector')\n",
    "segment_month_year = MonthYear_clean(Segment_MonthYear,column='Segment')\n",
    "subcat_month_year = MonthYear_clean(SubCategory_MonthYear,column='SubCategory')\n",
    "subseg_month_year = MonthYear_clean(SubSegment_MonthYear,column='SubSegment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6ac48172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_month_year(data, column):\n",
    "    final_month_year ={}\n",
    "    for key,df in data.items():\n",
    "        for sec in df[column].unique():\n",
    "            newkey = key + ' | ' + sec\n",
    "            new_df = df[df[column] == sec].reset_index(drop=True)\n",
    "            if new_df.shape[0] > 0:\n",
    "                final_month_year[newkey] = new_df\n",
    "    return final_month_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "265d60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_month_year1=split_month_year(category_month_year,'Category')\n",
    "sector_month_year1 = split_month_year(sector_month_year,'Sector')\n",
    "segment_month_year1 = split_month_year(segment_month_year,'Segment')\n",
    "subseg_month_year1 = split_month_year(subseg_month_year,'SubSegment')\n",
    "subcat_month_year1 = split_month_year(subcat_month_year,'SubCategory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b92a3b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_year1 = {}\n",
    "month_year1.update(sector_month_year1)\n",
    "month_year1.update(segment_month_year1)\n",
    "month_year1.update(subcat_month_year1)\n",
    "month_year1.update(subseg_month_year1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a94833af",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandMarketCategory = [key for key in category_month_year1.keys() if any(cat == key.split(' | ')[2]  for cat in categories )]\n",
    "if len(sectors) != 0:\n",
    "    brandMarketSector = [key for key in sector_month_year1.keys() if any(cat == key.split(' | ')[2]  for cat in sectors )]\n",
    "if len(segments) != 0:\n",
    "    brandMarketSegment = [key for key in segment_month_year1.keys() if any(cat == key.split(' | ')[2]  for cat in segments )]\n",
    "if len(subsegments) != 0:\n",
    "    brandMarketSubSegment = [key for key in subseg_month_year1.keys() if any(cat == key.split(' | ')[2] for cat in subsegments )]\n",
    "if len(subcategories) != 0:\n",
    "    brandMarketSubCategory = [key for key in subcat_month_year1.keys() if any(cat == key.split(' | ')[2] for cat in subcategories )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "17cb72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def completeDates1(dfList, promotionsEndOfWeekCleaned,column=\"Sector\"):\n",
    "    \"\"\"\n",
    "    Complete dates for each dataframe in dfList based on promotionsEndOfWeekCleaned.\n",
    "\n",
    "    Parameters:\n",
    "    dfList (list): List of dataframe keys.\n",
    "    promotionsEndOfWeekCleaned (dict): Dictionary containing cleaned promotions end of week data.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Tuple containing EndOfWeekcompletDate (dictionary), dfGroup (list), and dic (dictionary).\n",
    "    \"\"\"\n",
    "    # Create a list of unique brand-category combinations\n",
    "    brandCatList = sorted(set(key.split(' | ')[0]  for key in dfList))\n",
    "    # Initialize dictionaries and lists\n",
    "    EndOfWeekcompletDate = {}\n",
    "    dfGroup = []\n",
    "    dic = defaultdict(int)\n",
    "    \n",
    "    # Count occurrences of each brand-category combination\n",
    "    for key in brandCatList:\n",
    "        for name in dfList:\n",
    "            if (key.split(' | ')[0] == name.split(' | ')[0]):\n",
    "                \n",
    "                dic[key] += 1\n",
    "                \n",
    "    # Iterate over unique brand-category combinations\n",
    "    for name in dic.keys():\n",
    "\n",
    "        if column == \"Sector\" :\n",
    "            \n",
    "            # Filter dataframe keys associated with the current brand-category combination\n",
    "            dfName = [key for key in dfList if name == key.split(' | ')[0] and len(name.split(' | ')) == 1]\n",
    "        else:\n",
    "            \n",
    "            dfName = [key for key in dfList if name == key.split(' | ')[0]  ]\n",
    "        \n",
    "        # Extract unique dates from all associated dataframes\n",
    "        uniqueDates = pd.concat([promotionsEndOfWeekCleaned[key] for key in dfName])[['MonthYear']].drop_duplicates()\n",
    "        # Initialize dictionary for complete dates for each dataframe\n",
    "        dfCompleteDates = {}\n",
    "        # Add dataframe keys to the group list\n",
    "        dfGroup.append(dfName)\n",
    "        # Populate EndOfWeekcompletDate dictionary with dataframes merged on unique dates\n",
    "        for key in dfName:\n",
    "            EndOfWeekcompletDate[key] = pd.merge(uniqueDates, promotionsEndOfWeekCleaned[key], how='left')#.replace(np.nan, 0)\n",
    "            column = EndOfWeekcompletDate[key].columns[1]\n",
    "            year = EndOfWeekcompletDate[key].columns[3]\n",
    "            monthyear = EndOfWeekcompletDate[key].columns[0]\n",
    "            EndOfWeekcompletDate[key][column] = EndOfWeekcompletDate[key][column].fillna(method='ffill')      \n",
    "            EndOfWeekcompletDate[key][year] = pd.to_datetime(EndOfWeekcompletDate[key][monthyear], format='%b-%y').dt.year\n",
    "            EndOfWeekcompletDate[key] = EndOfWeekcompletDate[key].fillna(0)\n",
    "    return EndOfWeekcompletDate, dfGroup, dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3b1814ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCategory0,categoryGroup0,categoryDuplication0=completeDates1(brandMarketCategory,category_month_year1,column=\"Category\")\n",
    "if len(sectors) != 0:\n",
    "    dfSector0,secGroup0,secDuplication0=completeDates1(brandMarketSector,sector_month_year1,column=\"Sector\")\n",
    "if len(segments) != 0:\n",
    "    dfSegment0,segGroup0,segDuplication0=completeDates1(brandMarketSegment,segment_month_year1,column=\"Segment\")\n",
    "if len(subsegments) != 0:\n",
    "    dfSubSegment0,subsegGroup0,subsegDuplication0=completeDates1(brandMarketSubSegment,subseg_month_year1,column=\"Subsegment\")\n",
    "if len(subcategories) != 0:\n",
    "    dfSubCategory0,subcatGroup0,subcatDuplication0=completeDates1(brandMarketSubCategory,subcat_month_year1,column=\"Subcategory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "99912278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupingkeys(data):\n",
    "    grouped = defaultdict(list)\n",
    "\n",
    "    for sublist in data:\n",
    "        for entry in sublist:\n",
    "            prefix = \" | \".join(entry.split(\" | \")[:2])  # Extract first two parts\n",
    "            grouped[prefix].append(entry)\n",
    "    result = list(grouped.values())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "55074d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryGroup0=groupingkeys(categoryGroup0)\n",
    "if len(sectors) != 0:\n",
    "    secGroup0=groupingkeys(secGroup0)\n",
    "if len(segments) != 0:\n",
    "    segGroup0=groupingkeys(segGroup0)\n",
    "if len(subsegments) != 0:\n",
    "    subsegGroup0=groupingkeys(subsegGroup0)\n",
    "if len(subcategories) != 0:\n",
    "    subcatGroup0=groupingkeys(subcatGroup0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5e026eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20, 20, 20, 20, 20, 20, 20], [23, 22, 23, 22, 23, 22, 23]]\n",
      "[[20, 20, 20, 20, 20, 20, 20], [23, 22, 23, 22, 23, 22, 23], [22, 22, 22, 22, 22, 22, 22]]\n",
      "[[20, 20, 20, 20, 20, 20, 20], [23, 22, 23, 22, 23, 22, 23], [22, 22, 22, 22, 22, 22, 22], [22, 21, 21, 21, 20, 20, 22, 21, 21, 21, 20, 20, 21, 20, 20, 21, 20, 20, 21, 20, 20]]\n"
     ]
    }
   ],
   "source": [
    "final_lis0 = []\n",
    "category_lis = []\n",
    "if categories:\n",
    "    for i in range(len(categoryGroup0)):\n",
    "        category_lis += genrateIndexList(categoryGroup0[i], chartIndex=19, chartCount=6)[0]\n",
    "final_lis0.append(category_lis)  # Append empty list if sectors is False\n",
    "\n",
    "sec_lis = []\n",
    "if sectors:\n",
    "    for i in range(len(secGroup0)):\n",
    "        sec_lis += genrateIndexList(secGroup0[i], chartIndex=19, chartCount=6)[0]\n",
    "final_lis0.append(sec_lis)  # Append empty list if sectors is False\n",
    "print(final_lis0)\n",
    "\n",
    "seg_lis = []\n",
    "if segments:\n",
    "    for i in range(len(segGroup0)):\n",
    "        seg_lis += genrateIndexList(segGroup0[i], chartIndex=19, chartCount=6)[0]\n",
    "final_lis0.append(seg_lis)  # Append empty list if segments is False\n",
    "print(final_lis0)\n",
    "\n",
    "subseg_lis = []\n",
    "if subsegments:\n",
    "    for i in range(len(subsegGroup0)):\n",
    "        subseg_lis += genrateIndexList(subsegGroup0[i], chartIndex=19, chartCount=6)[0]\n",
    "final_lis0.append(subseg_lis)  # Append empty list if subsegments is False\n",
    "print(final_lis0)\n",
    "\n",
    "subcat_lis = []\n",
    "if subcategories:\n",
    "    for i in range(len(subcatGroup0)):\n",
    "        subcat_lis += genrateIndexList(subcatGroup0[i], chartIndex=19, chartCount=6)[0]\n",
    "final_lis0.append(subcat_lis)  # Append empty list if subcategories is False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc50143",
   "metadata": {},
   "source": [
    "### New slide 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3653fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_endofweek_P12M = {}\n",
    "past_12_months = pd.date_range(end=end_date , periods=12, freq='M').strftime('%b-%y').tolist()\n",
    "for key in modified_promotionEndOfWeek.keys():\n",
    "    df=modified_promotionEndOfWeek[key].copy()\n",
    "    df['End of Week'] = pd.to_datetime(df['End of Week'])\n",
    "    filtered_df = df[df['End of Week'].dt.strftime('%b-%y').isin(past_12_months)]\n",
    "    if filtered_df.shape[0] >0:\n",
    "        modified_endofweek_P12M[key] = filtered_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "06d18d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandMarket = list(set([key.split(' | ')[0]+' | '+key.split(' | ')[1] for key in modified_endofweek_P12M]))\n",
    "brandMarketCategory= [key for key in modified_endofweek_P12M.keys() if any(cat in key.split(' | ')[-1] for cat in categories )]\n",
    "if len(sectors) != 0:\n",
    "    brandMarketSector = [key for key in modified_endofweek_P12M.keys() if any(cat == key.split(' | ')[-1] for cat in sectors )]\n",
    "if len(segments) != 0:\n",
    "    brandMarketSegment = [key for key in modified_endofweek_P12M.keys() if any(cat == key.split(' | ')[-1] for cat in segments )]\n",
    "if len(subsegments) != 0:\n",
    "    brandMarketSubSegment = [key for key in modified_endofweek_P12M.keys() if any(cat == key.split(' | ')[-1] for cat in subsegments )]\n",
    "if len(subcategories) != 0:\n",
    "    brandMarketSubCategory = [key for key in modified_endofweek_P12M.keys() if any(cat == key.split(' | ')[-1] for cat in subcategories )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3ace0ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(categories) != 0:\n",
    "    dfCategory1,catGroup1,catDuplication1=completeDates(brandMarketCategory,modified_endofweek_P12M)\n",
    "if len(sectors) != 0:\n",
    "    dfSector1,secGroup1,secDuplication1=completeDates(brandMarketSector,modified_endofweek_P12M)\n",
    "if len(segments) != 0:\n",
    "    dfSegment1,segGroup1,segDuplication1=completeDates(brandMarketSegment,modified_endofweek_P12M)\n",
    "if len(subsegments) != 0:\n",
    "    dfSubSegment1,subsegGroup1,subsegDuplication1=completeDates(brandMarketSubSegment,modified_endofweek_P12M)\n",
    "if len(subcategories) != 0:\n",
    "    dfSubCategory1,subcatGroup1,subcatDuplication1=completeDates(brandMarketSubCategory,modified_endofweek_P12M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8479ede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promofrequencyclean(data):        \n",
    "        modified_dfCategory1 = {}\n",
    "        for k in data.keys():\n",
    "                chart_df=data[k].copy()\n",
    "                chart_df['Weekly VSOD'] = np.where((chart_df['VSOD']>.2)&(chart_df['Value Uplift (v. base) Normalized'] != ''),1,None)\n",
    "                chart_df['try'] = 0\n",
    "                chart_df['New Uplift'] = 0\n",
    "                chart_df['try'] = np.where((chart_df['Value Uplift (v. base) Normalized']>=2),1.8,chart_df['Value Uplift (v. base) Normalized'])\n",
    "                chart_df['New Uplift'] = np.where((chart_df['Weekly VSOD']==1)&(chart_df['Value Uplift (v. base) Normalized']>0.05),chart_df['try'],None)\n",
    "                if not chart_df['Weekly VSOD'].isnull().all():\n",
    "                        modified_dfCategory1[k]= chart_df \n",
    "        return modified_dfCategory1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9ad97599",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(categories)!=0: \n",
    "    modified_dfCategory1=promofrequencyclean(dfCategory1)\n",
    "if len(sectors)!=0: \n",
    "    modified_dfSector1=promofrequencyclean(dfSector1)\n",
    "if len(segments)!=0: \n",
    "    modified_dfSegment1=promofrequencyclean(dfSegment1)\n",
    "if len(subsegments)!=0: \n",
    "    modified_dfSubSegment1=promofrequencyclean(dfSubSegment1)\n",
    "if len(subcategories)!=0: \n",
    "    modified_dfSubCategory1=promofrequencyclean(dfSubCategory1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2f0aae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandMarket = list(set([key.split(' | ')[0]+' | '+key.split(' | ')[1] for key in modified_endofweek_P12M]))\n",
    "brandMarketCategory= [key for key in modified_dfCategory1.keys() if any(cat in key.split(' | ')[-1] for cat in categories )]\n",
    "if len(sectors) != 0:\n",
    "    brandMarketSector = [key for key in modified_dfSector1.keys() if any(cat == key.split(' | ')[-1] for cat in sectors )]\n",
    "if len(segments) != 0:\n",
    "    brandMarketSegment = [key for key in modified_dfSegment1.keys() if any(cat == key.split(' | ')[-1] for cat in segments )]\n",
    "if len(subsegments) != 0:\n",
    "    brandMarketSubSegment = [key for key in modified_dfSubSegment1.keys() if any(cat == key.split(' | ')[-1] for cat in subsegments )]\n",
    "if len(subcategories) != 0:\n",
    "    brandMarketSubCategory = [key for key in modified_dfSubCategory1.keys() if any(cat == key.split(' | ')[-1] for cat in subcategories )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "31f3763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(categories) != 0:\n",
    "    dfCategory1,catGroup1,catDuplication1=completeDates(brandMarketCategory,modified_endofweek_P12M)\n",
    "if len(sectors) != 0:\n",
    "    dfSector1,secGroup1,secDuplication1=completeDates(brandMarketSector,modified_endofweek_P12M)\n",
    "if len(segments) != 0:\n",
    "    dfSegment1,segGroup1,segDuplication1=completeDates(brandMarketSegment,modified_endofweek_P12M)\n",
    "if len(subsegments) != 0:\n",
    "    dfSubSegment1,subsegGroup1,subsegDuplication1=completeDates(brandMarketSubSegment,modified_endofweek_P12M)\n",
    "if len(subcategories) != 0:\n",
    "    dfSubCategory1,subcatGroup1,subcatDuplication1=completeDates(brandMarketSubCategory,modified_endofweek_P12M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c2bbe9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_region(data):\n",
    "    # Define categories for grouping\n",
    "    market_groups = {\n",
    "        \"RETAILER_REGIONS\": regions_RET,\n",
    "        \"RETAILER_CHANNELS\": channels_RET,\n",
    "        \"RETAILER_MARKET\": market_RET,\n",
    "        \"CHANNEL_REGIONS\": regions_CHAN,\n",
    "        \"CHANNEL_CHANNELS\": channels_CHAN,\n",
    "        \"CHANNEL_MARKET\": market_CHAN,\n",
    "        f\"{customareas}_REGIONS\": regions_CUST,\n",
    "        f\"{customareas}_CHANNELS\": channels_CUST,\n",
    "        f\"{customareas}_MARKET\": market_CUST,\n",
    "    }\n",
    "    result = []\n",
    "    for sublist in data:\n",
    "        for category, keywords in market_groups.items():\n",
    "            # Filter items matching the current category\n",
    "            base_category = category.split(\"_\")[0]\n",
    "\n",
    "            group = [\n",
    "                f\"{item} | {base_category}\" for item in sublist if item.split(\" | \")[1] in keywords\n",
    "            ]\n",
    "            if group:  # Append only non-empty groups\n",
    "                result.append(group)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "016f5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(categories)>0:\n",
    "    catGroup1 = group_by_region(catGroup1)\n",
    "if len(sectors)>0:\n",
    "    secGroup1 = group_by_region(secGroup1)\n",
    "if len(segments)>0:\n",
    "    segGroup1 = group_by_region(segGroup1)\n",
    "if len(subsegments)>0:\n",
    "    subsegGroup1 = group_by_region(subsegGroup1)\n",
    "if len(subcategories)>0:\n",
    "    subcatGroup1 = group_by_region(subcatGroup1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "95b943e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lis1 = []\n",
    "cat_lis = []\n",
    "if categories:\n",
    "    for i in range(len(catGroup1)):\n",
    "        cat_lis += genrateIndexList(catGroup1[i], chartIndex=25, chartCount=4)[0]\n",
    "    final_lis1.append(cat_lis)\n",
    "else:\n",
    "    final_lis1.append([])\n",
    "\n",
    "sec_lis = []\n",
    "if sectors:\n",
    "    for i in range(len(secGroup1)):\n",
    "        sec_lis += genrateIndexList(secGroup1[i], chartIndex=25, chartCount=4)[0]\n",
    "    final_lis1.append(sec_lis)\n",
    "else:\n",
    "    final_lis1.append([])\n",
    "\n",
    "seg_lis=[]\n",
    "if segments:\n",
    "    for i in range(len(segGroup1)):\n",
    "        seg_lis += genrateIndexList(segGroup1[i], chartIndex=25, chartCount=4)[0]\n",
    "    final_lis1.append(seg_lis)\n",
    "\n",
    "else:\n",
    "    final_lis1.append([])\n",
    "\n",
    "subseg_lis =[]\n",
    "if subsegments:\n",
    "    for i in range(len(subsegGroup1)):\n",
    "        subseg_lis +=  genrateIndexList(subsegGroup1[i], chartIndex=25, chartCount=4)[0]\n",
    "    final_lis1.append(subseg_lis)\n",
    "else:\n",
    "    final_lis1.append([])\n",
    "\n",
    "subcat_lis =[]\n",
    "if subcategories:\n",
    "    for i in range(len(subcatGroup1)):\n",
    "        subcat_lis +=  genrateIndexList(subcatGroup1[i], chartIndex=25, chartCount=4)[0]\n",
    "    final_lis1.append(subcat_lis)\n",
    "else:\n",
    "    final_lis1.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "21faef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "retailer=regions_RET+channels_RET+market_RET\n",
    "channels=regions_CHAN+channels_CHAN+channels_CHAN\n",
    "customarea=regions_CUST+channels_CUST+market_CUST\n",
    "def addarea(modified_dfCategory1,retailer,market=\"RETAILER\"):\n",
    "    keys_to_modify = [k for k in modified_dfCategory1.keys() if k.split(\" | \")[1] in retailer]\n",
    "    for k in keys_to_modify:\n",
    "        new_key = k + \" | \"+ market\n",
    "        modified_dfCategory1[new_key] = modified_dfCategory1[k]  \n",
    "        del modified_dfCategory1[k]       \n",
    "    return modified_dfCategory1      \n",
    "if len(categories)>0:            \n",
    "    modified_dfCategory1=addarea(modified_dfCategory1,retailer,market=\"RETAILER\")\n",
    "    modified_dfCategory1=addarea(modified_dfCategory1,channels,market=\"CHANNELS\")\n",
    "    modified_dfCategory1=addarea(modified_dfCategory1,customarea,market=f\"{customareas}\")\n",
    "\n",
    "if len(sectors)>0:            \n",
    "    modified_dfSector1=addarea(modified_dfSector1,retailer,market=\"RETAILER\")\n",
    "    modified_dfSector1=addarea(modified_dfSector1,channels,market=\"CHANNELS\")\n",
    "    modified_dfSector1=addarea(modified_dfSector1,customarea,market=f\"{customareas}\")\n",
    "if len(segments)>0:            \n",
    "    modified_dfSegment1=addarea(modified_dfSegment1,retailer,market=\"RETAILER\")\n",
    "    modified_dfSegment1=addarea(modified_dfSegment1,channels,market=\"CHANNELS\")\n",
    "    modified_dfSegment1=addarea(modified_dfSegment1,customarea,market=f\"{customareas}\")\n",
    "if len(subsegments)>0:            \n",
    "    modified_dfSubSegment1=addarea(modified_dfSubSegment1,retailer,market=\"RETAILER\")\n",
    "    modified_dfSubSegment1=addarea(modified_dfSubSegment1,channels,market=\"CHANNELS\")\n",
    "    modified_dfSubSegment1=addarea(modified_dfSubSegment1,customarea,market=f\"{customareas}\")\n",
    "if len(subcategories)>0:            \n",
    "    modified_dfSubCategory1=addarea(modified_dfSubCategory1,retailer,market=\"RETAILER\")\n",
    "    modified_dfSubCategory1=addarea(modified_dfSubCategory1,channels,market=\"CHANNELS\")\n",
    "    modified_dfSubCategory1=addarea(modified_dfSubCategory1,customarea,market=f\"{customareas}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5211df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in list(modified_promotionBrandsP12M.keys()):  # Convert to list to avoid runtime errors\n",
    "    df = modified_promotionBrandsP12M[k].copy()\n",
    "    # Filter rows based on 'Top Brands'\n",
    "    df = df[~df[f'{BrandOrTopB}'].str.contains('Others', case=False, na=False)]\n",
    "    df = df[~df[f'{BrandOrTopB}'].str.contains('Grand Total', case=False, na=False)]\n",
    "    df = df[df['Value Share'] > 0.01]\n",
    "    if not df.empty:\n",
    "        modified_promotionBrandsP12M[k] = df\n",
    "    else:\n",
    "        del modified_promotionBrandsP12M[k]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ee2a74",
   "metadata": {},
   "source": [
    "\n",
    "## Slide duplication: index, duplication and section names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ceca67f7-038d-44e1-98aa-cbc9a32d8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [*[0]*5,\n",
    "        #  *[1]*5,\n",
    "         *[1]*5,\n",
    "         *[2]*5,\n",
    "         *[3]*5,\n",
    "         *[4]*5,\n",
    "         *[5]*5,\n",
    "         *[6]*5,\n",
    "         *[7]*5,\n",
    "         *[8]*4,\n",
    "         *[9]*5,\n",
    "         *[10]*5,\n",
    "         *[11]*5,\n",
    "         *[12]*5,\n",
    "         *[13]*5,\n",
    "         *[14]*5,\n",
    "         *final_lis,\n",
    "         *[19]*5,\n",
    "         *final_lis0,\n",
    "         *final_lis1,\n",
    "         *[0]*5,\n",
    "         *[1]*5,\n",
    "         *[2]*5,\n",
    "         *[9]*5,\n",
    "         *[10]*5,\n",
    "         #*[11]*5,\n",
    "         *[12]*5,\n",
    "         *[13]*5\n",
    "        ]\n",
    "duplication = combine_duplications(Scope,count_df,[promotionsBrandSortedTotalFinal, #0\n",
    "                                                   #promotionsBrandSortedTotalFinal, #1\n",
    "                                                   newpromotionsNotBrandsWithMarket, #2\n",
    "                                                   concated, #3\n",
    "                                                   modified_promotionProductsP12M_volumeuplift, #4\n",
    "                                                   new_modified_promotionProductsP12M, #5\n",
    "                                                   new_modified_promotionProductsP12M, #6\n",
    "                                                   top20clientonly, #7\n",
    "                                                   bottom20clientonly,#8\n",
    "                                                   modified_promotionBrandsP12M, #10\n",
    "                                                   newModifiedBrands, #11\n",
    "                                                   PromoSalesTypes_data if promo_type else None,#12\n",
    "                                                   modified_promotionBrandsP12M if feature_share else None, #13\n",
    "                                                   modified_promotionBrandsP12M if display_share else None, #14\n",
    "                                                   modified_promotionEndOfWeek,#15\n",
    "                                                   PromoRet, #16-19\n",
    "                                                   modified_valueUplift, #20\n",
    "                                                   #month_year1,#21\n",
    "                                                   #modified_endofweek_P12M, #22\n",
    "                                                   modified_promotionBrandsP12M, #0 with no client\n",
    "                                                   #promotionsBrandNOTSortedTotalFinal, #1 with no client\n",
    "                                                   newpromotionsNotBrandsWithMarket, #2 with no client\n",
    "                                                   concated, #3 with no client\n",
    "                                                   modified_promotionBrandsP12M, # 10 with no client\n",
    "                                                   newModifiedBrands, #11 with no client\n",
    "                                                   #PromoSalesTypes_data if promo_type else None,#12  with no client\n",
    "                                                   modified_promotionBrandsP12M if feature_share else None, #13  with no client\n",
    "                                                   modified_promotionBrandsP12M if display_share else None #14 with no client\n",
    "                                                  ])\n",
    "section_names = [#\"Promo Value Sale\",#0\n",
    "                 \"Promo Evolution\", #1\n",
    "                 \"VSOD Summary by Sector\" , #2\n",
    "                 \"Value uplift by retailer by brand\", #3 \n",
    "                 \"Volume Uplift vs discount depth\",#4\n",
    "                 \"Value Uplift vs Promo Efficiency Quadrant\", #5\n",
    "                 \"Top 20 promotions\", #6\n",
    "                 \"Top 20 promotions CLIENT ONLY\", #7\n",
    "                 \"Bottom 20 promotions CLIENT ONLY\", #8\n",
    "                 \"Promo share vs Value Share\", #10\n",
    "                 \"Promo Sales by total size\",#11\n",
    "                 \"Promo Sales by promo type\", #12\n",
    "                 \"Feature Share vs Fair Share\", #13\n",
    "                 \"Display Share vs Fair Share\", #14\n",
    "                 \"Promo Frequency learnings\", #15\n",
    "                 \"Promo sales per retailer\", #16-19\n",
    "                 \"Value Uplift vs discount depth\" ,#20\n",
    "                 #\"Seasonality Index\",#21\n",
    "                 #\"Promotional Frequency Analysis\", #22\n",
    "                 #\"Promo Value Sale no client prio\",\n",
    "                 \"Promo Evolution no client prio\",\n",
    "                 \"VSOD Summary by Sector no client prio\",\n",
    "                 \"Value uplift by retailer by brand no client prio\",\n",
    "                \"Promo share vs Value Share no client prio\", #10\n",
    "                 \"Promo Sales by total size no client prio\",#11\n",
    "                 #\"Promo Sales by promo type no client prio\", #12\n",
    "                 \"Feature Share vs Fair Share no client prio\", #13\n",
    "                 \"Display Share vs Fair Share no client prio\" #14\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "#duplication.insert(89, 0)\n",
    "\n",
    "if len(sectors) > 0:\n",
    "       #duplication.insert(45,(len(client_manuf)+len(client_brands))*len(categories)* len(marketList))\n",
    "       duplication.insert(40, sect_vsod_count)\n",
    "if len(segments) > 0:\n",
    "        #duplication.insert(46,(len(client_manuf)+len(client_brands))*len(sectors)* len(marketList)) \n",
    "         duplication.insert(41, seg_vsod_count)\n",
    " \n",
    "else:\n",
    "    duplication.insert(41,1)  \n",
    "  \n",
    "if len(subsegments) > 0:\n",
    "        #duplication.insert(47,(len(client_manuf)+len(client_brands))*len(segments)* len(marketList))\n",
    "        duplication.insert(42, subseg_vsod_count)\n",
    "\n",
    "else:\n",
    "    duplication.insert(42,1)\n",
    "\n",
    "if len(subcategories) > 0:\n",
    "        #duplication.insert(48,(len(client_manuf)+len(client_brands))*len(segments)* len(marketList))\n",
    "        duplication.insert(43, subcat_vsod_count)\n",
    "\n",
    "else:\n",
    "    duplication.insert(43,1)\n",
    "\n",
    "\n",
    "duplication.insert(84,1)\n",
    "duplication.insert(85, 1)\n",
    "duplication.insert(86, 1)\n",
    "duplication.insert(87, 1)\n",
    "duplication.insert(88, 1)\n",
    "duplication.insert(89, 1)\n",
    "duplication.insert(90, 1)\n",
    "duplication.insert(91, 1)\n",
    "duplication.insert(92, 1)\n",
    "duplication.insert(93, 1)\n",
    "\n",
    "section_names = [f\"{name} {suffix}\" for name in section_names for suffix in suffixes]\n",
    "\n",
    "section_names.insert(40,'Volume Sold on Deal Sector')\n",
    "section_names.insert(41,'Volume Sold on Deal Segment')\n",
    "section_names.insert(42,'Volume Sold on Deal SubSegment')\n",
    "section_names.insert(43,'Volume Sold on Deal SubCategory')\n",
    "\n",
    "section_names.insert(84,'Seasonality Index Category')\n",
    "section_names.insert(85,'Seasonality Index Sector')\n",
    "section_names.insert(86,'Seasonality Index Segment')\n",
    "section_names.insert(87,'Seasonality Index Subsegment')\n",
    "section_names.insert(88,'Seasonality Index Subcategory')\n",
    "\n",
    "section_names.insert(89,'Promotional Frequency Analysis Category')\n",
    "section_names.insert(90,'Promotional Frequency Analysis Sector')\n",
    "section_names.insert(91,'Promotional Frequency Analysis Segment')\n",
    "section_names.insert(92,'Promotional Frequency Analysis Subsegment')\n",
    "section_names.insert(93,'Promotional Frequency Analysis Subcategory')\n",
    "# section_names.insert(94,'Promotional Frequency Analysis Subcategory')\n",
    "\n",
    "duplication[77]=1\n",
    "#index = [i for i in index if i != []]\n",
    "# duplication = [i for i in duplication if i != []]\n",
    "\n",
    "path = os.getcwd() + '//Promotion base.pptx'\n",
    "new_pre = os.getcwd() + '//slide duplicated.pptx'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19bbcf3",
   "metadata": {},
   "source": [
    "### Deck 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "78c45915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slides_name = ['Promo sales per retailer']\n",
    "# indices = [i for i, s in enumerate(section_names) if any(sub.lower() in s.lower() for sub in slides_name)]\n",
    "# indices\n",
    "# for i in range(indices[0], indices[-1]+1):\n",
    "#     duplication[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "44e60db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7,\n",
       " 24,\n",
       " 20,\n",
       " 16,\n",
       " 31,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 18,\n",
       " 18,\n",
       " 16,\n",
       " 29,\n",
       " 7,\n",
       " 11,\n",
       " 14,\n",
       " 13,\n",
       " 19,\n",
       " 7,\n",
       " 11,\n",
       " 14,\n",
       " 13,\n",
       " 19,\n",
       " 7,\n",
       " 11,\n",
       " 14,\n",
       " 12,\n",
       " 19,\n",
       " 7,\n",
       " 14,\n",
       " 17,\n",
       " 13,\n",
       " 24,\n",
       " 27,\n",
       " 94,\n",
       " 70,\n",
       " 70,\n",
       " 7,\n",
       " 25,\n",
       " 21,\n",
       " 16,\n",
       " 34,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 27,\n",
       " 74,\n",
       " 64,\n",
       " 48,\n",
       " 87,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 20,\n",
       " 37,\n",
       " 36,\n",
       " 33,\n",
       " 53,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 25,\n",
       " 21,\n",
       " 16,\n",
       " 34,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 25,\n",
       " 21,\n",
       " 16,\n",
       " 34,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1a93e125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 8, 8, 8, 8, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, [18, 17, 18, 16, 18, 17, 18, 17], [18, 16, 17, 18, 17, 18, 17, 18, 16, 18, 17, 17, 18, 17, 18, 17, 18, 16, 16, 18, 17, 18, 16], [18, 17, 18, 15, 18, 17, 18, 16, 18, 17, 18, 16, 18, 17, 18, 17, 18, 16, 18, 16], [18, 17, 18, 17, 18, 16, 18, 17, 18, 17, 18, 17, 18, 17], [18, 17, 18, 16, 18, 17, 18, 16, 18, 16, 18, 17, 18, 17, 18, 17, 18, 17, 18, 17, 18, 16, 18, 17, 18, 17], 19, 19, 19, 19, 19, [20, 20, 20, 20, 20, 20, 20], [23, 22, 23, 22, 23, 22, 23], [22, 22, 22, 22, 22, 22, 22], [22, 21, 21, 21, 20, 20, 22, 21, 21, 21, 20, 20, 21, 20, 20, 21, 20, 20, 21, 20, 20], [24, 24, 24, 23, 22, 22, 24, 24, 24, 22, 21, 21, 23, 22, 22, 23, 22, 22, 23, 22, 22], [26, 29, 26, 28, 26, 29, 26, 29], [26, 26, 26, 29, 26, 28, 26, 28, 26, 27, 26, 26, 26, 29, 26, 29, 26, 27, 26, 29, 26, 28], [26, 29, 26, 26, 26, 26, 29, 26, 28, 26, 29, 26, 26, 26, 26, 29, 26, 29, 26, 26, 26, 27, 26], [26, 29, 26, 29, 26, 28, 26, 29, 26, 29, 26, 29, 26, 28], [26, 29, 26, 28, 26, 28, 26, 28, 26, 29, 26, 27, 26, 29, 26, 28, 26, 29, 26, 27, 26, 29, 26, 28], 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13]\n",
      "[7, 24, 20, 16, 31, 0, 7, 7, 7, 7, 1, 4, 3, 3, 5, 7, 18, 18, 16, 29, 7, 11, 14, 13, 19, 7, 11, 14, 13, 19, 7, 11, 14, 12, 19, 7, 14, 17, 13, 24, 27, 94, 70, 70, 7, 25, 21, 16, 34, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 27, 74, 64, 48, 87, 1, 1, 1, 1, 1, 20, 37, 36, 33, 53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 25, 21, 16, 34, 0, 7, 7, 7, 7, 1, 4, 3, 3, 5, 7, 25, 21, 16, 34, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['Promo Evolution Category', 'Promo Evolution Sector', 'Promo Evolution Segment', 'Promo Evolution SubSegment', 'Promo Evolution SubCategory', 'VSOD Summary by Sector Category', 'VSOD Summary by Sector Sector', 'VSOD Summary by Sector Segment', 'VSOD Summary by Sector SubSegment', 'VSOD Summary by Sector SubCategory', 'Value uplift by retailer by brand Category', 'Value uplift by retailer by brand Sector', 'Value uplift by retailer by brand Segment', 'Value uplift by retailer by brand SubSegment', 'Value uplift by retailer by brand SubCategory', 'Volume Uplift vs discount depth Category', 'Volume Uplift vs discount depth Sector', 'Volume Uplift vs discount depth Segment', 'Volume Uplift vs discount depth SubSegment', 'Volume Uplift vs discount depth SubCategory', 'Value Uplift vs Promo Efficiency Quadrant Category', 'Value Uplift vs Promo Efficiency Quadrant Sector', 'Value Uplift vs Promo Efficiency Quadrant Segment', 'Value Uplift vs Promo Efficiency Quadrant SubSegment', 'Value Uplift vs Promo Efficiency Quadrant SubCategory', 'Top 20 promotions Category', 'Top 20 promotions Sector', 'Top 20 promotions Segment', 'Top 20 promotions SubSegment', 'Top 20 promotions SubCategory', 'Top 20 promotions CLIENT ONLY Category', 'Top 20 promotions CLIENT ONLY Sector', 'Top 20 promotions CLIENT ONLY Segment', 'Top 20 promotions CLIENT ONLY SubSegment', 'Top 20 promotions CLIENT ONLY SubCategory', 'Bottom 20 promotions CLIENT ONLY Category', 'Bottom 20 promotions CLIENT ONLY Sector', 'Bottom 20 promotions CLIENT ONLY Segment', 'Bottom 20 promotions CLIENT ONLY SubSegment', 'Bottom 20 promotions CLIENT ONLY SubCategory', 'Volume Sold on Deal Sector', 'Volume Sold on Deal Segment', 'Volume Sold on Deal SubSegment', 'Volume Sold on Deal SubCategory', 'Promo share vs Value Share Category', 'Promo share vs Value Share Sector', 'Promo share vs Value Share Segment', 'Promo share vs Value Share SubSegment', 'Promo share vs Value Share SubCategory', 'Promo Sales by total size Category', 'Promo Sales by total size Sector', 'Promo Sales by total size Segment', 'Promo Sales by total size SubSegment', 'Promo Sales by total size SubCategory', 'Promo Sales by promo type Category', 'Promo Sales by promo type Sector', 'Promo Sales by promo type Segment', 'Promo Sales by promo type SubSegment', 'Promo Sales by promo type SubCategory', 'Feature Share vs Fair Share Category', 'Feature Share vs Fair Share Sector', 'Feature Share vs Fair Share Segment', 'Feature Share vs Fair Share SubSegment', 'Feature Share vs Fair Share SubCategory', 'Display Share vs Fair Share Category', 'Display Share vs Fair Share Sector', 'Display Share vs Fair Share Segment', 'Display Share vs Fair Share SubSegment', 'Display Share vs Fair Share SubCategory', 'Promo Frequency learnings Category', 'Promo Frequency learnings Sector', 'Promo Frequency learnings Segment', 'Promo Frequency learnings SubSegment', 'Promo Frequency learnings SubCategory', 'Promo sales per retailer Category', 'Promo sales per retailer Sector', 'Promo sales per retailer Segment', 'Promo sales per retailer SubSegment', 'Promo sales per retailer SubCategory', 'Value Uplift vs discount depth Category', 'Value Uplift vs discount depth Sector', 'Value Uplift vs discount depth Segment', 'Value Uplift vs discount depth SubSegment', 'Value Uplift vs discount depth SubCategory', 'Seasonality Index Category', 'Seasonality Index Sector', 'Seasonality Index Segment', 'Seasonality Index Subsegment', 'Seasonality Index Subcategory', 'Promotional Frequency Analysis Category', 'Promotional Frequency Analysis Sector', 'Promotional Frequency Analysis Segment', 'Promotional Frequency Analysis Subsegment', 'Promotional Frequency Analysis Subcategory', 'Promo Evolution no client prio Category', 'Promo Evolution no client prio Sector', 'Promo Evolution no client prio Segment', 'Promo Evolution no client prio SubSegment', 'Promo Evolution no client prio SubCategory', 'VSOD Summary by Sector no client prio Category', 'VSOD Summary by Sector no client prio Sector', 'VSOD Summary by Sector no client prio Segment', 'VSOD Summary by Sector no client prio SubSegment', 'VSOD Summary by Sector no client prio SubCategory', 'Value uplift by retailer by brand no client prio Category', 'Value uplift by retailer by brand no client prio Sector', 'Value uplift by retailer by brand no client prio Segment', 'Value uplift by retailer by brand no client prio SubSegment', 'Value uplift by retailer by brand no client prio SubCategory', 'Promo share vs Value Share no client prio Category', 'Promo share vs Value Share no client prio Sector', 'Promo share vs Value Share no client prio Segment', 'Promo share vs Value Share no client prio SubSegment', 'Promo share vs Value Share no client prio SubCategory', 'Promo Sales by total size no client prio Category', 'Promo Sales by total size no client prio Sector', 'Promo Sales by total size no client prio Segment', 'Promo Sales by total size no client prio SubSegment', 'Promo Sales by total size no client prio SubCategory', 'Feature Share vs Fair Share no client prio Category', 'Feature Share vs Fair Share no client prio Sector', 'Feature Share vs Fair Share no client prio Segment', 'Feature Share vs Fair Share no client prio SubSegment', 'Feature Share vs Fair Share no client prio SubCategory', 'Display Share vs Fair Share no client prio Category', 'Display Share vs Fair Share no client prio Sector', 'Display Share vs Fair Share no client prio Segment', 'Display Share vs Fair Share no client prio SubSegment', 'Display Share vs Fair Share no client prio SubCategory']\n",
      "129\n",
      "129\n",
      "129\n",
      "[[18, 17, 18, 16, 18, 17, 18, 17], [18, 16, 17, 18, 17, 18, 17, 18, 16, 18, 17, 17, 18, 17, 18, 17, 18, 16, 16, 18, 17, 18, 16], [18, 17, 18, 15, 18, 17, 18, 16, 18, 17, 18, 16, 18, 17, 18, 17, 18, 16, 18, 16], [18, 17, 18, 17, 18, 16, 18, 17, 18, 17, 18, 17, 18, 17], [18, 17, 18, 16, 18, 17, 18, 16, 18, 16, 18, 17, 18, 17, 18, 17, 18, 17, 18, 17, 18, 16, 18, 17, 18, 17]]\n",
      "[[26, 29, 26, 28, 26, 29, 26, 29], [26, 26, 26, 29, 26, 28, 26, 28, 26, 27, 26, 26, 26, 29, 26, 29, 26, 27, 26, 29, 26, 28], [26, 29, 26, 26, 26, 26, 29, 26, 28, 26, 29, 26, 26, 26, 26, 29, 26, 29, 26, 26, 26, 27, 26], [26, 29, 26, 29, 26, 28, 26, 29, 26, 29, 26, 29, 26, 28], [26, 29, 26, 28, 26, 28, 26, 28, 26, 29, 26, 27, 26, 29, 26, 28, 26, 29, 26, 27, 26, 29, 26, 28]]\n",
      "1604\n"
     ]
    }
   ],
   "source": [
    "print(index)\n",
    "print(duplication)\n",
    "print(section_names)\n",
    "print(len(index))\n",
    "print(len(duplication))\n",
    "print(len(section_names))\n",
    "print(final_lis)\n",
    "print(final_lis1)\n",
    "print(sum(duplication))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "474f4496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slideDuplication(index,duplication,section_names,path,new_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeb24e2",
   "metadata": {},
   "source": [
    "## If we want specific slides duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e14224cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slides_name = ['display share', 'feature share']\n",
    "# indices = [i for i, s in enumerate(section_names) if any(sub.lower() in s.lower() for sub in slides_name)]\n",
    "# indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "016df9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_section_names = [section_names[i] for i in indices]\n",
    "# filtered_duplication = [duplication[i] for i in indices]\n",
    "# filtered_index = [index[i] for i in indices]\n",
    "\n",
    "# print(filtered_section_names)\n",
    "# print(filtered_duplication)\n",
    "# print(filtered_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c8ba8327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slideDuplication(filtered_index,filtered_duplication,filtered_section_names,path,new_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b830c75f",
   "metadata": {},
   "source": [
    "## Replace duplicated slides with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "78376167-8225-4f4f-af41-cd366f3e2273",
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = Presentation(new_pre)\n",
    "posItr = 0\n",
    "ind =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "2e21be34-0498-4c06-b4e4-bd68b94e38b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #slide 1\n",
    "# for key,value in Scope.items():\n",
    "#     dict = {key: count_df(modified_promotionBrandsP12M,value) }\n",
    "#     for key1,value1 in dict.items():\n",
    "#         filtered_dict = {key: value for key, value in modified_promotionBrandsP12M.items() if key in dict[key1]}\n",
    "#         if filtered_dict:\n",
    "#             promoValueSales(prs,filtered_dict,duplication[ind],position=posItr)\n",
    "#             posItr += len(filtered_dict)\n",
    "#         ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9ccad2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(modified_promotionBrandsP12M.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2a49aea0-21ff-4bf4-9427-d2f7a6b8a2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 2\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(promotionsBrandSortedTotalFinal,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in promotionsBrandSortedTotalFinal.items() if key in dict[key1]}\n",
    "        if filtered_dict:\n",
    "            promoEvolutionNew(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "        posItr += len(filtered_dict)\n",
    "        ind +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "08c9a579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "ec6850ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 98\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "1cd4fcae-6d85-4244-82e5-9a19f05b6bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 3\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(newpromotionsBrandsWithMarket,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in newpromotionsBrandsWithMarket.items() if key in dict[key1]}\n",
    "        if filtered_dict:\n",
    "            VSOD1(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "        posItr += len(filtered_dict)\n",
    "        ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "6c5c8934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "92914c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 126\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1b8dc777-7e02-4573-b8f9-000bb04fcdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 4\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(concated,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in concated.items() if key in dict[key1]}\n",
    "        if filtered_dict:\n",
    "            valueUpliftRetailer(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "        posItr += len(filtered_dict)\n",
    "        ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "97c4cfc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "27312e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 142\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "9c8ee2a2-5cdf-41f3-ad8a-95fb9baacc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 5\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(modified_promotionProductsP12M_volumeuplift,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in modified_promotionProductsP12M_volumeuplift.items() if key in dict[key1]}\n",
    "        if filtered_dict:\n",
    "            VolumeUplift(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "        posItr += len(filtered_dict)\n",
    "        ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "79067da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "cd0b667f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 230\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "30f24f2e-b093-4fe6-8605-1ef06f69e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 6\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(new_modified_promotionProductsP12M,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in new_modified_promotionProductsP12M.items() if key in dict[key1]}\n",
    "        if filtered_dict:\n",
    "            ValueUpliftvsPromoEfficiencyQuadrant(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "        posItr += len(filtered_dict)\n",
    "        ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "64e1fc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "569c3cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 294\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ba714fd4-a9da-45d9-9eb0-1a1889324bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 7\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(new_modified_promotionProductsP12M,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in new_modified_promotionProductsP12M.items() if key in dict[key1]}\n",
    "        if filtered_dict:\n",
    "            top20(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "        posItr += len(filtered_dict)\n",
    "        ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "e462a55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "477805d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 358\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "df90b497-4ca3-4467-9965-3eeba68fef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 8\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(top20clientonly,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in top20clientonly.items() if key in dict[key1]}\n",
    "        if filtered_dict:\n",
    "            top20Client(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "        posItr += len(filtered_dict)\n",
    "        ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "e578ca09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 421\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "4108f604-685c-4fd8-aab4-5c66967a67ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 9\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(bottom20clientonly,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in bottom20clientonly.items() if key in dict[key1]}\n",
    "        if filtered_dict:\n",
    "            bot20Client(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "        posItr += len(filtered_dict)\n",
    "        ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "c4b098f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "16765a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 496\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "762a2079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496\n"
     ]
    }
   ],
   "source": [
    "if len(sectors)>0:\n",
    "    newVolumeSold(prs, sect_vsod_merged, position=posItr, parent=direct_parent['Sector'], child = 'Sector')\n",
    "    print(posItr)\n",
    "    posItr += sect_vsod_count\n",
    "    ind +=1\n",
    "else:\n",
    "    ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "244a0620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 523\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "d41024fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(segments)>0:\n",
    "    newVolumeSold(prs, seg_vsod_merged, position=posItr, parent=direct_parent['Segment'], child = 'Segment')\n",
    "    posItr += seg_vsod_count\n",
    "    ind +=1\n",
    "    \n",
    "else:\n",
    "    ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "66bc536a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 617\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "92a5db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(subsegments)>0:\n",
    "    newVolumeSold(prs, subseg_vsod_merged, position=posItr, parent=direct_parent['SubSegment'], child = 'SubSegment')\n",
    "    posItr += subseg_vsod_count\n",
    "    ind+=1\n",
    "else:\n",
    "    ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "780b7472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 687\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "2298d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(subcategories)>0:\n",
    "    newVolumeSold(prs, subcat_vsod_merged, position=posItr, parent=direct_parent['SubCategory'], child = 'SubCategory')\n",
    "    posItr += subcat_vsod_count\n",
    "    ind+=1\n",
    "else:\n",
    "    ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "5677352e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 757\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "0ee42400-58ae-4311-8ac7-9914c0ae666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 11\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(modified_promotionBrandsP12M,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in modified_promotionBrandsP12M.items() if key in dict[key1]}\n",
    "        if filtered_dict:\n",
    "            PromoShare_vs_ValueShare(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "        posItr += len(filtered_dict)\n",
    "        ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "7f7b6a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 860\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "569341f7-9b94-4bf5-9114-fe10a6d0cfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 12\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(newModifiedBrands,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in newModifiedBrands.items() if key in dict[key1]}\n",
    "        if filtered_dict:\n",
    "            PromoSalesTotalSize(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "        posItr += len(filtered_dict)\n",
    "        ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "0b4e2148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 860\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "2e6331b0-3674-471a-8da0-d10719174ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 13\n",
    "if promo_type:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(PromoSalesTypes_data,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in PromoSalesTypes_data.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                PromoSalesTypes(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1\n",
    "else:\n",
    "    ind +=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "5192201c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 860\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "555338fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 14\n",
    "if feature_share:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(modified_promotionBrandsP12M,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in modified_promotionBrandsP12M.items() if key in dict[key1]}\n",
    "            if filtered_dict:    \n",
    "                featureShare(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1\n",
    "else:\n",
    "    ind +=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "b2ecb5b3-8308-43ec-b4aa-16c2e7b0797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 15\n",
    "if display_share:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(modified_promotionBrandsP12M,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in modified_promotionBrandsP12M.items() if key in dict[key1]}\n",
    "            if filtered_dict:    \n",
    "                displayShare(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1\n",
    "else:\n",
    "    ind +=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "f16eefd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 860\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "b5ffadfa-5f94-4967-84f6-54c1d2ab7d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 16\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(modified_promotionEndOfWeek,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in modified_promotionEndOfWeek.items() if key in dict[key1]}\n",
    "        if filtered_dict:\n",
    "            PromoFrequency(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "        posItr += len(filtered_dict)\n",
    "        ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "b84ad318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 1160\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "43caf10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if categories:\n",
    "    catFinal = sorted(splitDfsPromo(dfCategory,(client_manuf) ,genrateIndexList(catGroup[0])[0]))\n",
    "    catFinal = catFinal+sorted(splitDfsPromo(dfCategory,(client_brands) ,genrateIndexList(catGroup[0])[0]))\n",
    "    catFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "56f6fd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 1160\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "05117abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sectors:\n",
    "    secFinal = sorted(splitDfsPromo(dfSector,(client_manuf)  ,genrateIndexList(secGroup[0])[0]))\n",
    "    secFinal = secFinal + sorted(splitDfsPromo(dfSector,(client_brands)  ,genrateIndexList(secGroup[0])[0]))\n",
    "    secFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "9f5855f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 1160\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "c788ee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if segments:\n",
    "    segFinal = sorted(splitDfsPromo(dfSegment,(client_manuf)  ,genrateIndexList(segGroup[0])[0]))\n",
    "    segFinal = segFinal+sorted(splitDfsPromo(dfSegment,(client_brands)  ,genrateIndexList(segGroup[0])[0]))\n",
    "    segFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "889d3e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if subsegments:\n",
    "    subsegFinal = sorted(splitDfsPromo(dfSubSegment,(client_manuf)  ,genrateIndexList(subsegGroup[0])[0]))\n",
    "    subsegFinal = subsegFinal + sorted(splitDfsPromo(dfSubSegment,(client_brands)  ,genrateIndexList(subsegGroup[0])[0]))\n",
    "    subsegFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "f3153b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "if subcategories:\n",
    "    subcatFinal = sorted(splitDfsPromo(dfSubCategory,(client_manuf) ,genrateIndexList(subcatGroup[0])[0]))\n",
    "    subcatFinal = subcatFinal+sorted(splitDfsPromo(dfSubCategory,(client_brands) ,genrateIndexList(subcatGroup[0])[0]))\n",
    "    subcatFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "42f04b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 1160\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "5febe962-91f9-4b04-80a0-986f63399c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 75 1168\n",
      "20 76 1191\n",
      "14 77 1211\n",
      "26 78 1225\n"
     ]
    }
   ],
   "source": [
    "#Slide 17\n",
    "#split catGroup into Lists depends on num of charts \n",
    "catGroupSplit = splitListpromo(dfCategory, catGroup, [i-14 for i in index[ind]])\n",
    "promoSalesPerRetailer(prs,dfCategory,len(index[ind]),catGroupSplit,position=sum(duplication[:ind]))\n",
    "posItr = sum(duplication[:ind]) + len(index[ind])\n",
    "ind+=1\n",
    "print(len(index[ind]),ind, posItr)\n",
    "\n",
    "#split secGroup into Lists depends on num of charts \n",
    "if len(sectors) != 0: \n",
    "    secGroupSplit = splitListpromo(dfSector, secGroup, [i-14 for i in index[ind]])\n",
    "    promoSalesPerRetailer(prs,dfSector,len(index[ind]),secGroupSplit,position=posItr)\n",
    "    posItr += len(index[ind])\n",
    "ind+=1\n",
    "print(len(index[ind]),ind, posItr)\n",
    "\n",
    "#split segGroup into Lists depends on num of charts \n",
    "if len(segments) != 0: \n",
    "    segGroupSplit = splitListpromo(dfSegment, segGroup, [i-14 for i in index[ind]])\n",
    "    promoSalesPerRetailer(prs,dfSegment,len(index[ind]),segGroupSplit,position=posItr)\n",
    "    posItr += len(index[ind])\n",
    "ind+=1\n",
    "print(len(index[ind]),ind, posItr)\n",
    "\n",
    "#split subsegGroup into Lists depends on num of charts \n",
    "if len(subsegments) != 0:\n",
    "    subsegGroupSplit = splitListpromo(dfSubSegment, subsegGroup, [i-14 for i in index[ind]])\n",
    "\n",
    "    promoSalesPerRetailer(prs,dfSubSegment,len(index[ind]),subsegGroupSplit,position=posItr)\n",
    "    posItr += len(index[ind])\n",
    "ind+=1\n",
    "print(len(index[ind]),ind, posItr)\n",
    "\n",
    "#split subcatGroup into Lists depends on num of charts \n",
    "if len(subcategories) != 0:\n",
    "    subcatGroupSplit = splitListpromo(dfSubCategory, subcatGroup, [i-14 for i in index[ind]])\n",
    "    promoSalesPerRetailer(prs,dfSubCategory,len(index[ind]),subcatGroupSplit,position=posItr)\n",
    "    posItr += len(index[ind])\n",
    "ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "4bdf01c1-6ec8-405c-bb46-928310996eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 1271\n",
      "80 1308\n",
      "81 1344\n",
      "82 1377\n",
      "83 1430\n"
     ]
    }
   ],
   "source": [
    "# slide 21\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(modified_valueUplift,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in modified_valueUplift.items() if key in dict[key1]}\n",
    "        if filtered_dict:\n",
    "            valueUplift(prs,filtered_dict,duplication[ind],position=posItr)\n",
    "        posItr += len(filtered_dict)\n",
    "        print(ind,posItr)\n",
    "        ind +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "1d1031c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 1 1430\n"
     ]
    }
   ],
   "source": [
    "print(ind, duplication[ind], posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "0e02f578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edgewell\n",
      "Edgewell\n",
      "Edgewell\n",
      "Edgewell\n",
      "Edgewell\n",
      "Edgewell\n",
      "Edgewell\n",
      "1437 7\n"
     ]
    }
   ],
   "source": [
    "if len(categories)>0:\n",
    "    seasonality(prs,dfCategory0, len(index[ind]), categoryGroup0, position=posItr,slideby=\"Category\")\n",
    "    posItr += len(index[ind])\n",
    "ind+=1\n",
    "print(posItr, len(index[ind])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "fec4ed42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autos Scanning\n",
      "Bodega Aurrera\n",
      "Canal Moderno\n",
      "Mi Bodega\n",
      "Walmart\n",
      "Walmart Express\n",
      "Walmart Supercenter\n",
      "1444 7\n"
     ]
    }
   ],
   "source": [
    "if len(sectors)>0:\n",
    "    seasonality(prs, dfSector0, len(index[ind]), secGroup0, position=posItr,slideby=\"Sector\")\n",
    "    posItr += len(index[ind])\n",
    "ind+=1\n",
    "print(posItr, len(index[ind])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "95c95329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autos Scanning\n",
      "Bodega Aurrera\n",
      "Canal Moderno\n",
      "Mi Bodega\n",
      "Walmart\n",
      "Walmart Express\n",
      "Walmart Supercenter\n",
      "1451 21 87\n"
     ]
    }
   ],
   "source": [
    "if len(segments)>0:\n",
    "    seasonality(prs, dfSegment0, len(index[ind]), segGroup0, position=posItr,slideby=\"Segment\")\n",
    "    posItr += len(index[ind])\n",
    "ind+=1\n",
    "print(posItr, len(index[ind]),ind)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "cfffb4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autos Scanning\n",
      "Autos Scanning\n",
      "Autos Scanning\n",
      "Bodega Aurrera\n",
      "Bodega Aurrera\n",
      "Bodega Aurrera\n",
      "Canal Moderno\n",
      "Canal Moderno\n",
      "Canal Moderno\n",
      "Mi Bodega\n",
      "Mi Bodega\n",
      "Mi Bodega\n",
      "Walmart\n",
      "Walmart\n",
      "Walmart\n",
      "Walmart Express\n",
      "Walmart Express\n",
      "Walmart Express\n",
      "Walmart Supercenter\n",
      "Walmart Supercenter\n",
      "Walmart Supercenter\n",
      "1472 21 88\n"
     ]
    }
   ],
   "source": [
    "if len(subsegments) != 0:\n",
    "    seasonality(prs,dfSubSegment0,len(index[ind]),subsegGroup0,position=posItr,slideby=\"SubSegment\")\n",
    "    posItr += len(index[ind])\n",
    "ind+=1\n",
    "\n",
    "print(posItr, len(index[ind]),ind)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "8d74d722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autos Scanning\n",
      "Autos Scanning\n",
      "Autos Scanning\n",
      "Bodega Aurrera\n",
      "Bodega Aurrera\n",
      "Bodega Aurrera\n",
      "Canal Moderno\n",
      "Canal Moderno\n",
      "Canal Moderno\n",
      "Mi Bodega\n",
      "Mi Bodega\n",
      "Mi Bodega\n",
      "Walmart\n",
      "Walmart\n",
      "Walmart\n",
      "Walmart Express\n",
      "Walmart Express\n",
      "Walmart Express\n",
      "Walmart Supercenter\n",
      "Walmart Supercenter\n",
      "Walmart Supercenter\n"
     ]
    }
   ],
   "source": [
    "if len(subcategories) != 0:\n",
    "    seasonality(prs,dfSubCategory0,len(index[ind]),subcatGroup0,position=posItr,slideby=\"SubCategory\")\n",
    "    posItr += len(index[ind])\n",
    "ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "d43fdd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 89 1 1493\n"
     ]
    }
   ],
   "source": [
    "print(len(index[ind]), ind, duplication[ind], posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "bdb5a7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1493 89\n"
     ]
    }
   ],
   "source": [
    "print(posItr,ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "1d8b8952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Promotional_Frequency(prs, data, numOfDuplicates, dfGroup, position=0):\n",
    "    \"\"\"\n",
    "    Update PowerPoint presentation with Promo Sales per Retailer data.\n",
    "\n",
    "    Parameters:\n",
    "    prs (Presentation): PowerPoint presentation object to modify.\n",
    "    endOfWeek (dict): Dictionary containing end of week data.\n",
    "    numOfDuplicates (int): Number of slides to duplicate and update.\n",
    "    dfGroup (list): List containing dataframes grouped for each slide.\n",
    "    position (int, optional): Starting slide position in the presentation. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "    Replace the slides with new data\n",
    "    \"\"\"\n",
    "    # Define dictionaries to map chart numbers to chart order\n",
    "        \n",
    "    ch1 = {0: 0}\n",
    "    ch2 = {0: 0, 1: 1}\n",
    "    ch3 = {0: 0, 1: 1, 2: 2}\n",
    "    ch4 = {0: 0, 1: 1, 2: 2, 3: 3}\n",
    "    # Iterate through each slide to update\n",
    "    i =0\n",
    "\n",
    "    for slide_num in range(numOfDuplicates):\n",
    "            # Extract dataframes for the current slide\n",
    "            dfs = dfGroup[slide_num]\n",
    "            # Extract brand and category information\n",
    "            for i in range(len(dfs)):\n",
    "                client = dfs[0].split(' | ')[0]\n",
    "                retailer_ = dfs[0].split(' | ')[1]\n",
    "                col_ = dfs[0].split(' | ')[2]\n",
    "                market= dfs[0].split(' | ')[-1]\n",
    "                # # Get shapes in the slide\n",
    "                shapes = prs.slides[slide_num + position].shapes\n",
    "                # # Find and update title shape\n",
    "                titleNumber = get_shape_number(shapes, 'Promotional Frequency Analysis | Economy | Bucegi | P12M')\n",
    "                datasourcenum = get_shape_number(shapes, \"DATA SOURCE: Trade Panel/Retailer Data | Ending Apr 2024\")\n",
    "                headerNumber = get_shape_number(shapes, 'Promotional Frequency Analysis (Replace with So What)')\n",
    "                if titleNumber is not None:\n",
    "                    shapes[datasourcenum].text = data_source\n",
    "                    shapes[titleNumber].text = shapes[titleNumber].text.replace('Economy', col_).replace('Bucegi', client + \" | \" + market)\n",
    "                    shapes[titleNumber].text_frame.paragraphs[0].font.size = Pt(12)\n",
    "                    shapes[titleNumber].text_frame.paragraphs[0].font.name = 'Nexa Bold (Headings)'\n",
    "                    shapes[headerNumber].text_frame.paragraphs[0].font.size = Pt(16)\n",
    "                    shapes[headerNumber].text_frame.paragraphs[0].font.name = 'Nexa Bold (Headings)'\n",
    "\n",
    "            # Create table and chart objects\n",
    "            tables, charts = createTableAndChart(shapes)\n",
    "            # Determine the appropriate chart order dictionary based on the number of charts\n",
    "            chDic = ch2 if len(charts) == 2 else ch3 if len(charts) == 3 else ch4 if len(charts) == 4 else ch1 \n",
    "\n",
    "            for chartNum in range(len(charts)):\n",
    "                print(chartNum)\n",
    "                chart = charts[chDic[chartNum]].chart\n",
    "                chart_data = CategoryChartData()\n",
    "                chart_df = data.get(dfs[chartNum])\n",
    "                if chart_df is None:\n",
    "                    print(f\"Key '{dfs[chartNum]}' not found in data! Skipping...\")\n",
    "                    continue\n",
    "\n",
    "                # Apply conditions to Value Uplift\n",
    "                \n",
    "                chart_df['Weekly VSOD'] = np.where((chart_df['VSOD']>.2)&(chart_df['Value Uplift (v. base) Normalized'] != ''),1,None)\n",
    "                chart_df['try'] = 0\n",
    "                chart_df['New Uplift'] = 0\n",
    "                chart_df['try'] = np.where((chart_df['Value Uplift (v. base) Normalized']>=2),1.8,chart_df['Value Uplift (v. base) Normalized'])\n",
    "                chart_df['New Uplift'] = np.where((chart_df['Weekly VSOD']==1)&(chart_df['Value Uplift (v. base) Normalized']>0.05),chart_df['try'],None)\n",
    "                \n",
    "                # Add series to chart\n",
    "                chart_data.categories = chart_df['End of Week'].astype(str)\n",
    "                chart_data.add_series('Weekly VSOD', chart_df['Weekly VSOD'])\n",
    "                chart_data.add_series('New Uplift', chart_df['New Uplift'])\n",
    "                # Replace chart data\n",
    "                chart.replace_data(chart_data)\n",
    "\n",
    "                # Apply formatting and data labels\n",
    "                for series_idx, series in enumerate(chart.series):\n",
    "                    if series_idx == 1:\n",
    "                        # Show data label if >200%\n",
    "                        for point_idx, point in enumerate(series.points):\n",
    "                            value = (chart_df['Value Uplift (v. base) Normalized'].astype(float).replace(np.nan,0).iloc[point_idx] * 100)\n",
    "                            data_label = point.data_label\n",
    "                            data_label.has_text_frame = False\n",
    "                                \n",
    "                            if value >=200:\n",
    "                                point.marker.format.fill.solid()\n",
    "                                point.marker.format.fill.fore_color.rgb = RGBColor(230,229,229)\n",
    "                                point.marker.format.line.color.rgb = RGBColor(230,229,229)\n",
    "                                data_label = point.data_label\n",
    "                                data_label.has_text_frame = True\n",
    "                                data_label.text_frame.text = (str(round(value) ) +\"%\") \n",
    "                                data_label.position = XL_LABEL_POSITION.CENTER\n",
    "                                paragraph = point.data_label.text_frame.paragraphs[0]\n",
    "                                run = paragraph.runs[0] if paragraph.runs else paragraph.add_run()\n",
    "                                run.font.size = Pt(8)\n",
    "                                run.font.color.rgb = RGBColor(0, 160, 151)\n",
    "    \n",
    "                    chart.replace_data(chart_data)\n",
    "\n",
    "            # Update table with retailer information\n",
    "            table = tables[0].table\n",
    "            for rowNum, row in enumerate(table.rows):\n",
    "                cell = row.cells[0]\n",
    "                cell.text = dfs[rowNum].split(' | ')[1]\n",
    "                cell.text_frame.paragraphs[0].font.name = 'Nexa Bold'\n",
    "                cell.text_frame.paragraphs[0].font.size = Pt(8)\n",
    "                cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "f6b6cb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "22 1501\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "23 1523\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "Key 'Hawaiian Tropic | Canal Moderno | Sunscreen Baby | CHANNEL' not found in data! Skipping...\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "14 1546\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "24 1560\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "catGroup1Split = splitListpromo(modified_dfCategory1, catGroup1, [i-25 for i in index[ind]])\n",
    "\n",
    "Promotional_Frequency(prs,modified_dfCategory1,len(index[ind]),catGroup1Split,position=posItr)\n",
    "posItr +=len(catGroup1Split)\n",
    "ind+=1\n",
    "print(len(index[ind]), posItr)\n",
    "#Sector Replace\n",
    "if len(sectors) != 0: \n",
    "    secGroup1Split = splitListpromo(modified_dfSector1, secGroup1, [i-25 for i in index[ind]])\n",
    "    Promotional_Frequency(prs,modified_dfSector1,len(index[ind]),secGroup1Split,position=posItr)\n",
    "    posItr += len(secGroup1Split)\n",
    "ind+=1\n",
    "print(len(index[ind]), posItr)\n",
    "\n",
    "\n",
    "if len(segments) != 0: \n",
    "    segGroup1Split = splitListpromo(modified_dfSegment1, segGroup1, [i-25 for i in index[ind]])\n",
    "    Promotional_Frequency(prs,modified_dfSegment1,len(index[ind]),segGroup1Split,position=posItr)\n",
    "    posItr += len(segGroup1Split)\n",
    "ind+=1\n",
    "print(len(index[ind]), posItr)\n",
    "\n",
    "if len(subsegments) != 0:\n",
    "    subsegGroup1Split = splitListpromo(modified_dfSubSegment1, subsegGroup1, [i-25 for i in index[ind]])\n",
    "    Promotional_Frequency(prs,modified_dfSubSegment1,len(index[ind]),subsegGroup1Split,position=posItr)\n",
    "    posItr += len(subsegGroup1Split)\n",
    "ind+=1\n",
    "print(len(index[ind]), posItr)\n",
    "\n",
    "if len(subcategories) != 0:\n",
    "    subcatGroup1Split = splitListpromo(modified_dfSubCategory1, subcatGroup1, [i-25 for i in index[ind]])\n",
    "    Promotional_Frequency(prs,modified_dfSubCategory1,len(index[ind]),subcatGroup1Split,position=posItr)\n",
    "    posItr += len(subcatGroup1Split)\n",
    "ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "c746a677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slide 1 with no client brands\n",
    "# for key,value in Scope.items():\n",
    "#     dict = {key: count_df(promotionsBrandSortedTotalFinal,value) }\n",
    "#     for key1,value1 in dict.items():\n",
    "#         filtered_dict = {key: value for key, value in promotionsBrandSortedTotalFinal.items() if key in dict[key1]}\n",
    "#         if filtered_dict:\n",
    "#             promoEvolutionNew(prs,filtered_dict,duplication[ind],position=posItr)\n",
    "#             posItr += len(filtered_dict)\n",
    "#         ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "b39417e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 2 with no client brands\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(promotionsBrandNOTSortedTotalFinal,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in promotionsBrandNOTSortedTotalFinal.items() if key in dict[key1]}\n",
    "        if filtered_dict:\n",
    "            promoEvolutionNew(prs,filtered_dict,duplication[ind],position=posItr)\n",
    "            posItr += len(filtered_dict)\n",
    "        ind +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "42070784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 3 with no client brands\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(newpromotionsNotBrandsWithMarket,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in newpromotionsNotBrandsWithMarket.items() if key in dict[key1]}\n",
    "        if filtered_dict:\n",
    "            VSOD1(prs,filtered_dict,duplication[ind],position=posItr)\n",
    "        posItr += len(filtered_dict)\n",
    "        ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "c634a371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1715"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posItr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "7e53b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 4 with no client brands\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(concated,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in concated.items() if key in dict[key1]}\n",
    "        if filtered_dict:\n",
    "            valueUpliftRetailer_no(prs,filtered_dict,duplication[ind],position=posItr)\n",
    "        posItr += len(filtered_dict)\n",
    "        ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "9c2b0cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1731"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posItr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42a734c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "995b3726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 11 with no client prio\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(modified_promotionBrandsP12M,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in modified_promotionBrandsP12M.items() if key in dict[key1]}\n",
    "        if filtered_dict:\n",
    "            PromoShare_vs_ValueShare_no(prs,filtered_dict,duplication[ind],position=posItr)\n",
    "        posItr += len(filtered_dict)\n",
    "        ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "33d8a842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1834"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posItr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "f4018019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Category': []}\n",
      "1834\n",
      "{'Sector': []}\n",
      "1834\n",
      "{'Segment': []}\n",
      "1834\n",
      "{'Subsegment': []}\n",
      "1834\n",
      "{'Subcategory': []}\n",
      "1834\n"
     ]
    }
   ],
   "source": [
    "# slide 12 with no client prio\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(newModifiedBrands,value) }\n",
    "    print(dict)\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in newModifiedBrands.items() if key in dict[key1]}\n",
    "        if filtered_dict:\n",
    "            PromoSalesTotalSize_no(prs,filtered_dict,duplication[ind],position=posItr)\n",
    "        posItr += len(filtered_dict)\n",
    "        ind +=1\n",
    "        print(posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "7e142e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 13 with no client prio\n",
    "# if promo_type:\n",
    "#     for key,value in Scope.items():\n",
    "#         dict = {key: count_df(PromoSalesTypes_data,value) }\n",
    "#         for key1,value1 in dict.items():\n",
    "#             filtered_dict = {key: value for key, value in PromoSalesTypes_data.items() if key in dict[key1]}\n",
    "#             if filtered_dict:\n",
    "#                 PromoSalesTypes_no(prs,filtered_dict,duplication[ind],position=posItr)\n",
    "#             posItr += len(filtered_dict)\n",
    "#             ind +=1\n",
    "# else:\n",
    "#     ind +=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "5f3c723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 14 with no client prio\n",
    "if feature_share:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(modified_promotionBrandsP12M,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in modified_promotionBrandsP12M.items() if key in dict[key1]}\n",
    "            if filtered_dict:    \n",
    "                featureShare_no(prs,filtered_dict,duplication[ind],position=posItr)\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1\n",
    "else:\n",
    "    ind +=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "bfbef8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 15 with no client prio\n",
    "if display_share:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(modified_promotionBrandsP12M,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in modified_promotionBrandsP12M.items() if key in dict[key1]}\n",
    "            if filtered_dict:    \n",
    "                displayShare_no(prs,filtered_dict,duplication[ind],position=posItr)\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1\n",
    "else:\n",
    "    ind +=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217af932",
   "metadata": {},
   "source": [
    "## Output slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "c56e0982-087b-439b-a549-736abdbb54b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath=os.getcwd() + f\"\\\\Promotion {client_manuf[0]}.pptx\"\n",
    "prs.save(outputPath)\n",
    "# app = win32.Dispatch(\"PowerPoint.Application\")\n",
    "# presentation = app.Presentations.Open(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "b982c10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slide 127: Opened Excel workbook: Book1\n",
      "Slide 128: Opened Excel workbook: Book1\n",
      "Slide 129: Opened Excel workbook: Book1\n",
      "Slide 130: Opened Excel workbook: Book1\n",
      "Slide 131: Opened Excel workbook: Book1\n",
      "Slide 132: Opened Excel workbook: Book1\n",
      "Slide 133: Opened Excel workbook: Book1\n",
      "Slide 134: Opened Excel workbook: Book1\n",
      "Slide 135: Opened Excel workbook: Book1\n",
      "Slide 136: Opened Excel workbook: Book1\n",
      "Slide 137: Opened Excel workbook: Book1\n",
      "Slide 138: Opened Excel workbook: Book1\n",
      "Slide 139: Opened Excel workbook: Book1\n",
      "Slide 140: Opened Excel workbook: Book1\n",
      "Slide 141: Opened Excel workbook: Book1\n",
      "Slide 142: Opened Excel workbook: Book1\n",
      "Slide 143: Opened Excel workbook: Book1\n",
      "Slide 144: Opened Excel workbook: Book1\n",
      "Slide 145: Opened Excel workbook: Book1\n",
      "Slide 146: Opened Excel workbook: Book1\n",
      "Slide 147: Opened Excel workbook: Book1\n",
      "Slide 148: Opened Excel workbook: Book1\n",
      "Slide 149: Opened Excel workbook: Book1\n",
      "Slide 150: Opened Excel workbook: Book1\n",
      "Slide 151: Opened Excel workbook: Book1\n",
      "Slide 152: Opened Excel workbook: Book1\n",
      "Slide 153: Opened Excel workbook: Book1\n",
      "Slide 154: Opened Excel workbook: Book1\n",
      "Slide 155: Opened Excel workbook: Book1\n",
      "Slide 156: Opened Excel workbook: Book1\n",
      "Slide 157: Opened Excel workbook: Book1\n",
      "Slide 158: Opened Excel workbook: Book1\n",
      "Slide 159: Opened Excel workbook: Book1\n",
      "Slide 160: Opened Excel workbook: Book1\n",
      "Slide 161: Opened Excel workbook: Book1\n",
      "Slide 162: Opened Excel workbook: Book1\n",
      "Slide 163: Opened Excel workbook: Book1\n",
      "Slide 164: Opened Excel workbook: Book1\n",
      "Slide 165: Opened Excel workbook: Book1\n",
      "Slide 166: Opened Excel workbook: Book1\n",
      "Slide 167: Opened Excel workbook: Book1\n",
      "Slide 168: Opened Excel workbook: Book1\n",
      "Slide 169: Opened Excel workbook: Book1\n",
      "Slide 170: Opened Excel workbook: Book1\n",
      "Slide 171: Opened Excel workbook: Book1\n",
      "Slide 172: Opened Excel workbook: Book1\n",
      "Slide 173: Opened Excel workbook: Book1\n",
      "Slide 174: Opened Excel workbook: Book1\n",
      "Slide 175: Opened Excel workbook: Book1\n",
      "Slide 176: Opened Excel workbook: Book1\n",
      "Slide 177: Opened Excel workbook: Book1\n",
      "Slide 178: Opened Excel workbook: Book1\n",
      "Slide 179: Opened Excel workbook: Book1\n",
      "Slide 180: Opened Excel workbook: Book1\n",
      "Slide 181: Opened Excel workbook: Book1\n",
      "Slide 182: Opened Excel workbook: Book1\n",
      "Slide 183: Opened Excel workbook: Book1\n",
      "Slide 184: Opened Excel workbook: Book1\n",
      "Slide 185: Opened Excel workbook: Book1\n",
      "Slide 186: Opened Excel workbook: Book1\n",
      "Slide 187: Opened Excel workbook: Book1\n",
      "Slide 188: Opened Excel workbook: Book1\n",
      "Slide 189: Opened Excel workbook: Book1\n",
      "Slide 190: Opened Excel workbook: Book1\n",
      "Slide 191: Opened Excel workbook: Book1\n",
      "Slide 192: Opened Excel workbook: Book1\n",
      "Slide 193: Opened Excel workbook: Book1\n",
      "Slide 194: Opened Excel workbook: Book1\n",
      "Slide 195: Opened Excel workbook: Book1\n",
      "Slide 196: Opened Excel workbook: Book1\n",
      "Slide 197: Opened Excel workbook: Book1\n",
      "Slide 198: Opened Excel workbook: Book1\n",
      "Slide 199: Opened Excel workbook: Book1\n",
      "Slide 200: Opened Excel workbook: Book1\n",
      "Slide 201: Opened Excel workbook: Book1\n",
      "Slide 202: Opened Excel workbook: Book1\n",
      "Slide 203: Opened Excel workbook: Book1\n",
      "Slide 204: Opened Excel workbook: Book1\n",
      "Slide 205: Opened Excel workbook: Book1\n",
      "Slide 206: Opened Excel workbook: Book1\n",
      "Slide 207: Opened Excel workbook: Book1\n",
      "Slide 208: Opened Excel workbook: Book1\n",
      "Slide 209: Opened Excel workbook: Book1\n",
      "Slide 210: Opened Excel workbook: Book1\n",
      "Slide 211: Opened Excel workbook: Book1\n",
      "Slide 212: Opened Excel workbook: Book1\n",
      "Slide 213: Opened Excel workbook: Book1\n",
      "Slide 214: Opened Excel workbook: Book1\n",
      "Slide 215: Opened Excel workbook: Book1\n",
      "Slide 216: Opened Excel workbook: Book1\n",
      "Slide 217: Opened Excel workbook: Book1\n",
      "Slide 218: Opened Excel workbook: Book1\n",
      "Slide 219: Opened Excel workbook: Book1\n",
      "Slide 220: Opened Excel workbook: Book1\n",
      "Slide 221: Opened Excel workbook: Book1\n",
      "Slide 222: Opened Excel workbook: Book1\n",
      "Slide 223: Opened Excel workbook: Book1\n",
      "Slide 224: Opened Excel workbook: Book1\n",
      "Slide 225: Opened Excel workbook: Book1\n",
      "Slide 226: Opened Excel workbook: Book1\n",
      "Slide 227: Opened Excel workbook: Book1\n",
      "Slide 228: Opened Excel workbook: Book1\n",
      "Slide 229: Opened Excel workbook: Book1\n",
      "Slide 230: Opened Excel workbook: Book1\n",
      "Slide 231: Opened Excel workbook: Book1\n",
      "Slide 232: Opened Excel workbook: Book1\n",
      "Slide 233: Opened Excel workbook: Book1\n",
      "Slide 234: Opened Excel workbook: Book1\n",
      "Slide 235: Opened Excel workbook: Book1\n",
      "Slide 236: Opened Excel workbook: Book1\n",
      "Slide 237: Opened Excel workbook: Book1\n",
      "Slide 238: Opened Excel workbook: Book1\n",
      "Slide 239: Opened Excel workbook: Book1\n",
      "Slide 240: Opened Excel workbook: Book1\n",
      "Slide 241: Opened Excel workbook: Book1\n",
      "Slide 242: Opened Excel workbook: Book1\n",
      "Slide 243: Opened Excel workbook: Book1\n",
      "Slide 244: Opened Excel workbook: Book1\n",
      "Slide 245: Opened Excel workbook: Book1\n",
      "Slide 246: Opened Excel workbook: Book1\n",
      "Slide 247: Opened Excel workbook: Book1\n",
      "Slide 248: Opened Excel workbook: Book1\n",
      "Slide 249: Opened Excel workbook: Book1\n",
      "Slide 250: Opened Excel workbook: Book1\n",
      "Slide 251: Opened Excel workbook: Book1\n",
      "Slide 252: Opened Excel workbook: Book1\n",
      "Slide 253: Opened Excel workbook: Book1\n",
      "Slide 254: Opened Excel workbook: Book1\n",
      "Slide 255: Opened Excel workbook: Book1\n",
      "Slide 256: Opened Excel workbook: Book1\n",
      "Slide 257: Opened Excel workbook: Book1\n",
      "Slide 258: Opened Excel workbook: Book1\n",
      "Slide 259: Opened Excel workbook: Book1\n",
      "Slide 260: Opened Excel workbook: Book1\n",
      "Slide 261: Opened Excel workbook: Book1\n",
      "Slide 262: Opened Excel workbook: Book1\n",
      "Slide 263: Opened Excel workbook: Book1\n",
      "Slide 264: Opened Excel workbook: Book1\n",
      "Slide 265: Opened Excel workbook: Book1\n",
      "Slide 266: Opened Excel workbook: Book1\n",
      "Slide 267: Opened Excel workbook: Book1\n",
      "Slide 268: Opened Excel workbook: Book1\n",
      "Slide 269: Opened Excel workbook: Book1\n",
      "Slide 270: Opened Excel workbook: Book1\n",
      "Slide 271: Opened Excel workbook: Book1\n",
      "Slide 272: Opened Excel workbook: Book1\n",
      "Slide 273: Opened Excel workbook: Book1\n",
      "Slide 274: Opened Excel workbook: Book1\n",
      "Slide 275: Opened Excel workbook: Book1\n",
      "Slide 276: Opened Excel workbook: Book1\n",
      "Slide 277: Opened Excel workbook: Book1\n",
      "Slide 278: Opened Excel workbook: Book1\n",
      "Slide 279: Opened Excel workbook: Book1\n",
      "Slide 280: Opened Excel workbook: Book1\n",
      "Slide 281: Opened Excel workbook: Book1\n",
      "Slide 282: Opened Excel workbook: Book1\n",
      "Slide 283: Opened Excel workbook: Book1\n",
      "Slide 284: Opened Excel workbook: Book1\n",
      "Slide 285: Opened Excel workbook: Book1\n",
      "Slide 286: Opened Excel workbook: Book1\n",
      "Slide 287: Opened Excel workbook: Book1\n",
      "Slide 288: Opened Excel workbook: Book1\n",
      "Slide 289: Opened Excel workbook: Book1\n",
      "Slide 290: Opened Excel workbook: Book1\n",
      "Slide 291: Opened Excel workbook: Book1\n",
      "Slide 292: Opened Excel workbook: Book1\n",
      "Slide 293: Opened Excel workbook: Book1\n",
      "Slide 294: Opened Excel workbook: Book1\n",
      "Slide 1252: Opened Excel workbook: Book1\n",
      "Slide 1252: Opened Excel workbook: Book1\n",
      "Slide 1253: Opened Excel workbook: Book1\n",
      "Slide 1253: Opened Excel workbook: Book1\n",
      "Slide 1254: Opened Excel workbook: Book1\n",
      "Slide 1254: Opened Excel workbook: Book1\n",
      "Slide 1255: Opened Excel workbook: Book1\n",
      "Slide 1255: Opened Excel workbook: Book1\n",
      "Slide 1256: Opened Excel workbook: Book1\n",
      "Slide 1256: Opened Excel workbook: Book1\n",
      "Slide 1257: Opened Excel workbook: Book1\n",
      "Slide 1257: Opened Excel workbook: Book1\n",
      "Slide 1258: Opened Excel workbook: Book1\n",
      "Slide 1258: Opened Excel workbook: Book1\n",
      "Slide 1259: Opened Excel workbook: Book1\n",
      "Slide 1259: Opened Excel workbook: Book1\n",
      "Slide 1260: Opened Excel workbook: Book1\n",
      "Slide 1260: Opened Excel workbook: Book1\n",
      "Slide 1261: Opened Excel workbook: Book1\n",
      "Slide 1261: Opened Excel workbook: Book1\n",
      "Slide 1262: Opened Excel workbook: Book1\n",
      "Slide 1262: Opened Excel workbook: Book1\n",
      "Slide 1263: Opened Excel workbook: Book1\n",
      "Slide 1263: Opened Excel workbook: Book1\n",
      "Slide 1264: Opened Excel workbook: Book1\n",
      "Slide 1264: Opened Excel workbook: Book1\n",
      "Slide 1265: Opened Excel workbook: Book1\n",
      "Slide 1265: Opened Excel workbook: Book1\n",
      "Slide 1266: Opened Excel workbook: Book1\n",
      "Slide 1266: Opened Excel workbook: Book1\n",
      "Slide 1267: Opened Excel workbook: Book1\n",
      "Slide 1267: Opened Excel workbook: Book1\n",
      "Slide 1268: Opened Excel workbook: Book1\n",
      "Slide 1268: Opened Excel workbook: Book1\n",
      "Slide 1269: Opened Excel workbook: Book1\n",
      "Slide 1269: Opened Excel workbook: Book1\n",
      "Slide 1270: Opened Excel workbook: Book1\n",
      "Slide 1270: Opened Excel workbook: Book1\n",
      "Slide 1271: Opened Excel workbook: Book1\n",
      "Slide 1271: Opened Excel workbook: Book1\n",
      "Slide 1272: Opened Excel workbook: Book1\n",
      "Slide 1272: Opened Excel workbook: Book1\n",
      "Slide 1273: Opened Excel workbook: Book1\n",
      "Slide 1273: Opened Excel workbook: Book1\n",
      "Slide 1274: Opened Excel workbook: Book1\n",
      "Slide 1274: Opened Excel workbook: Book1\n",
      "Slide 1275: Opened Excel workbook: Book1\n",
      "Slide 1275: Opened Excel workbook: Book1\n",
      "Slide 1276: Opened Excel workbook: Book1\n",
      "Slide 1276: Opened Excel workbook: Book1\n",
      "Slide 1277: Opened Excel workbook: Book1\n",
      "Slide 1277: Opened Excel workbook: Book1\n",
      "Slide 1278: Opened Excel workbook: Book1\n",
      "Slide 1278: Opened Excel workbook: Book1\n",
      "Slide 1279: Opened Excel workbook: Book1\n",
      "Slide 1279: Opened Excel workbook: Book1\n",
      "Slide 1280: Opened Excel workbook: Book1\n",
      "Slide 1280: Opened Excel workbook: Book1\n",
      "Slide 1281: Opened Excel workbook: Book1\n",
      "Slide 1281: Opened Excel workbook: Book1\n",
      "Slide 1282: Opened Excel workbook: Book1\n",
      "Slide 1282: Opened Excel workbook: Book1\n",
      "Slide 1283: Opened Excel workbook: Book1\n",
      "Slide 1283: Opened Excel workbook: Book1\n",
      "Slide 1284: Opened Excel workbook: Book1\n",
      "Slide 1284: Opened Excel workbook: Book1\n",
      "Slide 1285: Opened Excel workbook: Book1\n",
      "Slide 1285: Opened Excel workbook: Book1\n",
      "Slide 1286: Opened Excel workbook: Book1\n",
      "Slide 1286: Opened Excel workbook: Book1\n",
      "Slide 1287: Opened Excel workbook: Book1\n",
      "Slide 1287: Opened Excel workbook: Book1\n",
      "Slide 1288: Opened Excel workbook: Book1\n",
      "Slide 1288: Opened Excel workbook: Book1\n",
      "Slide 1289: Opened Excel workbook: Book1\n",
      "Slide 1289: Opened Excel workbook: Book1\n",
      "Slide 1290: Opened Excel workbook: Book1\n",
      "Slide 1290: Opened Excel workbook: Book1\n",
      "Slide 1291: Opened Excel workbook: Book1\n",
      "Slide 1291: Opened Excel workbook: Book1\n",
      "Slide 1292: Opened Excel workbook: Book1\n",
      "Slide 1292: Opened Excel workbook: Book1\n",
      "Slide 1293: Opened Excel workbook: Book1\n",
      "Slide 1293: Opened Excel workbook: Book1\n",
      "Slide 1294: Opened Excel workbook: Book1\n",
      "Slide 1294: Opened Excel workbook: Book1\n",
      "Slide 1295: Opened Excel workbook: Book1\n",
      "Slide 1295: Opened Excel workbook: Book1\n",
      "Slide 1296: Opened Excel workbook: Book1\n",
      "Slide 1296: Opened Excel workbook: Book1\n",
      "Slide 1297: Opened Excel workbook: Book1\n",
      "Slide 1297: Opened Excel workbook: Book1\n",
      "Slide 1298: Opened Excel workbook: Book1\n",
      "Slide 1298: Opened Excel workbook: Book1\n",
      "Slide 1299: Opened Excel workbook: Book1\n",
      "Slide 1299: Opened Excel workbook: Book1\n",
      "Slide 1300: Opened Excel workbook: Book1\n",
      "Slide 1300: Opened Excel workbook: Book1\n",
      "Slide 1301: Opened Excel workbook: Book1\n",
      "Slide 1301: Opened Excel workbook: Book1\n",
      "Slide 1302: Opened Excel workbook: Book1\n",
      "Slide 1302: Opened Excel workbook: Book1\n",
      "Slide 1303: Opened Excel workbook: Book1\n",
      "Slide 1303: Opened Excel workbook: Book1\n",
      "Slide 1304: Opened Excel workbook: Book1\n",
      "Slide 1304: Opened Excel workbook: Book1\n",
      "Slide 1305: Opened Excel workbook: Book1\n",
      "Slide 1305: Opened Excel workbook: Book1\n",
      "Slide 1306: Opened Excel workbook: Book1\n",
      "Slide 1306: Opened Excel workbook: Book1\n",
      "Slide 1307: Opened Excel workbook: Book1\n",
      "Slide 1307: Opened Excel workbook: Book1\n",
      "Slide 1308: Opened Excel workbook: Book1\n",
      "Slide 1308: Opened Excel workbook: Book1\n",
      "Slide 1309: Opened Excel workbook: Book1\n",
      "Slide 1309: Opened Excel workbook: Book1\n",
      "Slide 1310: Opened Excel workbook: Book1\n",
      "Slide 1310: Opened Excel workbook: Book1\n",
      "Slide 1311: Opened Excel workbook: Book1\n",
      "Slide 1311: Opened Excel workbook: Book1\n",
      "Slide 1312: Opened Excel workbook: Book1\n",
      "Slide 1312: Opened Excel workbook: Book1\n",
      "Slide 1313: Opened Excel workbook: Book1\n",
      "Slide 1313: Opened Excel workbook: Book1\n",
      "Slide 1314: Opened Excel workbook: Book1\n",
      "Slide 1314: Opened Excel workbook: Book1\n",
      "Slide 1315: Opened Excel workbook: Book1\n",
      "Slide 1315: Opened Excel workbook: Book1\n",
      "Slide 1316: Opened Excel workbook: Book1\n",
      "Slide 1316: Opened Excel workbook: Book1\n",
      "Slide 1317: Opened Excel workbook: Book1\n",
      "Slide 1317: Opened Excel workbook: Book1\n",
      "Slide 1318: Opened Excel workbook: Book1\n",
      "Slide 1318: Opened Excel workbook: Book1\n",
      "Slide 1319: Opened Excel workbook: Book1\n",
      "Slide 1319: Opened Excel workbook: Book1\n",
      "Slide 1320: Opened Excel workbook: Book1\n",
      "Slide 1320: Opened Excel workbook: Book1\n",
      "Slide 1321: Opened Excel workbook: Book1\n",
      "Slide 1321: Opened Excel workbook: Book1\n",
      "Slide 1322: Opened Excel workbook: Book1\n",
      "Slide 1322: Opened Excel workbook: Book1\n",
      "Slide 1323: Opened Excel workbook: Book1\n",
      "Slide 1323: Opened Excel workbook: Book1\n",
      "Slide 1324: Opened Excel workbook: Book1\n",
      "Slide 1324: Opened Excel workbook: Book1\n",
      "Slide 1325: Opened Excel workbook: Book1\n",
      "Slide 1325: Opened Excel workbook: Book1\n",
      "Slide 1326: Opened Excel workbook: Book1\n",
      "Slide 1326: Opened Excel workbook: Book1\n",
      "Slide 1327: Opened Excel workbook: Book1\n",
      "Slide 1327: Opened Excel workbook: Book1\n",
      "Slide 1328: Opened Excel workbook: Book1\n",
      "Slide 1328: Opened Excel workbook: Book1\n",
      "Slide 1329: Opened Excel workbook: Book1\n",
      "Slide 1329: Opened Excel workbook: Book1\n",
      "Slide 1330: Opened Excel workbook: Book1\n",
      "Slide 1330: Opened Excel workbook: Book1\n",
      "Slide 1331: Opened Excel workbook: Book1\n",
      "Slide 1331: Opened Excel workbook: Book1\n",
      "Slide 1332: Opened Excel workbook: Book1\n",
      "Slide 1332: Opened Excel workbook: Book1\n",
      "Slide 1333: Opened Excel workbook: Book1\n",
      "Slide 1333: Opened Excel workbook: Book1\n",
      "Slide 1334: Opened Excel workbook: Book1\n",
      "Slide 1334: Opened Excel workbook: Book1\n",
      "Slide 1335: Opened Excel workbook: Book1\n",
      "Slide 1335: Opened Excel workbook: Book1\n",
      "Slide 1336: Opened Excel workbook: Book1\n",
      "Slide 1336: Opened Excel workbook: Book1\n",
      "Slide 1337: Opened Excel workbook: Book1\n",
      "Slide 1337: Opened Excel workbook: Book1\n",
      "Slide 1338: Opened Excel workbook: Book1\n",
      "Slide 1338: Opened Excel workbook: Book1\n",
      "Slide 1339: Opened Excel workbook: Book1\n",
      "Slide 1339: Opened Excel workbook: Book1\n",
      "Slide 1340: Opened Excel workbook: Book1\n",
      "Slide 1340: Opened Excel workbook: Book1\n",
      "Slide 1341: Opened Excel workbook: Book1\n",
      "Slide 1341: Opened Excel workbook: Book1\n",
      "Slide 1342: Opened Excel workbook: Book1\n",
      "Slide 1342: Opened Excel workbook: Book1\n",
      "Slide 1343: Opened Excel workbook: Book1\n",
      "Slide 1343: Opened Excel workbook: Book1\n",
      "Slide 1344: Opened Excel workbook: Book1\n",
      "Slide 1344: Opened Excel workbook: Book1\n",
      "Slide 1345: Opened Excel workbook: Book1\n",
      "Slide 1345: Opened Excel workbook: Book1\n",
      "Slide 1346: Opened Excel workbook: Book1\n",
      "Slide 1346: Opened Excel workbook: Book1\n",
      "Slide 1347: Opened Excel workbook: Book1\n",
      "Slide 1347: Opened Excel workbook: Book1\n",
      "Slide 1348: Opened Excel workbook: Book1\n",
      "Slide 1348: Opened Excel workbook: Book1\n",
      "Slide 1349: Opened Excel workbook: Book1\n",
      "Slide 1349: Opened Excel workbook: Book1\n",
      "Slide 1350: Opened Excel workbook: Book1\n",
      "Slide 1350: Opened Excel workbook: Book1\n",
      "Slide 1351: Opened Excel workbook: Book1\n",
      "Slide 1351: Opened Excel workbook: Book1\n",
      "Slide 1352: Opened Excel workbook: Book1\n",
      "Slide 1352: Opened Excel workbook: Book1\n",
      "Slide 1353: Opened Excel workbook: Book1\n",
      "Slide 1353: Opened Excel workbook: Book1\n",
      "Slide 1354: Opened Excel workbook: Book1\n",
      "Slide 1354: Opened Excel workbook: Book1\n",
      "Slide 1355: Opened Excel workbook: Book1\n",
      "Slide 1355: Opened Excel workbook: Book1\n",
      "Slide 1356: Opened Excel workbook: Book1\n",
      "Slide 1356: Opened Excel workbook: Book1\n",
      "Slide 1357: Opened Excel workbook: Book1\n",
      "Slide 1357: Opened Excel workbook: Book1\n",
      "Slide 1358: Opened Excel workbook: Book1\n",
      "Slide 1358: Opened Excel workbook: Book1\n",
      "Slide 1359: Opened Excel workbook: Book1\n",
      "Slide 1359: Opened Excel workbook: Book1\n",
      "Slide 1360: Opened Excel workbook: Book1\n",
      "Slide 1360: Opened Excel workbook: Book1\n",
      "Slide 1361: Opened Excel workbook: Book1\n",
      "Slide 1361: Opened Excel workbook: Book1\n",
      "Slide 1362: Opened Excel workbook: Book1\n",
      "Slide 1362: Opened Excel workbook: Book1\n",
      "Slide 1363: Opened Excel workbook: Book1\n",
      "Slide 1363: Opened Excel workbook: Book1\n",
      "Slide 1364: Opened Excel workbook: Book1\n",
      "Slide 1364: Opened Excel workbook: Book1\n",
      "Slide 1365: Opened Excel workbook: Book1\n",
      "Slide 1365: Opened Excel workbook: Book1\n",
      "Slide 1366: Opened Excel workbook: Book1\n",
      "Slide 1366: Opened Excel workbook: Book1\n",
      "Slide 1367: Opened Excel workbook: Book1\n",
      "Slide 1367: Opened Excel workbook: Book1\n",
      "Slide 1368: Opened Excel workbook: Book1\n",
      "Slide 1368: Opened Excel workbook: Book1\n",
      "Slide 1369: Opened Excel workbook: Book1\n",
      "Slide 1369: Opened Excel workbook: Book1\n",
      "Slide 1370: Opened Excel workbook: Book1\n",
      "Slide 1370: Opened Excel workbook: Book1\n",
      "Slide 1371: Opened Excel workbook: Book1\n",
      "Slide 1371: Opened Excel workbook: Book1\n",
      "Slide 1372: Opened Excel workbook: Book1\n",
      "Slide 1372: Opened Excel workbook: Book1\n",
      "Slide 1373: Opened Excel workbook: Book1\n",
      "Slide 1373: Opened Excel workbook: Book1\n",
      "Slide 1374: Opened Excel workbook: Book1\n",
      "Slide 1374: Opened Excel workbook: Book1\n",
      "Slide 1375: Opened Excel workbook: Book1\n",
      "Slide 1375: Opened Excel workbook: Book1\n",
      "Slide 1376: Opened Excel workbook: Book1\n",
      "Slide 1376: Opened Excel workbook: Book1\n",
      "Slide 1377: Opened Excel workbook: Book1\n",
      "Slide 1377: Opened Excel workbook: Book1\n",
      "Slide 1378: Opened Excel workbook: Book1\n",
      "Slide 1378: Opened Excel workbook: Book1\n",
      "Slide 1379: Opened Excel workbook: Book1\n",
      "Slide 1379: Opened Excel workbook: Book1\n",
      "Slide 1380: Opened Excel workbook: Book1\n",
      "Slide 1380: Opened Excel workbook: Book1\n",
      "Slide 1381: Opened Excel workbook: Book1\n",
      "Slide 1381: Opened Excel workbook: Book1\n",
      "Slide 1382: Opened Excel workbook: Book1\n",
      "Slide 1382: Opened Excel workbook: Book1\n",
      "Slide 1383: Opened Excel workbook: Book1\n",
      "Slide 1383: Opened Excel workbook: Book1\n",
      "Slide 1384: Opened Excel workbook: Book1\n",
      "Slide 1384: Opened Excel workbook: Book1\n",
      "Slide 1385: Opened Excel workbook: Book1\n",
      "Slide 1385: Opened Excel workbook: Book1\n",
      "Slide 1386: Opened Excel workbook: Book1\n",
      "Slide 1386: Opened Excel workbook: Book1\n",
      "Slide 1387: Opened Excel workbook: Book1\n",
      "Slide 1387: Opened Excel workbook: Book1\n",
      "Slide 1388: Opened Excel workbook: Book1\n",
      "Slide 1388: Opened Excel workbook: Book1\n",
      "Slide 1389: Opened Excel workbook: Book1\n",
      "Slide 1389: Opened Excel workbook: Book1\n",
      "Slide 1390: Opened Excel workbook: Book1\n",
      "Slide 1390: Opened Excel workbook: Book1\n",
      "Slide 1391: Opened Excel workbook: Book1\n",
      "Slide 1391: Opened Excel workbook: Book1\n",
      "Slide 1392: Opened Excel workbook: Book1\n",
      "Slide 1392: Opened Excel workbook: Book1\n",
      "Slide 1393: Opened Excel workbook: Book1\n",
      "Slide 1393: Opened Excel workbook: Book1\n",
      "Slide 1394: Opened Excel workbook: Book1\n",
      "Slide 1394: Opened Excel workbook: Book1\n",
      "Slide 1395: Opened Excel workbook: Book1\n",
      "Slide 1395: Opened Excel workbook: Book1\n",
      "Slide 1396: Opened Excel workbook: Book1\n",
      "Slide 1396: Opened Excel workbook: Book1\n",
      "Slide 1397: Opened Excel workbook: Book1\n",
      "Slide 1397: Opened Excel workbook: Book1\n",
      "Slide 1398: Opened Excel workbook: Book1\n",
      "Slide 1398: Opened Excel workbook: Book1\n",
      "Slide 1399: Opened Excel workbook: Book1\n",
      "Slide 1399: Opened Excel workbook: Book1\n",
      "Slide 1400: Opened Excel workbook: Book1\n",
      "Slide 1400: Opened Excel workbook: Book1\n",
      "Slide 1401: Opened Excel workbook: Book1\n",
      "Slide 1401: Opened Excel workbook: Book1\n",
      "Slide 1402: Opened Excel workbook: Book1\n",
      "Slide 1402: Opened Excel workbook: Book1\n",
      "Slide 1403: Opened Excel workbook: Book1\n",
      "Slide 1403: Opened Excel workbook: Book1\n",
      "Slide 1404: Opened Excel workbook: Book1\n",
      "Slide 1404: Opened Excel workbook: Book1\n",
      "Slide 1405: Opened Excel workbook: Book1\n",
      "Slide 1405: Opened Excel workbook: Book1\n",
      "Slide 1406: Opened Excel workbook: Book1\n",
      "Slide 1406: Opened Excel workbook: Book1\n",
      "Slide 1407: Opened Excel workbook: Book1\n",
      "Slide 1407: Opened Excel workbook: Book1\n",
      "Slide 1408: Opened Excel workbook: Book1\n",
      "Slide 1408: Opened Excel workbook: Book1\n",
      "Slide 1409: Opened Excel workbook: Book1\n",
      "Slide 1409: Opened Excel workbook: Book1\n",
      "Slide 1410: Opened Excel workbook: Book1\n",
      "Slide 1410: Opened Excel workbook: Book1\n",
      "Slide 1411: Opened Excel workbook: Book1\n",
      "Slide 1411: Opened Excel workbook: Book1\n",
      "Slide 1412: Opened Excel workbook: Book1\n",
      "Slide 1412: Opened Excel workbook: Book1\n",
      "Slide 1413: Opened Excel workbook: Book1\n",
      "Slide 1413: Opened Excel workbook: Book1\n",
      "Slide 1414: Opened Excel workbook: Book1\n",
      "Slide 1414: Opened Excel workbook: Book1\n",
      "Slide 1415: Opened Excel workbook: Book1\n",
      "Slide 1415: Opened Excel workbook: Book1\n",
      "Slide 1416: Opened Excel workbook: Book1\n",
      "Slide 1416: Opened Excel workbook: Book1\n",
      "Slide 1417: Opened Excel workbook: Book1\n",
      "Slide 1417: Opened Excel workbook: Book1\n",
      "Slide 1418: Opened Excel workbook: Book1\n",
      "Slide 1418: Opened Excel workbook: Book1\n",
      "Slide 1419: Opened Excel workbook: Book1\n",
      "Slide 1419: Opened Excel workbook: Book1\n",
      "Slide 1420: Opened Excel workbook: Book1\n",
      "Slide 1420: Opened Excel workbook: Book1\n",
      "Slide 1421: Opened Excel workbook: Book1\n",
      "Slide 1421: Opened Excel workbook: Book1\n",
      "Slide 1422: Opened Excel workbook: Book1\n",
      "Slide 1422: Opened Excel workbook: Book1\n",
      "Slide 1423: Opened Excel workbook: Book1\n",
      "Slide 1423: Opened Excel workbook: Book1\n",
      "Slide 1424: Opened Excel workbook: Book1\n",
      "Slide 1424: Opened Excel workbook: Book1\n",
      "Slide 1425: Opened Excel workbook: Book1\n",
      "Slide 1425: Opened Excel workbook: Book1\n",
      "Slide 1426: Opened Excel workbook: Book1\n",
      "Slide 1426: Opened Excel workbook: Book1\n",
      "Slide 1427: Opened Excel workbook: Book1\n",
      "Slide 1427: Opened Excel workbook: Book1\n",
      "Slide 1428: Opened Excel workbook: Book1\n",
      "Slide 1428: Opened Excel workbook: Book1\n",
      "Slide 1429: Opened Excel workbook: Book1\n",
      "Slide 1429: Opened Excel workbook: Book1\n",
      "Slide 1430: Opened Excel workbook: Book1\n",
      "Slide 1430: Opened Excel workbook: Book1\n",
      "Slide 1716: Opened Excel workbook: Book1\n",
      "Slide 1717: Opened Excel workbook: Book1\n",
      "Slide 1718: Opened Excel workbook: Book1\n",
      "Slide 1719: Opened Excel workbook: Book1\n",
      "Slide 1720: Opened Excel workbook: Book1\n",
      "Slide 1721: Opened Excel workbook: Book1\n",
      "Slide 1722: Opened Excel workbook: Book1\n",
      "Slide 1723: Opened Excel workbook: Book1\n",
      "Slide 1724: Opened Excel workbook: Book1\n",
      "Slide 1725: Opened Excel workbook: Book1\n",
      "Slide 1726: Opened Excel workbook: Book1\n",
      "Slide 1727: Opened Excel workbook: Book1\n",
      "Slide 1728: Opened Excel workbook: Book1\n",
      "Slide 1729: Opened Excel workbook: Book1\n",
      "Slide 1730: Opened Excel workbook: Book1\n",
      "Slide 1731: Opened Excel workbook: Book1\n"
     ]
    }
   ],
   "source": [
    "outputPath=os.getcwd() + f\"\\\\Promotion {client_manuf[0]}.pptx\"\n",
    "# prs.save(outputPath)\n",
    "# app = win32.Dispatch(\"PowerPoint.Application\")\n",
    "# presentation = app.Presentations.Open(outputPath)\n",
    "final=os.getcwd() +f\"\\\\Promotion {client_manuf[0]}.pptx\"\n",
    "open_chart_data_in_excel(final,outputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027352d5",
   "metadata": {},
   "source": [
    "## Value Uplift by product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "f413d6eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'c:\\\\Users\\\\BW4SA\\\\Documents\\\\Slide-Automate\\\\Promotion Slide DuplicateEdgewell Mexico Suncare Dataset.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[314], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m loaded_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      6\u001b[0m datasets_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\u001b[38;5;241m+\u001b[39m path1\n\u001b[1;32m----> 7\u001b[0m datasets \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasets_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(datasets_path\u001b[38;5;241m+\u001b[39md, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'c:\\\\Users\\\\BW4SA\\\\Documents\\\\Slide-Automate\\\\Promotion Slide DuplicateEdgewell Mexico Suncare Dataset.xlsx'"
     ]
    }
   ],
   "source": [
    "%run \"..\\general_functions\\generalFunctions.ipynb\"\n",
    "%run \"..\\Promotion Slide Duplicate\\Promotion Replacement Function.ipynb\"\n",
    "\n",
    "path1 = r\"/ValueUpliftvsDepth/\"\n",
    "loaded_data = {}\n",
    "datasets_path = os.getcwd()+ path1\n",
    "datasets = os.listdir(datasets_path)\n",
    "for d in datasets:\n",
    "    with open(datasets_path+d, 'rb') as handle:\n",
    "        loaded_data[d.split('.')[0]] = pd.read_csv(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7a2f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valueUplift_dict = {} # value\n",
    "i=0\n",
    "for key, df in loaded_data.items():\n",
    "    data = DetectHeader(df)\n",
    "    columns_to_ffill = [col for col in data.columns if 'item' in col.lower() or 'product' in col.lower()]\n",
    "    data[columns_to_ffill] = data[columns_to_ffill].fillna(method='ffill')\n",
    "    data = data[~data['Item'].str.contains('Total', case=False)].reset_index(drop=True)\n",
    "    for item in data['Item'].unique():\n",
    "        df = data[data['Item'] == item]\n",
    "        df['Discount Depth (%)'] = df['Discount Depth (%)'].str.replace('%','').astype(float) /100\n",
    "        df['Promo Price/Unit'] = df['Promo Price/Unit'].str.replace('','').astype(float)\n",
    "        if normalized:\n",
    "            df['Value Uplift (v. base) Normalized'] = df['Value Uplift (v. base) Normalized'].str.replace('%','').astype(float) /100\n",
    "        else:\n",
    "            df['Value Uplift (v. base)'] = df['Value Uplift (v. base)'].str.replace().str.replace('%','').astype(float) /100\n",
    "        df = df[df['End of Week'] != '0']\n",
    "        df['End of Week'] = pd.to_datetime(df['End of Week'])\n",
    "        df = df[(df['End of Week'] >= start_date) & (df['End of Week'] <= end_date)].reset_index(drop=True)\n",
    "        if df.shape[0]>0 and not df['Discount Depth (%)'].isna().all():\n",
    "            df = df.fillna(0).reset_index(drop = True)\n",
    "            new_key = key+'_'+ item\n",
    "            valueUplift_dict[new_key] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8d0bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sign = 'before'\n",
    "decimals = 2\n",
    "currency = ''\n",
    "data_source = \"DATA SOURCE: Trade Panel/Retailer Data | Ending July 2024\"\n",
    "\n",
    "\n",
    "index = [20]\n",
    "duplication = [len(valueUplift_dict.keys())]\n",
    "section_names = [\"Value Uplift by product\"]\n",
    "path = os.getcwd() + '//Promotion base Oct 2024.pptx'\n",
    "new_pre = os.getcwd() + '//slide duplicated value.pptx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bfe1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slideDuplication(index,duplication,section_names,path,new_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cddec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = Presentation(new_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d6c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each key-slide_num pair in modified_valueUplift\n",
    "for key, slide_num in zip(valueUplift_dict, range(len(valueUplift_dict.keys()))):\n",
    "        # Access the slide to be modified\n",
    "        slide = prs.slides[slide_num]\n",
    "        \n",
    "        # Extract data for the current key\n",
    "        df = valueUplift_dict[key]\n",
    "        #df = df[df['Value Uplift (v. base) Normalized'] !=0 ]\n",
    "        # Get shapes in the slide\n",
    "        shapes = slide.shapes\n",
    "        \n",
    "        # Find and update title shape\n",
    "        titleNumber = get_shape_number(shapes, \"Value Uplift vs discount depth | By Event | Category/Sector | Brand | Coop Alleanza | P12M\")\n",
    "        datasourcenum = get_shape_number(shapes, \"Data Source | Trade Panel\")\n",
    "        headerNumber = get_shape_number(shapes, 'Value Uplift vs discount depth (Replace With SO WHAT)')\n",
    "        if titleNumber is not None:\n",
    "            shapes[datasourcenum].text = data_source\n",
    "            shapes[titleNumber].text = shapes[titleNumber].text.replace('Category/Sector', key.split('_')[2]) \\\n",
    "                .replace('Brand | Coop Alleanza ', df['Item'][0])\n",
    "            shapes[titleNumber].text_frame.paragraphs[0].font.size = Pt(12)\n",
    "            shapes[titleNumber].text_frame.paragraphs[0].font.name = 'Nexa Bold (Headings)'\n",
    "            shapes[headerNumber].text_frame.paragraphs[0].font.size = Pt(16)\n",
    "            shapes[headerNumber].text_frame.paragraphs[0].font.name = 'Nexa Bold (Headings)'\n",
    "\n",
    "        # Create table and chart objects\n",
    "        tables, charts = createTableAndChart(slide.shapes)\n",
    "        chart1 = charts[0].chart  # First chart\n",
    "        chart2 = charts[1].chart  # Second chart\n",
    "        \n",
    "        # Extract data for charts\n",
    "        category = df['Item'].tolist()\n",
    "        x_values_discount = df['Discount Depth (%)'].tolist()\n",
    "        x_values_price = df['Promo Price/Unit'].tolist()\n",
    "        if normalized:\n",
    "            y_values = df['Value Uplift (v. base) Normalized'].tolist()\n",
    "        else:\n",
    "            y_values = df['Value Uplift (v. base)'].tolist()\n",
    "\n",
    "        \n",
    "        x_values_discount = [mround_numpy(value, 0.05) for value in x_values_discount]\n",
    "        x_values_price = [mround_numpy(value, 0.5) for value in x_values_price]\n",
    "        #Update first chart with Discount Depth vs Value Uplift data\n",
    "        chart_data1 = XyChartData()\n",
    "        series1 = chart_data1.add_series('Scatter')\n",
    "        for i in range(len(category)):\n",
    "            series1.add_data_point(x_values_discount[i], y_values[i])\n",
    "        chart1.replace_data(chart_data1)\n",
    "        \n",
    "        # Access the X-axis\n",
    "        \n",
    "        xlsx_file = BytesIO()\n",
    "        with chart_data1._workbook_writer._open_worksheet(xlsx_file) as (workbook, worksheet):\n",
    "            chart_data1._workbook_writer._populate_worksheet(workbook, worksheet)\n",
    "            worksheet.write(0, 4, \"Item\")\n",
    "            worksheet.write_column(1, 4, df['Item'].to_list(), None)\n",
    "            worksheet.write(0, 5, \"End of Week\")\n",
    "            worksheet.write_column(1, 5, df['End of Week'].to_list(), None)\n",
    "\n",
    "        chart1._workbook.update_from_xlsx_blob(xlsx_file.getvalue())\n",
    "\n",
    "        # Update second chart with Promo Price/Unit vs Value Uplift data\n",
    "        chart_data2 = XyChartData()\n",
    "        series2 = chart_data2.add_series('Scatter')\n",
    "        for i in range(len(category)):\n",
    "            series2.add_data_point(x_values_price[i], y_values[i])\n",
    "        chart2.replace_data(chart_data2)\n",
    "        \n",
    "        x_axis = chart2.category_axis\n",
    "        \n",
    "        # Loop through each X-axis category label and format as currency\n",
    "        if sign.lower() == 'before':\n",
    "            x_axis.tick_labels.number_format = f'\"{currency}\"#,##0.00'  if decimals == 2 else f'\"{currency}\"#,##0'\n",
    "        else:\n",
    "            x_axis.tick_labels.number_format = f'#,##0.00\"{currency}\"'  if decimals == 2 else f'#,##0\"{currency}\"'\n",
    "       \n",
    "        #x_axis.has_major_gridlines = False  # Optional: remove gridlines\n",
    "\n",
    "        xlsx_file = BytesIO()\n",
    "        with chart_data2._workbook_writer._open_worksheet(xlsx_file) as (workbook, worksheet):\n",
    "            chart_data2._workbook_writer._populate_worksheet(workbook, worksheet)\n",
    "            worksheet.write(0, 4, \"Item\")\n",
    "            worksheet.write_column(1, 4, df['Item'].to_list(), None)\n",
    "            worksheet.write(0, 5, \"End of Week\")\n",
    "            worksheet.write_column(1, 5, df['End of Week'].to_list(), None)\n",
    "        chart2._workbook.update_from_xlsx_blob(xlsx_file.getvalue())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca82e799",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath=os.getcwd() + \"\\\\Promotion EdgeWell ValueUplift.pptx\"\n",
    "prs.save(outputPath)\n",
    "app = win32.Dispatch(\"PowerPoint.Application\")\n",
    "presentation = app.Presentations.Open(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623751f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
