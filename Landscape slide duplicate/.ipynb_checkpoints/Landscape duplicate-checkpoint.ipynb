{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a9c8593",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"..\\general_functions\\generalFunctions.ipynb\"\n",
    "%run \"..\\general_functions\\Landscape Replacement Function.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05c80c6d-d2bf-4cde-abcc-f9a6b1872f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebb4a0e3-8023-4e9f-98a8-3b8723465f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "themePath = r\"C:\\\\Users\\\\BW4SA\\\\OneDrive - Pricing One SA\\\\Desktop\\\\Theme1.thmx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd2e15e",
   "metadata": {},
   "source": [
    "## Data Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "390cbb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_manuf = [\"Mondelez\"]\n",
    "client_brands = [\"Freia\", \"Twist\", \"Daim\"]\n",
    "\n",
    "# leave space before the currency if the sign is after and vise versa\n",
    "currency = ' Kr'\n",
    "decimals = 2\n",
    "sign = \"After\"\n",
    "\n",
    "categories = [\"Chocolate\"]\n",
    "sectors = [\"Tablet\",\"Countlines/Bar\",\"Small Bites\",\"Pralines\",\"Seasonal And Novelties\"]\n",
    "\n",
    "segments = [\"Tablet Milk\", \"Tablet Dark\",\"Countlines/Bar Milk\", \"Countlines/Bar Dark\", \"Small Bites Milk\", \"Small Bites Dark\", \"Pralines Mix\", \"Pralines Milk\", \"Pralines Dark\", \"Seasonal And Novelties Milk\",\"Seasonal And Novelties Mix\", \"Seasonal And Novelties Dark\"]\n",
    "areas = ['NATIONAL', \"RETAILER\"]\n",
    "POS = \"\"\n",
    "\n",
    "regions_RET  = [\"Extra\", \"Kiwi\"]\n",
    "channels_RET = []\n",
    "market_RET = []\n",
    "\n",
    "regions_CHAN = []\n",
    "channels_CHAN = []\n",
    "market_CHAN = []\n",
    "\n",
    "regions_POS = []\n",
    "channels_POS = []\n",
    "market_POS = []\n",
    "\n",
    "\n",
    "data_source = \"DATA SOURCE: Trade Panel/Retailer Data | Ending Jan 2024\"\n",
    "years = ['2021', '2022','2023']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2268f8d",
   "metadata": {},
   "source": [
    "### Cleaning Data_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4491486c",
   "metadata": {},
   "source": [
    "### Modifying Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "686d1b40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khaled\\PowePoint Automation\\Slide-Automate\\Landscape slide duplicate/Landscape Datasets/\n"
     ]
    }
   ],
   "source": [
    "loaded_data = {}\n",
    "\n",
    "datasets_path = os.getcwd()+\"/Landscape Datasets/\"\n",
    "print(datasets_path)\n",
    "\n",
    "datasets = os.listdir(datasets_path)\n",
    "for d in datasets:\n",
    "    with open(datasets_path+d, 'rb') as handle:\n",
    "        globals()[d.split('.')[0]] = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe996c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_sectors_dfs_new = {}\n",
    "sectors_totals_new= {}\n",
    "modified_sectors_P12M_new = {}\n",
    "dya_sectors_new = {}\n",
    "modified_sectors_clients_new = {}\n",
    "\n",
    "for s in sectors_dfs_new.keys():\n",
    "    t = sectors_dfs_new[s].copy()\n",
    "    t.columns = (t.iloc[13].replace(np.nan,'') + ' '+t.iloc[12].ffill().replace(np.nan, \"\")).str.strip()\n",
    "    t = t.iloc[t[t[t.columns[0]]==t.columns[0]].index[0]+1:]\n",
    "    t = t.applymap(lambda x: float(x) if pd.to_numeric(x, errors='coerce') == x else x)\n",
    "    t = t.applymap(lambda x: 0 if pd.isna(x) else x)\n",
    "    mod = t[(~t[t.columns[0]].astype(str).str.contains('Grand Total'))]\n",
    "    mod = mod.sort_values([col for col in mod.columns if 'Value Share' in col], ascending=False)\n",
    "    tot = t[(t[t.columns[0]].astype(str).str.contains('Grand Total'))]\n",
    "    modified_sectors_dfs_new[s] = mod\n",
    "    sectors_totals_new[s] = tot\n",
    "\n",
    "for s in sectors_P12M_dfs_new.keys():\n",
    "    t = sectors_P12M_dfs_new[s].copy()\n",
    "    t.columns = (t.iloc[12].replace(np.nan, \"\")).str.strip()\n",
    "    t = t.iloc[t[t[t.columns[0]]==t.columns[0]].index[0]+1:]\n",
    "    t = t.applymap(lambda x: float(x) if pd.to_numeric(x, errors='coerce') == x else x)\n",
    "    t = t.applymap(lambda x: 0 if pd.isna(x) else x)\n",
    "    mod = t[(~t[t.columns[0]].astype(str).str.contains('Grand Total'))]\n",
    "    mod = mod.sort_values([col for col in mod.columns if 'Value Share' in col], ascending=False)\n",
    "    tot = t[(t[t.columns[0]].astype(str).str.contains('Grand Total'))]\n",
    "    modified_sectors_P12M_new[s] = mod\n",
    "    dya_sectors_new[s] = tot\n",
    "\n",
    "for s in sectors_client_dfs_new.keys():\n",
    "    t = sectors_client_dfs_new[s].copy()\n",
    "    t.columns = (t.iloc[12].replace(np.nan, \"\")).str.strip()\n",
    "    t = t.iloc[t[t[t.columns[0]]==t.columns[0]].index[0]+1:]\n",
    "    t = t.applymap(lambda x: float(x) if pd.to_numeric(x, errors='coerce') == x else x)\n",
    "    t = t.applymap(lambda x: 0 if pd.isna(x) else x)\n",
    "    mod = t[(~t[t.columns[0]].astype(str).str.contains('Grand Total'))]\n",
    "    mod = mod.sort_values([col for col in mod.columns if 'Value Share' in col], ascending=False)\n",
    "    tot = t[(t[t.columns[0]].astype(str).str.contains('Grand Total'))]\n",
    "    modified_sectors_clients_new[s] = mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41ef24e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_segment_dfs_new = {}\n",
    "segment_totals_new= {}\n",
    "modified_segment_P12M_new = {}\n",
    "dya_segment_new = {}\n",
    "modified_segment_clients_new = {}\n",
    "    \n",
    "if len(segments)!=0:\n",
    "\n",
    "    for s in segments_dfs_new.keys():\n",
    "        t = segments_dfs_new[s].copy()\n",
    "        t.columns = (t.iloc[13].replace(np.nan,'') + ' '+t.iloc[12].ffill().replace(np.nan, \"\")).str.strip()\n",
    "        t = t.iloc[t[t[t.columns[0]]==t.columns[0]].index[0]+1:]\n",
    "        t['Sector'] = t['Sector'].ffill()\n",
    "        t['Segment'] = np.where(t['Segment'].isna(), t['Sector'], t['Segment'])\n",
    "        t = t.replace(np.nan, 0)\n",
    "        mod = t[(~t[t.columns[0]].astype(str).str.contains(' Total'))]\n",
    "        mod = mod.sort_values([col for col in mod.columns if 'Total Value Share' in col], ascending=False)\n",
    "        tot = t[(t[t.columns[0]].astype(str).str.contains(' Total'))]\n",
    "        modified_segment_dfs_new[s] = mod\n",
    "        segment_totals_new[s] = tot\n",
    "    \n",
    "    \n",
    "    for s in segments_P12M_dfs_new.keys():\n",
    "        t = segments_P12M_dfs_new[s].copy()\n",
    "        t.columns = (t.iloc[12].replace(np.nan, \"\")).str.strip()\n",
    "        t = t.iloc[t[t[t.columns[0]]==t.columns[0]].index[0]+1:]\n",
    "        t = t.applymap(lambda x: float(x) if pd.to_numeric(x, errors='coerce') == x else x)\n",
    "        t = t.applymap(lambda x: 0 if pd.isna(x) else x)\n",
    "        mod = t[(~t[t.columns[0]].astype(str).str.contains('Grand Total'))]\n",
    "        mod = mod.sort_values([col for col in mod.columns if 'Value Share' in col], ascending=False)\n",
    "        tot = t[(t[t.columns[0]].astype(str).str.contains('Grand Total'))]\n",
    "        modified_segment_P12M_new[s] = mod\n",
    "        dya_segment_new[s] = tot\n",
    "    \n",
    "    for s in segments_client_dfs_new.keys():\n",
    "        t = segments_client_dfs_new[s].copy()\n",
    "        t.columns = (t.iloc[12].replace(np.nan, \"\")).str.strip()\n",
    "        t = t.iloc[t[t[t.columns[0]]==t.columns[0]].index[0]+1:]\n",
    "        t = t.applymap(lambda x: float(x) if pd.to_numeric(x, errors='coerce') == x else x)\n",
    "        t = t.applymap(lambda x: 0 if pd.isna(x) else x)\n",
    "        mod = t[(~t[t.columns[0]].astype(str).str.contains('Grand Total'))]\n",
    "        mod = mod.sort_values([col for col in mod.columns if 'Value Share' in col], ascending=False)\n",
    "        tot = t[(t[t.columns[0]].astype(str).str.contains('Grand Total'))]\n",
    "        modified_segment_clients_new[s] = mod\n",
    "        \n",
    "        \n",
    "\n",
    "modified_segment_P12M_new = {}\n",
    "for key in segments_P12M_dfs_new.keys():\n",
    "    t = segments_P12M_dfs_new[key].copy()\n",
    "    t.columns = (t.iloc[12].replace(np.nan, '')).str.strip()\n",
    "    t = t[13:-1]\n",
    "    t['Sector'] = t['Sector'].ffill()\n",
    "    t['Segment'] = np.where(t['Segment'].isna(), t['Sector'], t['Segment'])\n",
    "    t = t.replace(np.nan, 0)\n",
    "    t = t[~t['Segment'].str.contains(' Total')]\n",
    "    t = t[t['Segment'].isin(segments)]\n",
    "    t = t.sort_values('WoB %', ascending = False)\n",
    "    modified_segment_P12M_new[key] = t\n",
    "\n",
    "modified_segment_clients_new = {}\n",
    "for key in segments_client_dfs_new.keys():\n",
    "    t = segments_client_dfs_new[key].copy()\n",
    "    t.columns = (t.iloc[12].replace(np.nan, '')).str.strip()\n",
    "    t = t[13:-1]\n",
    "    t['Sector'] = t['Sector'].ffill()\n",
    "    t['Segment'] = np.where(t['Segment'].isna(), t['Sector'], t['Segment'])\n",
    "    t = t.replace(np.nan, 0)\n",
    "    t = t[~t['Segment'].str.contains(' Total')]\n",
    "    t = t[t['Segment'].isin(segments)]\n",
    "    t = t.sort_values('WoB %', ascending = False)\n",
    "    modified_segment_clients_new[key] = t\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f463ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_manuf_dfs_new = {}\n",
    "modified_manuf_totals_new= {}\n",
    "modified_manuf_P12M_new = {}\n",
    "modified_manuf_P12M_regions_new = {}\n",
    "\n",
    "for s in manuf_dfs_new.keys():\n",
    "    t = manuf_dfs_new[s].copy()\n",
    "    t.columns = (t.iloc[13].replace(np.nan,'') + ' '+t.iloc[12].ffill().replace(np.nan, \"\")).str.strip()\n",
    "    t = t.iloc[t[t[t.columns[0]]==t.columns[0]].index[0]+1:]\n",
    "    t = t.applymap(lambda x: float(x) if pd.to_numeric(x, errors='coerce') == x else x)\n",
    "    t = t.applymap(lambda x: 0 if pd.isna(x) else x)\n",
    "    mod = t[(~t[t.columns[0]].astype(str).str.contains('Grand Total'))]\n",
    "    mod = mod.sort_values([col for col in mod.columns if 'Value Share' in col], ascending=False)\n",
    "    tot = t[(t[t.columns[0]].astype(str).str.contains('Grand Total'))]\n",
    "    modified_manuf_dfs_new[s] = mod\n",
    "    modified_manuf_totals_new[s] = tot\n",
    "    \n",
    "emptyDf=[key for key in modified_manuf_dfs_new.keys() if modified_manuf_dfs_new[key].shape[1]<4]\n",
    "for dic in [modified_manuf_dfs_new]:\n",
    "    if emptyDf:\n",
    "        columnsToAdd=list(set(dic.keys())-set(emptyDf))[0]\n",
    "        for df in emptyDf:\n",
    "            dic[df]=dic[df].drop(columns=[''])#list(set(dic[df].columns)-set(['']))\n",
    "            emptyCol=list(set(dic[columnsToAdd].columns)-set(dic[df].columns)-set(['']))\n",
    "            dic[df][emptyCol]=0.0\n",
    "            \n",
    "modified_manuf_dfs_new = dfSort(modified_manuf_dfs_new, client_manuf,'Top Companies',10, 'Total Value Share')\n",
    "\n",
    "\n",
    "for s in manuf_P12M_dfs_new.keys():\n",
    "    t = manuf_P12M_dfs_new[s].copy()\n",
    "    t.columns = (t.iloc[12].ffill().replace(np.nan, \"\") + ' ' + t.iloc[13].replace(np.nan, \"\")).str.strip()\n",
    "    t = t.iloc[t[t[t.columns[0]]==t.columns[0]].index[0]+1:]\n",
    "    t = t.applymap(lambda x: float(x) if pd.to_numeric(x, errors='coerce') == x else x)\n",
    "    t = t.applymap(lambda x: 0 if pd.isna(x) else x)\n",
    "    mod = t[(~t[t.columns[0]].astype(str).str.contains('Grand Total'))]\n",
    "    mod = mod.sort_values([col for col in mod.columns if 'Value Share' in col], ascending=False)\n",
    "    tot = t[(t[t.columns[0]].astype(str).str.contains('Grand Total'))]\n",
    "    modified_manuf_P12M_new[s] = mod\n",
    "\n",
    "emptyDf=[key for key in modified_manuf_P12M_new.keys() if modified_manuf_P12M_new[key].shape[1]<4]\n",
    "for dic in [modified_manuf_P12M_new]:\n",
    "    if emptyDf:\n",
    "        columnsToAdd=list(set(dic.keys())-set(emptyDf))[0]\n",
    "        for df in emptyDf:\n",
    "            dic[df]=dic[df].drop(columns=[''])#list(set(dic[df].columns)-set(['']))\n",
    "            emptyCol=list(set(dic[columnsToAdd].columns)-set(dic[df].columns)-set(['']))\n",
    "            dic[df][emptyCol]=0.0\n",
    "\n",
    "modified_manuf_P12M_new = dfSort(modified_manuf_P12M_new, client_manuf,'Top Companies',10, 'Value Share')\n",
    "    \n",
    "\n",
    "for s in manuf_P12M_dfs_regions_new.keys():\n",
    "    t = manuf_P12M_dfs_regions_new[s].copy()\n",
    "    t.columns = (t.iloc[13].replace(np.nan, \"\") + ' ' + t.iloc[12].ffill().replace(np.nan, \"\")).str.strip()\n",
    "\n",
    "    t = t.iloc[t[t[t.columns[0]]==t.columns[0]].index[0]+1:]\n",
    "    t = t.applymap(lambda x: float(x) if pd.to_numeric(x, errors='coerce') == x else x)\n",
    "    t = t.applymap(lambda x: 0 if pd.isna(x) else x)\n",
    "    mod = t[(~t[t.columns[0]].astype(str).str.contains('Grand Total'))]\n",
    "    mod = mod.sort_values([col for col in mod.columns if 'Value Share' in col], ascending=False)\n",
    "    tot = t[(t[t.columns[0]].astype(str).str.contains('Grand Total'))]\n",
    "    modified_manuf_P12M_regions_new[s] = mod\n",
    "    \n",
    "emptyDf=[key for key in modified_manuf_P12M_regions_new.keys() if modified_manuf_P12M_regions_new[key].shape[1]<4]\n",
    "for dic in [modified_manuf_P12M_regions_new]:\n",
    "    if emptyDf:\n",
    "        columnsToAdd=list(set(dic.keys())-set(emptyDf))[0]\n",
    "        for df in emptyDf:\n",
    "            dic[df]=dic[df].drop(columns=[''])#list(set(dic[df].columns)-set(['']))\n",
    "            emptyCol=list(set(dic[columnsToAdd].columns)-set(dic[df].columns)-set(['']))\n",
    "            dic[df][emptyCol]=0.0\n",
    "\n",
    "modified_manuf_P12M_regions_new = dfSort(modified_manuf_P12M_regions_new, client_manuf,'Top Companies',10, 'Value Share')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42f51274-52aa-48c2-8b9a-42594d743e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_brands_share_new = {}\n",
    "modified_brands_totals_new = {}\n",
    "modified_brands_P12M_new = {}\n",
    "modified_brands_evolution_new = {}\n",
    "\n",
    "\n",
    "for s in brands_dfs_new.keys():\n",
    "    t = brands_dfs_new[s].copy()\n",
    "    t.columns = (t.iloc[13].replace(np.nan,'') + ' '+t.iloc[12].ffill().replace(np.nan, \"\")).str.strip()\n",
    "    t = t.iloc[t[t[t.columns[0]]==t.columns[0]].index[0]+1:]\n",
    "    t = t.applymap(lambda x: float(x) if pd.to_numeric(x, errors='coerce') == x else x)\n",
    "    t = t.applymap(lambda x: 0 if pd.isna(x) else x)\n",
    "    # t = t[[col for col in t.columns if \"Total\" not in col]]\n",
    "    mod = t[(~t[t.columns[0]].astype(str).str.contains('Grand Total'))]\n",
    "    mod = mod.sort_values([col for col in mod.columns if 'Value Share' in col], ascending=False)\n",
    "    tot = t[(t[t.columns[0]].astype(str).str.contains('Grand Total'))]\n",
    "    modified_brands_share_new[s] = mod\n",
    "    modified_brands_totals_new[s] = tot\n",
    "    \n",
    "emptyDf=[key for key in modified_brands_share_new.keys() if modified_brands_share_new[key].shape[1]<4]\n",
    "for dic in [modified_brands_share_new]:\n",
    "    if emptyDf:\n",
    "        columnsToAdd=list(set(dic.keys())-set(emptyDf))[0]\n",
    "        for df in emptyDf:\n",
    "            dic[df]=dic[df].drop(columns=[''])#list(set(dic[df].columns)-set(['']))\n",
    "            emptyCol=list(set(dic[columnsToAdd].columns)-set(dic[df].columns)-set(['']))\n",
    "            dic[df][emptyCol]=0.0\n",
    "            \n",
    "modified_brands_share_new = dfSort(modified_brands_share_new, client_brands,'Top Brands',10, 'Total Value Share')\n",
    "for key in modified_brands_share_new.keys():\n",
    "    modified_brands_share_new[key] = modified_brands_share_new[key][modified_brands_share_new[key]['Total Value Share'] != 0]\n",
    "    \n",
    "\n",
    "for s in brands_P12M_dfs_new.keys():\n",
    "    t = brands_P12M_dfs_new[s].copy()\n",
    "    t.columns = (t.iloc[12].ffill().replace(np.nan, \"\")).str.strip()\n",
    "    t = t.iloc[t[t[t.columns[0]]==t.columns[0]].index[0]+1:]\n",
    "    t = t.applymap(lambda x: float(x) if pd.to_numeric(x, errors='coerce') == x else x)\n",
    "    t = t.applymap(lambda x: 0 if pd.isna(x) else x)\n",
    "    mod = t[(~t[t.columns[0]].astype(str).str.contains('Grand Total'))]\n",
    "    mod = mod.sort_values([col for col in mod.columns if 'Value Share' in col], ascending=False)\n",
    "    tot = t[(t[t.columns[0]].astype(str).str.contains('Grand Total'))]\n",
    "    modified_brands_P12M_new[s] = mod\n",
    "\n",
    "emptyDf=[key for key in modified_brands_P12M_new.keys() if modified_brands_P12M_new[key].shape[1]<4]\n",
    "for dic in [modified_brands_P12M_new]:\n",
    "    if emptyDf:\n",
    "        columnsToAdd=list(set(dic.keys())-set(emptyDf))[0]\n",
    "        for df in emptyDf:\n",
    "            dic[df]=dic[df].drop(columns=[''])#list(set(dic[df].columns)-set(['']))\n",
    "            emptyCol=list(set(dic[columnsToAdd].columns)-set(dic[df].columns)-set(['']))\n",
    "            dic[df][emptyCol]=0.0\n",
    "\n",
    "modified_brands_P12M_new = dfSort(modified_brands_P12M_new, client_brands,'Top Brands',10, 'Value Share')\n",
    "\n",
    "\n",
    "for s in brands_evolution_new.keys():\n",
    "    t = brands_evolution_new[s].copy()\n",
    "    t.columns = (t.iloc[12].replace(np.nan, \"\")).str.strip()\n",
    "    t = t.iloc[t[t[t.columns[0]]==t.columns[0]].index[0]+1:]\n",
    "    t['Year'] = t['Year'].ffill() \n",
    "    t = t.applymap(lambda x: float(x) if pd.to_numeric(x, errors='coerce') == x else x)\n",
    "    t = t.applymap(lambda x: 0 if pd.isna(x) else x)\n",
    "    mod = t[(~t[t.columns[0]].astype(str).str.contains('Grand Total'))]\n",
    "    mod = mod.sort_values([col for col in mod.columns if 'Value Share' in col], ascending=False)\n",
    "    tot = t[(t[t.columns[0]].astype(str).str.contains('Grand Total'))]\n",
    "    modified_brands_evolution_new[s] = mod\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "395252dd-08ce-40cb-8d76-f73da7578ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_brands_evolution_sorted_new = {}\n",
    "for k in modified_brands_evolution_new.keys():\n",
    "    x = modified_brands_evolution_new[k].copy()\n",
    "    x['Top Brands'] = np.where(x['Top Brands']==0, x['Year'], x['Top Brands'])\n",
    "    x['Top Brands'] = x['Top Brands'].str.replace('2022 ','').str.replace('2021 ','').str.replace('2023 ',\"\").str.replace('2020 ','')\n",
    "    x['Year'] = x['Year'].replace(0, np.nan).ffill().str.replace(' Total', '')\n",
    "    brand_sales = x.groupby('Top Brands')['Value Sales'].sum().sort_values(ascending=False).head(4)\n",
    "    final = x[(x['Top Brands'].isin(pd.Series(brand_sales.index))) | (x['Top Brands'].isin(client_brands))]\n",
    "    \n",
    "    final[['Price Evolution', 'Share Evolution']] = round(final[['Price Evolution', 'Share Evolution']].replace(np.nan,0).astype(float)*100).astype(int)\n",
    "    final = final[final['Top Brands'] != 'Others']\n",
    "    \n",
    "    final = final.drop_duplicates(subset = [\"Year\", 'Top Brands'])\n",
    "    final = final[final['Price Evolution'] != 0]\n",
    "    final = final[final['Top Brands'] != 'Others']\n",
    "    final = final.sort_values('Year')\n",
    "    \n",
    "    modified_brands_evolution_sorted_new[k] = final \n",
    "keys_to_remove = []\n",
    "for key, df in modified_brands_evolution_sorted_new.items():\n",
    "    if df.empty:  # Remove the () from df.empty\n",
    "        keys_to_remove.append(key)\n",
    "\n",
    "for key in keys_to_remove:\n",
    "    del modified_brands_evolution_sorted_new[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1efd1dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_retailer_regions = {}\n",
    "modified_retailer_channels = {}\n",
    "modified_retailer_markets = {}\n",
    "\n",
    "modified_channels_regions = {}\n",
    "modified_channels_channels = {}\n",
    "modified_channels_markets = {}\n",
    "\n",
    "modified_pos_regions = {}\n",
    "modified_pos_channels = {}\n",
    "modified_pos_markets = {}\n",
    "\n",
    "dya_retailer={}\n",
    "dya_channel={}\n",
    "dya_pos = {}\n",
    "\n",
    "for table in retailers_dfs_new.keys():\n",
    "    t = retailers_dfs_new[table].copy()\n",
    "    t.columns = t.iloc[12]\n",
    "    t = t.iloc[t[t[t.columns[0]]==t.columns[0]].index[0]+1:]\n",
    "    gran_tot = t[t['Region'] == \"Grand Total\"]\n",
    "    t['Channel'] = np.where(t['Channel'].isna(), t['Region'], t['Channel'])\n",
    "    t['Market'] = np.where(t['Market'].isna(), t['Channel'], t['Market'])\n",
    "    t['Region'] = t['Region'].ffill()\n",
    "    \n",
    "    r = t[(t['Region'].str.contains('Total'))]\n",
    "    r = r[r.Region.str.replace('Total','').str.strip().isin(regions_RET)].drop(columns = ['Channel','Market'])\n",
    "    r['Region'] = r['Region'].str.replace('Total', '').str.strip()\n",
    "    r['Value Share'] = r['Value Share'].astype(float)\n",
    "    r = r.sort_values('Value Share', ascending=False)\n",
    "    r=r.drop(columns=['WoB %', \"Relative Price\", \"Growth Contribution\"])\n",
    "    r.columns = r.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "    r = r.sort_values('WoB %', ascending=False)  \n",
    "    r = r.drop_duplicates()\n",
    "    \n",
    "    c = t[t['Channel'].isin(c +' Total' for c in channels_RET)].drop(columns = ['Region','Market'])\n",
    "    c['Channel'] = c['Channel'].str.replace(' Total','')\n",
    "    c['Value Share'] = c['Value Share'].astype(float) \n",
    "    c = c.sort_values('Value Share', ascending=False)\n",
    "    c=c.drop(columns=['WoB %', \"Relative Price\", \"Growth Contribution\"])\n",
    "    c.columns = c.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "    c = c.sort_values('WoB %', ascending=False)\n",
    "    c = c.drop_duplicates()\n",
    "    \n",
    "    m = t[t['Market'].isin(market_RET)].drop(columns = ['Region','Channel'])\n",
    "    m['Value Share'] = m['Value Share'].astype(float) \n",
    "    m = m.sort_values('Value Share', ascending=False)\n",
    "    m=m.drop(columns=['WoB %', \"Relative Price\", \"Growth Contribution\"])\n",
    "    m.columns = m.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "    m = m.sort_values('WoB %', ascending=False)\n",
    "    m = m.drop_duplicates()\n",
    "    \n",
    "    modified_retailer_regions[table] = r \n",
    "    modified_retailer_channels[table] = c\n",
    "    modified_retailer_markets[table] = m\n",
    "    dya_retailer[table] = gran_tot\n",
    "\n",
    "\n",
    "\n",
    "for table in channel_dfs_new.keys():\n",
    "    t = channel_dfs_new[table].copy()\n",
    "    t.columns = t.iloc[12]\n",
    "    t = t.iloc[t[t[t.columns[0]]==t.columns[0]].index[0]+1:]\n",
    "    gran_tot = t[t['Region'] == \"Grand Total\"]\n",
    "    t['Channel'] = np.where(t['Channel'].isna(), t['Region'], t['Channel'])\n",
    "    t['Market'] = np.where(t['Market'].isna(), t['Channel'], t['Market'])\n",
    "    t['Region'] = t['Region'].ffill()\n",
    "\n",
    "    r = t[(t['Region'].str.contains('Total'))]\n",
    "    r = r[r.Region.str.replace('Total','').str.strip().isin(regions_CHAN)].drop(columns = ['Channel','Market'])\n",
    "    r['Region'] = r['Region'].str.replace('Total', '').str.strip()\n",
    "    r['Value Share'] = r['Value Share'].astype(float)\n",
    "    r = r.sort_values('Value Share', ascending=False)\n",
    "    r=r.drop(columns=['WoB %', \"Relative Price\", \"Growth Contribution\"])\n",
    "    r.columns = r.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "    r = r.sort_values('WoB %', ascending=False)\n",
    "    r = r.drop_duplicates()\n",
    "    \n",
    "    c = t[t['Channel'].isin(c +' Total' for c in channels_CHAN)].drop(columns = ['Region', 'Market'])\n",
    "    c['Channel'] = c['Channel'].str.replace(' Total','')\n",
    "    c['Value Share'] = c['Value Share'].astype(float) \n",
    "    c = c.sort_values('Value Share', ascending=False)\n",
    "    c=c.drop(columns=['WoB %', \"Relative Price\", \"Growth Contribution\"])\n",
    "    c.columns = c.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "    c = c.sort_values('WoB %', ascending=False)\n",
    "    c = c.drop_duplicates()\n",
    "    \n",
    "    m = t[t['Market'].isin(market_CHAN)].drop(columns = ['Region','Channel'])\n",
    "    m['Value Share'] = m['Value Share'].astype(float) \n",
    "    m = m.sort_values('Value Share', ascending=False)\n",
    "    m=m.drop(columns=['WoB %', \"Relative Price\", \"Growth Contribution\"])\n",
    "    m.columns = m.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "    m = m.sort_values('WoB %', ascending=False)\n",
    "    m = m.drop_duplicates()\n",
    "    \n",
    "    modified_channels_regions[table] = r\n",
    "    modified_channels_channels[table] = c\n",
    "    modified_channels_markets[table] = m\n",
    "    dya_channel[table] = gran_tot\n",
    "\n",
    "\n",
    "\n",
    "for table in pos_dfs_new.keys():\n",
    "    t = pos_dfs_new[table].copy()\n",
    "    t.columns = t.iloc[12]\n",
    "    t = t.iloc[t[t[t.columns[0]]==t.columns[0]].index[0]+1:]\n",
    "    gran_tot = t[t['Region'] == \"Grand Total\"]\n",
    "    t['Channel'] = np.where(t['Channel'].isna(), t['Region'], t['Channel'])\n",
    "    t['Market'] = np.where(t['Market'].isna(), t['Channel'], t['Market'])\n",
    "    t['Region'] = t['Region'].ffill()\n",
    "\n",
    "    r = t[(t['Region'].str.contains('Total'))]\n",
    "    r = r[r.Region.str.replace('Total','').str.strip().isin(regions_POS)].drop(columns = ['Channel','Market'])\n",
    "    r['Region'] = r['Region'].str.replace('Total', '').str.strip()\n",
    "    r['Value Share'] = r['Value Share'].astype(float)\n",
    "    r = r.sort_values('Value Share', ascending=False)\n",
    "    r=r.drop(columns=['WoB %', \"Relative Price\", \"Growth Contribution\"])\n",
    "    r.columns = r.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "    r = r.sort_values('WoB %', ascending=False)\n",
    "    r = r.drop_duplicates()\n",
    "    \n",
    "    c = t[t['Channel'].isin(c +' Total' for c in channels_POS)].drop(columns = ['Region', 'Market'])\n",
    "    c['Channel'] = c['Channel'].str.replace(' Total','')\n",
    "    c['Value Share'] = c['Value Share'].astype(float) \n",
    "    c = c.sort_values('Value Share', ascending=False)\n",
    "    c=c.drop(columns=['WoB %', \"Relative Price\", \"Growth Contribution\"])\n",
    "    c.columns = c.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "    c = c.sort_values('WoB %', ascending=False)\n",
    "    c = c.drop_duplicates()\n",
    "    \n",
    "    m = t[t['Market'].isin(market_POS)].drop(columns = ['Region','Channel'])\n",
    "    m['Value Share'] = m['Value Share'].astype(float) \n",
    "    m = m.sort_values('Value Share', ascending=False)\n",
    "    m=m.drop(columns=['WoB %', \"Relative Price\", \"Growth Contribution\"])\n",
    "    m.columns = m.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "    m = m.sort_values('WoB %', ascending=False)\n",
    "    m = m.drop_duplicates()\n",
    "    \n",
    "    modified_pos_regions[table] = r\n",
    "    modified_pos_channels[table] = c\n",
    "    modified_pos_markets[table] = m\n",
    "    dya_pos[table] = gran_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f50aca92-aa46-4324-8bd6-40cd79b31a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_retailer_regions_client = {}\n",
    "modified_retailer_channels_client = {}\n",
    "modified_retailer_markets_client = {}\n",
    "\n",
    "modified_channels_regions_client = {}\n",
    "modified_channels_channels_client = {}\n",
    "modified_channels_markets_client = {}\n",
    "\n",
    "modified_pos_regions_client = {}\n",
    "modified_pos_channels_client = {}\n",
    "modified_pos_markets_client = {}\n",
    "\n",
    "for table in retailers_client_dfs_new.keys():\n",
    "    t = retailers_client_dfs_new[table].copy()\n",
    "    t.columns = t.iloc[12]\n",
    "    t = t.iloc[t[t[t.columns[0]]==t.columns[0]].index[0]+1:]\n",
    "    gran_tot = t[t['Region'] == \"Grand Total\"]\n",
    "    t['Channel'] = np.where(t['Channel'].isna(), t['Region'], t['Channel'])\n",
    "    t['Market'] = np.where(t['Market'].isna(), t['Channel'], t['Market'])\n",
    "    t['Region'] = t['Region'].ffill()\n",
    "    \n",
    "    r = t[(t['Region'].str.contains('Total'))]\n",
    "    r = r[r.Region.str.replace('Total','').str.strip().isin(regions_RET)].drop(columns = ['Channel', 'Market'])\n",
    "    r['Region'] = r['Region'].str.replace('Total', '').str.strip()\n",
    "    r['Value Share'] = r['Value Share'].astype(float)\n",
    "    r = r.sort_values('Value Share', ascending=False)\n",
    "    r=r.drop(columns=['WoB %', \"Relative Price\", \"Growth Contribution\"])\n",
    "    r.columns = r.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "    r = r.sort_values('WoB %', ascending=False)\n",
    "    r = r.drop_duplicates()\n",
    "    \n",
    "    c = t[t['Channel'].isin(c+' Total' for c in channels_RET)].drop(columns = ['Region','Market'])\n",
    "    c['Channel'] = c['Channel'].str.replace(' Total', '')\n",
    "    c['Value Share'] = c['Value Share'].astype(float) \n",
    "    c = c.sort_values('Value Share', ascending=False)\n",
    "    c=c.drop(columns=['WoB %', \"Relative Price\", \"Growth Contribution\"])\n",
    "    c.columns = c.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "    c = c.sort_values('WoB %', ascending=False)\n",
    "    c = c.drop_duplicates()\n",
    "    \n",
    "    m = t[t['Channel'].isin(market_RET)].drop(columns = ['Region','Channel'])\n",
    "    m['Value Share'] = m['Value Share'].astype(float) \n",
    "    m = m.sort_values('Value Share', ascending=False)\n",
    "    m=m.drop(columns=['WoB %', \"Relative Price\", \"Growth Contribution\"])\n",
    "    m.columns = m.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "    m = m.sort_values('WoB %', ascending=False)\n",
    "    m = m.drop_duplicates()\n",
    "    \n",
    "    modified_retailer_regions_client[table] = r \n",
    "    modified_retailer_channels_client[table] = c\n",
    "    modified_retailer_markets_client[table] = m\n",
    "\n",
    "\n",
    "\n",
    "for table in channel_client_dfs_new.keys():\n",
    "    t = channel_client_dfs_new[table].copy()\n",
    "    t.columns = t.iloc[12]\n",
    "    t = t.iloc[t[t[t.columns[0]]==t.columns[0]].index[0]+1:]\n",
    "    gran_tot = t[t['Region'] == \"Grand Total\"]\n",
    "    t['Channel'] = np.where(t['Channel'].isna(), t['Region'], t['Channel'])\n",
    "    t['Market'] = np.where(t['Market'].isna(), t['Channel'], t['Market'])\n",
    "    t['Region'] = t['Region'].ffill()\n",
    "    \n",
    "    r = t[(t['Region'].str.contains('Total'))]\n",
    "    r = r[r.Region.str.replace('Total','').str.strip().isin(regions_CHAN)].drop(columns = ['Channel','Market'])\n",
    "    r['Region'] = r['Region'].str.replace('Total', '').str.strip()\n",
    "    r['Value Share'] = r['Value Share'].astype(float)\n",
    "    r = r.sort_values('Value Share', ascending=False)\n",
    "    r=r.drop(columns=['WoB %', \"Relative Price\", \"Growth Contribution\"])\n",
    "    r.columns = r.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "    r = r.sort_values('WoB %', ascending=False)\n",
    "    r = r.drop_duplicates()\n",
    "    \n",
    "    c = t[t['Channel'].isin(c+' Total' for c in channels_CHAN)].drop(columns = ['Region','Market'])\n",
    "    c['Channel'] = c['Channel'].str.replace(' Total', '')\n",
    "    c['Value Share'] = c['Value Share'].astype(float) \n",
    "    c = c.sort_values('Value Share', ascending=False)\n",
    "    c=c.drop(columns=['WoB %', \"Relative Price\", \"Growth Contribution\"])\n",
    "    c.columns = c.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "    c = c.sort_values('WoB %', ascending=False)\n",
    "    c = c.drop_duplicates()\n",
    "    \n",
    "    m = t[t['Market'].isin(market_CHAN)].drop(columns = ['Region','Channel'])\n",
    "    m['Value Share'] = m['Value Share'].astype(float) \n",
    "    m = m.sort_values('Value Share', ascending=False)\n",
    "    m=m.drop(columns=['WoB %', \"Relative Price\", \"Growth Contribution\"])\n",
    "    m.columns = m.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "    m = m.sort_values('WoB %', ascending=False)\n",
    "    m = m.drop_duplicates()\n",
    "    \n",
    "    modified_channels_regions_client[table] = r\n",
    "    modified_channels_channels_client[table] = c\n",
    "    modified_channels_markets_client[table] = m\n",
    "\n",
    "\n",
    "for table in pos_client_dfs_new.keys():\n",
    "    t = pos_client_dfs_new[table].copy()\n",
    "    t.columns = t.iloc[12]\n",
    "    t = t.iloc[t[t[t.columns[0]]==t.columns[0]].index[0]+1:]\n",
    "    gran_tot = t[t['Region'] == \"Grand Total\"]\n",
    "    t['Channel'] = np.where(t['Channel'].isna(), t['Region'], t['Channel'])\n",
    "    t['Market'] = np.where(t['Market'].isna(), t['Channel'], t['Market'])\n",
    "    t['Region'] = t['Region'].ffill()\n",
    "    \n",
    "    r = t[(t['Region'].str.contains('Total'))]\n",
    "    r = r[r.Region.str.replace('Total','').str.strip().isin(regions_POS)].drop(columns = ['Channel','Market'])\n",
    "    r['Region'] = r['Region'].str.replace('Total', '').str.strip()\n",
    "    r['Value Share'] = r['Value Share'].astype(float)\n",
    "    r = r.sort_values('Value Share', ascending=False)\n",
    "    r=r.drop(columns=['WoB %', \"Relative Price\", \"Growth Contribution\"])\n",
    "    r.columns = r.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "    r = r.sort_values('WoB %', ascending=False)\n",
    "    r = r.drop_duplicates()\n",
    "    \n",
    "    c = t[t['Channel'].isin(c+' Total' for c in channels_POS)].drop(columns = ['Region','Market'])\n",
    "    c['Channel'] = c['Channel'].str.replace(' Total', '')\n",
    "    c['Value Share'] = c['Value Share'].astype(float) \n",
    "    c = c.sort_values('Value Share', ascending=False)\n",
    "    c=c.drop(columns=['WoB %', \"Relative Price\", \"Growth Contribution\"])\n",
    "    c.columns = c.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "    c = c.sort_values('WoB %', ascending=False)\n",
    "    c=c.drop_duplicates()\n",
    "    \n",
    "    m = t[t['Market'].isin(market_POS)].drop(columns = ['Region','Channel'])\n",
    "    m['Value Share'] = m['Value Share'].astype(float) \n",
    "    m = m.sort_values('Value Share', ascending=False)\n",
    "    m=m.drop(columns=['WoB %', \"Relative Price\", \"Growth Contribution\"])\n",
    "    m.columns = m.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "    m = m.sort_values('WoB %', ascending=False)\n",
    "    m = m.drop_duplicates()\n",
    "    \n",
    "    modified_pos_regions_client[table] = r\n",
    "    modified_pos_channels_client[table] = c\n",
    "    modified_pos_markets_client[table] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a0269b0-1c0d-4202-85d3-fe44a28060d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_calendar_new = {}\n",
    "for table in calendar_dfs_new.keys():\n",
    "    modified_tables = []\n",
    "    cleantable = calendar_dfs_new[table].copy()\n",
    "    cleantable.columns = (cleantable.iloc[12]).str.strip()\n",
    "    cleantable = cleantable[13:]\n",
    "    cleantable =cleantable[cleantable['MonthYear']!='Grand Total']\n",
    "    cleantable['time'] = pd.to_datetime(cleantable['MonthYear'], format='%b-%y')\n",
    "    cleantable = cleantable.nlargest(25, 'time')\n",
    "    cleantable = cleantable.sort_values('time')\n",
    "    cleantable['Av Price/KG'] = cleantable['Av Price/KG'].replace(np.nan, 0)\n",
    "    cleantable['Av Price/KG'] =round(cleantable['Av Price/KG'].astype(float),decimals)\n",
    "    modified_calendar_new[table] = cleantable\n",
    "\n",
    "\n",
    "keys_to_remove = []\n",
    "for key, df in modified_calendar_new.items():\n",
    "    if df.empty:  # Remove the () from df.empty\n",
    "        keys_to_remove.append(key)\n",
    "\n",
    "for key in keys_to_remove:\n",
    "    del modified_calendar_new[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f99540b4-9cce-4326-a2fb-9be1f22b735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_categories_dfs_new=[]\n",
    "for key in categories_overview_dfs_new.keys():\n",
    "    try:\n",
    "        dfCat=categories_overview_dfs_new[key].copy()\n",
    "        dfCat.columns = dfCat.iloc[12]\n",
    "        dfCat = dfCat.iloc[-1:,:]\n",
    "\n",
    "        dfCat[['Cat Volume Sales/M','Cat Value Sales/M']]=round(dfCat[['Volume Sales','Value Sales']].astype(float)/10**6, 2)\n",
    "        dfCat[['Cat Volume Sales Change YA','Cat Value Sales Change YA']]=round((dfCat[['Volume Sales IYA','Value Sales IYA']].astype(float)*100)-100,2)\n",
    "        dfCat['Cat IYA Price/KG']=round((dfCat['IYA Price/KG'].astype(float)*100),decimals)\n",
    "        dfCat['flag']=1\n",
    "\n",
    "        dfMamu=categories_overview_manuf_dfs_new[key].copy()\n",
    "        dfMamu.columns =   dfMamu.iloc[12]\n",
    "        dfMamu = dfMamu.iloc[-1:,:]\n",
    "        dfMamu[['Manu Volume Sales/M','Manu Value Sales/M']]=round(dfMamu[['Volume Sales','Value Sales']].astype(float)/10**6, 2)\n",
    "        dfMamu[['Manu Volume Sales Change YA','Manu Value Sales Change YA']]=round((dfMamu[['Volume Sales IYA','Value Sales IYA']].astype(float)*100)-100,2)\n",
    "        dfMamu['Manu IYA Price/KG']=round((dfMamu['IYA Price/KG'].astype(float)*100),2)\n",
    "        dfMamu['Impact Growth'] = dfMamu['Manu Value Sales Change YA'] - dfMamu['Manu Volume Sales Change YA']\n",
    "        dfMamu['flag']=1\n",
    "\n",
    "        table = pd.merge(dfCat[['flag','Cat Volume Sales/M','Cat Value Sales/M','Cat Volume Sales Change YA','Cat Value Sales Change YA','Cat IYA Price/KG']],dfMamu[['flag','Manu Volume Sales/M','Manu Value Sales/M','Manu Volume Sales Change YA','Manu Value Sales Change YA','Manu IYA Price/KG','Impact Growth']]).drop(columns='flag')\n",
    "        table = table[['Cat Value Sales/M','Cat Value Sales Change YA','Cat IYA Price/KG', 'Manu Value Sales/M','Manu Value Sales Change YA','Manu IYA Price/KG','Cat Volume Sales/M','Cat Volume Sales Change YA','Manu Volume Sales/M','Manu Volume Sales Change YA','Impact Growth']]\n",
    "        #table['Price Impact'] = str(int(round(table['Manu Volume Sales Change YA']-table['Manu Value Sales Change YA'])))+\"pts\"\n",
    "        table['Price Impact'] = str(int(round(table['Manu Value Sales Change YA']))-int(round(table['Manu Volume Sales Change YA'])))+\"pts\"\n",
    "        \n",
    "        table['Cat Value Sales Change YA']=str(int(round(table['Cat Value Sales Change YA'])))+'%'\n",
    "        table['Cat Volume Sales Change YA']=str(int(round(table['Cat Volume Sales Change YA'])))+'%'\n",
    "        table['Manu Value Sales Change YA']=str(int(round(table['Manu Value Sales Change YA'])))+'%'\n",
    "        table['Manu Volume Sales Change YA']=str(int(round(table['Manu Volume Sales Change YA'])))+'%'\n",
    "        table['Cat IYA Price/KG']=str(int(round(table['Cat IYA Price/KG'])))+'%'\n",
    "        table['Manu IYA Price/KG']=str(int(round(table['Manu IYA Price/KG'])))+'%'\n",
    "        lis=['Cat Value Sales/M','Manu Value Sales/M','Cat Volume Sales/M','Manu Volume Sales/M','Impact Growth']\n",
    "        for col in lis:\n",
    "            if round(table[col][0],1)==int(round(table[col][0],1)):\n",
    "                table[col]=int(round(table[col]))\n",
    "            else:\n",
    "                table[col]=round(table[col],1)\n",
    "        \n",
    "        dfVal=categories_values_dfs_new[key].copy()\n",
    "        dfVal.columns = dfVal.iloc[11]\n",
    "        dfVal=dfVal.iloc[12:,:]\n",
    "        dfVal['MonthYear']=dfVal['MonthYear'].ffill()\n",
    "\n",
    "        modified_categories_dfs_new.append([table,dfVal,key])\n",
    "    except:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1172000d-b7ca-46d2-b3ef-1211f7ba8362",
   "metadata": {},
   "outputs": [],
   "source": [
    "markets_dupl = list(set(regions_RET + channels_RET+market_RET +  regions_CHAN +channels_CHAN+ market_CHAN +regions_POS +channels_POS+ market_POS))\n",
    "\n",
    "sharGrowthDf_sec={}\n",
    "sharGrowthDf_seg={}\n",
    "\n",
    "for key in [\"National\"] + regions_RET + channels_RET+market_RET +  regions_CHAN +channels_CHAN+ market_CHAN+regions_POS +channels_POS+ market_POS:\n",
    "    sharGrowthDf_sec[key]=[k.split(' | ')[1] for k in manuf_P12M_dfs_new.keys() if key == k.split(' | ')[0] and k.split(' | ')[1] in sectors ]\n",
    "    sharGrowthDf_seg[key]=[k.split(' | ')[1] for k in manuf_P12M_dfs_new.keys() if key == k.split(' | ')[0] and k.split(' | ')[1] in segments]\n",
    "    \n",
    "    if len(sharGrowthDf_sec[key])==0:\n",
    "        sharGrowthDf_sec.pop(key,None)\n",
    "        \n",
    "    if len(sharGrowthDf_seg[key])==0:\n",
    "        sharGrowthDf_seg.pop(key,None)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a282f4",
   "metadata": {},
   "source": [
    "### Create Market Growth Market List for duplication and replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "809da84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "markets_name = ['regions_RET' , 'channels_RET','market_RET'  ,'regions_CHAN' ,'channels_CHAN', 'market_CHAN' ,'regions_POS' ,'channels_POS', 'market_POS']\n",
    "markets_val = [regions_RET , channels_RET,market_RET  ,regions_CHAN ,channels_CHAN, market_CHAN ,regions_POS ,channels_POS, market_POS]\n",
    "markets_dfs = [modified_retailer_regions , modified_retailer_channels,modified_retailer_markets  ,modified_channels_regions ,modified_channels_channels,  modified_channels_markets,modified_pos_regions ,modified_pos_channels, modified_pos_markets]\n",
    "market_total = [dya_retailer,dya_channel,dya_pos]\n",
    "slide_by = ['Region','Channel','Market']*3\n",
    "slide_for = [*['Retailer']*3,*['Channel']*3,*[POS]*3]\n",
    "market_list_Growth={}\n",
    "duplication_num = []\n",
    "section_name_Growth = []\n",
    "for idx,val in enumerate(markets_val):\n",
    "    if len(val)>0:\n",
    "        market_list_Growth[markets_name[idx]]=[val,markets_dfs[idx],market_total[idx//3],slide_by[idx],slide_for[idx]]\n",
    "        duplication_num.append(len(markets_dfs[idx].keys()))\n",
    "        section_name_Growth.append('Market Growth By '+slide_for[idx]+' For '+slide_by[idx])\n",
    "section_number = len(market_list_Growth.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68df0bf7",
   "metadata": {},
   "source": [
    "#####  Create Value_AvgPrice Market List for duplication and replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7a56013",
   "metadata": {},
   "outputs": [],
   "source": [
    "markets_name = ['regions_RET' , 'channels_RET','market_RET'  ,'regions_CHAN' ,'channels_CHAN', 'market_CHAN' ,'regions_POS' ,'channels_POS', 'market_POS']\n",
    "markets_val = [regions_RET , channels_RET,market_RET  ,regions_CHAN ,channels_CHAN, market_CHAN ,regions_POS ,channels_POS, market_POS]\n",
    "markets_dfs = [modified_retailer_regions , modified_retailer_channels,modified_retailer_markets  ,modified_channels_regions ,modified_channels_channels,  modified_channels_markets,modified_pos_regions ,modified_pos_channels, modified_pos_markets]\n",
    "client_dfs = [modified_retailer_regions_client , modified_retailer_channels_client,modified_retailer_markets_client  ,modified_channels_regions_client ,modified_channels_channels_client,  modified_channels_markets_client,modified_pos_regions_client ,modified_pos_channels_client, modified_pos_markets_client]\n",
    "market_total = [dya_retailer,dya_channel,dya_pos]\n",
    "slide_by = ['Region','Channel','Market']*3\n",
    "slide_for = [*['Retailer']*3,*['Channel']*3,*[POS]*3]\n",
    "market_list_Avg={}\n",
    "duplication_num_Avg = []\n",
    "section_name_Avg = []\n",
    "\n",
    "for idx,val in enumerate(markets_val):\n",
    "    if len(val)>0:\n",
    "        market_list_Avg[markets_name[idx]]=[val,markets_dfs[idx],client_dfs[idx],slide_by[idx],slide_for[idx]]\n",
    "        duplication_num_Avg.append(len(client_dfs[idx].keys()))\n",
    "        section_name_Avg.append('Value Vs AvgPrice By '+slide_for[idx]+' For '+slide_by[idx])\n",
    "section_number = len(market_list_Avg.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbdd250",
   "metadata": {},
   "source": [
    "### Slide 12 : Category Evolution Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7f00436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanSectorSegemnt(dfDic,catType):\n",
    "    catDic,totalDic = {},{}\n",
    "    for key,df in dfDic.items():\n",
    "        df=df.copy()\n",
    "        catIndex = df.index[df['Unnamed: 0'] == 'Sector'][0]\n",
    "        df.columns = (df.iloc[catIndex].replace(np.nan,'') + ' '+df.iloc[catIndex-1].ffill().replace(np.nan, \"\")).str.replace(' Values','').str.strip()\n",
    "        df = df.iloc[catIndex+1:]\n",
    "        df['Sector'] = df['Sector'].ffill()\n",
    "        \n",
    "        col = 'Segment' if catType == 'Segment' else 'Sector'\n",
    "        if col =='Segment':\n",
    "            df[col] = np.where(df[col].isna(), df['Sector'], df[col])\n",
    "            \n",
    "        df = df.applymap(lambda x: float(x) if pd.to_numeric(x, errors='coerce') == x else x)\n",
    "        df = df.applymap(lambda x: 0 if pd.isna(x) else x)\n",
    "        addative = df[~df['Sector'].str.contains(' Total')].sort_values('WoB %', ascending = False)\n",
    "        \n",
    "        total = df[df['Sector'].str.contains(' Total')]\n",
    "        total['Sector'] = total['Sector'].str.replace(' Total','')\n",
    "\n",
    "        catDic[key] = addative\n",
    "        totalDic[key] = total\n",
    "        \n",
    "    return catDic,totalDic\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b62d90a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cea_sectors_P12M_new,cea_dya_sectors_new=cleanSectorSegemnt(sectors_P12M_dfs_new,'Sector')\n",
    "cea_sectors_clients_new,cea_sectors_clients_total_new=cleanSectorSegemnt(sectors_client_dfs_new,'Sector')\n",
    "cea_segment_P12M_new,cea_dya_segment_new,cea_segment_clients_new,cea_segment_clients_total_new ={},{},{},{}\n",
    "if segments:\n",
    "\n",
    "    cea_segment_P12M_new,cea_dya_segment_new=cleanSectorSegemnt(segments_P12M_dfs_new,'Segment')\n",
    "    cea_segment_clients_new,cea_segment_clients_total_new=cleanSectorSegemnt(segments_client_dfs_new,'Segment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70ab16e",
   "metadata": {},
   "source": [
    "## Slide 13 : Share And Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6c15000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaningMarket(dfsDictionary):\n",
    "    retailerDic,totalRetailerDic = {},{}\n",
    "    for key,df in dfsDictionary.items():\n",
    "        df=df.copy()\n",
    "        startIndex = df.index[df['Unnamed: 0'] == 'Region'][0]\n",
    "        df.columns = df.iloc[startIndex].replace(np.nan,'')\n",
    "        df = df.iloc[startIndex+1:]\n",
    "        df = df[~df['Channel'].astype(str).str.contains('Total')]\n",
    "\n",
    "#         df[[col for col in df.columns[:3]]] = df[[col for col in df.columns[:3]]].ffill()\n",
    "        addative = df[~df['Region'].str.contains(' Total')]\n",
    "        total = df[df['Region'].str.contains(' Total')].sort_values('Trade WoB %', ascending = False).reset_index(drop=True)\n",
    "        total = total.applymap(lambda x: float(x) if pd.to_numeric(x, errors='coerce') == x else x)\n",
    "        total = total.applymap(lambda x: 0 if pd.isna(x) else x)\n",
    "        if total.shape[0]!=0:\n",
    "            retailerDic[key] = addative\n",
    "            totalRetailerDic[key] = total\n",
    "    return retailerDic,totalRetailerDic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4038ace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_retailers_clients = {}\n",
    "if retailers_dfs_new:\n",
    "    modified_retailers,retailers_total=cleaningMarket(retailers_dfs_new)\n",
    "    modified_retailers_clients,retailers_clients_total=cleaningMarket(retailers_client_dfs_new)\n",
    "    retailerCatDic = {key : modified_retailers_clients[key] for key in modified_retailers_clients.keys() if len(set(categories).intersection(set(key.split(' | '))))}\n",
    "    retailerSecDic = {key : modified_retailers_clients[key] for key in modified_retailers_clients.keys() if len(set(sectors).intersection(set(key.split(' | '))))}\n",
    "    retailerSegDic = {key : modified_retailers_clients[key] for key in modified_retailers_clients.keys() if len(set(segments).intersection(set(key.split(' | '))))}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99de1197",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_channel_clients = {}\n",
    "modified_pos_clients = {}\n",
    "\n",
    "\n",
    "if channel_dfs_new:\n",
    "    modified_channel,channel_total=cleaningMarket(channel_dfs_new)\n",
    "    modified_channel_clients,channel_clients_total=cleaningMarket(channel_client_dfs_new)\n",
    "    channelCatDic = {key : modified_channel_clients[key] for key in modified_channel_clients.keys() if len(set(categories).intersection(set(key.split(' | '))))}\n",
    "    channelSecDic = {key : modified_channel_clients[key] for key in modified_channel_clients.keys() if len(set(sectors).intersection(set(key.split(' | '))))}\n",
    "    channelSegDic = {key : modified_channel_clients[key] for key in modified_channel_clients.keys() if len(set(segments).intersection(set(key.split(' | '))))}\n",
    "\n",
    "if pos_dfs_new:\n",
    "    modified_pos,pos_total=cleaningMarket(pos_dfs_new)\n",
    "    modified_pos_clients,pos_clients_total=cleaningMarket(pos_client_dfs_new)\n",
    "    posCatDic = {key : modified_pos_clients[key] for key in modified_pos_clients.keys() if len(set(categories).intersection(set(key.split(' | '))))}\n",
    "    posSecDic = {key : modified_pos_clients[key] for key in modified_pos_clients.keys() if len(set(sectors).intersection(set(key.split(' | '))))}\n",
    "    posSegDic = {key : modified_pos_clients[key] for key in modified_pos_clients.keys() if len(set(segments).intersection(set(key.split(' | '))))}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "064ffecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "retailerDup = [len(retailerCatDic.keys()),len(retailerSecDic.keys()),len(retailerSegDic.keys())] if retailers_dfs_new else[]\n",
    "channelDup = [len(channelCatDic.keys()),len(channelSecDic.keys()),len(channelSegDic.keys())] if channel_dfs_new else[]\n",
    "posDup = [len(posCatDic.keys()),len(posSecDic.keys()),len(posSegDic.keys())] if pos_dfs_new else[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef21c020",
   "metadata": {},
   "source": [
    "## Slide Creations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef0bd4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genrateIndexList(scopeCategory ,chartIndex =0 ,chartCount =4 ):\n",
    "    if len(scopeCategory) == 0:\n",
    "        return []\n",
    "    page = len(scopeCategory) # number of sector or segment or category\n",
    " \n",
    "    lis=[]\n",
    "    while page >chartCount:\n",
    "        lis.append(chartCount + chartIndex)\n",
    "        page -=chartCount\n",
    "    lis.append(page + chartIndex)\n",
    "    return [lis]\n",
    "\n",
    "sectorIndex = genrateIndexList(sectors,4,3)\n",
    "segmentIndex = genrateIndexList(segments,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bec4c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "slide13Index = [*[*[12]* (3 if segments else 2)]*(3 - ((not retailers_dfs_new)+(not channel_dfs_new) + (not pos_dfs_new) ))]\n",
    "slide13Dup = retailerDup + channelDup + posDup\n",
    "index = [*[0]*(4 if segments else 3),*[1]*(4 if segments else 3),*[2]*(2 if segments else 1),*[2]*section_number, *[3]*(2 if segments else 1),*[3]*section_number, 4, *sectorIndex*2,*segmentIndex*2,8, 9,10,*[11]*(2 if segments else 1)]+slide13Index\n",
    "\n",
    "duplication = [len(modified_manuf_dfs_new.keys()), len(modified_brands_share_new.keys()),len(modified_sectors_dfs_new.keys()),len(modified_segment_dfs_new.keys())if segments else 0, len(modified_manuf_dfs_new.keys()), len(modified_brands_share_new.keys()), len(modified_sectors_dfs_new.keys()), len(modified_segment_dfs_new.keys())if segments else 0,len(modified_sectors_P12M_new.keys()),len(modified_segment_P12M_new.keys())if segments else 0,*duplication_num, len(modified_sectors_clients_new.keys()),len(modified_segment_clients_new.keys())if segments else 0, *duplication_num_Avg,len(modified_manuf_P12M_new.keys()), len(sharGrowthDf_sec.keys()), len(sharGrowthDf_sec.keys()),len(sharGrowthDf_seg.keys()) if segments else 0, len(sharGrowthDf_seg.keys()) if segments else 0, len(modified_calendar_new.keys()), len(modified_brands_evolution_sorted_new.keys()), len(categories_overview_dfs_new.keys()),len(cea_sectors_clients_new.keys()),len(cea_segment_clients_new.keys())*len(sectors) if segments else 0] + slide13Dup \n",
    "duplication = [item for item in duplication if item !=0]\n",
    "\n",
    "\n",
    "section_names_slide1 = [\"Market Trends by Manufacturer\",\"Market Trends by Brands\",\"Market Trends by Sectors\"] + ([\"Market Trends by Segments\"] if len(segments)>0 else [])\n",
    "section_names_slide2 = [\"Market Concentraion By Manufacturer\", \"Market Concentration By Brands\", \"Market Concentration By Sectors\"]+ ([\"Market Concentration By Segments\"] if len(segments)>0 else [])\n",
    "section_names_slide3 = [\"Market Growth By Sectors\"]+([\"Market Growth By Segments\"]if len(segments)>0 else [])+[*section_name_Growth]\n",
    "section_names_slide4 = [\"Value Vs AvgPrice By Sectors\"]+([\"Value Vs AvgPrice By Segments\"]if len(segments)>0 else [])+[*section_name_Avg]\n",
    "section_names_slide5 = ['Share and Growth By Manufacturer/Brands']\n",
    "section_names_slide6 = ['Share And Growth By Manufacturer By Sector', 'Share And Growth By Brands By Sector'] + (['Share And Growth By Manufacturer By Segment', 'Share And Growth By Brands By Segment'] if len(segments)>0 else [] )\n",
    "section_names_slide7 =  [\"Category Trends\"]\n",
    "section_names_slide8 =  ['Share Evolution By Brand']\n",
    "section_names_slide9 =  [\"Category Overview\"]\n",
    "section_names_slide11 =  [\"Sales and Growth By Sector\"]+([\"Sales and Growth By Segment\"] if len(segments)>0 else [])\n",
    "\n",
    "retailerSection = [\"Share and Growth By Category By Retailer\",\"Share and Growth By Sector By Retailer\"]+[\"Share and Growth By Segment By Retailer\"] if segments else +[]\n",
    "channelSection = [\"Share and Growth By Category By Channel\",\"Share and Growth By Sector By Channel\"]+[\"Share and Growth By Segment By Channel\"]if segments else +[]\n",
    "POSSection = [\"Share and Growth By Category By POS\",\"Share and Growth By Sector By POS\"]+[\"Share and Growth By Segment By POS\"]if segments else +[]\n",
    "section_names_slide13 =  retailerSection+(channelSection if modified_channel_clients else [])+(POSSection if modified_pos_clients else [])\n",
    "\n",
    "section_names = [*section_names_slide1,*section_names_slide2,*section_names_slide3,*section_names_slide4,*section_names_slide5,*section_names_slide6,*section_names_slide7,*section_names_slide8,*section_names_slide9,*section_names_slide11,*section_names_slide13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e70fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + '\\Landscape base.pptx'\n",
    "new_pre = os.getcwd() + '\\Landscape duplicate.pptx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a7ff737-309e-4248-8706-ef373cece6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "27\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "print(len(index))\n",
    "print(len(duplication))\n",
    "print(len(section_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e986f78c",
   "metadata": {},
   "outputs": [
    {
     "ename": "com_error",
     "evalue": "(-2147352567, 'Exception occurred.', (0, 'Microsoft PowerPoint', 'Slides.Paste : Invalid request.  Clipboard is empty or contains data which may not be pasted here.', '', 0, -2147188160), None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mcom_error\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mslideDuplication\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43mduplication\u001b[49m\u001b[43m,\u001b[49m\u001b[43msection_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnew_pre\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16128\\1722540262.py:38\u001b[0m, in \u001b[0;36mslideDuplication\u001b[1;34m(index, duplication, section_names, path, new_pre)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num_duplicate \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(duplication[i]):\n\u001b[0;32m     37\u001b[0m     slide\u001b[38;5;241m.\u001b[39mCopy()\n\u001b[1;32m---> 38\u001b[0m     \u001b[43mpresentation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSlides\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPaste\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m.1\u001b[39m)\n\u001b[0;32m     40\u001b[0m lis\u001b[38;5;241m.\u001b[39mappend(presentation\u001b[38;5;241m.\u001b[39mSlides\u001b[38;5;241m.\u001b[39mcount\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mduplication[i])\n",
      "File \u001b[1;32m<COMObject <unknown>>:2\u001b[0m, in \u001b[0;36mPaste\u001b[1;34m(self, Index)\u001b[0m\n",
      "\u001b[1;31mcom_error\u001b[0m: (-2147352567, 'Exception occurred.', (0, 'Microsoft PowerPoint', 'Slides.Paste : Invalid request.  Clipboard is empty or contains data which may not be pasted here.', '', 0, -2147188160), None)"
     ]
    }
   ],
   "source": [
    "slideDuplication(index,duplication,section_names,path,new_pre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "593b9fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = Presentation(new_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c8019f",
   "metadata": {},
   "source": [
    "### Slide 1_ Market_Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c63f902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_position(end):\n",
    "    return sum(duplication[i] * (1 if isinstance(index[i], int) else len(index[i])) for i in range(end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee57ab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0\n",
    "Market_Trends(prs, list(modified_manuf_dfs_new.keys()), modified_manuf_dfs_new, modified_manuf_totals_new, client_manuf ,position = calculate_position(p), slide_by = 'Top Companies')\n",
    "p+=1\n",
    "Market_Trends(prs, list(modified_brands_share_new.keys()), modified_brands_share_new, modified_brands_totals_new, client_brands ,position =calculate_position(p), slide_by = 'Top Brands')\n",
    "p+=1\n",
    "Market_Trends(prs, list(modified_sectors_dfs_new.keys()), modified_sectors_dfs_new, sectors_totals_new, sectors ,position = calculate_position(p), slide_by = 'Sector')\n",
    "p+=1\n",
    "if len(segments)!=0:\n",
    "    Market_Trends(prs, list(modified_segment_dfs_new.keys()), modified_segment_dfs_new, segment_totals_new, segments ,position = calculate_position(p), slide_by = 'Segment')\n",
    "    p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eb00e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in modified_brands_share_new.keys():\n",
    "    modified_brands_share_new[k]['Top Brands'] = modified_brands_share_new[k]['Top Brands'].str.replace(\"Private Label\", \"PL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818bdd5e",
   "metadata": {},
   "source": [
    "### Slide 2_Market_Concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cca01905",
   "metadata": {},
   "outputs": [],
   "source": [
    "Market_Concentration(prs,list(modified_manuf_dfs_new.keys()), modified_manuf_dfs_new, modified_manuf_totals_new, client_manuf ,position =  calculate_position(p), slide_by = 'Top Companies')\n",
    "p+=1\n",
    "Market_Concentration(prs,list(modified_brands_share_new.keys()), modified_brands_share_new, modified_brands_totals_new, client_brands ,position =  calculate_position(p), slide_by = 'Top Brands')\n",
    "p+=1\n",
    "Market_Concentration(prs,list(modified_sectors_dfs_new.keys()), modified_sectors_dfs_new, sectors_totals_new, sectors ,position =  calculate_position(p), slide_by = 'Sector')\n",
    "p+=1\n",
    "if len(segments)!=0:\n",
    "    Market_Concentration(prs,list(modified_segment_dfs_new.keys()), modified_segment_dfs_new, segment_totals_new, segments ,position =  calculate_position(p), slide_by = 'Segment')\n",
    "    p+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4649a3",
   "metadata": {},
   "source": [
    "## Slide 3_Market_Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f20270fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Market_Growth(prs,list(modified_sectors_P12M_new.keys()), modified_sectors_P12M_new, dya_sectors_new, position = calculate_position(p) , slide_by = 'Sector')\n",
    "p+=1\n",
    "if len(segments) !=0:\n",
    "    Market_Growth(prs,list(modified_segment_P12M_new.keys()), modified_segment_P12M_new, dya_segment_new, position = calculate_position(p) , slide_by = 'Segment') \n",
    "    p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5eca0084",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,val in market_list_Growth.items():\n",
    "    Market_Growth(prs, list(val[1].keys()), val[1], val[2], position = calculate_position(p), slide_by = val[3], slide_for = val[4])\n",
    "    p+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74a843c",
   "metadata": {},
   "source": [
    "## Slide4_ValueSales_AvgPrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8538f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_list=[\"National\"] + regions_RET + channels_RET+market_RET +  regions_CHAN +channels_CHAN+ market_CHAN+regions_POS +channels_POS+ market_POS\n",
    "manuf_brand_list = client_manuf + client_brands\n",
    "ValueSales_AvgPrice(prs, list(modified_sectors_clients_new.keys()), modified_sectors_P12M_new, modified_sectors_clients_new,manuf_brand_list, market_list,position = calculate_position(p), slide_by = 'Sector')\n",
    "ValueSales_AvgPrice(prs, list(modified_sectors_clients_new.keys()), modified_sectors_P12M_new, modified_sectors_clients_new,manuf_brand_list, market_list,position = calculate_position(p), slide_by = 'Sector')\n",
    "\n",
    "p+=1\n",
    "if len(segments)!=0:\n",
    "    ValueSales_AvgPrice(prs, list(modified_segment_clients_new.keys()), modified_segment_P12M_new, modified_segment_clients_new,manuf_brand_list,market_list, position = calculate_position(p) , slide_by = 'Segment')\n",
    "    ValueSales_AvgPrice(prs, list(modified_segment_clients_new.keys()), modified_segment_P12M_new, modified_segment_clients_new,manuf_brand_list,market_list, position = calculate_position(p) , slide_by = 'Segment')\n",
    "    p+=1\n",
    "catg_list=[f'{categories[0]}'] + sectors + segments\n",
    "for key,val in market_list_Avg.items():\n",
    "    ValueSales_AvgPrice(prs, list(val[2].keys()), val[1], val[2],manuf_brand_list,catg_list ,position = calculate_position(p), slide_by = val[3], slide_for = val[4])\n",
    "    ValueSales_AvgPrice(prs, list(val[2].keys()), val[1], val[2],manuf_brand_list,catg_list ,position = calculate_position(p), slide_by = val[3], slide_for = val[4])\n",
    "    p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cc525dfc-c395-424d-b77b-3ed0934842ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in modified_brands_P12M_new.keys():\n",
    "    modified_brands_P12M_new[k] = modified_brands_P12M_new[k].rename(columns = { \"Value Share P12M\":\"Value Share\", \"Share DYA P12M\":\"Share DYA\", \"Av Price/KG P12M\":\"Av Price/KG\"})\n",
    "    modified_brands_P12M_new[k] = modified_brands_P12M_new[k].sort_values('Value Share', ascending = False)\n",
    "    modified_brands_P12M_new[k] = modified_brands_P12M_new[k][modified_brands_P12M_new[k]['Value Share']!=0]    \n",
    "    modified_brands_P12M_new[k]['Sorting'] = np.where(modified_brands_P12M_new[k]['Top Brands'] == 'Others', 1, 0)\n",
    "    modified_brands_P12M_new[k] = modified_brands_P12M_new[k].sort_values('Sorting', ascending = True).drop(columns = 'Sorting')\n",
    "    \n",
    "for k in modified_manuf_P12M_new.keys():\n",
    "    modified_manuf_P12M_new[k] = modified_manuf_P12M_new[k].sort_values('Total Value Share', ascending=False)\n",
    "    modified_manuf_P12M_new[k]['Sorting'] = np.where(modified_manuf_P12M_new[k]['Top Companies'] == 'Others', 1, 0)\n",
    "    modified_manuf_P12M_new[k] = modified_manuf_P12M_new[k].sort_values('Sorting', ascending = True).drop(columns = 'Sorting')\n",
    "    modified_manuf_P12M_new[k] = modified_manuf_P12M_new[k][modified_manuf_P12M_new[k]['Value Share P12M']!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40b8d2c",
   "metadata": {},
   "source": [
    "## Slide5_Share_Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "507b6899",
   "metadata": {},
   "outputs": [],
   "source": [
    "Share_Growth(prs, list(modified_manuf_P12M_new.keys()), modified_manuf_P12M_new, modified_brands_P12M_new, position =calculate_position(p))\n",
    "p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ed8204ac-bce9-4efb-bd42-a904dc1c7f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in modified_brands_P12M_new.keys():\n",
    "    modified_brands_P12M_new[k] = modified_brands_P12M_new[k].rename(columns = {\"Value Share\": \"Value Share P12M\", \"Share DYA\":\"Share DYA P12M\", \"Av Price/KG\":\"Av Price/KG P12M\"})\n",
    "    modified_brands_P12M_new[k]['Top Brands'] = modified_brands_P12M_new[k]['Top Brands'].str.replace('Norgesgruppen', \"NG\").str.replace(\"Private Label\", \"PL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ee17eb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in modified_brands_P12M_new.items():\n",
    "        modified_brands_P12M_new[key] = df[df['Value Share P12M'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15664481",
   "metadata": {},
   "source": [
    "### Slide6_Share and Growth By Manufacturer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6cbc3f9d-5d9a-4605-95cb-374a5d5502ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = calculate_position(p)\n",
    "sectors_list = [sectors[i:i+3] for i in range(0, len(sectors), 3)]\n",
    "for key in sharGrowthDf_sec.keys():\n",
    "    for sublist in sectors_list:\n",
    "        Share_Growth_Separately( prs,[key], modified_manuf_P12M_new,position=c,slide_by='Manufacturer | By Sector', list_tables=sublist,first_col='Top Companies' )\n",
    "        c += 1  # Correctly incrementing the variable c\n",
    "p+=1\n",
    "\n",
    "c=calculate_position(p)\n",
    "for key in sharGrowthDf_sec.keys():\n",
    "    for sublist in sectors_list:\n",
    "        Share_Growth_Separately( prs,[key], modified_brands_P12M_new,position=c,slide_by='Brands | By Sector', list_tables=sublist,first_col='Top Brands' )\n",
    "        c += 1  # Correctly incrementing the variable c\n",
    "p+=1\n",
    "if len(segments)!=0:\n",
    "    c = calculate_position(p)\n",
    "    segments_list = [segments[i:i+3] for i in range(0, len(segments), 3)]\n",
    "    for key in sharGrowthDf_seg.keys():\n",
    "        for sublist in segments_list:\n",
    "            Share_Growth_Separately( prs,[key], modified_manuf_P12M_new,position=c,slide_by='Manufacturer | By Segment', list_tables=sublist,first_col='Top Companies' )\n",
    "            c += 1  # Correctly incrementing the variable c\n",
    "    p+=1\n",
    "    \n",
    "    c=calculate_position(p)\n",
    "    for key in sharGrowthDf_seg.keys():\n",
    "        for sublist in segments_list:\n",
    "            Share_Growth_Separately( prs,[key], modified_brands_P12M_new,position=c,slide_by='Brands | By Segment', list_tables=sublist,first_col='Top Brands' )\n",
    "            c += 1  # Correctly incrementing the variable c\n",
    "    p+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e828947f",
   "metadata": {},
   "source": [
    "#### Slide9_Category_Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "46737191-c533-46c4-8346-c4d0a0eb1ad2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Category_Trend(prs,list(modified_calendar_new.keys()), modified_calendar_new, position = calculate_position(p))\n",
    "p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "449ade26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in modified_brands_evolution_sorted_new.keys():\n",
    "    t = modified_brands_evolution_sorted_new[k].copy()\n",
    "    t['Tot Sort'] = np.where(t['Top Brands'] == 'Total', 0, 1)\n",
    "    t = t.sort_values(['Year', 'Tot Sort'], ascending=[True, True])\n",
    "    t = t.drop(columns='Tot Sort')\n",
    "\n",
    "    modified_brands_evolution_sorted_new[k] = t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddfd7ea",
   "metadata": {},
   "source": [
    "#### Slide10_Share_Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e7a468f4-a9a7-4bee-bcde-320fb57bb92a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Share_Evolution(prs, list(modified_brands_evolution_sorted_new.keys()), modified_brands_evolution_sorted_new, position = calculate_position(p))\n",
    "p+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cc87b2",
   "metadata": {},
   "source": [
    "### Slide11_CategoryOverview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bfe24fa5-dfcc-46eb-8f7d-59746b13b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "CategoryOverview(prs,modified_categories_dfs_new,col='MonthYear',position=calculate_position(p),scope = sectors, slide_by = 'Sector')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6355e3",
   "metadata": {},
   "source": [
    "## Slide 12 : Category Evolution Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff8354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryEvolution(prs,cea_sectors_clients_new,cea_sectors_P12M_new,cea_dya_sectors_new,cea_sectors_clients_total_new,categories[0],manuf_brand_list,position = calculate_position(p))\n",
    "p += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e20810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos = len(modified_sectors_clients_new.keys())\n",
    "if len(segments)!=0:\n",
    "    posadd=calculate_position(p)\n",
    "    for sec in sectors:\n",
    "        print(pos,sec)\n",
    "        categoryEvolution(prs,cea_segment_clients_new,cea_segment_P12M_new,cea_dya_segment_new,cea_segment_clients_total_new,sec,manuf_brand_list,col='Segment',position = posadd)\n",
    "        posadd += len(modified_segment_clients_new.keys())\n",
    "    p+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a828d1d0",
   "metadata": {},
   "source": [
    "## Slide 13 : Share And Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef634e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retailers \n",
    "shareGrowth(prs,retailers_clients_total,retailers_total,catSecSeg,col='Region',position = calculate_position(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6328d2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if retailers_dfs_new:\n",
    "    shareGrowth(prs,retailerCatDic,retailers_total,catSecSeg,col='Region',position = calculate_position(p)) \n",
    "    p+=1\n",
    "    shareGrowth(prs,retailerSecDic,retailers_total,catSecSeg,col='Region',position = posItr) \n",
    "    p+=1\n",
    "\n",
    "    if segments:\n",
    "        \n",
    "        shareGrowth(prs,retailerSegDic,retailers_total,catSecSeg,col='Region',position = calculate_position(p))    \n",
    "        p+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94405d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## channel\n",
    "if channel_dfs_new:\n",
    "    shareGrowth(prs,channelCatDic,channel_total,catSecSeg,col='Region',position = calculate_position(p)) \n",
    "    p+=1\n",
    "    shareGrowth(prs,channelSecDic,channel_total,catSecSeg,col='Region',position = calculate_position(p)) \n",
    "    p+=1\n",
    "\n",
    "    if segments:\n",
    "        \n",
    "        shareGrowth(prs,channelSegDic,channel_total,catSecSeg,col='Region',position = calculate_position(p))    \n",
    "        p+=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9db5c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "##pos\n",
    "if pos_dfs_new:\n",
    "    shareGrowth(prs,posCatDic,pos_total,catSecSeg,col='Region',position = calculate_position(p)) \n",
    "    p+=1\n",
    "    shareGrowth(prs,posSecDic,pos_total,catSecSeg,col='Region',position = calculate_position(p)) \n",
    "    p+=1\n",
    "\n",
    "    if segments:\n",
    "        \n",
    "        shareGrowth(prs,posSegDic,pos_total,catSecSeg,col='Region',position = calculate_position(p))    \n",
    "        p+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497343aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a77b5bf8-313b-4919-a680-edac829866dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath = os.getcwd()+\"\\\\Landscape output.pptx\"\n",
    "\n",
    "prs.save(outputPath)\n",
    "app = win32.Dispatch(\"PowerPoint.Application\")\n",
    "presentation = app.Presentations.Open(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d6e491f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script started at: Mon Jun  3 09:45:17 2024\n",
      "Script ended at: Mon Jun  3 09:46:38 2024\n",
      "Elapsed time: 81.06 seconds\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Script started at: {time.ctime(start_time)}\")\n",
    "print(f\"Script ended at: {time.ctime(end_time)}\")\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d55cff12-abc1-48b1-8b39-bf8c58ca36ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 326.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9938a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a6b675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
