{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"..\\general_functions\\generalFunctions.ipynb\"\n",
    "%run \"..\\Innovation CBC Slide Duplicate\\Innovation CBC Replacement Function.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = r\"Innovation CBC Datasets/Edgewell Mexico Inno Extract.xlsx\"\n",
    "data_source = \"DATA SOURCE: Consumer Test | June 2025\"\n",
    "market='Walmart'\n",
    "sheet_name1='Performance'\n",
    "sheet_name2='Ranking'\n",
    "wdtext=\"WD assumption = 50 WD\"\n",
    "unitorvolume= 'Unit'\n",
    "unitorvolshare= 'New ' + unitorvolume + ' Share' #New Volume Share\n",
    "client= 'Edgewell'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data in Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.read_excel(filePath,'Performance').rename(columns={'Unnamed: 2': 'Product', 'Unnamed: 3': 'ProductSize'})\n",
    "rank = pd.read_excel(filePath,'Ranking')\n",
    "sourcing = pd.read_excel(filePath,\"Sourcing\")\n",
    "fair = pd.read_excel(filePath,\"Fair\")\n",
    "merged = pd.merge(sourcing, fair, left_on=\"Rescaled share diff\", right_on=\"Fair Share\", how=\"inner\", suffixes=('', '_f'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfSlides=performance.Grouping.value_counts().reset_index()\n",
    "numberOfSlides['Count']=numberOfSlides['count'].apply(lambda x : 1 if x<=5 else ((x//5) +( 0 if x%5 ==0 else 1)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the 'performance' DataFrame by the 'Grouping' column and getting unique 'Sheets names' for each group\n",
    "columnName = performance.groupby('Grouping')['Sheets names'].unique().reset_index()\n",
    "\n",
    "# Creating a dictionary where each key is a unique 'Grouping' value and each value is a DataFrame containing \n",
    "# 'New volume share' column and the columns listed in 'Sheets names' for that group\n",
    "dfDic = {columnName['Grouping'].iloc[i]: rank[[unitorvolshare] + list(columnName['Sheets names'].iloc[i])] for i in range(columnName.shape[0])}\n",
    "\n",
    "# Initializing an empty dictionary to store split DataFrames\n",
    "dfDicSplit = {}\n",
    "\n",
    "# Column name to be prioritized in the final DataFrames\n",
    "col = unitorvolshare\n",
    "\n",
    "# Iterating over each key-value pair in dfDic\n",
    "for key, value in dfDic.items():\n",
    "    # Checking if the number of columns (excluding 'New volume share') is greater than 5\n",
    "    if value.shape[1] - 1 > 5:\n",
    "        numOfColumns = 0\n",
    "        # Splitting the DataFrame into chunks of 5 columns if there are more than 5 columns\n",
    "        while numOfColumns < value.shape[1] - 1:\n",
    "            print('split number = ', numOfColumns)\n",
    "            # Creating a new DataFrame with the next set of 5 columns\n",
    "            dfDicSplit[key + '_Num ' + str(numOfColumns)] = value.iloc[:, numOfColumns + 1:numOfColumns + 6]\n",
    "            # Adding the 'New volume share' column to the new DataFrame\n",
    "            dfDicSplit[key + '_Num ' + str(numOfColumns)][col] = value[col]\n",
    "            # Reordering columns to place 'New volume share' at the front\n",
    "            columns_order = [col] + [cl for cl in dfDicSplit[key + '_Num ' + str(numOfColumns)].columns if cl != col]\n",
    "            dfDicSplit[key + '_Num ' + str(numOfColumns)] = dfDicSplit[key + '_Num ' + str(numOfColumns)].reindex(columns=columns_order)\n",
    "            numOfColumns += 5\n",
    "    else:\n",
    "        # If the number of columns (excluding 'New volume share') is 5 or fewer, add the DataFrame as is to dfDicSplit\n",
    "        dfDicSplit[key] = value\n",
    "        dfDicSplit[key][\"To color\"] = rank[\"To color\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Advanced Protection': 1,\n",
       " 'Baby': 1,\n",
       " 'Beautycare': 4,\n",
       " 'Kids': 1,\n",
       " 'Ozono': 3,\n",
       " 'Silk Hydration': 3,\n",
       " 'Sport': 4}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dictionary to store the count of columns (excluding 'New volume share' and the 'Grouping' column)\n",
    "# for each DataFrame in dfDicSplit\n",
    "duplicationList={key:value.shape[1]-2 for key,value in dfDicSplit.items()}\n",
    "duplicationList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the 'performance' DataFrame by the 'Grouping' column and aggregating 'Sheets names' and 'Product' into lists\n",
    "grouped = performance.groupby('Grouping')[['Sheets names', 'Product']].agg(list)\n",
    "\n",
    "# Creating a dictionary where each key is a 'Grouping' value and each value is a dictionary \n",
    "# with 'Sheets names' as keys and 'Product' as values\n",
    "result = grouped.apply(lambda x: dict(zip(x['Sheets names'], x['Product'])), axis=1).to_dict()\n",
    "\n",
    "# Initializing an empty list to store the number of products minus one for each grouping\n",
    "sum_list = []\n",
    "\n",
    "# Iterating over each inner dictionary in the result dictionary\n",
    "for inner_dict in result.values():\n",
    "    # Calculating the number of products for the current grouping\n",
    "    inner_sum = len(inner_dict.values())\n",
    "    # Appending the number of products minus one to sum_list\n",
    "    sum_list.append(inner_sum - 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplication Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "startIndex=8\n",
    "index = [0,list(duplicationList.values()),7,[i+startIndex for i in sum_list]]\n",
    "duplication = [performance.Grouping.nunique(),1,performance.Grouping.nunique(),1]\n",
    "section_names = [\"Innovation Summary\",\"Innovation ranking\",\"Innovation potential\",\"Innovation sourcing\"]\n",
    "\n",
    "path = os.getcwd() + '//Inno CBC base Oct 2024.pptx'\n",
    "new_pre = os.getcwd() + '//slide duplicated.pptx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "4\n",
      "[0, [1, 1, 4, 1, 3, 3, 4], 7, [8, 8, 11, 8, 10, 10, 11]]\n",
      "[7, 1, 7, 1]\n",
      "['Innovation Summary', 'Innovation ranking', 'Innovation potential', 'Innovation sourcing']\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(index))\n",
    "print(len(duplication))\n",
    "print(len(section_names))\n",
    "print(index)\n",
    "print(duplication)\n",
    "print(section_names)\n",
    "print(sum(duplication))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shouldn't be hased in the first run\n",
    "slideDuplication(index,duplication,section_names,path,new_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = Presentation(new_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_position(end):\n",
    "    return sum(duplication[i] * (1 if isinstance(index[i], int) else len(index[i])) for i in range(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Innovation Summary (Slide 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0\n",
    "numOfDuplicatesSummarySlide = len(list(duplicationList.values()))*duplication[0]\n",
    "Innovation_Summary(prs, performance,grouped, numOfDuplicates=numOfDuplicatesSummarySlide, position=calculate_position(p))\n",
    "p+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Innovation Ranking (Slide 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced Protection\n",
      "Baby\n",
      "Beautycare\n",
      "Kids\n",
      "Ozono\n",
      "Silk Hydration\n",
      "Sport\n"
     ]
    }
   ],
   "source": [
    "numOfDuplicatesFirstSlide = len(list(duplicationList.values())) * duplication[1]\n",
    "innovationRanking(prs,dfDicSplit,performance,unitorvolshare,client,numOfDuplicates=numOfDuplicatesFirstSlide,position=calculate_position(p))\n",
    "p+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Innovation Potential (Slide 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "innovationPotential(prs,performance, wdtext,unitorvolume,numOfDuplicates = duplication[p],position=calculate_position(p))\n",
    "p+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Innovation Sourcing (Slide 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfDuplicatesThirdSlide = len(list(sum_list)) * duplication[2]\n",
    "innovationSourcing(prs,performance, merged,result, sum_list, numOfDuplicates = numOfDuplicatesThirdSlide, position=calculate_position(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = str(date.today())\n",
    "outputPath=os.getcwd() + \"\\\\Innovation CBC \"+market+\" output \"+today+\".pptx\"\n",
    "prs.save(outputPath)\n",
    "app = win32.Dispatch(\"PowerPoint.Application\")\n",
    "presentation = app.Presentations.Open(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slide counts - Summary: 7, Ranking: 7, Potential: 7, Sourcing: 7\n",
      "[1]\n",
      "[1, 8, 15, 22, 2]\n",
      "[1, 8, 15, 22, 2, 9, 16, 23, 3]\n",
      "[1, 8, 15, 22, 2, 9, 16, 23, 3, 10, 17, 24, 4]\n",
      "[1, 8, 15, 22, 2, 9, 16, 23, 3, 10, 17, 24, 4, 11, 18, 25, 5]\n",
      "[1, 8, 15, 22, 2, 9, 16, 23, 3, 10, 17, 24, 4, 11, 18, 25, 5, 12, 19, 26, 6]\n",
      "[1, 8, 15, 22, 2, 9, 16, 23, 3, 10, 17, 24, 4, 11, 18, 25, 5, 12, 19, 26, 6, 13, 20, 27, 7]\n",
      "New slide order (1-based): [1, 8, 15, 22, 2, 9, 16, 23, 3, 10, 17, 24, 4, 11, 18, 25, 5, 12, 19, 26, 6, 13, 20, 27, 7, 14, 21, 28]\n",
      "Reordered 28 slides successfully\n",
      "Removing 4 sections...\n",
      "All sections removed.\n",
      "0\n",
      "Advanced Protection\n",
      "1\n",
      "Baby\n",
      "2\n",
      "Beautycare\n",
      "3\n",
      "Kids\n",
      "4\n",
      "Ozono\n",
      "5\n",
      "Silk Hydration\n",
      "6\n",
      "Sport\n",
      "Reordered presentation saved as: c:\\Users\\Salma Hany\\Documents\\Slide-Automate\\Innovation CBC Slide Duplicate\\Innovation CBC Walmart reordered output 2025-08-19.pptx\n",
      "Slide reordering complete! All formatting preserved.\n"
     ]
    }
   ],
   "source": [
    "summary_slide_count = max(duplication)\n",
    "ranking_slide_count = max(duplication)\n",
    "potential_slide_count = max(duplication) \n",
    "sourcing_slide_count = max(duplication)\n",
    "\n",
    "print(f\"Slide counts - Summary: {summary_slide_count}, Ranking: {ranking_slide_count}, Potential: {potential_slide_count}, Sourcing: {sourcing_slide_count}\")\n",
    "\n",
    "\n",
    "app = win32.Dispatch(\"PowerPoint.Application\")\n",
    "presentation = app.Presentations.Open(outputPath)\n",
    "\n",
    "new_order = []\n",
    "max_slides_per_section = max(summary_slide_count,ranking_slide_count, potential_slide_count, sourcing_slide_count)\n",
    "for round_num in range(max_slides_per_section):\n",
    "    if round_num < summary_slide_count:\n",
    "        summary_slide_index =  round_num +1\n",
    "        new_order.append(summary_slide_index)\n",
    "    if round_num < ranking_slide_count:\n",
    "        ranking_slide_index = round_num +1  + summary_slide_count \n",
    "        new_order.append(ranking_slide_index)\n",
    "        \n",
    "    if round_num < potential_slide_count:\n",
    "        potential_slide_index = ranking_slide_count + summary_slide_count + round_num  +1\n",
    "        new_order.append(potential_slide_index)\n",
    "        \n",
    "    if round_num < sourcing_slide_count:\n",
    "        sourcing_slide_index = ranking_slide_count + potential_slide_count + summary_slide_count + round_num +1\n",
    "        new_order.append(sourcing_slide_index)\n",
    "\n",
    "print(f\"New slide order (1-based): {new_order}\")\n",
    "def reorder_slides_in_place(presentation, new_order):\n",
    "    total_slides = presentation.Slides.Count\n",
    "    \n",
    "    slides_temp = []\n",
    "    \n",
    "    for slide_index in new_order:\n",
    "        if slide_index <= total_slides:\n",
    "            original_slide = presentation.Slides(slide_index)\n",
    "            original_slide.Copy()\n",
    "            time.sleep(0.5) \n",
    "            new_slide = presentation.Slides.Paste(presentation.Slides.Count + 1)\n",
    "            slides_temp.append(new_slide)\n",
    "    \n",
    "    for i in range(total_slides, 0, -1):\n",
    "        presentation.Slides(i).Delete()\n",
    "    \n",
    "    print(f\"Reordered {len(slides_temp)} slides successfully\")\n",
    "    return presentation\n",
    "\n",
    "# Reorder the slides\n",
    "presentation = reorder_slides_in_place(presentation, new_order)\n",
    "\n",
    "reordered_outputPath = os.getcwd() + \"\\\\Innovation CBC \"+market+\" reordered output \"+today+\".pptx\"\n",
    "def remove_all_sections(presentation):\n",
    "    try:\n",
    "        section_count = presentation.SectionProperties.Count\n",
    "        print(f\"Removing {section_count} sections...\")\n",
    "        for i in range(section_count, 0, -1):\n",
    "            presentation.SectionProperties.Delete(i, False)  # False = keep slides\n",
    "        print(\"All sections removed.\")\n",
    "        return presentation\n",
    "    except Exception as e:\n",
    "        print(f\"Error removing sections: {e}\")\n",
    "\n",
    "presentation = remove_all_sections(presentation)\n",
    "\n",
    "# Add Section names\n",
    "for i, key in enumerate(dfDicSplit):\n",
    "    print(i)\n",
    "    print(key)\n",
    "    presentation.SectionProperties.AddBeforeSlide(i*4+1,key)\n",
    "\n",
    "presentation.SaveAs(reordered_outputPath)\n",
    "\n",
    "\n",
    "print(f\"Reordered presentation saved as: {reordered_outputPath}\")\n",
    "print(\"Slide reordering complete! All formatting preserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
