{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"..\\general_functions\\generalFunctions.ipynb\"\n",
    "%run \"..\\Innovation CBC Slide Duplicate\\Innovation CBC Replacement Function.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = r\"C:\\Users\\Salma Hany\\Documents\\Slide-Automate\\Innovation CBC Slide Duplicate\\Carrefour inno data.xlsx\"\n",
    "data_source = \"DATA SOURCE: Consumer Test | April 2025\"\n",
    "market='Carrefour'\n",
    "sheet_name1='Performance'\n",
    "sheet_name2='Ranking'\n",
    "wdtext=\"WD assumption = Sector Avg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data in Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.read_excel(filePath,'Performance').rename(columns={'Unnamed: 2': 'Product', 'Unnamed: 3': 'ProductSize'})\n",
    "rank = pd.read_excel(filePath,'Ranking')\n",
    "sourcing = pd.read_excel(filePath,\"Sourcing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfSlides=performance.Grouping.value_counts().reset_index()\n",
    "numberOfSlides['Count']=numberOfSlides['count'].apply(lambda x : 1 if x<=5 else ((x//5) +( 0 if x%5 ==0 else 1)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnName = performance.groupby('Grouping')['Sheets names'].unique().reset_index()\n",
    "\n",
    "# Find the first column name matching the pattern 'New ... share'\n",
    "share_cols = [col for col in rank.columns if re.match(r'^New .* Share$', col, re.IGNORECASE)]\n",
    "if share_cols:\n",
    "    col = share_cols[0]  # use the first match\n",
    "    # print(col)\n",
    "    dfDic = {\n",
    "        columnName['Grouping'].iloc[i]: rank[[col] + list(columnName['Sheets names'].iloc[i])]\n",
    "        for i in range(columnName.shape[0])}\n",
    "   \n",
    "# Initializing an empty dictionary to store split DataFrames\n",
    "dfDicSplit = {}\n",
    "\n",
    "# Column name to be prioritized in the final DataFrames\n",
    "# col = 'New volume share'\n",
    "\n",
    "    \n",
    "# Iterating over each key-value pair in dfDic\n",
    "for key, value in dfDic.items():\n",
    "    # Checking if the number of columns (excluding 'New volume share') is greater than 5\n",
    "    if value.shape[1] - 1 > 5:\n",
    "        numOfColumns = 0\n",
    "        # Splitting the DataFrame into chunks of 5 columns if there are more than 5 columns\n",
    "        while numOfColumns < value.shape[1] - 1:\n",
    "            print('split number = ', numOfColumns)\n",
    "            # Creating a new DataFrame with the next set of 5 columns\n",
    "            dfDicSplit[key + '_Num ' + str(numOfColumns)] = value.iloc[:, numOfColumns + 1:numOfColumns + 6]\n",
    "            # Adding the 'New volume share' column to the new DataFrame\n",
    "            dfDicSplit[key + '_Num ' + str(numOfColumns)][col] = value[col]\n",
    "            # Reordering columns to place 'New volume share' at the front\n",
    "            columns_order = [col] + [cl for cl in dfDicSplit[key + '_Num ' + str(numOfColumns)].columns if cl != col]\n",
    "            dfDicSplit[key + '_Num ' + str(numOfColumns)] = dfDicSplit[key + '_Num ' + str(numOfColumns)].reindex(columns=columns_order)\n",
    "            numOfColumns += 5\n",
    "    else:\n",
    "        # If the number of columns (excluding 'New volume share') is 5 or fewer, add the DataFrame as is to dfDicSplit\n",
    "        dfDicSplit[key] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Advanced Protection': 1,\n",
       " 'Baby': 1,\n",
       " 'Beautycare': 4,\n",
       " 'Kids': 1,\n",
       " 'Ozono': 3,\n",
       " 'Silk Hydration': 3,\n",
       " 'Sport': 4}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dictionary to store the count of columns (excluding 'New volume share' and the 'Grouping' column)\n",
    "# for each DataFrame in dfDicSplit\n",
    "duplicationList={key:value.shape[1]-1 for key,value in dfDicSplit.items()}\n",
    "duplicationList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the 'performance' DataFrame by the 'Grouping' column and aggregating 'Sheets names' and 'Product' into lists\n",
    "grouped = performance.groupby('Grouping')[['Sheets names', 'Product']].agg(list)\n",
    "\n",
    "# Creating a dictionary where each key is a 'Grouping' value and each value is a dictionary \n",
    "# with 'Sheets names' as keys and 'Product' as values\n",
    "result = grouped.apply(lambda x: dict(zip(x['Sheets names'], x['Product'])), axis=1).to_dict()\n",
    "\n",
    "# Initializing an empty list to store the number of products minus one for each grouping\n",
    "sum_list = []\n",
    "\n",
    "# Iterating over each inner dictionary in the result dictionary\n",
    "for inner_dict in result.values():\n",
    "    # Calculating the number of products for the current grouping\n",
    "    inner_sum = len(inner_dict.values())\n",
    "    # Appending the number of products minus one to sum_list\n",
    "    sum_list.append(inner_sum - 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplication Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 4, 1, 3, 3, 4]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(duplicationList.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "startIndex=8\n",
    "index = [0,list(duplicationList.values()),7,[i+startIndex for i in sum_list]]\n",
    "duplication = [1,1,performance.Grouping.nunique(),1]\n",
    "section_names = [\"Innovation Summary\",\"Innovation ranking\",\"Innovation potential\",\"Innovation sourcing\"]\n",
    "\n",
    "path = os.getcwd() + '//Inno CBC base Oct 2024.pptx'\n",
    "new_pre = os.getcwd() + '//slide duplicated.pptx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "4\n",
      "[0, [1, 1, 4, 1, 3, 3, 4], 7, [8, 8, 11, 8, 10, 10, 11]]\n",
      "[1, 1, 7, 1]\n",
      "['Innovation Summary', 'Innovation ranking', 'Innovation potential', 'Innovation sourcing']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(index))\n",
    "print(len(duplication))\n",
    "print(len(section_names))\n",
    "print(index)\n",
    "print(duplication)\n",
    "print(section_names)\n",
    "print(sum(duplication))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shouldn't be hased in the first run\n",
    "slideDuplication(index,duplication,section_names,path,new_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = Presentation(new_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_position(end):\n",
    "    return sum(duplication[i] * (1 if isinstance(index[i], int) else len(index[i])) for i in range(end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0\n",
    "Innovation_Summary(prs, performance,numOfDuplicates=duplication[p], position=calculate_position(p))\n",
    "p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced Protection\n",
      "Baby\n",
      "Beautycare\n",
      "Kids\n",
      "Ozono\n",
      "Silk Hydration\n",
      "Sport\n"
     ]
    }
   ],
   "source": [
    "numOfDuplicatesFirstSlide = len(list(duplicationList.values())) * duplication[p]\n",
    "\n",
    "innovationRanking(prs,dfDicSplit,performance,numOfDuplicates=numOfDuplicatesFirstSlide,position=calculate_position(p))\n",
    "p+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positionOfSecondSlide = numOfDuplicatesFirstSlide \n",
    "innovationPotential(prs,performance, wdtext,numOfDuplicates = duplication[p],position=calculate_position(p))\n",
    "p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def innovationSourcing(prs, performance, sourcing, result, sumlist, numOfDuplicates, position=0):\n",
    "    \"\"\"\n",
    "    Updates PowerPoint slides with sourcing analysis based on provided data.\n",
    "\n",
    "    Parameters:\n",
    "    prs (Presentation): PowerPoint presentation object.\n",
    "    performance (DataFrame): DataFrame containing performance data.\n",
    "    sourcing (DataFrame): DataFrame containing sourcing data.\n",
    "    result (dict): Dictionary mapping groups to products.\n",
    "    sumlist (list): List of sums indicating the number of products per group.\n",
    "    numOfDuplicates (int): Number of duplicates to process.\n",
    "    position (int, optional): Starting position of the slide to update. Default is 0.\n",
    "    \"\"\"\n",
    "    for group, slide_num in zip(result, range(len(sumlist))):\n",
    "        # Access the slide based on the current position and slide number\n",
    "        slide = prs.slides[slide_num + position]\n",
    "        shapes = slide.shapes\n",
    "        tables, charts = createTableAndChart(shapes)\n",
    "        \n",
    "        # Define the market and update the title and data source text\n",
    "        titleNumber = get_shape_number(shapes, \"Innovation | Sourcing Analysis | Rescaled Delta Share by Product | Panda | Cookies'n Creme innovation\")\n",
    "        dataSourceNumber = get_shape_number(shapes, \"DATA SOURCE: Consumer Test | Dec 2023\")\n",
    "        shapes[dataSourceNumber-1].text = data_source\n",
    "        shapes[titleNumber].text = shapes[titleNumber].text.replace('Panda', market).replace(\"Cookies'n Creme innovation\", group)\n",
    "        shapes[titleNumber].text_frame.paragraphs[0].font.size = Pt(12)\n",
    "        shapes[titleNumber].text_frame.paragraphs[0].font.name = 'Nexa Bold (Headings)'\n",
    "\n",
    "        # Prepare the DataFrame for chart data\n",
    "        # print(sourcing.columns)\n",
    "        new = sourcing[['Rescaled share diff'] + list(result[group].keys())]\n",
    "        new['sum'] = new[list(result[group].keys())].apply(lambda x: sum(x), axis=1)\n",
    "        new_sorted = new.sort_values(by='sum', ascending=True).iloc[:11]\n",
    "\n",
    "        # Update the charts with new data\n",
    "        for i, (key, value) in zip(range(len(list(result[group].keys()))), result[group].items()):\n",
    "\n",
    "            chart_data = CategoryChartData()\n",
    "            chart_data.categories = new_sorted['Rescaled share diff']\n",
    "            chart_data.add_series(value, new_sorted.iloc[:, i+1] * -1)\n",
    "            charts[i].chart.replace_data(chart_data)\n",
    "\n",
    "        # Update the table with new data\n",
    "        for row_number, row in enumerate(tables[0].table.rows, start=0):\n",
    "            for column_num, cell in enumerate(row.cells):\n",
    "                if row_number == 0 and column_num > 0:\n",
    "                    # Update the header row with product names\n",
    "                    value = list(result[group].values())[column_num - 1]\n",
    "                    cell.text = str(value)\n",
    "                    cell.text_frame.paragraphs[0].runs[0].font.size = Pt(8)\n",
    "                    cell.text_frame.paragraphs[0].runs[0].font.bold = False\n",
    "                    cell.text_frame.paragraphs[0].font.name = 'Nexa Bold'\n",
    "                    cell.text_frame.paragraphs[0].runs[0].font.color.rgb = RGBColor(87, 85, 85)\n",
    "                if row_number > 0 and column_num == 0:\n",
    "                    # Update the first column with Rescaled share diff values\n",
    "                    value = new_sorted.iloc[row_number - 1, column_num]\n",
    "                    cell.text = str(value)\n",
    "                    cell.text_frame.paragraphs[0].alignment = PP_ALIGN.LEFT\n",
    "                    cell.text_frame.paragraphs[0].runs[0].font.size = Pt(7)\n",
    "                    cell.text_frame.paragraphs[0].runs[0].font.bold = False\n",
    "                    cell.text_frame.paragraphs[0].font.name = 'Nexa Book'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numOfDuplicatesThirdSlide = numOfDuplicatesFirstSlide + duplication[1]\n",
    "# numOfDuplicatesThirdSlide = len(list(sum_list)) * duplication[2]\n",
    "# positionOfThirdSlide = positionOfSecondSlide + duplication[1]\n",
    "innovationSourcing(prs,performance, sourcing,result, sum_list, numOfDuplicates = duplication[p], position=calculate_position(p))\n",
    "p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = str(date.today())\n",
    "outputPath=os.getcwd() + \"\\\\Innovation CBC \"+market+\" output \"+today+\".pptx\"\n",
    "prs.save(outputPath)\n",
    "app = win32.Dispatch(\"PowerPoint.Application\")\n",
    "presentation = app.Presentations.Open(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
