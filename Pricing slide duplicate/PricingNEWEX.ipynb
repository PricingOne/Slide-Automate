{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8130bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import adodbapi\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d77d233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provider=MSOLAP.8;Data Source=powerbi://api.powerbi.com/v1.0/myorg/Groupe Bel;Initial Catalog=Bel France Dataset;Timeout=900;\n"
     ]
    }
   ],
   "source": [
    "client_manuf =[\"Bel\"]\n",
    "client_brands = [\"Kiri\",\"La Vache Qui Rit\",\"Boursin\"]\n",
    "\n",
    "decimals = 2\n",
    "sign = \"After\"\n",
    "currency = 'â‚¬'\n",
    "currency = ' '+ currency if sign.lower() == 'after' else  currency + ' '\n",
    "\n",
    "prodORitem = \"Business Name\"\n",
    "categories = [\"Total Fromage\"]\n",
    "sectors = [\"Soft Cheese\",\"Aperitif\"]\n",
    "segments = [\"Enfant\",\"Frais A Tartiner\",\"Salade\"]\n",
    "subsegments= []\n",
    "subcategories= []\n",
    "\n",
    "national = True\n",
    "customareas= \"\"\n",
    "areas = [\"NATIONAL\",\"RETAILER\"]\n",
    " \n",
    "regions_RET  = [\"Carrefour\",\"Intermarche\"]\n",
    "channels_RET = []\n",
    "market_RET = []\n",
    " \n",
    "regions_CHAN = []\n",
    "channels_CHAN = []\n",
    "market_CHAN = []\n",
    " \n",
    "regions_CUST = []\n",
    "channels_CUST = []\n",
    "market_CUST = []\n",
    " \n",
    "regions_REG =[]\n",
    "channels_REG = []\n",
    "market_REG= []\n",
    "\n",
    "data_source = \"DATA SOURCE: Trade Panel/Retailer Data | July 2025\"\n",
    "years = ['2023','2024', \"2025\"]\n",
    " \n",
    "ManufOrTopC =\"Top Companies\"\n",
    "BrandOrTopB = \"Top Brands\"\n",
    "end_date = \"2025-08-01\"\n",
    "\n",
    "past_12_months = pd.date_range(end=end_date, periods=12, freq='ME').strftime('%b-%y').tolist()\n",
    "past_3_months = pd.date_range(end=end_date, periods=3, freq='ME').strftime('%b-%y').tolist()\n",
    "past_6_months= pd.date_range(end=end_date, periods=6, freq='ME').strftime('%b-%y').tolist()\n",
    "past_36_months = pd.date_range(end=end_date, periods=36, freq='ME').strftime('%b-%y').tolist()\n",
    "\n",
    "National= [\"NATIONAL\"] if national else []\n",
    "regions = regions_RET + regions_CHAN + regions_CUST\n",
    "channels = channels_RET + channels_CHAN + channels_CUST\n",
    "markets = market_RET + market_CHAN + market_CUST\n",
    "brands_only = True  # Get the Data of SKU Share by brands level only\n",
    "\n",
    "\n",
    "entity_hierarchy = [\n",
    "    (\"Area\",\"NATIONAL\",National),\n",
    "    (\"Region\", \"RETAILER\", regions_RET),\n",
    "    (\"Channel\", \"RETAILER\", channels_RET),\n",
    "    (\"Market\", \"RETAILER\",  market_RET),\n",
    "    (\"Region\", \"CHANNEL\",regions_CHAN),\n",
    "    (\"Channel\", \"CHANNEL\",channels_CHAN),\n",
    "    (\"Market\", \"CHANNEL\",market_CHAN),\n",
    "   (\"Region\", \"REGION\",regions_REG),\n",
    "   (\"Channel\",\"REGION\",channels_REG),\n",
    "   (\"Market\",\"REGION\", market_REG),\n",
    "   (\"Region\",customareas, regions_CUST),\n",
    "    (\"Channel\", customareas, channels_CUST),\n",
    "    (\"Market\", customareas, market_CUST)\n",
    "]\n",
    "\n",
    "hierarchy_levels = [\n",
    "    (\"Category\", categories),\n",
    "    (\"Sector\", sectors),\n",
    "    (\"Segment\", segments)\n",
    "    \n",
    " \n",
    "]\n",
    "direct_parent = {\"Sector\":\"Category\",\n",
    "                \"Segment\":\"Sector\"}\n",
    "                \n",
    "\n",
    "server = \"powerbi://api.powerbi.com/v1.0/myorg/Groupe Bel\"\n",
    "dataset_name = \"Bel France Dataset\"\n",
    "\n",
    "p12m_dax = \"{\" + \", \".join(f'\"{date}\"' for date in past_12_months) + \"}\"\n",
    "p3m_dax = \"{\" + \", \".join(f'\"{date}\"' for date in past_3_months) + \"}\"\n",
    "P6m_dax = \"{\" + \", \".join(f'\"{date}\"' for date in past_6_months) + \"}\"\n",
    "p36m_dax = \"{\" + \", \".join(f'\"{date}\"' for date in past_36_months) + \"}\"\n",
    "\n",
    "slides_Period=\"P3M\"\n",
    "period=p12m_dax if slides_Period==\"P12M\" else p3m_dax if slides_Period==\"P3M\" else P6m_dax if slides_Period==\"P6M\" else p36m_dax\n",
    "\n",
    "path=os.path.join(os.getcwd(),\"Pricing Datasets NewEX\")\n",
    "conn_str = f\"Provider=MSOLAP.8;Data Source={server};Initial Catalog={dataset_name};Timeout=900;\"\n",
    "print(conn_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e9bcad",
   "metadata": {},
   "source": [
    "## Price Positioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e63c9c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "All DataFrames saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_positioning_brands.pkl.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "All DataFrames saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_positioning_manuf.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(BrandorManuf,entity_name,entity_type, mkt, area, hierby):\n",
    "    outputdic = {}\n",
    "    key =  f\"{entity_type} | {entity_name}\"\n",
    "\n",
    "\n",
    "    columns = [\n",
    "        \"Relative Price\",'Av Price/Unit','Value Sales','Value Share','Value Share DYA','Av Price/KG','IYA Price/KG'\n",
    "    ]\n",
    "    \n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    # Main query\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(\n",
    "                    Products,\n",
    "                    Products[{BrandorManuf}]\n",
    "                ),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({period}, Calendar[MonthYear]),\n",
    "            Products[{hierby}] = \"{entity_type}\",\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    # Grand total query (not grouped by BrandOrTopB, just Category)\n",
    "    grandtotal_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                VALUES(Products[Category]),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({period}, Calendar[MonthYear]),\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "        )\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "            \n",
    "\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(grandtotal_query)\n",
    "            grandtotal_columns = [desc[0] for desc in cursor.description]\n",
    "            grandtotal_data = cursor.fetchall()\n",
    "            \n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)         \n",
    "            df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "\n",
    "            grand_tot = pd.DataFrame(grandtotal_data, columns=grandtotal_columns)\n",
    "            \n",
    "            grand_tot.columns = grand_tot.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "            grand_tot = grand_tot.loc[~(grand_tot.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "\n",
    "            grand_tot[df.columns[0]] = 'Grand Total'\n",
    "\n",
    "            # Reorder columns if necessary\n",
    "            grand_tot = grand_tot[df.columns]\n",
    "            \n",
    "            \n",
    "\n",
    "            # Concatenate the two\n",
    "\n",
    "            df = pd.concat([df, grand_tot], ignore_index=True)\n",
    "            outputdic[key] = df  \n",
    "\n",
    "            \n",
    "            print(f\"Query executed successfully for {entity_name}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {mkt}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {mkt}: {e}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "\n",
    "def process_dax_queries(BrandorManuf,entity_hierarchy, hierarchy_levels):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        dfs_results = {} \n",
    "        futures = {}\n",
    "        ordered_keys=[]\n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "            if isinstance(hier_values, list):\n",
    "                for value in hier_values:\n",
    "                    for mkt, area, entity_list in entity_hierarchy:\n",
    "                        for entity in entity_list:\n",
    "                            # print(hierby,value,entity)                                    \n",
    "                            key = f\"{value} | {entity}\"\n",
    "                            ordered_keys.append(key)\n",
    "                            future = executor.submit(execute_dax_query,BrandorManuf, entity,value,mkt, area, hierby)\n",
    "                            futures[future] = key\n",
    "       \n",
    "        temp_results = {}\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            temp_results.update(result)\n",
    "\n",
    "        # Insert results in original order\n",
    "        for key in ordered_keys:\n",
    "            if key in temp_results:\n",
    "                dfs_results[key] = temp_results[key]\n",
    "        if BrandorManuf==f'{BrandOrTopB}':\n",
    "            filename =  f\"price_positioning_brands.pkl\"\n",
    "        else:\n",
    "            filename =  f\"price_positioning_manuf.pkl\"\n",
    "        output_file = f\"{path}\\\\{filename}\"\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            pd.to_pickle(dfs_results, f)\n",
    "        \n",
    "        print(f\"All DataFrames saved to {output_file}.\")\n",
    "\n",
    "process_dax_queries(f'{BrandOrTopB}',entity_hierarchy,hierarchy_levels) \n",
    "process_dax_queries(f'{ManufOrTopC}',entity_hierarchy,hierarchy_levels) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4fc172",
   "metadata": {},
   "source": [
    "## Sector/Segment/SubSegment Leaderships (SINGLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25e87c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "All DataFrames for Category saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\Category_leadership.pkl.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "All DataFrames for Sector saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\Sector_leadership.pkl.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "All DataFrames for Segment saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\Segment_leadership.pkl.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "All DataFrames for Category saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\Category_total_leadership.pkl.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "All DataFrames for Sector saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\Sector_total_leadership.pkl.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "All DataFrames for Segment saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\Segment_total_leadership.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(entity_name, mkt, area, hierby, client, total=True):\n",
    "    outputdic = {}\n",
    "    key = f\"{client} | {entity_name}\" if client else f\"{entity_name}\"\n",
    "\n",
    "    \n",
    "    columns = [\n",
    "        \"Value Share\", \"Value Sales\", \"Av Price/KG\", \"WoB %\", \"Gross Margin %\"\n",
    "    ]\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    # Prepare client brand filter conditionally\n",
    "    client_filter = \"\"\n",
    "    if not total and client:\n",
    "        client_filter = f'''\n",
    "            FILTER(\n",
    "                Products,\n",
    "                Products[{BrandOrTopB}] = \"{client}\"\n",
    "            ),\n",
    "        '''\n",
    "\n",
    "    # Main query\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(\n",
    "                    Products,\n",
    "                    Products[{hierby}]\n",
    "                ),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({period}, Calendar[MonthYear]),\n",
    "            {client_filter}\n",
    "            TREATAS({{ \"{entity_name}\" }}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"Category\")\n",
    "        )\n",
    "    \"\"\"\n",
    "    # Grand total query\n",
    "    grandtotal_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                VALUES(Products[Category]),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({period}, Calendar[MonthYear]),\n",
    "            {client_filter}\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{mkt}])\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns_result = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "\n",
    "\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(grandtotal_query)\n",
    "            grandtotal_columns = [desc[0] for desc in cursor.description]\n",
    "            grandtotal_data = cursor.fetchall()\n",
    "\n",
    "        df = pd.DataFrame(data, columns=columns_result)\n",
    "        df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "        df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]\n",
    "\n",
    "        grand_tot = pd.DataFrame(grandtotal_data, columns=grandtotal_columns)\n",
    "        grand_tot.columns = grand_tot.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "        grand_tot = grand_tot.loc[~(grand_tot.select_dtypes(include='number') == 0).all(axis=1)]\n",
    "        grand_tot[df.columns[0]] = 'Grand Total'\n",
    "        grand_tot = grand_tot[df.columns]\n",
    "        df = pd.concat([df, grand_tot], ignore_index=True)\n",
    "        outputdic[key] = df\n",
    "\n",
    "        print(f\"Query executed successfully for {entity_name}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {mkt}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {mkt}: {e}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "def process_dax_queries(entity_hierarchy, hierarchy_levels, client_brands=None, total=False):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        \n",
    "        dfs_results = {} \n",
    "        futures = {}\n",
    "        ordered_keys = []\n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "            if isinstance(hier_values, list):\n",
    "                if client_brands: \n",
    "                    for mkt, area, entity_list in entity_hierarchy:\n",
    "                        for entity in entity_list:\n",
    "                            for client in client_brands:\n",
    "                                key = f\"{client} | {entity}\"\n",
    "                                ordered_keys.append(key)\n",
    "                                future = executor.submit(\n",
    "                                    execute_dax_query, entity, mkt, area, hierby, client, total\n",
    "                                )\n",
    "                                futures[future] = key\n",
    "                else:\n",
    "                    for mkt, area, entity_list in entity_hierarchy:\n",
    "                        for entity in entity_list:\n",
    "                            key = f\"{entity}\"\n",
    "                            ordered_keys.append(key)\n",
    "                            future = executor.submit(\n",
    "                                execute_dax_query, entity, mkt, area, hierby, '', total\n",
    "                            )\n",
    "                            futures[future] = key\n",
    "\n",
    "            temp_results = {}\n",
    "            for future in as_completed(futures):\n",
    "                result = future.result()\n",
    "                temp_results.update(result)\n",
    "\n",
    "            for key in ordered_keys:\n",
    "                if key in temp_results:\n",
    "                    dfs_results[key] = temp_results[key]\n",
    "\n",
    "            if client_brands:\n",
    "                filename = f\"{hierby}_leadership.pkl\"\n",
    "            else:\n",
    "                filename = f\"{hierby}_total_leadership.pkl\"\n",
    "\n",
    "            output_file = f\"{path}\\\\{filename}\"\n",
    "            with open(output_file, \"wb\") as f:\n",
    "                pd.to_pickle(dfs_results, f)\n",
    "            \n",
    "            print(f\"All DataFrames for {hierby} saved to {output_file}.\")\n",
    "\n",
    "# Execute\n",
    "if client_brands:\n",
    "    process_dax_queries(entity_hierarchy, hierarchy_levels, client_brands=client_brands)\n",
    "\n",
    "process_dax_queries(entity_hierarchy, hierarchy_levels, total=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b263f3c8",
   "metadata": {},
   "source": [
    "## Sector/Segment Leaderships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "362fe3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "All DataFrames for Segment saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\brand_Segment.pkl.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "All DataFrames for Segment saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\manuf_Segment.pkl.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "All DataFrames for Segment saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\total_Segment.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(entity_name, mkt, area, hierby,direct_parent, client,manuf, total=False):\n",
    "    outputdic = {}\n",
    "    key = f\"{client} | {entity_name}\" if client else (f\"{manuf} | {entity_name}\" if manuf else f\"{entity_name}\")\n",
    "\n",
    "\n",
    "    columns = [\n",
    "        \"Value Share\", \"Value Sales\", \"Av Price/KG\", \"WoB %\", \"Gross Margin %\"\n",
    "    ]\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    # Prepare client brand filter conditionally\n",
    "    client_filter = \"\"\n",
    "    if not total and client:\n",
    "        client_filter = f'''\n",
    "            FILTER(\n",
    "                Products,\n",
    "                Products[{BrandOrTopB}] = \"{client}\"\n",
    "            ),\n",
    "        '''    \n",
    "    manuf_filter=''\n",
    "    if not total and manuf:\n",
    "        manuf_filter = f'''\n",
    "            FILTER(\n",
    "                Products,\n",
    "                Products[{ManufOrTopC}] = \"{manuf}\"\n",
    "            ),\n",
    "        '''\n",
    "\n",
    "    # Main query\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(\n",
    "                    Products,\n",
    "                    Products[{direct_parent[hierby]}],\n",
    "                    Products[{hierby}]\n",
    "                    \n",
    "                ),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({period}, Calendar[MonthYear]),\n",
    "            {client_filter}\n",
    "            {manuf_filter}\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"Category\")\n",
    "        )\n",
    "    \"\"\"\n",
    "    parenttotal_dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(\n",
    "                    Products,\n",
    "                    Products[{direct_parent[hierby]}]                   \n",
    "                ),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({period}, Calendar[MonthYear]),\n",
    "            {client_filter}\n",
    "            {manuf_filter}\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"Category\")\n",
    "        )\n",
    "    \"\"\"\n",
    "        # Grand total query\n",
    "    grandtotal_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                VALUES(Products[Category]),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({period}, Calendar[MonthYear]),\n",
    "            {client_filter}\n",
    "            {manuf_filter}\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{mkt}])\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns_result = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(parenttotal_dax_query)\n",
    "            maintotal_columns = [desc[0] for desc in cursor.description]\n",
    "            maintotal_data = cursor.fetchall()\n",
    "            \n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(grandtotal_query)\n",
    "            grandtotal_columns = [desc[0] for desc in cursor.description]\n",
    "            grandtotal_data = cursor.fetchall()\n",
    "\n",
    "        df = pd.DataFrame(data, columns=columns_result)\n",
    "        df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "        df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]\n",
    "        maintotal_df = pd.DataFrame(maintotal_data, columns=maintotal_columns)\n",
    "        maintotal_df.columns = maintotal_df.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "        maintotal_df = maintotal_df.loc[~(maintotal_df.select_dtypes(include='number') == 0).all(axis=1)]\n",
    "        \n",
    "        grand_tot = pd.DataFrame(grandtotal_data, columns=grandtotal_columns)\n",
    "        grand_tot.columns = grand_tot.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "        grand_tot = grand_tot.loc[~(grand_tot.select_dtypes(include='number') == 0).all(axis=1)]\n",
    "        \n",
    "        if maintotal_df.shape[1] > 1:\n",
    "            maintotal_df.iloc[:, 0] = maintotal_df.iloc[:, 0].astype(str) + \" Total\"\n",
    "\n",
    "        if maintotal_df.empty:\n",
    "            outputdic[key] = maintotal_df\n",
    "            return outputdic\n",
    "        if not maintotal_df.empty:\n",
    "            df_with_totals = pd.concat([df,maintotal_df], ignore_index=True)\n",
    "    \n",
    "        if not grand_tot.empty:\n",
    "            # Create a dict for the first two columns\n",
    "            grand_tot[df.columns[0]] = 'Grand Total'\n",
    "            grand_tot[df.columns[1]] = np.nan  # or pd.NA\n",
    "\n",
    "            # Ensure all required columns exist, fill missing ones with NaN\n",
    "            for col in df.columns:\n",
    "                if col not in grand_tot.columns:\n",
    "                    grand_tot[col] = np.nan\n",
    "\n",
    "            # Reorder columns exactly as in df\n",
    "            grand_tot = grand_tot[df.columns]\n",
    "            df = pd.concat([df_with_totals, grand_tot], ignore_index=True)\n",
    "\n",
    "        outputdic[key] = df\n",
    "\n",
    "        print(f\"Query executed successfully for {entity_name}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {mkt}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {mkt}: {e}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "def process_dax_queries(entity_hierarchy, hierarchy_levels,direct_parent, client_brands=None,client_manuf=None, total=False):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        dfs_results = {} \n",
    "        futures = {}\n",
    "        ordered_keys = []\n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "            if hierby == \"Category\" or direct_parent[hierby]==\"Category\":\n",
    "                    continue\n",
    "            if isinstance(hier_values, list):\n",
    "                if client_brands and not total: \n",
    "                    for mkt, area, entity_list in entity_hierarchy:\n",
    "                        for entity in entity_list:\n",
    "                            for client in client_brands:\n",
    "                                key = f\"{client} | {entity}\"\n",
    "                                ordered_keys.append(key)\n",
    "                                future = executor.submit(\n",
    "                                    execute_dax_query, entity, mkt, area, hierby,direct_parent, client,'', ''\n",
    "                                )\n",
    "                                futures[future] = key\n",
    "                if client_manuf and not total:\n",
    "                    for mkt, area, entity_list in entity_hierarchy:\n",
    "                        for entity in entity_list:\n",
    "                            for manuf in client_manuf:\n",
    "                                key = f\"{manuf} | {entity}\"\n",
    "                                ordered_keys.append(key)\n",
    "                                future = executor.submit(\n",
    "                                    execute_dax_query, entity, mkt, area, hierby,direct_parent, '',manuf,''\n",
    "                                )\n",
    "                                futures[future] = key               \n",
    "                elif total==True:\n",
    "                    for mkt, area, entity_list in entity_hierarchy:\n",
    "                        for entity in entity_list:\n",
    "                            key = f\"{entity}\"\n",
    "                            ordered_keys.append(key)\n",
    "                            future = executor.submit(\n",
    "                                execute_dax_query, entity, mkt, area, hierby, direct_parent,'','', total\n",
    "                            )\n",
    "                            futures[future] = key\n",
    "\n",
    "            temp_results = {}\n",
    "            for future in as_completed(futures):\n",
    "                result = future.result()\n",
    "                temp_results.update(result)\n",
    "\n",
    "            for key in ordered_keys:\n",
    "                if key in temp_results:\n",
    "                    dfs_results[key] = temp_results[key]\n",
    "\n",
    "            if client_brands:\n",
    "                filename = f\"brand_{hierby}.pkl\"\n",
    "            elif client_manuf:\n",
    "                filename = f\"manuf_{hierby}.pkl\"\n",
    "            else:\n",
    "                filename = f\"total_{hierby}.pkl\"\n",
    "\n",
    "            output_file = f\"{path}\\\\{filename}\"\n",
    "            with open(output_file, \"wb\") as f:\n",
    "                pd.to_pickle(dfs_results, f)\n",
    "            \n",
    "            print(f\"All DataFrames for {hierby} saved to {output_file}.\")\n",
    "\n",
    "if client_brands:\n",
    "    process_dax_queries(entity_hierarchy, hierarchy_levels,direct_parent, client_brands=client_brands)\n",
    "if client_manuf:\n",
    "    process_dax_queries(entity_hierarchy, hierarchy_levels,direct_parent, client_manuf=client_manuf)   \n",
    "process_dax_queries(entity_hierarchy, hierarchy_levels,direct_parent, total=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0800646",
   "metadata": {},
   "source": [
    "## Shelf & Avg Price / KG By Brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3eb2ca95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "All DataFrames for Sector saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\shelf_Sector_top_brands.pkl.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "All DataFrames for Segment saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\shelf_Segment_top_brands.pkl.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "All DataFrames for Sector saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\shelf_Sector_all_brands.pkl.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "All DataFrames for Segment saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\shelf_Segment_all_brands.pkl.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "All DataFrames for Sector saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\shelf_Sector_top_manuf.pkl.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "All DataFrames for Segment saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\shelf_Segment_top_manuf.pkl.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "All DataFrames for Sector saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\shelf_Sector_all_manuf.pkl.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "All DataFrames for Segment saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\shelf_Segment_all_manuf.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(manuforbrand,entity_name,entity_type, mkt, area, hierby, incall=True):\n",
    "    outputdic = {}\n",
    "    key =  f\"{entity_type} | {entity_name}\"\n",
    "    \n",
    "    if manuforbrand==f'{BrandOrTopB}':\n",
    "        columns = [\n",
    "            \"Relative Price\", \"Av Price/Unit\", \"Value Sales\", \"IYA Price/KG\", \"Base Price/KG\",\"Av Price/KG\",\"Value Share\",\"WoB %\",\"Value Share DYA\"\n",
    "        ]\n",
    "    else:\n",
    "        columns = [\"Base Price/KG\",\"Av Price/KG\",\"Value Share\",\"WoB %\",\"Value Share DYA\"]\n",
    " \n",
    "\n",
    "    \n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    " \n",
    "    # Prepare client brand filter conditionally\n",
    "    scope_filter = \"\"\n",
    "    if incall:\n",
    "        scope_filter = f'''\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"Category\"),\n",
    "            Products[{direct_parent[hierby]}] = \"{entity_type}\"\n",
    "            \n",
    "        '''\n",
    "    else:\n",
    "        scope_filter = f'''\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\"),\n",
    "            Products[{direct_parent[hierby]}] = \"{entity_type}\"\n",
    "        '''\n",
    " \n",
    "    # Main query\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(\n",
    "                    Products,\n",
    "                    Products[{hierby}],\n",
    "                    Products[{manuforbrand}]\n",
    "                ),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({period}, Calendar[MonthYear]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{mkt}]),\n",
    "            {scope_filter}\n",
    "        )\n",
    "    \"\"\"\n",
    "    parenttotal_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(\n",
    "                    Products,\n",
    "                    Products[{hierby}]\n",
    " \n",
    "                ),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({period}, Calendar[MonthYear]),\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            {scope_filter}\n",
    "        )\n",
    "    \"\"\"\n",
    "   \n",
    "    # Grand total query\n",
    "    grandtotal_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                VALUES(Products[Category]),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({period}, Calendar[MonthYear]),\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            {scope_filter}\n",
    " \n",
    "        )\n",
    "    \"\"\"\n",
    " \n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns_result = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "            \n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(parenttotal_query)\n",
    "            maintotal_columns = [desc[0] for desc in cursor.description]\n",
    "            maintotal_data = cursor.fetchall()\n",
    "            \n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(grandtotal_query)\n",
    "            grandtotal_columns = [desc[0] for desc in cursor.description]\n",
    "            grandtotal_data = cursor.fetchall()\n",
    "            \n",
    " \n",
    "        df = pd.DataFrame(data, columns=columns_result)\n",
    "        df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "        df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]\n",
    " \n",
    " \n",
    "        maintotal_df = pd.DataFrame(maintotal_data, columns=maintotal_columns)\n",
    "        maintotal_df.columns = maintotal_df.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "        maintotal_df = maintotal_df.loc[~(maintotal_df.select_dtypes(include='number') == 0).all(axis=1)]\n",
    "\n",
    "\n",
    "        grand_tot = pd.DataFrame(grandtotal_data, columns=grandtotal_columns)\n",
    "        grand_tot.columns = grand_tot.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "        grand_tot = grand_tot.loc[~(grand_tot.select_dtypes(include='number') == 0).all(axis=1)]\n",
    "\n",
    " \n",
    "        if maintotal_df.shape[1] > 1:\n",
    "            maintotal_df.iloc[:, 0] = maintotal_df.iloc[:, 0].astype(str) + \" Total\"\n",
    " \n",
    "        if maintotal_df.empty:\n",
    "            outputdic[key] = maintotal_df\n",
    "            return outputdic\n",
    "        if not maintotal_df.empty:\n",
    "            df_with_totals = pd.concat([df,maintotal_df], ignore_index=True)\n",
    " \n",
    "        if not grand_tot.empty:\n",
    "            # Ensure 'Grand Total' label is added to the first column of grand_tot\n",
    "            grand_tot[df_with_totals.columns[0]] = 'Grand Total'\n",
    " \n",
    "            # Keep only columns that exist in df_with_totals\n",
    "            common_columns = [col for col in df_with_totals.columns if col in grand_tot.columns]\n",
    "            grand_tot = grand_tot[common_columns]\n",
    " \n",
    "            # Align grand_tot with df_with_totals in case column order matters\n",
    "            grand_tot = grand_tot.reindex(columns=df_with_totals.columns)\n",
    "\n",
    "\n",
    "\n",
    "        df = pd.concat([df_with_totals, grand_tot], ignore_index=True)\n",
    "        outputdic[key] = df\n",
    " \n",
    " \n",
    "        print(f\"Query executed successfully for {entity_name}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {mkt}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {mkt}: {e}\")\n",
    " \n",
    "    return outputdic\n",
    " \n",
    " \n",
    "def process_dax_queries(manuforbrand,entity_hierarchy, hierarchy_levels, incall=False):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        hierarchy_dict = dict(hierarchy_levels)\n",
    " \n",
    "        for hierby, _ in hierarchy_levels:\n",
    "            if hierby == \"Category\":\n",
    "                continue\n",
    "                   \n",
    "            dfs_results = {}\n",
    "            futures = {}\n",
    "            ordered_keys = []\n",
    "            # Get the parent level name (e.g., 'Segment')\n",
    "            parent_level = direct_parent[hierby]\n",
    "            parent_values = hierarchy_dict.get(parent_level, [])\n",
    "            if isinstance(parent_values, list):\n",
    "                for value in parent_values:\n",
    "                    for mkt, area, entity_list in entity_hierarchy:\n",
    "                        for entity in entity_list:\n",
    "                            key = f\"{value} | {entity}\"                          \n",
    "                            ordered_keys.append(key)\n",
    "                            future = executor.submit(\n",
    "                                execute_dax_query,manuforbrand, entity, value, mkt, area, hierby,incall\n",
    "                            )\n",
    "                            futures[future] = key\n",
    "            temp_results = {}\n",
    "            for future in as_completed(futures):\n",
    "                result = future.result()\n",
    "                temp_results.update(result)\n",
    " \n",
    "            for key in ordered_keys:\n",
    "                if key in temp_results:\n",
    "                    dfs_results[key] = temp_results[key]\n",
    "            if manuforbrand==f'{BrandOrTopB}':\n",
    "                if incall==False:\n",
    "                    filename = f\"shelf_{hierby}_top_brands.pkl\"\n",
    "                else:\n",
    "                    filename = f\"shelf_{hierby}_all_brands.pkl\"\n",
    "            else:\n",
    "                if incall==False:\n",
    "                    filename = f\"shelf_{hierby}_top_manuf.pkl\"\n",
    "                else:\n",
    "                    filename = f\"shelf_{hierby}_all_manuf.pkl\"\n",
    " \n",
    "            output_file = f\"{path}\\\\{filename}\"\n",
    "            with open(output_file, \"wb\") as f:\n",
    "                pd.to_pickle(dfs_results, f)\n",
    "           \n",
    "            print(f\"All DataFrames for {hierby} saved to {output_file}.\")\n",
    " \n",
    " \n",
    " \n",
    "# Execute\n",
    "process_dax_queries(f'{BrandOrTopB}',entity_hierarchy, hierarchy_levels,incall=False)\n",
    "process_dax_queries(f'{BrandOrTopB}',entity_hierarchy, hierarchy_levels, incall=True)\n",
    "process_dax_queries(f'{ManufOrTopC}',entity_hierarchy, hierarchy_levels,incall=False)\n",
    "process_dax_queries(f'{ManufOrTopC}',entity_hierarchy, hierarchy_levels, incall=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c5b360",
   "metadata": {},
   "source": [
    "## Price Point Distribution By Product (Item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e76e696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "All DataFrames for Sector saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_distribution_Sector_p12m.pkl.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleaa\\AppData\\Local\\Temp\\ipykernel_14224\\738960321.py:118: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, maintotal_df], ignore_index=True)\n",
      "C:\\Users\\aleaa\\AppData\\Local\\Temp\\ipykernel_14224\\738960321.py:118: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, maintotal_df], ignore_index=True)\n",
      "C:\\Users\\aleaa\\AppData\\Local\\Temp\\ipykernel_14224\\738960321.py:118: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, maintotal_df], ignore_index=True)\n",
      "C:\\Users\\aleaa\\AppData\\Local\\Temp\\ipykernel_14224\\738960321.py:118: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, maintotal_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleaa\\AppData\\Local\\Temp\\ipykernel_14224\\738960321.py:118: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, maintotal_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleaa\\AppData\\Local\\Temp\\ipykernel_14224\\738960321.py:118: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, maintotal_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "All DataFrames for Segment saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_distribution_Segment_p12m.pkl.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "All DataFrames for Sector saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_distribution_Sector_p3m.pkl.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleaa\\AppData\\Local\\Temp\\ipykernel_14224\\738960321.py:118: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, maintotal_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for NATIONAL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleaa\\AppData\\Local\\Temp\\ipykernel_14224\\738960321.py:118: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, maintotal_df], ignore_index=True)\n",
      "C:\\Users\\aleaa\\AppData\\Local\\Temp\\ipykernel_14224\\738960321.py:118: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, maintotal_df], ignore_index=True)\n",
      "C:\\Users\\aleaa\\AppData\\Local\\Temp\\ipykernel_14224\\738960321.py:118: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, maintotal_df], ignore_index=True)\n",
      "C:\\Users\\aleaa\\AppData\\Local\\Temp\\ipykernel_14224\\738960321.py:118: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, maintotal_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleaa\\AppData\\Local\\Temp\\ipykernel_14224\\738960321.py:118: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, maintotal_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Intermarche.\n",
      "All DataFrames for Segment saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_distribution_Segment_p3m.pkl.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "All DataFrames for Sector saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_distribution_Sector_manuf_p12m.pkl.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "All DataFrames for Segment saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_distribution_Segment_manuf_p12m.pkl.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "All DataFrames for Sector saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_distribution_Sector_manuf_p3m.pkl.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "All DataFrames for Segment saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_distribution_Segment_manuf_p3m.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(entity_name, entity_type, mkt, area, hierby, client, manuf,p12m=True):\n",
    "    outputdic = {}\n",
    "\n",
    "    key = f\"{client} | {entity_name} | {entity_type}\" if client else f\"{manuf} | {entity_name} | {entity_type}\" \n",
    "    \n",
    "    if p12m :\n",
    "        timeper=p12m_dax\n",
    "    else:\n",
    "        timeper=p3m_dax    \n",
    "    columns = [\"Base Price/Unit\", \"Base Price/KG\", \"Value Sales\", \"Gross Margin %\"]\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "    client_filter=''\n",
    "    if client:\n",
    "        client_filter = f'''\n",
    "                FILTER(\n",
    "                    Products,\n",
    "                    Products[{BrandOrTopB}] = \"{client}\" &&\n",
    "                    Products[{ManufOrTopC}] = \"{manuf}\"\n",
    "                ),\n",
    "            '''\n",
    "   \n",
    "    manuf_filter = f'FILTER(Products, Products[{ManufOrTopC}] = \"{manuf}\"),' if manuf else \"\"\n",
    "\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(\n",
    "                    Products,\n",
    "                    Products[{hierby}],\n",
    "                    Products[{prodORitem}],\n",
    "                    Products[Total Size]\n",
    "                ),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[{direct_parent[hierby]}] = \"{entity_type}\",\n",
    "            TREATAS({timeper}, Calendar[MonthYear]),\n",
    "            {client_filter}\n",
    "            {manuf_filter}\n",
    "            TREATAS({{ \"{entity_name}\" }}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{direct_parent[hierby]}\")\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    # Parent total query\n",
    "    parenttotal_dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(Products, Products[{hierby}]),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({timeper}, Calendar[MonthYear]),\n",
    "            {client_filter}\n",
    "            {manuf_filter}\n",
    "            TREATAS({{ \"{entity_name}\" }}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"Category\")\n",
    "        )\n",
    "    \"\"\"\n",
    "    itemtotal_dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(Products,Products[{prodORitem}]),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({timeper}, Calendar[MonthYear]),\n",
    "            {client_filter}\n",
    "            {manuf_filter}\n",
    "            TREATAS({{ \"{entity_name}\" }}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"Category\")\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    grandtotal_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(VALUES(Products[Category]), {column_exprs}),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({timeper}, Calendar[MonthYear]),\n",
    "            {client_filter}\n",
    "            {manuf_filter}\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            TREATAS({{ \"{entity_name}\" }}, Market[{mkt}])\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn:\n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(dax_query)\n",
    "                df = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])\n",
    "\n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(parenttotal_dax_query)\n",
    "                maintotal_df = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])\n",
    "          \n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(itemtotal_dax_query)\n",
    "                itemtotal_df = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])\n",
    "\n",
    "\n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(grandtotal_query)\n",
    "                grand_tot = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])\n",
    "\n",
    "        for dataframe in [df,maintotal_df,itemtotal_df, grand_tot]:\n",
    "            dataframe.columns = dataframe.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "            dataframe.dropna(how='all', inplace=True)\n",
    "\n",
    "        if not maintotal_df.empty:\n",
    "            maintotal_df.iloc[:, 0] = maintotal_df.iloc[:, 0].astype(str) + \" Total\"\n",
    "            df = pd.concat([df, maintotal_df], ignore_index=True)\n",
    "      \n",
    "        if not itemtotal_df.empty:\n",
    "            itemtotal_df.iloc[:, 0] = itemtotal_df.iloc[:, 0].astype(str) + \" Total\"\n",
    "            df = pd.concat([df, itemtotal_df], ignore_index=True)\n",
    "            \n",
    "        if not grand_tot.empty:\n",
    "            grand_tot[df.columns[0]] = 'Grand Total'\n",
    "            grand_tot[df.columns[1]] = np.nan\n",
    "            grand_tot = grand_tot.reindex(columns=df.columns)\n",
    "            df = pd.concat([df, grand_tot], ignore_index=True)\n",
    "\n",
    "        outputdic[key] = df\n",
    "        print(f\"Query executed successfully for {entity_name}.\")\n",
    "\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {mkt}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {mkt}: {e}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "def process_dax_queries(entity_hierarchy, hierarchy_levels, client_brands=None, client_manuf=None,p12m=True):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "            if hierby == \"Category\":\n",
    "                continue\n",
    "\n",
    "            hierarchy_dict = dict(hierarchy_levels)\n",
    "            parent_level = direct_parent.get(hierby)\n",
    "            parent_values = hierarchy_dict.get(parent_level, [])\n",
    "\n",
    "            if not parent_values:\n",
    "                continue\n",
    "\n",
    "            futures = {}\n",
    "            ordered_keys = []\n",
    "\n",
    "            # Determine prodORitem per level\n",
    "\n",
    "            for value in parent_values:\n",
    "                for mkt, area, entity_list in entity_hierarchy:\n",
    "                    for entity in entity_list:\n",
    "                        if client_brands:\n",
    "                            for client in client_brands:\n",
    "                                for manuf in client_manuf:\n",
    "                                    key = f\"{client} | {entity} | {value}\"\n",
    "                                    ordered_keys.append(key)\n",
    "                                    futures[executor.submit(\n",
    "                                        execute_dax_query, entity, value, mkt, area, hierby, client, manuf,p12m\n",
    "                                    )] = key\n",
    "                        elif client_manuf:\n",
    "                            for manuf in client_manuf:\n",
    "                                key = f\"{manuf} | {entity} | {value}\"\n",
    "                                ordered_keys.append(key)\n",
    "                                futures[executor.submit(\n",
    "                                    execute_dax_query, entity, value, mkt, area, hierby, None, manuf, p12m\n",
    "                                )] = key\n",
    "\n",
    "            dfs_results = {}\n",
    "            for future in as_completed(futures):\n",
    "                result = future.result()\n",
    "                dfs_results.update(result)\n",
    "\n",
    "            dfs_results = {key: dfs_results[key] for key in ordered_keys if key in dfs_results}\n",
    "            if p12m:\n",
    "                 filename = f\"price_distribution_{hierby}_{'p12m' if client_brands else 'manuf_p12m'}.pkl\"\n",
    "            else:\n",
    "                 filename = f\"price_distribution_{hierby}_{'p3m' if client_brands else 'manuf_p3m'}.pkl\"\n",
    "                     \n",
    "            output_file = f\"{path}\\\\{filename}\"\n",
    "            with open(output_file, \"wb\") as f:\n",
    "                pd.to_pickle(dfs_results, f)\n",
    "            print(f\"All DataFrames for {hierby} saved to {output_file}.\")\n",
    "\n",
    "\n",
    "# Example Invocation\n",
    "if client_brands:\n",
    "    process_dax_queries(entity_hierarchy, hierarchy_levels, client_brands=client_brands,client_manuf=client_manuf,p12m=True)\n",
    "    process_dax_queries(entity_hierarchy, hierarchy_levels, client_brands=client_brands,client_manuf=client_manuf,p12m=False)\n",
    "\n",
    "process_dax_queries(entity_hierarchy, hierarchy_levels, client_manuf=client_manuf,p12m=True)\n",
    "process_dax_queries(entity_hierarchy, hierarchy_levels, client_manuf=client_manuf,p12m=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c703548",
   "metadata": {},
   "source": [
    "## Price Point Distribution By Product Scraped(Item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30616f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "All DataFrames for Sector saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_distribution_scraped_Sector.pkl.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "All DataFrames for Segment saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_distribution_scraped_Segment.pkl.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "All DataFrames for Sector saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_distribution_scraped_Sector_manuf.pkl.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "All DataFrames for Segment saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_distribution_scraped_Segment_manuf.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(entity_name,entity_type, market,area, hierby, client, manuf):\n",
    "    outputdic={}\n",
    "    key = f\"{client} | {entity_name} | {entity_type}\" if client else f\"{manuf} | {entity_name} | {entity_type}\" \n",
    "    \n",
    "    columns = [\n",
    "        \"Scraped Av. Price/Unit\", \"Scraped Av. Price/KG\"\n",
    "    ]\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "    client_filter = \"\"\n",
    "    client_filter=\"\"\n",
    "    if client:\n",
    "        client_filter = f'''\n",
    "                Products[Top Brands] = \"{client}\"&&\n",
    "                \n",
    "        '''\n",
    "    if manuf:\n",
    "        manuf_filter = f'''\n",
    "                Products[Top Companies] = \"{manuf}\"\n",
    "        '''\n",
    "        \n",
    "\n",
    "    # Main query\n",
    "    dax_query = f\"\"\"\n",
    "    EVALUATE\n",
    "    SUMMARIZECOLUMNS(   \n",
    "        Calendar[End of Week],\n",
    "        Products[{hierby}],\n",
    "        Products[{prodORitem}],\n",
    "        Products[Ean],\n",
    "        Products[Total Size],\n",
    "        FILTER(\n",
    "            Products,\n",
    "                {client_filter}\n",
    "                {manuf_filter}\n",
    "                && Products[Category] = \"{categories[0]}\"\n",
    "                && Products[{direct_parent[hierby]}] = \"{entity_type}\"\n",
    "        ),\n",
    "        FILTER('Market', 'Market'[Area] = \"{area}\"),\n",
    "        TREATAS({{ \"{entity_name}\" }}, Market[{market}]),\n",
    "        FILTER('Scope', 'Scope'[Scope] = \"{direct_parent[hierby]}\"),\n",
    "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
    "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
    "    )\n",
    "    \"\"\"\n",
    "    parenttotal_dax_query = f\"\"\"\n",
    "    EVALUATE\n",
    "    SUMMARIZECOLUMNS(   \n",
    "        Calendar[End of Week],\n",
    "        Products[{hierby}],\n",
    "\n",
    "        FILTER(\n",
    "            Products,\n",
    "                {client_filter}\n",
    "                {manuf_filter}\n",
    "                && Products[Category] = \"{categories[0]}\"\n",
    "                && Products[{direct_parent[hierby]}] = \"{entity_type}\"\n",
    "        ),\n",
    "        FILTER('Market', 'Market'[Area] = \"{area}\"),\n",
    "        TREATAS({{ \"{entity_name}\" }}, Market[{market}]),\n",
    "        FILTER('Scope', 'Scope'[Scope] = \"{direct_parent[hierby]}\"),\n",
    "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
    "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn:\n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(dax_query)\n",
    "                df = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(parenttotal_dax_query)\n",
    "            maintotal_columns = [desc[0] for desc in cursor.description]\n",
    "            maintotal_data = cursor.fetchall()\n",
    "            \n",
    "        df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "        \n",
    "        maintotal_df = pd.DataFrame(maintotal_data, columns=maintotal_columns)\n",
    "        maintotal_df.columns = maintotal_df.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "\n",
    "        if maintotal_df.shape[1] > 1:\n",
    "            maintotal_df.iloc[:, 1] = maintotal_df.iloc[:, 1].astype(str) + \" Total\"\n",
    "\n",
    "        if not maintotal_df.empty:\n",
    "            df = pd.concat([df,maintotal_df], ignore_index=True)\n",
    "\n",
    "        outputdic[key] = df\n",
    "\n",
    "        print(f\"Query executed successfully for {entity_name}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {area}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {area}: {e}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "def process_dax_queries(entity_hierarchy, hierarchy_levels, client_brands=None,client_manuf=None):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "            if hierby == \"Category\":\n",
    "                continue\n",
    "\n",
    "            hierarchy_dict = dict(hierarchy_levels)\n",
    "            parent_level = direct_parent.get(hierby)\n",
    "            parent_values = hierarchy_dict.get(parent_level, [])\n",
    "\n",
    "            if not parent_values:\n",
    "                continue\n",
    "\n",
    "            futures = {}\n",
    "            ordered_keys = []\n",
    "\n",
    "            # Determine prodORitem per level\n",
    "\n",
    "            for value in parent_values:\n",
    "                for market,area, entity_list in entity_hierarchy:\n",
    "                    for entity in entity_list:\n",
    "                        if client_brands:\n",
    "                            for client in client_brands:\n",
    "                                for manuf in client_manuf:\n",
    "                                    key = f\"{client} | {entity} | {value}\"\n",
    "                                    ordered_keys.append(key)\n",
    "                                    futures[executor.submit(\n",
    "                                        execute_dax_query, entity, value,market,area, hierby, client, manuf\n",
    "                                    )] = key\n",
    "                        elif client_manuf:\n",
    "                            for manuf in client_manuf:\n",
    "                                key = f\"{manuf} | {entity} | {value}\"\n",
    "                                ordered_keys.append(key)\n",
    "                                futures[executor.submit(\n",
    "                                    execute_dax_query, entity, value, market,area, hierby, None, manuf\n",
    "                                )] = key\n",
    "\n",
    "            dfs_results = {}\n",
    "            for future in as_completed(futures):\n",
    "                result = future.result()\n",
    "                dfs_results.update(result)\n",
    "\n",
    "            dfs_results = {key: dfs_results[key] for key in ordered_keys if key in dfs_results}\n",
    "\n",
    "            if client_brands:\n",
    "                filename = f\"price_distribution_scraped_{hierby}.pkl\"\n",
    "            else:\n",
    "                filename = f\"price_distribution_scraped_{hierby}_manuf.pkl\"\n",
    "\n",
    "\n",
    "            output_file = f\"{path}\\\\{filename}\"\n",
    "            with open(output_file, \"wb\") as f:\n",
    "                pd.to_pickle(dfs_results, f)\n",
    "            \n",
    "            print(f\"All DataFrames for {hierby} saved to {output_file}.\")\n",
    "\n",
    "if client_brands:\n",
    "    process_dax_queries(entity_hierarchy, hierarchy_levels, client_brands=client_brands,client_manuf=client_manuf)\n",
    "if client_manuf:\n",
    "    process_dax_queries(entity_hierarchy, hierarchy_levels, client_manuf=client_manuf)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b3ddea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "All DataFrames for Sector saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_distribution_scraped_Sector_Ean.pkl.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "All DataFrames for Segment saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_distribution_scraped_Segment_Ean.pkl.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "All DataFrames for Sector saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_distribution_scraped_Sector_Ean_manuf.pkl.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "All DataFrames for Segment saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_distribution_scraped_Segment_Ean_manuf.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(entity_name,entity_type,market,area, hierby, client, manuf):\n",
    "    outputdic={}\n",
    "    key = f\"{client} | {entity_name} | {entity_type}\" if client else f\"{manuf} | {entity_name} | {entity_type}\" \n",
    "    \n",
    "    columns = [\n",
    "        \"Value Sales\"\n",
    "    ]\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "    client_filter = \"\"\n",
    "    client_filter=\"\"\n",
    "    if client:\n",
    "        client_filter = f'''\n",
    "                Products[Top Brands] = \"{client}\"&&\n",
    "                \n",
    "        '''\n",
    "    if manuf:\n",
    "        manuf_filter = f'''\n",
    "                Products[Top Companies] = \"{manuf}\"\n",
    "        '''\n",
    "        \n",
    "\n",
    "    # Main query\n",
    "    dax_query = f\"\"\"\n",
    "    EVALUATE\n",
    "    SUMMARIZECOLUMNS(  \n",
    "        Products[Ean],\n",
    "   \n",
    "        FILTER(\n",
    "            Products,\n",
    "                {client_filter}\n",
    "                {manuf_filter}\n",
    "                && Products[{direct_parent[hierby]}] = \"{entity_type}\"\n",
    "        ),\n",
    "        FILTER('Market', 'Market'[Area] = \"{area}\"),\n",
    "        TREATAS({{ \"{entity_name}\" }}, Market[{market}]),\n",
    "        TREATAS({p12m_dax}, Calendar[MonthYear]),\n",
    "        FILTER('Scope', 'Scope'[Scope] = \"{direct_parent[hierby]}\"),\n",
    "        \"Value Sales\", [Value Sales]\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn:\n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(dax_query)\n",
    "                df = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])\n",
    "  \n",
    "        df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "        \n",
    "    \n",
    "        outputdic[key] = df\n",
    "\n",
    "        print(f\"Query executed successfully for {entity_name}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {area}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {area}: {e}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "def process_dax_queries(entity_hierarchy, hierarchy_levels, client_brands=None,client_manuf=None):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "            if hierby == \"Category\":\n",
    "                continue\n",
    "\n",
    "            hierarchy_dict = dict(hierarchy_levels)\n",
    "            parent_level = direct_parent.get(hierby)\n",
    "            parent_values = hierarchy_dict.get(parent_level, [])\n",
    "\n",
    "            if not parent_values:\n",
    "                continue\n",
    "\n",
    "            futures = {}\n",
    "            ordered_keys = []\n",
    "\n",
    "            # Determine prodORitem per level\n",
    "\n",
    "            for value in parent_values:\n",
    "                for market,area, entity_list in entity_hierarchy:\n",
    "                    for entity in entity_list:\n",
    "                        if client_brands:\n",
    "                            for client in client_brands:\n",
    "                                for manuf in client_manuf:\n",
    "                                    key = f\"{client} | {entity} | {value}\"\n",
    "                                    ordered_keys.append(key)\n",
    "                                    futures[executor.submit(\n",
    "                                        execute_dax_query, entity, value,market,area, hierby, client, manuf\n",
    "                                    )] = key\n",
    "                        elif client_manuf:\n",
    "                            for manuf in client_manuf:\n",
    "                                key = f\"{manuf} | {entity} | {value}\"\n",
    "                                ordered_keys.append(key)\n",
    "                                futures[executor.submit(\n",
    "                                    execute_dax_query, entity, value,market,area, hierby, None, manuf\n",
    "                                )] = key\n",
    "\n",
    "            dfs_results = {}\n",
    "            for future in as_completed(futures):\n",
    "                result = future.result()\n",
    "                dfs_results.update(result)\n",
    "\n",
    "            dfs_results = {key: dfs_results[key] for key in ordered_keys if key in dfs_results}\n",
    "\n",
    "            if client_brands:\n",
    "                filename = f\"price_distribution_scraped_{hierby}_Ean.pkl\"\n",
    "            else:\n",
    "                filename = f\"price_distribution_scraped_{hierby}_Ean_manuf.pkl\"\n",
    "\n",
    "\n",
    "            output_file = f\"{path}\\\\{filename}\"\n",
    "            with open(output_file, \"wb\") as f:\n",
    "                pd.to_pickle(dfs_results, f)\n",
    "            \n",
    "            print(f\"All DataFrames for {hierby} saved to {output_file}.\")\n",
    "\n",
    "if client_brands:\n",
    "    process_dax_queries(entity_hierarchy, hierarchy_levels, client_brands=client_brands,client_manuf=client_manuf)\n",
    "if client_manuf:\n",
    "    process_dax_queries(entity_hierarchy, hierarchy_levels, client_manuf=client_manuf)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae1e0ac",
   "metadata": {},
   "source": [
    "## Price Point Comparison by Product (scraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3024dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database error for NATIONAL in Area: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 33) Column '<oii>NATIONAL</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: cdec6fdd-b2ba-42bc-b527-bbc0dd07e907 \\nDate (UTC): 9/14/2025 9:21:35 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Brands],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Category] = \"Total Fromage\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Area\"),\n",
      "        TREATAS({ \"NATIONAL\" }, Market[NATIONAL]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Category\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Intermarche in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 36) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: aec3e96d-7cbd-4e7a-ab6e-7b543245547e \\nDate (UTC): 9/14/2025 9:21:35 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Brands],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Category] = \"Total Fromage\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Intermarche\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Category\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Carrefour in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 34) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: ba12e69c-3425-4cb1-80b1-4875f193407b \\nDate (UTC): 9/14/2025 9:21:35 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Brands],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Category] = \"Total Fromage\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Carrefour\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Category\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Carrefour in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 34) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: 42a28860-ab7d-4286-b1a9-aa400d8bab6e \\nDate (UTC): 9/14/2025 9:21:35 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Brands],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Sector] = \"Soft Cheese\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Carrefour\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Sector\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Intermarche in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 36) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: 9ecb58f8-75f5-4b97-a965-1d661a313510 \\nDate (UTC): 9/14/2025 9:21:36 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Brands],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Sector] = \"Soft Cheese\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Intermarche\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Sector\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for NATIONAL in Area: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 33) Column '<oii>NATIONAL</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: fd8ded2b-fe43-46d4-9780-e32d3edad137 \\nDate (UTC): 9/14/2025 9:21:36 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Brands],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Sector] = \"Aperitif\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Area\"),\n",
      "        TREATAS({ \"NATIONAL\" }, Market[NATIONAL]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Sector\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Carrefour in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 34) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: 9745495b-3b37-412d-84c1-c6234433e126 \\nDate (UTC): 9/14/2025 9:21:36 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Brands],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Sector] = \"Aperitif\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Carrefour\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Sector\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for NATIONAL in Area: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 33) Column '<oii>NATIONAL</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: 04ed1cd0-4bf3-4289-80a4-c79fd46ef4ab \\nDate (UTC): 9/14/2025 9:21:36 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Brands],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Sector] = \"Soft Cheese\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Area\"),\n",
      "        TREATAS({ \"NATIONAL\" }, Market[NATIONAL]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Sector\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Intermarche in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 36) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: 14624de5-a506-499e-83dd-aa0d07fdae5b \\nDate (UTC): 9/14/2025 9:21:37 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Brands],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Sector] = \"Aperitif\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Intermarche\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Sector\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for NATIONAL in Area: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 33) Column '<oii>NATIONAL</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: 2d91239f-42f2-4dba-9daf-28a61636d5e8 \\nDate (UTC): 9/14/2025 9:21:37 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Brands],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Segment] = \"Enfant\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Area\"),\n",
      "        TREATAS({ \"NATIONAL\" }, Market[NATIONAL]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Segment\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Carrefour in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 34) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: 185b56ee-fb0c-4446-9d19-2dde97eb392d \\nDate (UTC): 9/14/2025 9:21:37 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Brands],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Segment] = \"Enfant\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Carrefour\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Segment\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for NATIONAL in Area: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 33) Column '<oii>NATIONAL</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: db90bb17-528c-4956-99b0-a7701d1c50ed \\nDate (UTC): 9/14/2025 9:21:37 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Brands],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Segment] = \"Frais A Tartiner\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Area\"),\n",
      "        TREATAS({ \"NATIONAL\" }, Market[NATIONAL]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Segment\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Intermarche in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 36) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: 16dfe4d5-ac9c-448f-b181-ebf80454db8a \\nDate (UTC): 9/14/2025 9:21:37 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Brands],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Segment] = \"Frais A Tartiner\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Intermarche\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Segment\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Carrefour in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 34) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: 0205721f-6b15-4700-bbc6-602a6acb1b6c \\nDate (UTC): 9/14/2025 9:21:37 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Brands],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Segment] = \"Frais A Tartiner\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Carrefour\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Segment\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for NATIONAL in Area: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 33) Column '<oii>NATIONAL</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: e8f87aa8-bdb4-4504-8dfd-dce0da0b3971 \\nDate (UTC): 9/14/2025 9:21:37 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Brands],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Segment] = \"Salade\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Area\"),\n",
      "        TREATAS({ \"NATIONAL\" }, Market[NATIONAL]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Segment\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Intermarche in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 36) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: b42a486e-ae7c-44cf-bd09-b517efc3f478 \\nDate (UTC): 9/14/2025 9:21:37 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Brands],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Segment] = \"Enfant\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Intermarche\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Segment\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Carrefour in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 34) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: 0b07d58f-ace4-4ae9-a33e-071e469798f2 \\nDate (UTC): 9/14/2025 9:21:38 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Brands],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Segment] = \"Salade\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Carrefour\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Segment\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Intermarche in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 36) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: 4ac5a2ee-98f0-47fc-a490-ed441dd6ca24 \\nDate (UTC): 9/14/2025 9:21:38 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Brands],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Segment] = \"Salade\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Intermarche\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Segment\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "All DataFrames saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_point_by_brands_items_scraped.pkl.\n",
      "Database error for Intermarche in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 36) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: c9cdcfaa-cef2-4a8e-9577-84698ce406f4 \\nDate (UTC): 9/14/2025 9:21:39 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Companies],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Sector] = \"Soft Cheese\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Intermarche\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Sector\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for NATIONAL in Area: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 33) Column '<oii>NATIONAL</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: 7fa175fc-e578-473c-a562-8da3c88927cb \\nDate (UTC): 9/14/2025 9:21:39 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Companies],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Category] = \"Total Fromage\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Area\"),\n",
      "        TREATAS({ \"NATIONAL\" }, Market[NATIONAL]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Category\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Carrefour in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 34) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: b40a2085-d12a-41d0-b4b3-df596bb106e8 \\nDate (UTC): 9/14/2025 9:21:39 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Companies],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Category] = \"Total Fromage\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Carrefour\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Category\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Carrefour in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 34) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: da18c364-038d-45c4-9989-a0004f281548 \\nDate (UTC): 9/14/2025 9:21:39 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Companies],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Sector] = \"Soft Cheese\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Carrefour\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Sector\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for NATIONAL in Area: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 33) Column '<oii>NATIONAL</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: 6a3abb8c-7e7d-4e67-8800-cf10fae85b61 \\nDate (UTC): 9/14/2025 9:21:40 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Companies],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Sector] = \"Soft Cheese\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Area\"),\n",
      "        TREATAS({ \"NATIONAL\" }, Market[NATIONAL]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Sector\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Intermarche in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 36) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: 962ca43d-823a-4002-b529-808e4d1ee1e7 \\nDate (UTC): 9/14/2025 9:21:40 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Companies],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Category] = \"Total Fromage\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Intermarche\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Category\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for NATIONAL in Area: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 33) Column '<oii>NATIONAL</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: 0cbb98f2-76a5-4bbe-813d-ae1e31103a80 \\nDate (UTC): 9/14/2025 9:21:40 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Companies],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Sector] = \"Aperitif\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Area\"),\n",
      "        TREATAS({ \"NATIONAL\" }, Market[NATIONAL]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Sector\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Carrefour in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 34) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: 18776bf2-0c5f-4e0e-92b9-dab1e2eefef2 \\nDate (UTC): 9/14/2025 9:21:40 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Companies],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Sector] = \"Aperitif\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Carrefour\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Sector\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Intermarche in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 36) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: 673a0deb-b0ef-43a1-ab7e-d2b896949985 \\nDate (UTC): 9/14/2025 9:21:41 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Companies],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Sector] = \"Aperitif\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Intermarche\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Sector\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for NATIONAL in Area: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 33) Column '<oii>NATIONAL</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: 479a277d-a0bd-4cb6-acdb-dd146a55a939 \\nDate (UTC): 9/14/2025 9:21:41 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Companies],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Segment] = \"Enfant\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Area\"),\n",
      "        TREATAS({ \"NATIONAL\" }, Market[NATIONAL]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Segment\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Carrefour in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 34) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: 385f7feb-5804-4396-8b84-982ed039f242 \\nDate (UTC): 9/14/2025 9:21:41 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Companies],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Segment] = \"Enfant\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Carrefour\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Segment\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for NATIONAL in Area: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 33) Column '<oii>NATIONAL</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: c25cee2b-5d12-40d8-9fd4-cbc0d3f5ed01 \\nDate (UTC): 9/14/2025 9:21:41 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Companies],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Segment] = \"Frais A Tartiner\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Area\"),\n",
      "        TREATAS({ \"NATIONAL\" }, Market[NATIONAL]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Segment\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Intermarche in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 36) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: 0aa53ebb-4f60-4c10-a934-91fcb4c71235 \\nDate (UTC): 9/14/2025 9:21:41 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Companies],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Segment] = \"Enfant\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Intermarche\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Segment\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Carrefour in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 34) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: e8f0a662-570f-472b-9a62-f9e7fb77cd05 \\nDate (UTC): 9/14/2025 9:21:41 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Companies],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Segment] = \"Frais A Tartiner\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Carrefour\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Segment\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Intermarche in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 36) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: 65056d88-0b0f-4b6d-9a42-5139ef3fca6e \\nDate (UTC): 9/14/2025 9:21:41 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Companies],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Segment] = \"Frais A Tartiner\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Intermarche\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Segment\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for NATIONAL in Area: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 33) Column '<oii>NATIONAL</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: eef0822a-b7d9-476a-ab3c-2af55aff9709 \\nDate (UTC): 9/14/2025 9:21:41 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Companies],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Segment] = \"Salade\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Area\"),\n",
      "        TREATAS({ \"NATIONAL\" }, Market[NATIONAL]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Segment\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Carrefour in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 34) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: f627e382-cfbb-45c6-b2cc-c0be977281a0 \\nDate (UTC): 9/14/2025 9:21:42 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Companies],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Segment] = \"Salade\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Carrefour\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Segment\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "Database error for Intermarche in Region: (-2147352567, 'Exception occurred.', (0, 'Microsoft OLE DB Provider for Analysis Services.', \"Query (15, 36) Column '<oii>RETAILER</oii>' in table '<oii>Market</oii>' cannot be found or may not be used in this expression. \\n \\nTechnical Details: \\nRootActivityId: 0448ad4d-24ee-4bc3-8101-a0b563dafd24 \\nDate (UTC): 9/14/2025 9:21:42 AM\", None, 0, -2147467259), None)\n",
      "Command:\n",
      "\n",
      "    EVALUATE\n",
      "    SUMMARIZECOLUMNS(   \n",
      "        Calendar[End of Week],\n",
      "        Products[Top Companies],\n",
      "        Products[Business Name],\n",
      "        Products[Ean],\n",
      "        Products[Total Size],\n",
      "        FILTER(\n",
      "            Products,\n",
      "                Products[Category] = \"Manual Shave Men\"\n",
      "                && Products[Segment] = \"Salade\"\n",
      "        ),\n",
      "        FILTER('Market', 'Market'[Area] = \"Region\"),\n",
      "        TREATAS({ \"Intermarche\" }, Market[RETAILER]),\n",
      "        FILTER('Scope', 'Scope'[Scope] = \"Segment\"),\n",
      "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
      "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
      "    )\n",
      "    \n",
      "Parameters:\n",
      "[]\n",
      "All DataFrames saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_point_by_manuf_items_scraped.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(BrandORManuf,entity_name,entity_type,market, area, hierby):\n",
    "    outputdic={}\n",
    "    key = f\"{entity_name} | {entity_type}\" \n",
    "    \n",
    "\n",
    "    # Main query\n",
    "    dax_query = f\"\"\"\n",
    "    EVALUATE\n",
    "    SUMMARIZECOLUMNS(   \n",
    "        Calendar[End of Week],\n",
    "        Products[{BrandORManuf}],\n",
    "        Products[{prodORitem}],\n",
    "        Products[Ean],\n",
    "        Products[Total Size],\n",
    "        FILTER(\n",
    "            Products,\n",
    "                Products[Category] = \"{categories[0]}\"\n",
    "                && Products[{hierby}] = \"{entity_type}\"\n",
    "        ),\n",
    "        FILTER('Market', 'Market'[Area] = \"{area}\"),\n",
    "        TREATAS({{ \"{entity_name}\" }}, Market[{market}]),\n",
    "        FILTER('Scope', 'Scope'[Scope] = \"{hierby}\"),\n",
    "        \"Scraped Av. Price/Unit\", [Scraped Av. Price/Unit],\n",
    "        \"Scraped Av. Price/KG\", [Scraped Av. Price/KG]\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn:\n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(dax_query)\n",
    "                df = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])\n",
    "    \n",
    "        df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "\n",
    "        outputdic[key] = df\n",
    "\n",
    "        print(f\"Query executed successfully for {entity_name}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {area}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {area}: {e}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "def process_dax_queries(BrandORManuf,entity_hierarchy, hierarchy_levels):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        dfs_results = {} \n",
    "        futures = {}\n",
    "        ordered_keys=[]\n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "            if isinstance(hier_values, list):\n",
    "                for value in hier_values:\n",
    "                    for market,area, entity_list in entity_hierarchy:\n",
    "                        for entity in entity_list:\n",
    "                            # print(hierby,value,entity)                                    \n",
    "                            key = f\"{entity} | {value}\"\n",
    "                            ordered_keys.append(key)\n",
    "                            future = executor.submit(execute_dax_query,BrandORManuf, entity,value,market,area, hierby)\n",
    "                            futures[future] = key\n",
    "       \n",
    "        temp_results = {}\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            temp_results.update(result)\n",
    "\n",
    "        # Insert results in original order\n",
    "        for key in ordered_keys:\n",
    "            if key in temp_results:\n",
    "                dfs_results[key] = temp_results[key]\n",
    "        if BrandORManuf==f\"{BrandOrTopB}\":         \n",
    "            filename = f\"price_point_by_brands_items_scraped.pkl\"\n",
    "        else:\n",
    "            filename = f\"price_point_by_manuf_items_scraped.pkl\"\n",
    "            \n",
    "        output_file = f\"{path}\\\\{filename}\"\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            pd.to_pickle(dfs_results, f)\n",
    "        \n",
    "        print(f\"All DataFrames saved to {output_file}.\")\n",
    "\n",
    "process_dax_queries(f\"{BrandOrTopB}\",entity_hierarchy, hierarchy_levels)\n",
    "process_dax_queries(f\"{ManufOrTopC}\",entity_hierarchy, hierarchy_levels)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45219ecd",
   "metadata": {},
   "source": [
    "## Price Point Distribution By Brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cdf5d184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "All DataFrames saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_distribution_by_brands_category.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(entity_name, entity_type, mkt, area, hierby):\n",
    "    outputdic = {}\n",
    "\n",
    "    key = f\"{entity_name} | {entity_type}\" \n",
    "    \n",
    "\n",
    "\n",
    "    columns = \"Av Price/Unit\", \"Value Share\"\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(\n",
    "                    Products,\n",
    "                    Products[{BrandOrTopB}],\n",
    "                    Products[Pack Size]\n",
    "                ),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[{hierby}] = \"{entity_type}\",\n",
    "            TREATAS({period}, Calendar[MonthYear]),\n",
    "            TREATAS({{ \"{entity_name}\" }}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    # Parent total query\n",
    "    parenttotal_dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(Products, Products[{BrandOrTopB}]),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[{hierby}] = \"{entity_type}\",\n",
    "        \n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({period}, Calendar[MonthYear]),\n",
    "            TREATAS({{ \"{entity_name}\" }}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    grandtotal_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(VALUES(Products[Category]), {column_exprs}),\n",
    "            Products[{hierby}] = \"{entity_type}\",\n",
    "            \n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({period}, Calendar[MonthYear]),\n",
    "            TREATAS({{ \"{entity_name}\" }}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # 1. Main query\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            data_columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "\n",
    "        # 2. Parent total query\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(parenttotal_dax_query)\n",
    "            maintotal_columns = [desc[0] for desc in cursor.description]\n",
    "            maintotal_data = cursor.fetchall()\n",
    "\n",
    "        # 3. Grand total query\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(grandtotal_query)\n",
    "            grandtotal_columns = [desc[0] for desc in cursor.description]\n",
    "            grandtotal_data = cursor.fetchall()\n",
    "\n",
    "        # Now build DataFrames safely\n",
    "        df = pd.DataFrame(data, columns=data_columns)\n",
    "        df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "        df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]\n",
    "\n",
    "        maintotal_df = pd.DataFrame(maintotal_data, columns=maintotal_columns)\n",
    "        maintotal_df.columns = maintotal_df.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "        maintotal_df = maintotal_df.loc[~(maintotal_df.select_dtypes(include='number') == 0).all(axis=1)]\n",
    "        \n",
    "\n",
    "        grand_tot = pd.DataFrame(grandtotal_data, columns=grandtotal_columns)\n",
    "        grand_tot.columns = grand_tot.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "        grand_tot = grand_tot.loc[~(grand_tot.select_dtypes(include='number') == 0).all(axis=1)]\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        if not maintotal_df.empty:\n",
    "            maintotal_df.iloc[:, 0] = maintotal_df.iloc[:, 0].astype(str) + \" Total\"\n",
    "            df = pd.concat([df,maintotal_df], ignore_index=True)\n",
    "  \n",
    "        if not grand_tot.empty:\n",
    "            grand_tot[df.columns[0]] = 'Grand Total'\n",
    "            grand_tot[df.columns[1]] = np.nan\n",
    "            grand_tot = grand_tot.reindex(columns=df.columns)\n",
    "            df = pd.concat([df, grand_tot], ignore_index=True)\n",
    "\n",
    "        outputdic[key] = df\n",
    "        print(f\"Query executed successfully for {entity_name}.\")\n",
    "\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {mkt}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {mkt}: {e}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "def process_dax_queries(entity_hierarchy, hierarchy_levels):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        dfs_results = {} \n",
    "        futures = {}\n",
    "        ordered_keys=[]\n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "            if isinstance(hier_values, list):\n",
    "                for value in hier_values:\n",
    "                    for mkt, area, entity_list in entity_hierarchy:\n",
    "                        for entity in entity_list:\n",
    "                            # print(hierby,value,entity)                                    \n",
    "                            key = f\"{entity} | {value}\"\n",
    "                            ordered_keys.append(key)\n",
    "                            future = executor.submit(execute_dax_query, entity,value,mkt, area, hierby)\n",
    "                            futures[future] = key\n",
    "       \n",
    "        temp_results = {}\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            temp_results.update(result)\n",
    "\n",
    "        # Insert results in original order\n",
    "        for key in ordered_keys:\n",
    "            if key in temp_results:\n",
    "                dfs_results[key] = temp_results[key]\n",
    "        filename = f\"price_distribution_by_brands_category.pkl\"\n",
    "        output_file = f\"{path}\\\\{filename}\"\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            pd.to_pickle(dfs_results, f)\n",
    "        \n",
    "        print(f\"All DataFrames saved to {output_file}.\")\n",
    "\n",
    "process_dax_queries(entity_hierarchy,hierarchy_levels) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b617cd93",
   "metadata": {},
   "source": [
    "## By brand For Sec,Seg,SubSeg... (Slide 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10d078e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "All DataFrames for Sector saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_distribution_by_brands_Sector.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "All DataFrames for Segment saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_distribution_by_brands_Segment.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(entity_name, entity_type, mkt, area, hierby):\n",
    "    outputdic = {}\n",
    " \n",
    "    key = f\"{entity_name} | {entity_type}\"\n",
    "    \n",
    "    columns = \"Av Price/Unit\", \"Value Share\"\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "             \n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(\n",
    "                    Products,\n",
    "                    Products[{BrandOrTopB}],\n",
    "                    Products[{hierby}],\n",
    "                    Products[Pack Size]\n",
    "                ),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[{direct_parent[hierby]}] = \"{entity_type}\",\n",
    "            TREATAS({period}, Calendar[MonthYear]),\n",
    "            TREATAS({{ \"{entity_name}\" }}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{direct_parent[hierby]}\")\n",
    "        )\n",
    "    \"\"\"\n",
    " \n",
    "    # Parent total query\n",
    "    parenttotal_dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(Products, Products[{BrandOrTopB}]),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[{direct_parent[hierby]}] = \"{entity_type}\",\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({period}, Calendar[MonthYear]),\n",
    "            TREATAS({{ \"{entity_name}\" }}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"Category\")\n",
    "        )\n",
    "    \"\"\"\n",
    "    itemtotal_dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(Products,Products[{BrandOrTopB}],\n",
    "                Products[{hierby}]),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[{direct_parent[hierby]}] = \"{entity_type}\",\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({period}, Calendar[MonthYear]),\n",
    "            TREATAS({{ \"{entity_name}\" }}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"Category\")\n",
    "        )\n",
    "    \"\"\"\n",
    " \n",
    "    grandtotal_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(VALUES(Products[Category]), {column_exprs}),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({period}, Calendar[MonthYear]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            TREATAS({{ \"{entity_name}\" }}, Market[{mkt}])\n",
    "        )\n",
    "    \"\"\"\n",
    " \n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn:\n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(dax_query)\n",
    "                df = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])\n",
    " \n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(parenttotal_dax_query)\n",
    "                maintotal_df = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])\n",
    "         \n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(itemtotal_dax_query)\n",
    "                itemtotal_df = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])\n",
    " \n",
    " \n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(grandtotal_query)\n",
    "                grand_tot = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])\n",
    " \n",
    "        for dataframe in [df,maintotal_df,itemtotal_df, grand_tot]:\n",
    "            dataframe.columns = dataframe.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "            dataframe.dropna(how='all', inplace=True)\n",
    "       \n",
    "            cols_to_check = [\"Av Price/Unit\", \"Value Share\"]\n",
    "            dataframe.drop(\n",
    "                index=dataframe[\n",
    "                    (dataframe[cols_to_check].abs() < 1e-6).all(axis=1)\n",
    "                ].index,\n",
    "                inplace=True\n",
    "            )    \n",
    "           \n",
    " \n",
    "        if not maintotal_df.empty:\n",
    "            maintotal_df.iloc[:, 0] = maintotal_df.iloc[:, 0].astype(str) + \" Total\"\n",
    "            df = pd.concat([df, maintotal_df], ignore_index=True)\n",
    "     \n",
    "        if not itemtotal_df.empty:\n",
    "            itemtotal_df.iloc[:, 1] = itemtotal_df.iloc[:, 1].astype(str) + \" Total\"\n",
    "            df = pd.concat([df, itemtotal_df], ignore_index=True)\n",
    "           \n",
    "        if not grand_tot.empty:\n",
    "            grand_tot[df.columns[0]] = 'Grand Total'\n",
    "            grand_tot[df.columns[1]] = np.nan\n",
    "            grand_tot = grand_tot.reindex(columns=df.columns)\n",
    "            df = pd.concat([df, grand_tot], ignore_index=True)\n",
    " \n",
    "        outputdic[key] = df\n",
    "        print(f\"Query executed successfully for {entity_name}.\")\n",
    " \n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {mkt}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {mkt}: {e}\")\n",
    " \n",
    "    return outputdic\n",
    " \n",
    " \n",
    "def process_dax_queries(entity_hierarchy, hierarchy_levels):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "            if hierby == \"Category\":\n",
    "                continue\n",
    " \n",
    "            hierarchy_dict = dict(hierarchy_levels)\n",
    "            parent_level = direct_parent.get(hierby)\n",
    "            parent_values = hierarchy_dict.get(parent_level, [])\n",
    " \n",
    "            if not parent_values:\n",
    "                continue\n",
    " \n",
    "            futures = {}\n",
    "            ordered_keys = []\n",
    " \n",
    "            # Determine prodORitem per level\n",
    " \n",
    "            for value in parent_values:\n",
    "                for mkt, area, entity_list in entity_hierarchy:\n",
    "                    for entity in entity_list:\n",
    "                        for manuf in client_manuf:\n",
    "                            key = f\"{entity} | {value}\"\n",
    "                            ordered_keys.append(key)\n",
    "                            futures[executor.submit(\n",
    "                                execute_dax_query, entity, value, mkt, area, hierby\n",
    "                            )] = key\n",
    " \n",
    "            dfs_results = {}\n",
    "            for future in as_completed(futures):\n",
    "                result = future.result()\n",
    "                dfs_results.update(result)\n",
    " \n",
    "            dfs_results = {key: dfs_results[key] for key in ordered_keys if key in dfs_results}\n",
    "           \n",
    "            filename = f\"price_distribution_by_brands_{hierby}\"\n",
    "                     \n",
    "            output_file = f\"{path}\\\\{filename}\"\n",
    "            with open(output_file, \"wb\") as f:\n",
    "                pd.to_pickle(dfs_results, f)\n",
    "            print(f\"All DataFrames for {hierby} saved to {output_file}.\")\n",
    " \n",
    " \n",
    "process_dax_queries(entity_hierarchy, hierarchy_levels)\n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43544eb7",
   "metadata": {},
   "source": [
    "## Price Point Comparison by Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d08f455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "All DataFrames for Segment saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_point_by_brands_items_P12M.pkl.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "All DataFrames for Segment saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_point_by_brands_items_P3M.pkl.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "All DataFrames for Segment saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_point_by_manuf_items_P12M.pkl.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Intermarche.\n",
      "All DataFrames for Segment saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_point_by_manuf_items_P3M.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(ManuforBrand,entity_name, entity_type, mkt, area, hierby, p12m=True):\n",
    "    outputdic = {}\n",
    "\n",
    "    key = f\"{entity_name} | {entity_type}\"\n",
    "    \n",
    "    if p12m:\n",
    "        timeper = p12m_dax\n",
    "        columns = [\"Value Share\", \"Gross Margin %\"]\n",
    "        row_fields = [\n",
    "            f\"Products[{ManuforBrand}]\",\n",
    "            f\"Products[{prodORitem}]\"\n",
    "        ]\n",
    "    else:\n",
    "        timeper = p3m_dax\n",
    "        columns = [\"Base Price/Unit\", \"Base Price/KG\", \"Value Sales\", \"Value Share\"]\n",
    "        row_fields = [\n",
    "            f\"Products[{ManuforBrand}]\",\n",
    "            f\"Products[{prodORitem}]\",\n",
    "            \"Products[Total Size]\"\n",
    "        ]\n",
    "\n",
    "    summarize_fields = \",\\n                        \".join(row_fields)\n",
    "    column_exprs = \",\\n                \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(\n",
    "                    Products,\n",
    "                    {summarize_fields}\n",
    "                ),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            Products[{hierby}] = \"{entity_type}\",\n",
    "            TREATAS({timeper}, Calendar[MonthYear]),\n",
    "            TREATAS({{ \"{entity_name}\" }}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    # Parent total query\n",
    "    parenttotal_dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(Products, Products[{ManuforBrand}]),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({timeper}, Calendar[MonthYear]),\n",
    "            TREATAS({{ \"{entity_name}\" }}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            Products[{hierby}] = \"{entity_type}\",\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "        )\n",
    "    \"\"\"\n",
    "    itemtotal_dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(Products,Products[{prodORitem}]),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({timeper}, Calendar[MonthYear]),\n",
    "            Products[{hierby}] = \"{entity_type}\",\n",
    "            TREATAS({{ \"{entity_name}\" }}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    grandtotal_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE( \n",
    "            ADDCOLUMNS(VALUES(Products[Category]), {column_exprs}),\n",
    "            TREATAS({timeper}, Calendar[MonthYear]),\n",
    "            Products[{hierby}] = \"{entity_type}\",\n",
    "            TREATAS({{ \"{entity_name}\" }}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "            \n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        \n",
    "        \n",
    "        with adodbapi.connect(conn_str) as conn:\n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(dax_query)\n",
    "                df = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])\n",
    "\n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(parenttotal_dax_query)\n",
    "                maintotal_df = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])\n",
    "          \n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(itemtotal_dax_query)\n",
    "                itemtotal_df = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])\n",
    "\n",
    "\n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(grandtotal_query)\n",
    "                grand_tot = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])\n",
    "          \n",
    "            numeric_columns = columns\n",
    "            for i, dataframe in enumerate([df, maintotal_df, itemtotal_df, grand_tot]):\n",
    "                dataframe.columns = dataframe.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "                dataframe.dropna(how='all', inplace=True)\n",
    "\n",
    "                if not dataframe.empty:\n",
    "                    # Force conversion to numeric in case some values are strings\n",
    "                    dataframe[numeric_columns] = dataframe[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "                    # Now drop rows where all numeric values are 0.0\n",
    "                    mask_all_zero = (dataframe[numeric_columns].fillna(0.0) == 0.0).all(axis=1)\n",
    "                    dataframe = dataframe[~mask_all_zero]\n",
    "\n",
    "                if i == 0:\n",
    "                    df = dataframe\n",
    "                elif i == 1:\n",
    "                    maintotal_df = dataframe\n",
    "                elif i == 2:\n",
    "                    itemtotal_df = dataframe\n",
    "                else:\n",
    "                    grand_tot = dataframe\n",
    "\n",
    "\n",
    "\n",
    "        if not maintotal_df.empty:\n",
    "            maintotal_df.iloc[:, 0] = maintotal_df.iloc[:, 0].astype(str) + \" Total\"\n",
    "            df = pd.concat([df, maintotal_df], ignore_index=True)\n",
    "            \n",
    "        if not p12m:\n",
    "            if not itemtotal_df.empty:\n",
    "                itemtotal_df.iloc[:, 0] = itemtotal_df.iloc[:, 0].astype(str) + \" Total\"\n",
    "                df = pd.concat([df, itemtotal_df], ignore_index=True)\n",
    "            \n",
    "        if not grand_tot.empty:\n",
    "            grand_tot[df.columns[0]] = 'Grand Total'\n",
    "            grand_tot[df.columns[1]] = np.nan\n",
    "            grand_tot = grand_tot.reindex(columns=df.columns)\n",
    "            df = pd.concat([df, grand_tot], ignore_index=True)\n",
    "\n",
    "        outputdic[key] = df\n",
    "        print(f\"Query executed successfully for {entity_name}.\")\n",
    "\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {mkt}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {mkt}: {e}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "def process_dax_queries(ManuforBrand,entity_hierarchy, hierarchy_levels,p12m):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        dfs_results = {} \n",
    "        futures = {}\n",
    "        ordered_keys=[]\n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "            if isinstance(hier_values, list):\n",
    "                for value in hier_values:\n",
    "                    for mkt, area, entity_list in entity_hierarchy:\n",
    "                        for entity in entity_list:\n",
    "                            # print(hierby,value,entity)                                    \n",
    "                            key = f\"{entity} | {value}\"\n",
    "                            ordered_keys.append(key)\n",
    "                            future = executor.submit(execute_dax_query,ManuforBrand, entity,value,mkt, area, hierby,p12m)\n",
    "                            futures[future] = key\n",
    "\n",
    "        dfs_results = {}\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            dfs_results.update(result)\n",
    "\n",
    "        dfs_results = {key: dfs_results[key] for key in ordered_keys if key in dfs_results}\n",
    "        if ManuforBrand ==f'{BrandOrTopB}' :\n",
    "            if p12m:\n",
    "                    filename = f\"price_point_by_brands_items_P12M.pkl\"\n",
    "            else:\n",
    "                    filename = f\"price_point_by_brands_items_P3M.pkl\"\n",
    "        else:\n",
    "            if p12m:\n",
    "                    filename = f\"price_point_by_manuf_items_P12M.pkl\"\n",
    "            else:\n",
    "                    filename = f\"price_point_by_manuf_items_P3M.pkl\"           \n",
    "        output_file = f\"{path}\\\\{filename}\"\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            pd.to_pickle(dfs_results, f)\n",
    "        print(f\"All DataFrames for {hierby} saved to {output_file}.\")\n",
    "\n",
    "\n",
    "# Example Invocation\n",
    "process_dax_queries(f'{BrandOrTopB}',entity_hierarchy, hierarchy_levels,p12m=True)\n",
    "process_dax_queries(f'{BrandOrTopB}',entity_hierarchy, hierarchy_levels,p12m=False)\n",
    "process_dax_queries(f'{ManufOrTopC}',entity_hierarchy, hierarchy_levels,p12m=True)\n",
    "process_dax_queries(f'{ManufOrTopC}',entity_hierarchy, hierarchy_levels,p12m=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50029e3",
   "metadata": {},
   "source": [
    "## Price Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88086e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Carrefour.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Intermarche.\n",
      "Query executed successfully for Carrefour.\n",
      "All DataFrames saved to c:\\Users\\aleaa\\Documents\\Slide-Automate\\Pricing slide duplicate\\Pricing Datasets NewEX\\price_correlation_P3Y.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(entity_name,entity_type, mkt, area, hierby):\n",
    "    outputdic = {}\n",
    "    key =  f\"{entity_type} | {entity_name}\"\n",
    "    \n",
    "\n",
    "    columns = [\n",
    "        \"Volume Share\",'Av Price/KG','Value Share'\n",
    "    ]\n",
    "    \n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    # Main query\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                CROSSJOIN(\n",
    "                    DISTINCT(Products[{BrandOrTopB}]),\n",
    "                    DISTINCT(Calendar[QuarterStart]),\n",
    "                    DISTINCT(Calendar[End of Week])\n",
    "                ),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({p36m_dax}, Calendar[MonthYear]),\n",
    "            Products[{hierby}] = \"{entity_type}\",\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "        )\n",
    "\n",
    "    \"\"\"\n",
    "    fristcoltot_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(\n",
    "                    products,\n",
    "                    Products[{BrandOrTopB}]\n",
    "                ),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({p36m_dax}, Calendar[MonthYear]),\n",
    "            Products[{hierby}] = \"{entity_type}\",\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "        )\n",
    "\n",
    "    \"\"\"\n",
    "    secondcoltot_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(\n",
    "                    Calendar,\n",
    "                    Calendar[QuarterStart]\n",
    "                ),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({p36m_dax}, Calendar[MonthYear]),\n",
    "            Products[{hierby}] = \"{entity_type}\",\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"Category\")\n",
    "        )\n",
    "    \"\"\"\n",
    "    # Grand total query (not grouped by BrandOrTopB, just Category)\n",
    "    grandtotal_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(\n",
    "                    Products,\n",
    "                    Products[Category]\n",
    "                ),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({p36m_dax}, Calendar[MonthYear]),\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{mkt}]),\n",
    "            TREATAS({{\"{area}\"}}, Market[Area]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"Category\")\n",
    "        )\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "            \n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(fristcoltot_query)\n",
    "            fristttotal_columns = [desc[0] for desc in cursor.description]\n",
    "            fristtotal_data = cursor.fetchall()       \n",
    "             \n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(secondcoltot_query)\n",
    "            sectotal_columns = [desc[0] for desc in cursor.description]\n",
    "            sectotal_data = cursor.fetchall()  \n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(grandtotal_query)\n",
    "            grandtotal_columns = [desc[0] for desc in cursor.description]\n",
    "            grandtotal_data = cursor.fetchall()\n",
    "            \n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)         \n",
    "            df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "\n",
    "            maintotal_df = pd.DataFrame(fristtotal_data, columns=fristttotal_columns)\n",
    "            maintotal_df.columns = maintotal_df.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "            maintotal_df = maintotal_df.loc[~(maintotal_df.select_dtypes(include='number') == 0).all(axis=1)]\n",
    "            \n",
    "            sectotal_df = pd.DataFrame(sectotal_data, columns=sectotal_columns)\n",
    "            sectotal_df.columns = sectotal_df.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "            sectotal_df = sectotal_df.loc[~(sectotal_df.select_dtypes(include='number') == 0).all(axis=1)]\n",
    "        \n",
    "            grand_tot = pd.DataFrame(grandtotal_data, columns=grandtotal_columns)\n",
    "            grand_tot.columns = grand_tot.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "            grand_tot = grand_tot.loc[~(grand_tot.select_dtypes(include='number') == 0).all(axis=1)]\n",
    "\n",
    "            if maintotal_df.shape[1] > 1:\n",
    "                maintotal_df.iloc[:, 0] = maintotal_df.iloc[:, 0].astype(str) + \" Total\"\n",
    "            \n",
    "            if sectotal_df.shape[1] > 1:\n",
    "                first_col = sectotal_df.columns[0]\n",
    "                # Ensure datetime\n",
    "                sectotal_df[first_col] = pd.to_datetime(sectotal_df[first_col], errors='coerce')\n",
    "\n",
    "                # Format date and append ' total'\n",
    "                sectotal_df[first_col] = sectotal_df[first_col].dt.strftime('%Y-%m-%d') + \" Total\"\n",
    "\n",
    "\n",
    "\n",
    "            if sectotal_df.empty:\n",
    "                outputdic[key] = sectotal_df\n",
    "                return outputdic\n",
    "\n",
    "            if maintotal_df.empty:\n",
    "                outputdic[key] = maintotal_df\n",
    "                return outputdic\n",
    "        \n",
    "            \n",
    "            if not maintotal_df.empty:\n",
    "                df_with_totals = pd.concat([df,maintotal_df], ignore_index=True)\n",
    "                \n",
    "            df_with_totals['QuarterStart'] = pd.to_datetime(df_with_totals['QuarterStart']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "            if not sectotal_df.empty:\n",
    "                dfsec_with_totals = pd.concat([df_with_totals,sectotal_df], ignore_index=True)\n",
    "\n",
    "            \n",
    "\n",
    "            grand_tot = pd.DataFrame(grandtotal_data, columns=grandtotal_columns)\n",
    "            grand_tot.columns = grand_tot.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "            grand_tot = grand_tot.loc[~(grand_tot.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "          \n",
    "            if not grand_tot.empty:\n",
    "                # Set first column value to 'Grand Total', second column to NaN\n",
    "                grand_tot[df.columns[0]] = 'Grand Total'\n",
    "                grand_tot[df.columns[1]] = np.nan  # or pd.NA\n",
    "\n",
    "                # Restrict grand_tot to only columns that appear in df\n",
    "                grand_tot = grand_tot[df.columns.intersection(grand_tot.columns)]\n",
    "\n",
    "            # Concatenate all together\n",
    "            df = pd.concat([dfsec_with_totals, grand_tot], ignore_index=True)\n",
    "\n",
    "            outputdic[key] = df\n",
    "\n",
    "\n",
    "            \n",
    "            print(f\"Query executed successfully for {entity_name}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {mkt}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {mkt}: {e}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "\n",
    "def process_dax_queries(entity_hierarchy, hierarchy_levels):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        dfs_results = {} \n",
    "        futures = {}\n",
    "        ordered_keys=[]\n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "            if isinstance(hier_values, list):\n",
    "                for value in hier_values:\n",
    "                    for mkt, area, entity_list in entity_hierarchy:\n",
    "                        for entity in entity_list:\n",
    "                            # print(hierby,value,entity)                                    \n",
    "                            key = f\"{value} | {entity}\"\n",
    "                            ordered_keys.append(key)\n",
    "                            future = executor.submit(execute_dax_query, entity,value,mkt, area, hierby)\n",
    "                            futures[future] = key\n",
    "       \n",
    "        temp_results = {}\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            temp_results.update(result)\n",
    "\n",
    "        # Insert results in original order\n",
    "        for key in ordered_keys:\n",
    "            if key in temp_results:\n",
    "                dfs_results[key] = temp_results[key]\n",
    "        filename =  f\"price_correlation_P3Y.pkl\"\n",
    "\n",
    "        output_file = f\"{path}\\\\{filename}\"\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            pd.to_pickle(dfs_results, f)\n",
    "        \n",
    "        print(f\"All DataFrames saved to {output_file}.\")\n",
    "\n",
    "process_dax_queries(entity_hierarchy,hierarchy_levels) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927e5450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
