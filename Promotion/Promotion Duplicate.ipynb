{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "15a454f5-c4e1-460c-a27d-40aa00dfcac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "slides_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6ecc6d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "%run \"{os.path.dirname(os.getcwd())}\\general_functions\\generalFunctions.ipynb\" #container\n",
    "%run \"{os.getcwd()}\\Promotion Replacement Function.ipynb\" #container\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6999d128",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "837215b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6b5d5ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### RUN IF TOOL #######\n",
    "if tool:\n",
    "    filename = 'parameters.xlsx'\n",
    "\n",
    "    # Get the current working directory\n",
    "    current_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "    # Construct the full path to the file\n",
    "    f_path = os.path.join(current_dir, filename)\n",
    "    print(f_path)\n",
    "    #xls = pd.ExcelFile(f_path)\n",
    "    parm = pd.read_excel(f_path, sheet_name='Promotion')\n",
    "    fields = dict(zip(parm['Field'],parm['Value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "26fd59b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### RUN IF TOOL #######\n",
    "if tool:\n",
    "    server = \"powerbi://api.powerbi.com/v1.0/myorg/\"+ fields['server']\n",
    "    dataset_name = fields['f_name']\n",
    "    f_name = os.getcwd()+\"/\"+fields['f_name']+\".xlsx\"\n",
    "\n",
    "    client_manuf = list(set(fields['client_manuf'].split(','))-set(['']))\n",
    "    client_brands = list(set(fields['client_brands'].split(','))-set(['']))\n",
    "\n",
    "    decimals = fields['decimals']\n",
    "    sign = fields['sign']\n",
    "    currency = fields['currency']\n",
    "    currency = ' '+ currency if sign.lower() == 'after' else  currency + ' ' \n",
    "\n",
    "    categories = list(set(fields['categories'].split(','))-set(['']))\n",
    "    sectors=list(set(fields['sectors'].split(','))-set(['']))\n",
    "    segments=list(set(fields['segments'].split(','))-set(['']))\n",
    "    subsegments=list(set(fields['subsegments'].split(','))-set(['']))\n",
    "    subcategories=list(set(fields['subcategories'].split(','))-set(['']))\n",
    "\n",
    "    national=fields['national']\n",
    "    customareas=fields['customareas']\n",
    "    areas = list(set(fields['areas'].split(','))-set(['']))+[customareas]\n",
    "\n",
    "    regions_RET = list(set(fields['regions_RET'].split(','))-set(['']))\n",
    "    channels_RET = list(set(fields['channels_RET'].split(','))-set(['']))\n",
    "    market_RET=list(set(fields['market_RET'].split(','))-set(['']))\n",
    "\n",
    "    regions_CHAN=list(set(fields['regions_CHAN'].split(','))-set(['']))\n",
    "    channels_CHAN=list(set(fields['channels_CHAN'].split(','))-set(['']))\n",
    "    market_CHAN=list(set(fields['market_CHAN'].split(','))-set(['']))\n",
    "\n",
    "    regions_CUST=list(set(fields['regions_CUST'].split(','))-set(['']))\n",
    "    channels_CUST=list(set(fields['channels_CUST'].split(','))-set(['']))\n",
    "    market_CUST=list(set(fields['market_CUST'].split(','))-set(['']))\n",
    "\n",
    "    data_source=fields['data_source']\n",
    "    years=list(set(fields['years'].split(','))-set(['']))\n",
    "    start_date = fields['start_date']\n",
    "    end_date=fields['end_date']\n",
    "\n",
    "    ManufOrTopC = fields['ManufOrTopC']\n",
    "    BrandOrTopB = fields['BrandOrTopB']\n",
    "    prodORitem = fields['prodORitem']\n",
    "\n",
    "    percent = fields['percent']\n",
    "    percentstr=fields['percentstr']\n",
    "\n",
    "    National=[\"NATIONAL\"]if national else []\n",
    "    subcatg_parent = fields['subcatg_parent']\n",
    "    subcatg_parent_list = segments\n",
    "    promo_col = list(set(fields['promo_col'].split(','))-set(['']))\n",
    "    selectedBrands = client_brands \n",
    "    marketList = regions_RET + channels_RET + market_RET + regions_CHAN + channels_CHAN + market_CHAN \n",
    "    notInScope = []\n",
    "    OpenEditData=fields['OpenEditData']\n",
    "    normalized = fields['normalized']\n",
    "    promo_type = fields['promo_type']\n",
    "    display_share = fields['display_share']\n",
    "    feature_share = fields['feature_share']\n",
    "    slides_Period = fields['slides_Period']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "9c6195f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### RUN IF TOOL #######\n",
    "if tool:\n",
    "    direct_parent = {\"Sector\":\"Category\",\n",
    "                    \"Segment\":\"Sector\",\n",
    "                    \"SubSegment\":\"Segment\", \n",
    "                    \"SubCategory\":\"Segment\"}\n",
    "    Scope = {\n",
    "        \"Category\": categories,\n",
    "        \"Sector\": sectors,\n",
    "        \"Segment\": segments,\n",
    "        \"Subsegment\": subsegments,\n",
    "        \"Subcategory\": subcategories\n",
    "    }\n",
    "    suffixes = [\"Category\", \"Sector\", \"Segment\",'SubSegment', 'SubCategory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2a25d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "###### RUN IF TOOL #######\n",
    "if tool:\n",
    "    defaults = ast.literal_eval(\"{\" + fields['defaults'] + \"}\")\n",
    "    marketList = regions_RET + channels_RET + market_RET + regions_CHAN + channels_CHAN + market_CHAN + regions_CUST + channels_CUST + market_CUST\n",
    "    categoryList=categories +sectors+segments+subsegments+subcategories\n",
    "    # defaults = {\n",
    "    #     'Manual Shave Men': 6.69,'Disposables': 7.98,\"System\" : 5.03,\"Razors\" : 2.80,\"Refills\" : 6.58\n",
    "    # }\n",
    "    diff_market_value = {\n",
    "    }\n",
    "\n",
    "    def totalsize (lis,defaultdic,diffmarketdic=[]):\n",
    "\n",
    "        max_total_size = {\n",
    "        f\"{category} | {market}\": diff_market_value.get(market.upper(), {}).get(category, defaults[category])\n",
    "        for market in lis\n",
    "        for category in defaults\n",
    "        }\n",
    "\n",
    "        return max_total_size  \n",
    "\n",
    "    max_total_size=750#totalsize(marketList,defaults,diff_market_value)\n",
    "\n",
    "    custom_colors = [\n",
    "        RGBColor(91, 159, 153),    # Darker teal\n",
    "        RGBColor(131, 199, 193),   # Brighter medium teal\n",
    "        RGBColor(168, 216, 212),   # Original light teal\n",
    "        RGBColor(198, 236, 232),   # Very light teal\n",
    "        RGBColor(111, 179, 173),\n",
    "        RGBColor(121, 189, 183)\n",
    "    ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "86ff0039",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### RUN IF MANUAL TRIGGER #######\n",
    "if not tool:\n",
    "    ManufOrTopC =\"Top Companies\"\n",
    "    BrandOrTopB = \"Top Brands\"\n",
    "    prodORitem=\"SKU\"\n",
    "\n",
    "    client_manuf =[\"Malard Nicolas\"]\n",
    "    client_brands = [\"Nicolas\"]\n",
    "\n",
    "    categories =[\"Effervescents\"]\n",
    "    sectors = [\"Champagnes\",\"Mousseux\",\"Effervescents Sans Alcool\"]\n",
    "    segments = [\"Blanc De Blancs\",\"Bruts\",\"Crus\",\"Extra Brut\",\"Millesimes\",\"Rosés\",\"Mousseux Bourgogne\",\"Mousseux Italiens\",\"Mousseux Val De Loire\",\"Mousseux Alsace\",\"Mousseux Bordelais\"]\n",
    "    subsegments= []\n",
    "    subcategories= []\n",
    "\n",
    "    decimals = 2\n",
    "    sign = \"after\"\n",
    "    currency = '€'\n",
    "    currency = ' '+ currency if sign.lower() == 'after' else  currency + ' '\n",
    "\n",
    "    national = False\n",
    "    customareas= \"REVENUE\"\n",
    "    areas = [\"CHANNEL\",\"REGION\", f'{customareas}']\n",
    "\n",
    "    regions_RET  = []\n",
    "    channels_RET = []\n",
    "    market_RET = []\n",
    "    \n",
    "    regions_CHAN = [\"NICOLAS\"]\n",
    "    channels_CHAN = [\"NICOLAS QCN\",\"NICOLAS VCN\",\"NICOLAS QCT\",\"NICOLAS QCA\",\"NICOLAS CCP\"]#\"NICOLAS VCT\",\"NICOLAS RN\",\"NICOLAS CCQ\",\"NICOLAS CCC\"]#\n",
    "    market_CHAN = []\n",
    "\n",
    "    regions_REG = []\n",
    "    channels_REG = [\"NICOLAS IDF\",\"NICOLAS PAC\",\"NICOLAS RHO\",\"NICOLAS AQU\",\"NICOLAS EST\"]#\"NICOLAS OCC\",\"NICOLAS HAU\",\"NICOLAS NDI\",\"NICOLAS BRE\",\"NICOLAS LOI\",\"NICOLAS CEN\",\"NICOLAS BOU\"]#\n",
    "    market_REG = []\n",
    "\n",
    "    regions_CUST = []\n",
    "    channels_CUST = [\"CA A\",\"CA B\",\"CA C\",\"CA D\",\"CA E\"]\n",
    "    market_CUST = []\n",
    "\n",
    "\n",
    "    data_source = \"DATA SOURCE: Trade Panel/Retailer Data | Ending June 2025\"\n",
    "    end_date = \"2025-07-01\"#\"01/07/2025\"\n",
    "    years = ['2023', '2024','2025']\n",
    "    slides_Period='P12M'\n",
    "\n",
    "    subcatg_parent = \"Segment\"\n",
    "    subcatg_parent_list = segments\n",
    "    \n",
    "    percent = 1000000\n",
    "    percentstr=\"'000 000\"\n",
    "    start_date = \"23/07/2023\"\t\n",
    "\n",
    "\n",
    "\n",
    "    promo_col = []\n",
    "    selectedBrands = client_brands \n",
    "    marketList = regions_RET + channels_RET + market_RET + regions_CHAN + channels_CHAN + market_CHAN + regions_CUST + channels_CUST + market_CUST  + regions_REG + channels_REG + market_REG\n",
    "    notInScope = []\n",
    "    OpenEditData=True\n",
    "    direct_parent = {\"Sector\":\"Category\",\n",
    "                    \"Segment\":\"Sector\",\n",
    "                    \"SubSegment\":\"Segment\", \n",
    "                    \"SubCategory\":\"Segment\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d93407ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### RUN IF MANUAL TRIGGER #######\n",
    "if not tool:\n",
    "    normalized = True\n",
    "    promo_type = True\n",
    "    display_share = False  # True if Available\n",
    "    feature_share = False\n",
    "\n",
    "    categoryList=categories +sectors+segments+subsegments+subcategories\n",
    "    #defaults = {\n",
    "    #    'EFFERFEC': 750,\n",
    "    #    'Disposables': 7.98,\n",
    "    #   \"System\" : 5.03,\n",
    "    #   \"Razors\" : 2.80,\n",
    "    #    \"Refills\" : 6.58\n",
    "    #}\n",
    "    diff_market_value = {\n",
    "\n",
    "    }\n",
    "\n",
    "    def totalsize (lis,defaultdic,diffmarketdic=[]):\n",
    "\n",
    "        max_total_size = 750 # I also updated that in replacement to change at the end!\n",
    "\n",
    "        return max_total_size  \n",
    "\n",
    "    max_total_size=[750] #totalsize(marketList,defaults,diff_market_value)\n",
    "\n",
    "    custom_colors = [\n",
    "        RGBColor(91, 159, 153),    # Darker teal\n",
    "        RGBColor(131, 199, 193),   # Brighter medium teal\n",
    "        RGBColor(168, 216, 212),   # Original light teal\n",
    "        RGBColor(198, 236, 232),   # Very light teal\n",
    "        RGBColor(111, 179, 173),\n",
    "        RGBColor(121, 189, 183)\n",
    "    ]\n",
    "    Scope = {\n",
    "        \"Category\": categories,\n",
    "        \"Sector\": sectors,\n",
    "        \"Segment\": segments,\n",
    "        \"Subsegment\": subsegments,\n",
    "        \"Subcategory\": subcategories\n",
    "    }\n",
    "    suffixes = [\"Category\", \"Sector\", \"Segment\",'SubSegment', 'SubCategory']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71fd5a3",
   "metadata": {},
   "source": [
    "## Reading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "461dc096-382d-4c3b-91c1-8610a7cd684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = {}\n",
    "datasets_path = os.getcwd()+\"/Promotion Datasets/\"\n",
    "datasets = os.listdir(datasets_path)\n",
    "for d in datasets:\n",
    "    with open(datasets_path+d, 'rb') as handle:\n",
    "        globals()[d.split('.')[0]] = pd.read_pickle(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707e341f",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c1c2b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[f\"modified_promotionBrands{slides_Period}\"] = cleaningData(globals()[f\"promotions_brands_{slides_Period}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "057130a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature_share & display_share:\n",
    "    globals()[f\"modified_promotionBrands_share{slides_Period}\"] = cleaningData_featureshare(globals()[f\"promotions_brands_{slides_Period}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "77d32fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[f\"modified_promotionBrands{slides_Period}_total\"] = cleaningdata_with_grand_total(globals()[f\"promotions_brands_{slides_Period}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8ad3da6e-fb47-4873-b875-bd146d89d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[f\"modified_promotionProducts{slides_Period}\"] = cleaningData(globals()[f\"promotions_products_{slides_Period}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c5159e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[f\"modified_promotionProducts{slides_Period}_updated\"] = {}\n",
    "for key, df in globals()[f\"modified_promotionProducts{slides_Period}\"].items():\n",
    "    df = df.copy()\n",
    "    df = df[df[f'{prodORitem}'] != '']\n",
    "    df = df[df['Promo Sales'] >= 10000]\n",
    "    df = df.sort_values(by='Promo Value', ascending=False).reset_index(drop=True)\n",
    "    if not df.empty:\n",
    "        globals()[f\"modified_promotionProducts{slides_Period}_updated\"][key] = df\n",
    "globals()[f\"modified_promotionProducts{slides_Period}_volumeuplift\"] = globals()[f\"modified_promotionProducts{slides_Period}_updated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b40a1e66-80f4-4dd0-9af8-a1a4e1cdc795",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_promotionEndOfWeek = cleaningData(promotions_EndOfWeek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "10343316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'23/07/2023'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c86f6a2a-90f7-40b1-8f9f-723f5578455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_valueUplift = cleaningData(value_uplift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "7da7fc3d-461c-4a38-8ae2-8d19805e5a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "newModifiedBrands,threshold = cleaning13New(globals()[f\"promotions_brands_{slides_Period}\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "4ae1fa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for each pivot call in a list of tuples:\n",
    "pivot_params = [\n",
    "    (Sector_client_VSOD, 'Top Brands', 'Sector_client_VSODNew'),\n",
    "    (Sector_manuf_VSOD, 'Top Companies', 'Sector_manuf_VSODNew'),\n",
    "    (Segment_client_VSOD, 'Top Brands', 'Segment_client_VSODNew'),\n",
    "    (Segment_manuf_VSOD, 'Top Companies', 'Segment_manuf_VSODNew'),\n",
    "    (SubSegment_client_VSOD, 'Top Brands', 'SubSegment_client_VSODNew'),\n",
    "    (SubSegment_manuf_VSOD, 'Top Companies', 'SubSegment_manuf_VSODNew'),\n",
    "    (SubCategory_client_VSOD, 'Top Brands', 'SubCategory_client_VSODNew'),\n",
    "    (SubCategory_manuf_VSOD, 'Top Companies', 'SubCategory_manuf_VSODNew')\n",
    "]\n",
    "\n",
    "# Prepare a dictionary to store results:\n",
    "pivot_results = {}\n",
    "\n",
    "for data_dict, pivot_col, result_name in pivot_params:\n",
    "    pivot_results[result_name] = dict_to_pivot_general(\n",
    "        data_dict=data_dict,\n",
    "        pivot_col=pivot_col,\n",
    "        value_col='VSOD',\n",
    "        aggfunc='sum',\n",
    "        fill_value=pd.NA\n",
    "    )\n",
    "\n",
    "# If you want to have these as separate variables in your workspace, you can unpack like:\n",
    "Sector_client_VSODNew = pivot_results['Sector_client_VSODNew']\n",
    "Sector_manuf_VSODNew = pivot_results['Sector_manuf_VSODNew']\n",
    "Segment_client_VSODNew = pivot_results['Segment_client_VSODNew']\n",
    "Segment_manuf_VSODNew = pivot_results['Segment_manuf_VSODNew']\n",
    "SubSegment_client_VSODNew = pivot_results['SubSegment_client_VSODNew']\n",
    "SubSegment_manuf_VSODNew = pivot_results['SubSegment_manuf_VSODNew']\n",
    "SubCategory_client_VSODNew = pivot_results['SubCategory_client_VSODNew']\n",
    "SubCategory_manuf_VSODNew = pivot_results['SubCategory_manuf_VSODNew']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d18ef6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors) >0:\n",
    "    a = Sector_VSOD\n",
    "    if len(Sector_client_VSODNew) >0:\n",
    "        b = cleaningData(Sector_client_VSODNew)\n",
    "        sect_vsod_merged = merging(a,b, col=[direct_parent[\"Sector\"],'Sector'])\n",
    "    else:\n",
    "        sect_vsod_merged = a\n",
    "    c = cleaningData(Sector_manuf_VSODNew)  \n",
    "    for key in sect_vsod_merged:\n",
    "        merged_df = pd.merge(sect_vsod_merged[key], c[key], on=[direct_parent[\"Sector\"],'Sector'], how='left')\n",
    "        merged_df = merged_df.fillna(0)\n",
    "        if merged_df.shape[0]>0:\n",
    "            sect_vsod_merged[key] = merged_df    \n",
    "\n",
    "if len(segments) >0:\n",
    "    a = Segment_VSOD\n",
    "    if len(Segment_client_VSODNew) > 0:\n",
    "        b = cleaningData(Segment_client_VSODNew)\n",
    "        seg_vsod_merged = merging(a,b, col=[direct_parent[\"Segment\"],'Segment'])\n",
    "    else:\n",
    "        seg_vsod_merged = a\n",
    "    \n",
    "    c = cleaningData(Segment_manuf_VSODNew)\n",
    "    for key in seg_vsod_merged:\n",
    "        # Merge DataFrames based on 'Sector' column\n",
    "        merged_df = pd.merge(seg_vsod_merged[key], c[key], on=[direct_parent[\"Segment\"],'Segment'], how='left')\n",
    "        merged_df = merged_df.fillna(0)\n",
    "        if merged_df.shape[0]>0:\n",
    "            seg_vsod_merged[key] = merged_df    \n",
    "\n",
    "if len(subsegments) >0:\n",
    "    a = SubSegment_VSOD\n",
    "    if len(SubSegment_client_VSODNew) > 0 :\n",
    "        b = cleaningData(SubSegment_client_VSODNew)\n",
    "        subseg_vsod_merged = merging(a,b, col=[direct_parent[\"SubSegment\"],'SubSegment'])\n",
    "    else:\n",
    "        subseg_vsod_merged = a\n",
    "    c = cleaningData(SubSegment_manuf_VSOD)\n",
    "    for key in subseg_vsod_merged:\n",
    "        # Merge DataFrames based on 'Sector' column\n",
    "        merged_df = pd.merge(subseg_vsod_merged[key], c[key], on=[direct_parent[\"SubSegment\"],'SubSegment'], how='left')\n",
    "        merged_df = merged_df.fillna(0)\n",
    "        if merged_df.shape[0]>0:\n",
    "            subseg_vsod_merged[key] = merged_df    \n",
    "\n",
    "if len(subcategories) >0:\n",
    "    a = SubCategory_VSOD\n",
    "    if len(SubCategory_client_VSODNew) > 0 :\n",
    "        b = cleaningData(SubCategory_client_VSODNew)\n",
    "        subcat_vsod_merged = merging(a,b, col=[direct_parent[\"SubCategory\"],'SubCategory'])\n",
    "    else:\n",
    "        subcat_vsod_merged = a\n",
    "    c = cleaningData(SubCategory_manuf_VSODNew)\n",
    "    for key in subcat_vsod_merged:\n",
    "        # Merge DataFrames based on 'Sector' column\n",
    "        merged_df = pd.merge(subcat_vsod_merged[key], c[key], on=[direct_parent[\"SubCategory\"],'SubCategory'], how='left')\n",
    "        merged_df = merged_df.fillna(0)\n",
    "        if merged_df.shape[0]>0:\n",
    "            subcat_vsod_merged[key] = merged_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "e97a11db",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=client_brands+client_manuf\n",
    "if len(sectors)!=0:\n",
    "    sect_vsod_merged=splitkeys(sect_vsod_merged,categories,parent=direct_parent['Sector'],clientlist=client)\n",
    "if len(segments)!=0:\n",
    "    seg_vsod_merged=splitkeys(seg_vsod_merged,sectors,parent=direct_parent['Segment'],clientlist=client)\n",
    "if len(subsegments)!=0:\n",
    "    subseg_vsod_merged=splitkeys(subseg_vsod_merged,segments,parent=direct_parent['SubSegment'],clientlist=client)\n",
    "if len(subcategories)!=0:\n",
    "    subcat_vsod_merged=splitkeys(subcat_vsod_merged,segments,parent=direct_parent['SubCategory'],clientlist=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b271ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors):\n",
    "    sect_vsod_count =0\n",
    "    for key,df in sect_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                sect_vsod_count +=1\n",
    "    sect_vsod_count = sect_vsod_count *len(categories)\n",
    " \n",
    "if len(segments):\n",
    "    seg_vsod_count =0\n",
    "    for key,df in seg_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                seg_vsod_count +=1\n",
    "    #seg_vsod_count = seg_vsod_count * len(sectors) \n",
    "    seg_vsod_count = seg_vsod_count           \n",
    " \n",
    "if len(subsegments) >0:\n",
    "    subseg_vsod_count =0\n",
    "    for key,df in subseg_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                subseg_vsod_count +=1\n",
    "    #subseg_vsod_count =subseg_vsod_count *len(segments)\n",
    "    subseg_vsod_count = subseg_vsod_count\n",
    " \n",
    "if len(subcategories) >0:\n",
    "    subcat_vsod_count =0\n",
    "    for key,df in subcat_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                subcat_vsod_count +=1\n",
    "    #subcat_vsod_count = subcat_vsod_count * len(subsegments)\n",
    "    subcat_vsod_count = subcat_vsod_count\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "6dd04ba3-5570-4ad4-8d61-252872480a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "promotionsBrandSortedTotalFinal={}\n",
    "promotionsBrandSortedTotal=dfSort(globals()[f\"modified_promotionBrands{slides_Period}\"], client_brands, \"Top Brands\", num=8,salesCol='Promo Value')\n",
    "for key,df in promotionsBrandSortedTotal.items():\n",
    "     df_client = selectClientBrands(promotionsBrandSortedTotal[key],'Top Brands', 'Promo Value')\n",
    "     number_of_brands_needed = max(6 - len(df_client),0)\n",
    "     \n",
    "     df = df[~df['Top Brands'].isin(client_brands)]\n",
    "     df = df[~df['Top Brands'].str.contains('Others', case=False)]\n",
    "     \n",
    "     df = df.sort_values(by='Promo Value', ascending=False).head(number_of_brands_needed)\n",
    "     df = pd.concat([df, df_client], ignore_index=True)\n",
    "     df = df.sort_values(by='Promo Value', ascending=False).reset_index(drop=True)\n",
    "     df = df[~df['Top Brands'].str.contains('Grand Total', case=False)]\n",
    "     df = df[df['Value Share'] > 0.01]\n",
    "        \n",
    "     df['VSOD Evaluation vs YA'] = df['VSOD Evaluation vs YA'].astype(float)\n",
    "     df['Promo Value Uplift vs YA'] = df['Promo Value Uplift vs YA'].astype(float)\n",
    "     \n",
    "     if df.shape[0] >0:\n",
    "          promotionsBrandSortedTotalFinal[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e66555e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "promotionsBrandNOTSortedTotalFinal={}\n",
    "promotionsBrandNOTSortedTotalFinal=dfSort(globals()[f\"modified_promotionBrands{slides_Period}\"], client_brands, \"Top Brands\", num=8,salesCol='Promo Value')\n",
    "for key,df in globals()[f\"modified_promotionBrands{slides_Period}\"].items():\n",
    "     df = df.sort_values(by='Promo Value', ascending=False).reset_index(drop=True)\n",
    "     df = df[~df['Top Brands'].str.contains('Others', case=False)]\n",
    "     df = df[~df['Top Brands'].str.contains('Grand Total', case=False)]\n",
    "     df = df[df['Value Share'] > 0.01]\n",
    "     df['VSOD Evaluation vs YA'] = df['VSOD Evaluation vs YA'].astype(float)\n",
    "     df['Promo Value Uplift vs YA'] = df['Promo Value Uplift vs YA'].astype(float)\n",
    "     if df.shape[0] >0:\n",
    "          promotionsBrandNOTSortedTotalFinal[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "75e0e42f-2500-4d43-9ed2-2b5ac567a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selectedBrands_og = selectedBrands\n",
    "#selectedBrands= selectedBrands + [\"Grand Total\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "04ef915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_brands(data_dict, client_brands):\n",
    "    filtered_dict = {}\n",
    "    \n",
    "    for key, df in data_dict.items():\n",
    "        # Sort by Promo Value descending and get top 10\n",
    "        top_10 = df.sort_values('Promo Value', ascending=False).head(10)\n",
    "        \n",
    "        # Add any missing client brands\n",
    "        client_rows = df[df['Top Brands'].isin(client_brands)]\n",
    "        \n",
    "        # Combine, remove duplicates, take top 9 (with grand total) then sort again\n",
    "        filtered_dict[key] = pd.concat([client_rows,top_10]).drop_duplicates().head(9).sort_values('Promo Value', ascending=False)\n",
    "    \n",
    "    return filtered_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f63ad683",
   "metadata": {},
   "outputs": [],
   "source": [
    "promotionsBrandsSelected = filter_brands(globals()[f\"modified_promotionBrands{slides_Period}_total\"], client_brands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ab470824-4116-42ea-b87c-150650a1d61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# promotionsBrandsSelected={key:globals()[f\"modified_promotionBrands{slides_Period}_total\"][key][globals()[f\"modified_promotionBrands{slides_Period}_total\"][key]['Top Brands'].isin(selectedBrands)].sort_values(by='Promo Value',ascending=False) for key in globals()[f\"modified_promotionBrands{slides_Period}_total\"].keys()   if all(cat != key.split(' | ')[0] for cat in categories)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "5deb8699",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in promotionsBrandsSelected:\n",
    "    grand_total_row = promotionsBrandsSelected[key].loc[promotionsBrandsSelected[key]['Top Brands'] == 'Grand Total']\n",
    "    sorted_df = promotionsBrandsSelected[key].loc[promotionsBrandsSelected[key]['Top Brands'] != 'Grand Total']\n",
    "    promotionsBrandsSelected[key] = pd.concat([grand_total_row, sorted_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "bf5988c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selectedBrands = selectedBrands_og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "6d4a6ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not including client brands\n",
    "promotionsNotBrandsSelected = {\n",
    "    key: globals()[f\"modified_promotionBrands{slides_Period}_total\"][key][\n",
    "        ~globals()[f\"modified_promotionBrands{slides_Period}_total\"][key]['Top Brands'].isin(selectedBrands)\n",
    "    ].sort_values(by='Value Share', ascending=False)\n",
    "    for key in globals()[f\"modified_promotionBrands{slides_Period}_total\"].keys()\n",
    "    if all(cat != key.split(' | ')[0] for cat in categories)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "5825f852-d5a8-4717-863c-60bce7831474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "promotionsBrandsWithMarket=concatAttribute(promotionsBrandsSelected,marketList)\n",
    "promotionsBrandsWithMarket = fillingMissingBrands(promotionsBrandsWithMarket,client_brands)\n",
    "promotionsNotBrandsWithMarket=concatAttribute(promotionsNotBrandsSelected,marketList)\n",
    "promotionsNotBrandsWithMarket = fillingMissingBrands(promotionsNotBrandsWithMarket,client_brands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "762fb5e2-0b4d-442f-9531-040980af3115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_market(data, Scope):\n",
    "    final = {}\n",
    "    for k,df in data.items():\n",
    "        for key, value in Scope.items():\n",
    "            df_market = df[df['SOURCE'].isin(value)]\n",
    "            df_market = df_market.reset_index(drop=True)\n",
    "            if df_market.shape[0] >0:\n",
    "                final[k + ' | ' + value[0]] = df_market\n",
    "    return final        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b2a003a6-6da6-495c-a2d9-a9b0af5a7a88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newpromotionsBrandsWithMarket = split_market(promotionsBrandsWithMarket,Scope)\n",
    "newpromotionsNotBrandsWithMarket = split_market(promotionsNotBrandsWithMarket,Scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "6e045f79-110e-4cb8-b237-b514151b9c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatAttributeNew(sorted):\n",
    "    \"\"\"\n",
    "    Concatenate DataFrames from a sorted dictionary based on exact matches of categories, sectors, segments,\n",
    "    subsegments, and subcategories. Adds a 'SOURCE' column to each DataFrame indicating its market.\n",
    "\n",
    "    Parameters:\n",
    "    sorted (dict): Dictionary with keys like 'category | sector | segment | brand' and values as DataFrames.\n",
    "    categories, sectors, segments, subsegments, subcategories (list): Lists of strings to match exactly.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary with matched group names as keys and concatenated DataFrames as values.\n",
    "    \"\"\"\n",
    "    # Combine all lists and preserve order without duplicates\n",
    "    lis = list(dict.fromkeys(categories + sectors + segments + subsegments + subcategories))\n",
    "\n",
    "    marketDic = defaultdict(list)\n",
    "    concatenatedDic = {}\n",
    "\n",
    "    for i in lis:\n",
    "        for key, df in sorted.items():\n",
    "            parts = key.split(' | ')\n",
    "            if i in parts:\n",
    "                # Determine market label\n",
    "        \n",
    "                market_label = parts[1]  # category\n",
    "\n",
    "                df = df.copy()  # Avoid modifying original\n",
    "                df['SOURCE'] = market_label\n",
    "                marketDic[i].append(df)\n",
    "\n",
    "        if marketDic[i]:\n",
    "            concatenatedDic[i] = pd.concat(marketDic[i], ignore_index=True)\n",
    "\n",
    "    return concatenatedDic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "28e29be2-2f65-4603-8858-1087e008b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "concated = concatAttributeNew(globals()[f\"modified_promotionBrands{slides_Period}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "84e39181",
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature_share & display_share:\n",
    "    concated1 = concatAttributeNew(globals()[f\"modified_promotionBrands_share{slides_Period}\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "8b8c6fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[f\"new_modified_promotionProducts{slides_Period}\"] = filter_data(globals()[f\"modified_promotionProducts{slides_Period}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "d5316486-6b68-430c-963f-11df7ef98c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top20clientonly = filter_data_Top(globals()[f\"modified_promotionProducts{slides_Period}\"])\n",
    "bottom20clientonly = filter_data_Bot(globals()[f\"modified_promotionProducts{slides_Period}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "4f3e9198-c36a-4544-8a00-92a1e2ab89cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promotionsEndOfWeekCleaning(promotions_EndOfWeek, notInScope, col='Top Brands'):\n",
    "    promotionsEndOfWeek = {}\n",
    "    for key, value in promotions_EndOfWeek.items():\n",
    "        df = value.copy()\n",
    "        if df.shape[0] != 0:\n",
    "            modified_key = key\n",
    "            flag = False if any(element in modified_key for element in notInScope) else True\n",
    "            if flag:\n",
    "                promotionsEndOfWeek[modified_key] = df[df[col] != 'Grand Total'].reset_index(drop=True).replace(np.nan, 0)\n",
    "        else:\n",
    "            print(key, ' Is empty')\n",
    "    \n",
    "    return promotionsEndOfWeek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c3bdd031-7086-48bc-b9b6-d9e09be82bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod=cleaningData(promotions_EndOfWeek)\n",
    "promotionsEndOfWeekCleaned=promotionsEndOfWeekCleaning(mod,notInScope,col='End of Week')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "4e7408ac-109a-48e1-83ee-1f3acda454ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "brandMarketCategory = [key for key in promotionsEndOfWeekCleaned.keys() if any(cat in key.split(' | ')[0] for cat in categories )]\n",
    "if len(sectors) != 0:\n",
    "    brandMarketSector = [key for key in promotionsEndOfWeekCleaned.keys() if any(cat == key.split(' | ')[0] for cat in sectors )]\n",
    "if len(segments) != 0:\n",
    "    brandMarketSegment = [key for key in promotionsEndOfWeekCleaned.keys() if any(cat == key.split(' | ')[0] for cat in segments )]\n",
    "if len(subsegments) != 0:\n",
    "    brandMarketSubSegment = [key for key in promotionsEndOfWeekCleaned.keys() if any(cat == key.split(' | ')[0] for cat in subsegments )]\n",
    "if len(subcategories) != 0:\n",
    "    brandMarketSubCategory = [key for key in promotionsEndOfWeekCleaned.keys() if any(cat == key.split(' | ')[0] for cat in subcategories )]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "33070cde-4b18-410c-bf87-00d132014a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeDates(dfList, promotionsEndOfWeekCleaned):\n",
    "    # Create a list of unique brand-category combinations\n",
    "    brandCatList = sorted(set(key.split(' | ')[0] + ' | ' + key.split(' | ')[1] for key in dfList))\n",
    "    EndOfWeekcompletDate = {}\n",
    "    dfGroup = []\n",
    "    dic = defaultdict(int)\n",
    "    for key in brandCatList:\n",
    "        for name in dfList:\n",
    "            if (key.split(' | ')[0] == name.split(' | ')[0]) and (key.split(' | ')[1] == name.split(' | ')[1]):\n",
    "                dic[key] += 1\n",
    "                \n",
    "    # Iterate over unique brand-category combinations\n",
    "    for name in dic.keys():\n",
    "        # Get dataframe keys associated with the current brand-category combination\n",
    "        dfName = [key for key in dfList if name == (key.split(' | ')[0] + ' | ' + key.split(' | ')[1])]\n",
    "        uniqueDates = pd.concat([promotionsEndOfWeekCleaned[key] for key in dfName])[['End of Week']].drop_duplicates()\n",
    "        if uniqueDates.shape[0] > 0:\n",
    "            dfCompleteDates = {}\n",
    "            dfGroup.append(dfName)\n",
    "            for key in dfName:\n",
    "                EndOfWeekcompletDate[key] = pd.merge(uniqueDates, promotionsEndOfWeekCleaned[key], how='left').replace(np.nan, 0).sort_values(by='End of Week').reset_index(drop = True)\n",
    "    return EndOfWeekcompletDate, dfGroup, dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "26bde262-eab5-4afc-ab44-9c3658cb974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(categories) != 0:\n",
    "    dfCategory,catGroup,catDuplication=completeDates(brandMarketCategory,promotionsEndOfWeekCleaned)\n",
    "if len(sectors) != 0:\n",
    "    dfSector,secGroup,secDuplication=completeDates(brandMarketSector,promotionsEndOfWeekCleaned)\n",
    "if len(segments) != 0:\n",
    "    dfSegment,segGroup,segDuplication=completeDates(brandMarketSegment,promotionsEndOfWeekCleaned)\n",
    "if len(subsegments) != 0:\n",
    "    dfSubSegment,subsegGroup,subsegDuplication=completeDates(brandMarketSubSegment,promotionsEndOfWeekCleaned)\n",
    "if len(subcategories) != 0:\n",
    "    dfSubCategory,subcatGroup,subcatDuplication=completeDates(brandMarketSubCategory,promotionsEndOfWeekCleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "4108f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors):\n",
    "    sect_vsod_count =0\n",
    "    for key,df in sect_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                sect_vsod_count +=1\n",
    "    sect_vsod_count = sect_vsod_count *len(categories)\n",
    " \n",
    "if len(segments):\n",
    "    seg_vsod_count =0\n",
    "    for key,df in seg_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                seg_vsod_count +=1\n",
    "    seg_vsod_count = seg_vsod_count           \n",
    " \n",
    "if len(subsegments) >0:\n",
    "    subseg_vsod_count =0\n",
    "    for key,df in subseg_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                subseg_vsod_count +=1\n",
    "    subseg_vsod_count = subseg_vsod_count\n",
    " \n",
    "if len(subcategories) >0:\n",
    "    subcat_vsod_count =0\n",
    "    for key,df in subcat_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                subcat_vsod_count +=1\n",
    "    subcat_vsod_count = subcat_vsod_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "43c6f94a-d00f-46ad-9011-678073e6bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PromoRet ={}\n",
    "if len(categories)!=0:\n",
    "    first_key, first_value = next(iter(catDuplication.items()))\n",
    "    PromoRet.update({first_key: first_value})\n",
    "if len(sectors)!=0:\n",
    "    sec_key, sec_value = next(iter(secDuplication.items()))\n",
    "    PromoRet.update({sec_key:sec_value})\n",
    "if len(segments)!=0:\n",
    "    third_key, third_value = next(iter(segDuplication.items()))\n",
    "    PromoRet.update({third_key: third_value})\n",
    "if len(subsegments)!=0:\n",
    "    fourth_key, fourth_value = next(iter(subsegDuplication.items()))\n",
    "    PromoRet.update({fourth_key:fourth_value})\n",
    "if len(subcategories)!=0:\n",
    "    fifth_key, fifth_value = next(iter(subcatDuplication.items()))\n",
    "    PromoRet.update({fifth_key:fifth_value })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a728a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "PromoSalesTypes_data = {}\n",
    "for key in brands_promo_type.keys():\n",
    "    df=brands_promo_type[key].copy()\n",
    "    df[\"Promo Sales\"] = pd.to_numeric(df[\"Promo Sales\"], errors=\"coerce\").fillna(0)\n",
    "    df[\"Value Share\"] = pd.to_numeric(df[\"Value Share\"], errors=\"coerce\").fillna(0)\n",
    "    df = df[df['Promo Type'].notna()]\n",
    "    brand_totals = df.groupby(\"Top Brands\")['Promo Sales'].sum()\n",
    "    df[\"Brand Total Sales\"] = df[\"Top Brands\"].map(brand_totals)\n",
    "    df[\"% Promo Sales\"] = df[\"Promo Sales\"] / df[\"Brand Total Sales\"]\n",
    "\n",
    "    df = df[~df['Top Brands'].str.contains('Others|Grand Total', case=False)]\n",
    "    df = df[df['Value Share'] > 0.01]\n",
    "    df = df[df['Promo Sales'] > 0]\n",
    "    # Select client brands and additional brands needed to make 10 brands\n",
    "    df_client = selectClientBrands(brands_promo_type[key],'Top Brands', 'Value Share')\n",
    "    comp_brand = df[~df['Top Brands'].isin(cb for cb in client_brands)].drop_duplicates(\"Top Brands\")\n",
    "    if not df_client.empty:\n",
    "        comp_brand = comp_brand.nlargest(10-df_client[\"Top Brands\"].nunique(), \"Value Share\")[\"Top Brands\"].to_list()\n",
    "        # Concatenate client brands and additional brands\n",
    "        df = df[df[\"Top Brands\"].isin(comp_brand + client_brands)]\n",
    "        df = df.reset_index(drop=True)\n",
    "        df = df.sort_values(\"Value Share\", ascending=False).reset_index(drop=True)\n",
    "        df = df[~df['Promo Type'].fillna('').str.contains('NONE/PL|Undefined|Nan', na=False)]\n",
    "        # print(comp_brand)\n",
    "        if df.shape[0]:\n",
    "            PromoSalesTypes_data[key] =df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "88c1ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lis = []\n",
    "cat_lis = []\n",
    "if categories:\n",
    "    for i in range(len(catGroup)):\n",
    "        cat_lis += genrateIndexList(catGroup[i], chartIndex=14, chartCount=4)[0]\n",
    "    final_lis.append(cat_lis)\n",
    "else:\n",
    "    final_lis.append([])\n",
    "\n",
    "sec_lis = []\n",
    "if sectors:\n",
    "    for i in range(len(secGroup)):\n",
    "        sec_lis += genrateIndexList(secGroup[i], chartIndex=14, chartCount=4)[0]\n",
    "    final_lis.append(sec_lis)\n",
    "else:\n",
    "    final_lis.append([])\n",
    "\n",
    "seg_lis=[]\n",
    "if segments:\n",
    "    for i in range(len(segGroup)):\n",
    "        seg_lis += genrateIndexList(segGroup[i], chartIndex=14, chartCount=4)[0]\n",
    "    final_lis.append(seg_lis)\n",
    "\n",
    "else:\n",
    "    final_lis.append([])\n",
    "\n",
    "subseg_lis =[]\n",
    "if subsegments:\n",
    "    for i in range(len(subsegGroup)):\n",
    "        subseg_lis +=  genrateIndexList(subsegGroup[i], chartIndex=14, chartCount=4)[0]\n",
    "    final_lis.append(subseg_lis)\n",
    "else:\n",
    "    final_lis.append([])\n",
    "\n",
    "subcat_lis =[]\n",
    "if subcategories:\n",
    "    for i in range(len(subcatGroup)):\n",
    "        subcat_lis +=  genrateIndexList(subcatGroup[i], chartIndex=14, chartCount=4)[0]\n",
    "    final_lis.append(subcat_lis)\n",
    "else:\n",
    "    final_lis.append([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd4fa9",
   "metadata": {},
   "source": [
    "### New Slide 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "db1737be",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_month_year=MonthYear_clean(Category_MonthYear,column='Category')\n",
    "sector_month_year = MonthYear_clean(Sector_MonthYear,column='Sector')\n",
    "segment_month_year = MonthYear_clean(Segment_MonthYear,column='Segment')\n",
    "subcat_month_year = MonthYear_clean(SubCategory_MonthYear,column='SubCategory')\n",
    "subseg_month_year = MonthYear_clean(SubSegment_MonthYear,column='SubSegment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "6ac48172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_month_year(data, column):\n",
    "    final_month_year ={}\n",
    "    for key,df in data.items():\n",
    "        for sec in df[column].unique():\n",
    "            newkey = key + ' | ' + sec\n",
    "            new_df = df[df[column] == sec].reset_index(drop=True)\n",
    "            if new_df.shape[0] > 0:\n",
    "                final_month_year[newkey] = new_df\n",
    "    return final_month_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "265d60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_month_year1=split_month_year(category_month_year,'Category')\n",
    "sector_month_year1 = split_month_year(sector_month_year,'Sector')\n",
    "segment_month_year1 = split_month_year(segment_month_year,'Segment')\n",
    "subseg_month_year1 = split_month_year(subseg_month_year,'SubSegment')\n",
    "subcat_month_year1 = split_month_year(subcat_month_year,'SubCategory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b92a3b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_year1 = {}\n",
    "month_year1.update(sector_month_year1)\n",
    "month_year1.update(segment_month_year1)\n",
    "month_year1.update(subcat_month_year1)\n",
    "month_year1.update(subseg_month_year1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "a94833af",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandMarketCategory = [key for key in category_month_year1.keys() if any(cat == key.split(' | ')[2]  for cat in categories )]\n",
    "if len(sectors) != 0:\n",
    "    brandMarketSector = [key for key in sector_month_year1.keys() if any(cat == key.split(' | ')[2]  for cat in sectors )]\n",
    "if len(segments) != 0:\n",
    "    brandMarketSegment = [key for key in segment_month_year1.keys() if any(cat == key.split(' | ')[2]  for cat in segments )]\n",
    "if len(subsegments) != 0:\n",
    "    brandMarketSubSegment = [key for key in subseg_month_year1.keys() if any(cat == key.split(' | ')[2] for cat in subsegments )]\n",
    "if len(subcategories) != 0:\n",
    "    brandMarketSubCategory = [key for key in subcat_month_year1.keys() if any(cat == key.split(' | ')[2] for cat in subcategories )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "17cb72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeDates1(dfList, promotionsEndOfWeekCleaned,column=\"Sector\"):\n",
    "    brandCatList = sorted(set(key.split(' | ')[0]  for key in dfList))\n",
    "    EndOfWeekcompletDate = {}\n",
    "    dfGroup = []\n",
    "    dic = defaultdict(int)\n",
    "    for key in brandCatList:\n",
    "        for name in dfList:\n",
    "            if (key.split(' | ')[0] == name.split(' | ')[0]):\n",
    "                \n",
    "                dic[key] += 1\n",
    "    for name in dic.keys():\n",
    "\n",
    "        if column == \"Sector\" :\n",
    "            dfName = [key for key in dfList if name == key.split(' | ')[0] and len(name.split(' | ')) == 1]\n",
    "        else:\n",
    "            dfName = [key for key in dfList if name == key.split(' | ')[0]  ]\n",
    "        uniqueDates = pd.concat([promotionsEndOfWeekCleaned[key] for key in dfName])[['MonthYear']].drop_duplicates()\n",
    "        dfCompleteDates = {}\n",
    "        dfGroup.append(dfName)\n",
    "        for key in dfName:\n",
    "            EndOfWeekcompletDate[key] = pd.merge(uniqueDates, promotionsEndOfWeekCleaned[key], how='left')#.replace(np.nan, 0)\n",
    "            column = EndOfWeekcompletDate[key].columns[1]\n",
    "            year = EndOfWeekcompletDate[key].columns[3]\n",
    "            monthyear = EndOfWeekcompletDate[key].columns[0]\n",
    "            EndOfWeekcompletDate[key][column] = EndOfWeekcompletDate[key][column].fillna(method='ffill')      \n",
    "            EndOfWeekcompletDate[key][year] = pd.to_datetime(EndOfWeekcompletDate[key][monthyear], format='%b-%y').dt.year\n",
    "            EndOfWeekcompletDate[key] = EndOfWeekcompletDate[key].fillna(0)\n",
    "    return EndOfWeekcompletDate, dfGroup, dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "3b1814ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCategory0,categoryGroup0,categoryDuplication0=completeDates1(brandMarketCategory,category_month_year1,column=\"Category\")\n",
    "if len(sectors) != 0:\n",
    "    dfSector0,secGroup0,secDuplication0=completeDates1(brandMarketSector,sector_month_year1,column=\"Sector\")\n",
    "if len(segments) != 0:\n",
    "    dfSegment0,segGroup0,segDuplication0=completeDates1(brandMarketSegment,segment_month_year1,column=\"Segment\")\n",
    "if len(subsegments) != 0:\n",
    "    dfSubSegment0,subsegGroup0,subsegDuplication0=completeDates1(brandMarketSubSegment,subseg_month_year1,column=\"Subsegment\")\n",
    "if len(subcategories) != 0:\n",
    "    dfSubCategory0,subcatGroup0,subcatDuplication0=completeDates1(brandMarketSubCategory,subcat_month_year1,column=\"Subcategory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "55074d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryGroup0=groupingkeys(categoryGroup0)\n",
    "if len(sectors) != 0:\n",
    "    secGroup0=groupingkeys(secGroup0)\n",
    "if len(segments) != 0:\n",
    "    segGroup0=groupingkeys(segGroup0)\n",
    "if len(subsegments) != 0:\n",
    "    subsegGroup0=groupingkeys(subsegGroup0)\n",
    "if len(subcategories) != 0:\n",
    "    subcatGroup0=groupingkeys(subcatGroup0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "94eb5ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], [22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22]]\n",
      "[[20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], [22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22], [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24]]\n",
      "[[20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], [22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22], [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24], []]\n"
     ]
    }
   ],
   "source": [
    "final_lis0 = []\n",
    "category_lis = []\n",
    "if categories:\n",
    "    for i in range(len(categoryGroup0)):\n",
    "        category_lis += genrateIndexList(categoryGroup0[i], chartIndex=19, chartCount=6)[0]\n",
    "final_lis0.append(category_lis)  # Append empty list if sectors is False\n",
    "\n",
    "sec_lis = []\n",
    "if sectors:\n",
    "    for i in range(len(secGroup0)):\n",
    "        sec_lis += genrateIndexList(secGroup0[i], chartIndex=19, chartCount=6)[0]\n",
    "final_lis0.append(sec_lis)  # Append empty list if sectors is False\n",
    "print(final_lis0)\n",
    "\n",
    "seg_lis = []\n",
    "if segments:\n",
    "    for i in range(len(segGroup0)):\n",
    "        seg_lis += genrateIndexList(segGroup0[i], chartIndex=19, chartCount=6)[0]\n",
    "final_lis0.append(seg_lis)  # Append empty list if segments is False\n",
    "print(final_lis0)\n",
    "\n",
    "subseg_lis = []\n",
    "if subsegments:\n",
    "    for i in range(len(subsegGroup0)):\n",
    "        subseg_lis += genrateIndexList(subsegGroup0[i], chartIndex=19, chartCount=6)[0]\n",
    "final_lis0.append(subseg_lis)  # Append empty list if subsegments is False\n",
    "print(final_lis0)\n",
    "\n",
    "subcat_lis = []\n",
    "if subcategories:\n",
    "    for i in range(len(subcatGroup0)):\n",
    "        subcat_lis += genrateIndexList(subcatGroup0[i], chartIndex=19, chartCount=6)[0]\n",
    "final_lis0.append(subcat_lis)  # Append empty list if subcategories is False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc50143",
   "metadata": {},
   "source": [
    "### New slide 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "3653fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[f\"modified_endofweek_{slides_Period}\"] = {}\n",
    "past_12_months = pd.date_range(end=end_date , periods=12, freq='M').strftime('%b-%y').tolist()\n",
    "for key in modified_promotionEndOfWeek.keys():\n",
    "    df=modified_promotionEndOfWeek[key].copy()\n",
    "    df['End of Week'] = pd.to_datetime(df['End of Week'])\n",
    "    filtered_df = df[df['End of Week'].dt.strftime('%b-%y').isin(past_12_months)]\n",
    "    if filtered_df.shape[0] >0:\n",
    "        globals()[f\"modified_endofweek_{slides_Period}\"][key] = filtered_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "06d18d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandMarketCategory= [key for key in globals()[f\"modified_endofweek_{slides_Period}\"].keys() if any(cat in key.split(' | ')[0] for cat in categories )]\n",
    "if len(sectors) != 0:\n",
    "    brandMarketSector = [key for key in globals()[f\"modified_endofweek_{slides_Period}\"].keys() if any(cat == key.split(' | ')[0] for cat in sectors )]\n",
    "if len(segments) != 0:\n",
    "    brandMarketSegment = [key for key in globals()[f\"modified_endofweek_{slides_Period}\"].keys() if any(cat == key.split(' | ')[0] for cat in segments )]\n",
    "if len(subsegments) != 0:\n",
    "    brandMarketSubSegment = [key for key in globals()[f\"modified_endofweek_{slides_Period}\"].keys() if any(cat == key.split(' | ')[0] for cat in subsegments )]\n",
    "if len(subcategories) != 0:\n",
    "    brandMarketSubCategory = [key for key in globals()[f\"modified_endofweek_{slides_Period}\"].keys() if any(cat == key.split(' | ')[0] for cat in subcategories )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "3ace0ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(categories) != 0:\n",
    "    dfCategory1,catGroup1,catDuplication1=completeDates(brandMarketCategory,globals()[f\"modified_endofweek_{slides_Period}\"])\n",
    "if len(sectors) != 0:\n",
    "    dfSector1,secGroup1,secDuplication1=completeDates(brandMarketSector,globals()[f\"modified_endofweek_{slides_Period}\"])\n",
    "if len(segments) != 0:\n",
    "    dfSegment1,segGroup1,segDuplication1=completeDates(brandMarketSegment,globals()[f\"modified_endofweek_{slides_Period}\"])\n",
    "if len(subsegments) != 0:\n",
    "    dfSubSegment1,subsegGroup1,subsegDuplication1=completeDates(brandMarketSubSegment,globals()[f\"modified_endofweek_{slides_Period}\"])\n",
    "if len(subcategories) != 0:\n",
    "    dfSubCategory1,subcatGroup1,subcatDuplication1=completeDates(brandMarketSubCategory,globals()[f\"modified_endofweek_{slides_Period}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "8479ede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promofrequencyclean(data):        \n",
    "        modified_dfCategory1 = {}\n",
    "        for k in data.keys():\n",
    "                chart_df=data[k].copy()\n",
    "                chart_df['Weekly VSOD'] = np.where((chart_df['VSOD']>.2)&(chart_df['Value Uplift (v. base) Normalized'] != ''),1,None)\n",
    "                chart_df['try'] = 0\n",
    "                chart_df['New Uplift'] = 0\n",
    "                chart_df['try'] = np.where((chart_df['Value Uplift (v. base) Normalized']>=2),1.8,chart_df['Value Uplift (v. base) Normalized'])\n",
    "                chart_df['New Uplift'] = np.where((chart_df['Weekly VSOD']==1)&(chart_df['Value Uplift (v. base) Normalized']>0.05),chart_df['try'],None)\n",
    "                if not chart_df['Weekly VSOD'].isnull().all():\n",
    "                        modified_dfCategory1[k]= chart_df \n",
    "        return modified_dfCategory1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "9ad97599",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(categories)!=0: \n",
    "    modified_dfCategory1=promofrequencyclean(dfCategory1)\n",
    "if len(sectors)!=0: \n",
    "    modified_dfSector1=promofrequencyclean(dfSector1)\n",
    "if len(segments)!=0: \n",
    "    modified_dfSegment1=promofrequencyclean(dfSegment1)\n",
    "if len(subsegments)!=0: \n",
    "    modified_dfSubSegment1=promofrequencyclean(dfSubSegment1)\n",
    "if len(subcategories)!=0: \n",
    "    modified_dfSubCategory1=promofrequencyclean(dfSubCategory1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "2f0aae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandMarketCategory= [key for key in modified_dfCategory1.keys() if any(cat in key.split(' | ')[0] for cat in categories )]\n",
    "if len(sectors) != 0:\n",
    "    brandMarketSector = [key for key in modified_dfSector1.keys() if any(cat == key.split(' | ')[0] for cat in sectors )]\n",
    "if len(segments) != 0:\n",
    "    brandMarketSegment = [key for key in modified_dfSegment1.keys() if any(cat == key.split(' | ')[0] for cat in segments )]\n",
    "if len(subsegments) != 0:\n",
    "    brandMarketSubSegment = [key for key in modified_dfSubSegment1.keys() if any(cat == key.split(' | ')[0] for cat in subsegments )]\n",
    "if len(subcategories) != 0:\n",
    "    brandMarketSubCategory = [key for key in modified_dfSubCategory1.keys() if any(cat == key.split(' | ')[0] for cat in subcategories )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "31f3763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(categories) != 0:\n",
    "    dfCategory1,catGroup1,catDuplication1=completeDates(brandMarketCategory,globals()[f\"modified_endofweek_{slides_Period}\"])\n",
    "if len(sectors) != 0:\n",
    "    dfSector1,secGroup1,secDuplication1=completeDates(brandMarketSector,globals()[f\"modified_endofweek_{slides_Period}\"])\n",
    "if len(segments) != 0:\n",
    "    dfSegment1,segGroup1,segDuplication1=completeDates(brandMarketSegment,globals()[f\"modified_endofweek_{slides_Period}\"])\n",
    "if len(subsegments) != 0:\n",
    "    dfSubSegment1,subsegGroup1,subsegDuplication1=completeDates(brandMarketSubSegment,globals()[f\"modified_endofweek_{slides_Period}\"])\n",
    "if len(subcategories) != 0:\n",
    "    dfSubCategory1,subcatGroup1,subcatDuplication1=completeDates(brandMarketSubCategory,globals()[f\"modified_endofweek_{slides_Period}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "c2bbe9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_region(data):\n",
    "    # Define categories for grouping\n",
    "    market_groups = {\n",
    "        \"RETAILER_REGIONS\": regions_RET,\n",
    "        \"RETAILER_CHANNELS\": channels_RET,\n",
    "        \"RETAILER_MARKET\": market_RET,\n",
    "        \"CHANNEL_REGIONS\": regions_CHAN,\n",
    "        \"CHANNEL_CHANNELS\": channels_CHAN,\n",
    "        \"CHANNEL_MARKET\": market_CHAN,\n",
    "        f\"{customareas}_REGIONS\": regions_CUST,\n",
    "        f\"{customareas}_CHANNELS\": channels_CUST,\n",
    "        f\"{customareas}_MARKET\": market_CUST,\n",
    "    }\n",
    "    result = []\n",
    "    for sublist in data:\n",
    "        for category, keywords in market_groups.items():\n",
    "            # Filter items matching the current category\n",
    "            base_category = category.split(\"_\")[0]\n",
    "\n",
    "            group = [\n",
    "                f\"{item} | {base_category}\" for item in sublist if item.split(\" | \")[-1] in keywords\n",
    "            ]\n",
    "            if group:  # Append only non-empty groups\n",
    "                result.append(group)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "016f5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(categories)>0:\n",
    "    catGroup1 = group_by_region(catGroup1)\n",
    "if len(sectors)>0:\n",
    "    secGroup1 = group_by_region(secGroup1)\n",
    "if len(segments)>0:\n",
    "    segGroup1 = group_by_region(segGroup1)\n",
    "if len(subsegments)>0:\n",
    "    subsegGroup1 = group_by_region(subsegGroup1)\n",
    "if len(subcategories)>0:\n",
    "    subcatGroup1 = group_by_region(subcatGroup1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "95b943e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lis1 = []\n",
    "cat_lis = []\n",
    "if categories:\n",
    "    for i in range(len(catGroup1)):\n",
    "        cat_lis += genrateIndexList(catGroup1[i], chartIndex=25, chartCount=4)[0]\n",
    "    final_lis1.append(cat_lis)\n",
    "else:\n",
    "    final_lis1.append([])\n",
    "\n",
    "sec_lis = []\n",
    "if sectors:\n",
    "    for i in range(len(secGroup1)):\n",
    "        sec_lis += genrateIndexList(secGroup1[i], chartIndex=25, chartCount=4)[0]\n",
    "    final_lis1.append(sec_lis)\n",
    "else:\n",
    "    final_lis1.append([])\n",
    "\n",
    "seg_lis=[]\n",
    "if segments:\n",
    "    for i in range(len(segGroup1)):\n",
    "        seg_lis += genrateIndexList(segGroup1[i], chartIndex=25, chartCount=4)[0]\n",
    "    final_lis1.append(seg_lis)\n",
    "\n",
    "else:\n",
    "    final_lis1.append([])\n",
    "\n",
    "subseg_lis =[]\n",
    "if subsegments:\n",
    "    for i in range(len(subsegGroup1)):\n",
    "        subseg_lis +=  genrateIndexList(subsegGroup1[i], chartIndex=25, chartCount=4)[0]\n",
    "    final_lis1.append(subseg_lis)\n",
    "else:\n",
    "    final_lis1.append([])\n",
    "\n",
    "subcat_lis =[]\n",
    "if subcategories:\n",
    "    for i in range(len(subcatGroup1)):\n",
    "        subcat_lis +=  genrateIndexList(subcatGroup1[i], chartIndex=25, chartCount=4)[0]\n",
    "    final_lis1.append(subcat_lis)\n",
    "else:\n",
    "    final_lis1.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "21faef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "retailer=regions_RET+channels_RET+market_RET\n",
    "channels=regions_CHAN+channels_CHAN+channels_CHAN\n",
    "customarea=regions_CUST+channels_CUST+market_CUST\n",
    "def addarea(modified_dfCategory1,retailer,market=\"RETAILER\"):\n",
    "    keys_to_modify = [k for k in modified_dfCategory1.keys() if k.split(\" | \")[-1] in retailer]\n",
    "    for k in keys_to_modify:\n",
    "        new_key = k + \" | \"+ market\n",
    "        modified_dfCategory1[new_key] = modified_dfCategory1[k]  \n",
    "        del modified_dfCategory1[k]       \n",
    "    return modified_dfCategory1      \n",
    "if len(categories)>0:            \n",
    "    modified_dfCategory1=addarea(modified_dfCategory1,retailer,market=\"RETAILER\")\n",
    "    modified_dfCategory1=addarea(modified_dfCategory1,channels,market=\"CHANNEL\")\n",
    "    modified_dfCategory1=addarea(modified_dfCategory1,customarea,market=f\"{customareas}\")\n",
    "\n",
    "if len(sectors)>0:            \n",
    "    modified_dfSector1=addarea(modified_dfSector1,retailer,market=\"RETAILER\")\n",
    "    modified_dfSector1=addarea(modified_dfSector1,channels,market=\"CHANNEL\")\n",
    "    modified_dfSector1=addarea(modified_dfSector1,customarea,market=f\"{customareas}\")\n",
    "if len(segments)>0:            \n",
    "    modified_dfSegment1=addarea(modified_dfSegment1,retailer,market=\"RETAILER\")\n",
    "    modified_dfSegment1=addarea(modified_dfSegment1,channels,market=\"CHANNEL\")\n",
    "    modified_dfSegment1=addarea(modified_dfSegment1,customarea,market=f\"{customareas}\")\n",
    "if len(subsegments)>0:            \n",
    "    modified_dfSubSegment1=addarea(modified_dfSubSegment1,retailer,market=\"RETAILER\")\n",
    "    modified_dfSubSegment1=addarea(modified_dfSubSegment1,channels,market=\"CHANNEL\")\n",
    "    modified_dfSubSegment1=addarea(modified_dfSubSegment1,customarea,market=f\"{customareas}\")\n",
    "if len(subcategories)>0:            \n",
    "    modified_dfSubCategory1=addarea(modified_dfSubCategory1,retailer,market=\"RETAILER\")\n",
    "    modified_dfSubCategory1=addarea(modified_dfSubCategory1,channels,market=\"CHANNEL\")\n",
    "    modified_dfSubCategory1=addarea(modified_dfSubCategory1,customarea,market=f\"{customareas}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ec5211df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in list(globals()[f\"modified_promotionBrands{slides_Period}\"].keys()):  # Convert to list to avoid runtime errors\n",
    "    df = globals()[f\"modified_promotionBrands{slides_Period}\"][k].copy()\n",
    "    # Filter rows based on 'Top Brands'\n",
    "    df = df[~df['Top Brands'].str.contains('Others', case=False, na=False)]\n",
    "    df = df[~df['Top Brands'].str.contains('Grand Total', case=False, na=False)]\n",
    "    df = df[df['Value Share'] > 0.01]\n",
    "    if not df.empty:\n",
    "        globals()[f\"modified_promotionBrands{slides_Period}\"][k] = df\n",
    "    else:\n",
    "        del globals()[f\"modified_promotionBrands{slides_Period}\"][k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "25d54fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature_share & display_share:\n",
    "    for k in list(globals()[f\"modified_promotionBrands_share{slides_Period}\"].keys()):  # Convert to list to avoid runtime errors\n",
    "        df = globals()[f\"modified_promotionBrands_share{slides_Period}\"][k].copy()\n",
    "        # Filter rows based on 'Top Brands'\n",
    "        df = df[~df['Top Brands'].str.contains('Others', case=False, na=False)]\n",
    "        df = df[~df['Top Brands'].str.contains('Grand Total', case=False, na=False)]\n",
    "        df = df[df['Value Share'] > 0.01]\n",
    "        if not df.empty:\n",
    "            globals()[f\"modified_promotionBrands_share{slides_Period}\"][k] = df\n",
    "        else:\n",
    "            del globals()[f\"modified_promotionBrands_share{slides_Period}\"][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "ecdd4477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newpromotionsNotBrandsWithMarket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ee2a74",
   "metadata": {},
   "source": [
    "\n",
    "## Slide duplication: index, duplication and section names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "ceca67f7-038d-44e1-98aa-cbc9a32d8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [*[0]*5,\n",
    "         #*[1]*5,\n",
    "         *[1]*5,\n",
    "         *[2]*5,\n",
    "         *[3]*5,\n",
    "         *[4]*5,\n",
    "         *[5]*5,\n",
    "         *[6]*5,\n",
    "         *[7]*5,\n",
    "         *[8]*4,\n",
    "         *[9]*5,\n",
    "         *[10]*5,\n",
    "         *[11]*5,\n",
    "         *[12]*5,\n",
    "         *[13]*5,\n",
    "         *[14]*5,\n",
    "         *final_lis,\n",
    "         *[19]*5,\n",
    "         *final_lis0,\n",
    "         *final_lis1,\n",
    "         *[0]*5,\n",
    "         *[1]*5,\n",
    "         *[2]*5,\n",
    "         *[9]*5,\n",
    "         *[10]*5,\n",
    "        #  *[11]*5,\n",
    "         *[12]*5,\n",
    "         *[13]*5\n",
    "         #*[14]*5\n",
    "        ]\n",
    "duplication = combine_duplications(Scope,count_df,[#modified_promotionBrandsP12M, #0\n",
    "                                                   promotionsBrandSortedTotalFinal, #1\n",
    "                                                   newpromotionsBrandsWithMarket, #2\n",
    "                                                   concated, #3\n",
    "                                                   globals()[f\"modified_promotionProducts{slides_Period}_volumeuplift\"], #4\n",
    "                                                   globals()[f\"new_modified_promotionProducts{slides_Period}\"], #5\n",
    "                                                   globals()[f\"new_modified_promotionProducts{slides_Period}\"], #6\n",
    "                                                   top20clientonly, #7\n",
    "                                                   bottom20clientonly,#8\n",
    "                                                   globals()[f\"modified_promotionBrands{slides_Period}\"], #10\n",
    "                                                   newModifiedBrands, #11\n",
    "                                                   PromoSalesTypes_data if promo_type else None,#12\n",
    "                                                   globals()[f\"modified_promotionBrands_share{slides_Period}\"] if feature_share else None, #13\n",
    "                                                   globals()[f\"modified_promotionBrands_share{slides_Period}\"] if display_share else None, #14\n",
    "                                                   modified_promotionEndOfWeek,#15\n",
    "                                                   PromoRet, #16-19\n",
    "                                                   modified_valueUplift, #20\n",
    "                                                   #month_year1,#21\n",
    "                                                   #modified_endofweek_P12M, #22\n",
    "                                                   #modified_promotionBrandsP12M, #0 with no client\n",
    "                                                   promotionsBrandNOTSortedTotalFinal, #1 with no client\n",
    "                                                   newpromotionsNotBrandsWithMarket, #2 with no client\n",
    "                                                   concated, #3 with no client\n",
    "                                                   globals()[f\"modified_promotionBrands{slides_Period}\"], # 10 with no client\n",
    "                                                   newModifiedBrands, #11 with no client\n",
    "                                                   #PromoSalesTypes_data if promo_type else None,#12  with no client\n",
    "                                                   globals()[f\"modified_promotionBrands_share{slides_Period}\"] if feature_share else None, #13  with no client\n",
    "                                                   globals()[f\"modified_promotionBrands_share{slides_Period}\"] if display_share else None #14 with no client\n",
    "                                                  ])\n",
    "section_names = [#\"Promo Value Sale\",#0\n",
    "                 \"Promo Evolution\", #1\n",
    "                 \"VSOD Summary by Sector\" , #2\n",
    "                 \"Value uplift by retailer by brand\", #3 \n",
    "                 \"Volume Uplift vs discount depth\",#4\n",
    "                 \"Value Uplift vs Promo Efficiency Quadrant\", #5\n",
    "                 \"Top 20 promotions\", #6\n",
    "                 \"Top 20 promotions CLIENT ONLY\", #7\n",
    "                 \"Bottom 20 promotions CLIENT ONLY\", #8\n",
    "                 \"Promo share vs Value Share\", #10\n",
    "                 \"Promo Sales by total size\",#11\n",
    "                 \"Promo Sales by promo type\", #12\n",
    "                 \"Feature Share vs Fair Share\", #13\n",
    "                 \"Display Share vs Fair Share\", #14\n",
    "                 \"Promo Frequency learnings\", #15\n",
    "                 \"Promo sales per retailer\", #16-19\n",
    "                 \"Value Uplift vs discount depth\" ,#20\n",
    "                 #\"Seasonality Index\",#21\n",
    "                 #\"Promotional Frequency Analysis\", #22\n",
    "                 #\"Promo Value Sale no client prio\",\n",
    "                 \"Promo Evolution no client prio\",\n",
    "                 \"VSOD Summary by Sector no client prio\",\n",
    "                 \"Value uplift by retailer by brand no client prio\",\n",
    "                \"Promo share vs Value Share no client prio\", #10\n",
    "                 \"Promo Sales by total size no client prio\",#11\n",
    "                 #\"Promo Sales by promo type no client prio\", #12\n",
    "                 \"Feature Share vs Fair Share no client prio\", #13\n",
    "                 \"Display Share vs Fair Share no client prio\" #14\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "#duplication.insert(89, 0)\n",
    "\n",
    "if len(sectors) > 0:\n",
    "       #duplication.insert(45,(len(client_manuf)+len(client_brands))*len(categories)* len(marketList))\n",
    "       duplication.insert(40, sect_vsod_count)\n",
    "if len(segments) > 0:\n",
    "        #duplication.insert(46,(len(client_manuf)+len(client_brands))*len(sectors)* len(marketList)) \n",
    "         duplication.insert(41, seg_vsod_count)\n",
    " \n",
    "else:\n",
    "    duplication.insert(41,0)  \n",
    "  \n",
    "if len(subsegments) > 0:\n",
    "        #duplication.insert(47,(len(client_manuf)+len(client_brands))*len(segments)* len(marketList))\n",
    "        duplication.insert(42, subseg_vsod_count)\n",
    "\n",
    "else:\n",
    "    duplication.insert(42,0)\n",
    "\n",
    "if len(subcategories) > 0:\n",
    "        #duplication.insert(48,(len(client_manuf)+len(client_brands))*len(segments)* len(marketList))\n",
    "        duplication.insert(43, subcat_vsod_count)\n",
    "\n",
    "else:\n",
    "    duplication.insert(43,0)\n",
    "\n",
    "\n",
    "duplication.insert(84,1)\n",
    "duplication.insert(85, 1)\n",
    "duplication.insert(86, 1)\n",
    "duplication.insert(87, 1)\n",
    "duplication.insert(88, 0)\n",
    "duplication.insert(89, 1)\n",
    "duplication.insert(90, 1)\n",
    "duplication.insert(91, 1)\n",
    "duplication.insert(92, 1)\n",
    "duplication.insert(93, 0)\n",
    "\n",
    "section_names = [f\"{name} {suffix}\" for name in section_names for suffix in suffixes]\n",
    "\n",
    "section_names.insert(40,'Volume Sold on Deal Sector')\n",
    "section_names.insert(41,'Volume Sold on Deal Segment')\n",
    "section_names.insert(42,'Volume Sold on Deal SubSegment')\n",
    "section_names.insert(43,'Volume Sold on Deal SubCategory')\n",
    "\n",
    "section_names.insert(84,'Seasonality Index Category')\n",
    "section_names.insert(85,'Seasonality Index Sector')\n",
    "section_names.insert(86,'Seasonality Index Segment')\n",
    "section_names.insert(87,'Seasonality Index Subsegment')\n",
    "section_names.insert(88,'Seasonality Index Subcategory')\n",
    "\n",
    "section_names.insert(89,'Promotional Frequency Analysis Category')\n",
    "section_names.insert(90,'Promotional Frequency Analysis Sector')\n",
    "section_names.insert(91,'Promotional Frequency Analysis Segment')\n",
    "section_names.insert(92,'Promotional Frequency Analysis Subsegment')\n",
    "section_names.insert(93,'Promotional Frequency Analysis Subcategory')\n",
    "#section_names.insert(94,'Promotional Frequency Analysis Subcategory')\n",
    "\n",
    "duplication[77]=1\n",
    "#index = [i for i in index if i != []]\n",
    "# duplication = [i for i in duplication if i != []]\n",
    "#\n",
    "\n",
    "path = os.getcwd() + '//Promotion base.pptx'\n",
    "new_pre = os.getcwd() + '//slide duplicated.pptx'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19bbcf3",
   "metadata": {},
   "source": [
    "### Deck 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "1a93e125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 8, 8, 8, 8, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, [18, 18, 18, 18, 18, 18, 18, 18], [18, 18, 18, 18, 18, 18, 18, 18], [18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18], [], [], 19, 19, 19, 19, 19, [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], [22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22], [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24], [], [], [26, 29, 26, 29, 26, 26, 29, 26, 29, 26], [26, 29, 26, 29, 26, 26, 29, 26, 29, 26], [26, 29, 26, 29, 26, 26, 29, 26, 29, 26, 26, 29, 26, 29, 26, 26, 29, 26, 29, 26], [], [], 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13]\n",
      "[16, 32, 176, 0, 0, 16, 16, 16, 0, 0, 1, 3, 11, 0, 0, 16, 30, 129, 0, 0, 16, 32, 143, 0, 0, 16, 32, 143, 0, 0, 16, 16, 48, 0, 0, 16, 16, 48, 0, 0, 32, 96, 0, 0, 16, 48, 176, 0, 0, 16, 32, 176, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 32, 128, 0, 0, 1, 1, 1, 1, 0, 9, 9, 20, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 16, 48, 176, 0, 0, 0, 16, 16, 0, 0, 1, 3, 11, 0, 0, 16, 48, 176, 0, 0, 16, 32, 176, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['Promo Evolution Category', 'Promo Evolution Sector', 'Promo Evolution Segment', 'Promo Evolution SubSegment', 'Promo Evolution SubCategory', 'VSOD Summary by Sector Category', 'VSOD Summary by Sector Sector', 'VSOD Summary by Sector Segment', 'VSOD Summary by Sector SubSegment', 'VSOD Summary by Sector SubCategory', 'Value uplift by retailer by brand Category', 'Value uplift by retailer by brand Sector', 'Value uplift by retailer by brand Segment', 'Value uplift by retailer by brand SubSegment', 'Value uplift by retailer by brand SubCategory', 'Volume Uplift vs discount depth Category', 'Volume Uplift vs discount depth Sector', 'Volume Uplift vs discount depth Segment', 'Volume Uplift vs discount depth SubSegment', 'Volume Uplift vs discount depth SubCategory', 'Value Uplift vs Promo Efficiency Quadrant Category', 'Value Uplift vs Promo Efficiency Quadrant Sector', 'Value Uplift vs Promo Efficiency Quadrant Segment', 'Value Uplift vs Promo Efficiency Quadrant SubSegment', 'Value Uplift vs Promo Efficiency Quadrant SubCategory', 'Top 20 promotions Category', 'Top 20 promotions Sector', 'Top 20 promotions Segment', 'Top 20 promotions SubSegment', 'Top 20 promotions SubCategory', 'Top 20 promotions CLIENT ONLY Category', 'Top 20 promotions CLIENT ONLY Sector', 'Top 20 promotions CLIENT ONLY Segment', 'Top 20 promotions CLIENT ONLY SubSegment', 'Top 20 promotions CLIENT ONLY SubCategory', 'Bottom 20 promotions CLIENT ONLY Category', 'Bottom 20 promotions CLIENT ONLY Sector', 'Bottom 20 promotions CLIENT ONLY Segment', 'Bottom 20 promotions CLIENT ONLY SubSegment', 'Bottom 20 promotions CLIENT ONLY SubCategory', 'Volume Sold on Deal Sector', 'Volume Sold on Deal Segment', 'Volume Sold on Deal SubSegment', 'Volume Sold on Deal SubCategory', 'Promo share vs Value Share Category', 'Promo share vs Value Share Sector', 'Promo share vs Value Share Segment', 'Promo share vs Value Share SubSegment', 'Promo share vs Value Share SubCategory', 'Promo Sales by total size Category', 'Promo Sales by total size Sector', 'Promo Sales by total size Segment', 'Promo Sales by total size SubSegment', 'Promo Sales by total size SubCategory', 'Promo Sales by promo type Category', 'Promo Sales by promo type Sector', 'Promo Sales by promo type Segment', 'Promo Sales by promo type SubSegment', 'Promo Sales by promo type SubCategory', 'Feature Share vs Fair Share Category', 'Feature Share vs Fair Share Sector', 'Feature Share vs Fair Share Segment', 'Feature Share vs Fair Share SubSegment', 'Feature Share vs Fair Share SubCategory', 'Display Share vs Fair Share Category', 'Display Share vs Fair Share Sector', 'Display Share vs Fair Share Segment', 'Display Share vs Fair Share SubSegment', 'Display Share vs Fair Share SubCategory', 'Promo Frequency learnings Category', 'Promo Frequency learnings Sector', 'Promo Frequency learnings Segment', 'Promo Frequency learnings SubSegment', 'Promo Frequency learnings SubCategory', 'Promo sales per retailer Category', 'Promo sales per retailer Sector', 'Promo sales per retailer Segment', 'Promo sales per retailer SubSegment', 'Promo sales per retailer SubCategory', 'Value Uplift vs discount depth Category', 'Value Uplift vs discount depth Sector', 'Value Uplift vs discount depth Segment', 'Value Uplift vs discount depth SubSegment', 'Value Uplift vs discount depth SubCategory', 'Seasonality Index Category', 'Seasonality Index Sector', 'Seasonality Index Segment', 'Seasonality Index Subsegment', 'Seasonality Index Subcategory', 'Promotional Frequency Analysis Category', 'Promotional Frequency Analysis Sector', 'Promotional Frequency Analysis Segment', 'Promotional Frequency Analysis Subsegment', 'Promotional Frequency Analysis Subcategory', 'Promo Evolution no client prio Category', 'Promo Evolution no client prio Sector', 'Promo Evolution no client prio Segment', 'Promo Evolution no client prio SubSegment', 'Promo Evolution no client prio SubCategory', 'VSOD Summary by Sector no client prio Category', 'VSOD Summary by Sector no client prio Sector', 'VSOD Summary by Sector no client prio Segment', 'VSOD Summary by Sector no client prio SubSegment', 'VSOD Summary by Sector no client prio SubCategory', 'Value uplift by retailer by brand no client prio Category', 'Value uplift by retailer by brand no client prio Sector', 'Value uplift by retailer by brand no client prio Segment', 'Value uplift by retailer by brand no client prio SubSegment', 'Value uplift by retailer by brand no client prio SubCategory', 'Promo share vs Value Share no client prio Category', 'Promo share vs Value Share no client prio Sector', 'Promo share vs Value Share no client prio Segment', 'Promo share vs Value Share no client prio SubSegment', 'Promo share vs Value Share no client prio SubCategory', 'Promo Sales by total size no client prio Category', 'Promo Sales by total size no client prio Sector', 'Promo Sales by total size no client prio Segment', 'Promo Sales by total size no client prio SubSegment', 'Promo Sales by total size no client prio SubCategory', 'Feature Share vs Fair Share no client prio Category', 'Feature Share vs Fair Share no client prio Sector', 'Feature Share vs Fair Share no client prio Segment', 'Feature Share vs Fair Share no client prio SubSegment', 'Feature Share vs Fair Share no client prio SubCategory', 'Display Share vs Fair Share no client prio Category', 'Display Share vs Fair Share no client prio Sector', 'Display Share vs Fair Share no client prio Segment', 'Display Share vs Fair Share no client prio SubSegment', 'Display Share vs Fair Share no client prio SubCategory']\n",
      "129\n",
      "129\n",
      "129\n",
      "[[18, 18, 18, 18, 18, 18, 18, 18], [18, 18, 18, 18, 18, 18, 18, 18], [18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18], [], []]\n",
      "[[26, 29, 26, 29, 26, 26, 29, 26, 29, 26], [26, 29, 26, 29, 26, 26, 29, 26, 29, 26], [26, 29, 26, 29, 26, 26, 29, 26, 29, 26, 26, 29, 26, 29, 26, 26, 29, 26, 29, 26], [], []]\n",
      "2589\n"
     ]
    }
   ],
   "source": [
    "print(index)\n",
    "print(duplication)\n",
    "print(section_names)\n",
    "print(len(index))\n",
    "print(len(duplication))\n",
    "print(len(section_names))\n",
    "print(final_lis)\n",
    "print(final_lis1)\n",
    "print(sum(duplication))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "474f4496",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[277], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m     slideDuplication(filtered_index,filtered_duplication,filtered_section_names,path,new_pre)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mslideDuplication\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43mduplication\u001b[49m\u001b[43m,\u001b[49m\u001b[43msection_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnew_pre\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13180\\612993193.py:44\u001b[0m, in \u001b[0;36mslideDuplication\u001b[1;34m(index, duplication, section_names, path, new_pre)\u001b[0m\n\u001b[0;32m     42\u001b[0m slide\u001b[38;5;241m=\u001b[39mpresentation\u001b[38;5;241m.\u001b[39mSlides[index[i]]\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num_duplicate \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(duplication[i]):\n\u001b[1;32m---> 44\u001b[0m     duplicated_slide \u001b[38;5;241m=\u001b[39m \u001b[43mslide\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDuplicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     duplicated_slide\u001b[38;5;241m.\u001b[39mMoveTo(presentation\u001b[38;5;241m.\u001b[39mSlides\u001b[38;5;241m.\u001b[39mCount)\n\u001b[0;32m     46\u001b[0m lis\u001b[38;5;241m.\u001b[39mappend(presentation\u001b[38;5;241m.\u001b[39mSlides\u001b[38;5;241m.\u001b[39mcount\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mduplication[i])\n",
      "File \u001b[1;32m<COMObject <unknown>>:2\u001b[0m, in \u001b[0;36mDuplicate\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if len(slides_name) >0:\n",
    "    indices = [i for i, s in enumerate(section_names) if any(sub.lower() in s.lower() for sub in slides_name)]\n",
    "    filtered_section_names = [section_names[i] for i in indices]\n",
    "    filtered_duplication = [duplication[i] for i in indices]\n",
    "    filtered_index = [index[i] for i in indices]\n",
    "    slideDuplication(filtered_index,filtered_duplication,filtered_section_names,path,new_pre)\n",
    "else:\n",
    "    slideDuplication(index,duplication,section_names,path,new_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b830c75f",
   "metadata": {},
   "source": [
    "## Replace duplicated slides with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78376167-8225-4f4f-af41-cd366f3e2273",
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = Presentation(new_pre)\n",
    "posItr = 0\n",
    "ind =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a49aea0-21ff-4bf4-9427-d2f7a6b8a2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 2\n",
    "try:\n",
    "    if 0 in filtered_index:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(promotionsBrandSortedTotalFinal,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in promotionsBrandSortedTotalFinal.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                \n",
    "                promoEvolutionNew(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6850ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 224\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd4fcae-6d85-4244-82e5-9a19f05b6bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 3\n",
    "try:\n",
    "    if 1 in filtered_index:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(newpromotionsBrandsWithMarket,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in newpromotionsBrandsWithMarket.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                VSOD1(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92914c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 272\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8dc777-7e02-4573-b8f9-000bb04fcdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 4\n",
    "try:\n",
    "    if 2 in filtered_index:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(concated,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in concated.items() if key in dict[key1]}\n",
    "            if len(filtered_dict)>0:\n",
    "                valueUpliftRetailer(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27312e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 287\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8ee2a2-5cdf-41f3-ad8a-95fb9baacc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 5\n",
    "try:\n",
    "    if 3 in filtered_index:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(globals()[f\"modified_promotionProducts{slides_Period}_volumeuplift\"],value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in globals()[f\"modified_promotionProducts{slides_Period}_volumeuplift\"].items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                VolumeUplift(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0b667f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 462\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f24f2e-b093-4fe6-8605-1ef06f69e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 6\n",
    "try:\n",
    "    if 4 in filtered_index:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(globals()[f\"new_modified_promotionProducts{slides_Period}\"],value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in globals()[f\"new_modified_promotionProducts{slides_Period}\"].items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                ValueUpliftvsPromoEfficiencyQuadrant(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569c3cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 653\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba714fd4-a9da-45d9-9eb0-1a1889324bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 7\n",
    "try:\n",
    "    if 5 in filtered_index:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(globals()[f\"new_modified_promotionProducts{slides_Period}\"],value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in globals()[f\"new_modified_promotionProducts{slides_Period}\"].items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                top20(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477805d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 844\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df90b497-4ca3-4467-9965-3eeba68fef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 8\n",
    "try:\n",
    "    if 6 in filtered_index:\n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(top20clientonly,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in top20clientonly.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                top20Client(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e578ca09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 924\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4108f604-685c-4fd8-aab4-5c66967a67ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 9\n",
    "try:\n",
    "    if 7 in filtered_index:\n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(bottom20clientonly,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in bottom20clientonly.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                bot20Client(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16765a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 1004\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf3e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Sector</th>\n",
       "      <th>VSOD</th>\n",
       "      <th>Malard Nicolas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Effervescents</td>\n",
       "      <td>Mousseux</td>\n",
       "      <td>0.23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Effervescents</td>\n",
       "      <td>Champagnes</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Effervescents</td>\n",
       "      <td>Effervescents Sans Alcool</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Effervescents Total</td>\n",
       "      <td>Effervescents Total</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Category                     Sector  VSOD  Malard Nicolas\n",
       "0        Effervescents                   Mousseux  0.23             NaN\n",
       "1        Effervescents                 Champagnes  0.43            0.03\n",
       "2        Effervescents  Effervescents Sans Alcool  0.03             NaN\n",
       "3  Effervescents Total        Effervescents Total  0.38            0.03"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sect_vsod_merged[\"Effervescents | CA D | Effervescents | Malard Nicolas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762a2079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effervescents | CA D | Effervescents | Nicolas\n",
      "Effervescents | CA D | Effervescents | Malard Nicolas\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "NAN/INF not supported in write_number() without 'nan_inf_to_errors' Workbook() option",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[151], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     run_slide \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_slide:\n\u001b[1;32m---> 13\u001b[0m     \u001b[43mnewVolumeSold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msect_vsod_merged\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposItr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirect_parent\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSector\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSector\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     posItr \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sect_vsod_count\n\u001b[0;32m     15\u001b[0m     ind \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5148\\508845219.py:88\u001b[0m, in \u001b[0;36mnewVolumeSold\u001b[1;34m(prs, data, position, parent, child)\u001b[0m\n\u001b[0;32m     86\u001b[0m chart_data\u001b[38;5;241m.\u001b[39madd_series(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVolume Sold on Deal\u001b[39m\u001b[38;5;124m'\u001b[39m, modified_list)\n\u001b[0;32m     87\u001b[0m chart_data\u001b[38;5;241m.\u001b[39madd_series(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, non_volume)\n\u001b[1;32m---> 88\u001b[0m \u001b[43mchart2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchart_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m slidenum\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\SophieZIMMERMANN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pptx\\chart\\chart.py:167\u001b[0m, in \u001b[0;36mChart.replace_data\u001b[1;34m(self, chart_data)\u001b[0m\n\u001b[0;32m    165\u001b[0m rewriter \u001b[38;5;241m=\u001b[39m SeriesXmlRewriterFactory(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchart_type, chart_data)\n\u001b[0;32m    166\u001b[0m rewriter\u001b[38;5;241m.\u001b[39mreplace_series_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chartSpace)\n\u001b[1;32m--> 167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workbook\u001b[38;5;241m.\u001b[39mupdate_from_xlsx_blob(\u001b[43mchart_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxlsx_blob\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\SophieZIMMERMANN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pptx\\chart\\data.py:94\u001b[0m, in \u001b[0;36m_BaseChartData.xlsx_blob\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mxlsx_blob\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     90\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m    Return a blob containing an Excel workbook file populated with the\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m    contents of this chart data object.\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_workbook_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxlsx_blob\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SophieZIMMERMANN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pptx\\chart\\xlsx.py:23\u001b[0m, in \u001b[0;36m_BaseWorkbookWriter.xlsx_blob\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     21\u001b[0m xlsx_file \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_worksheet(xlsx_file) \u001b[38;5;28;01mas\u001b[39;00m (workbook, worksheet):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_populate_worksheet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworkbook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworksheet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xlsx_file\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[1;32mc:\\Users\\SophieZIMMERMANN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pptx\\chart\\xlsx.py:129\u001b[0m, in \u001b[0;36mCategoryWorkbookWriter._populate_worksheet\u001b[1;34m(self, workbook, worksheet)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03mWrite the chart data contents to *worksheet* in category chart\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03mlayout. Write categories starting in the first column starting in\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;124;03mthe first cell.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_categories(workbook, worksheet)\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworkbook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworksheet\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SophieZIMMERMANN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pptx\\chart\\xlsx.py:175\u001b[0m, in \u001b[0;36mCategoryWorkbookWriter._write_series\u001b[1;34m(self, workbook, worksheet)\u001b[0m\n\u001b[0;32m    173\u001b[0m series_col \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m+\u001b[39m col_offset\n\u001b[0;32m    174\u001b[0m worksheet\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;241m0\u001b[39m, series_col, series\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m--> 175\u001b[0m \u001b[43mworksheet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_column\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseries_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_format\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SophieZIMMERMANN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xlsxwriter\\worksheet.py:107\u001b[0m, in \u001b[0;36mconvert_cell_args.<locals>.cell_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m     new_args \u001b[38;5;241m=\u001b[39m xl_cell_to_rowcol(first_arg)\n\u001b[0;32m    105\u001b[0m     args \u001b[38;5;241m=\u001b[39m new_args \u001b[38;5;241m+\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SophieZIMMERMANN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xlsxwriter\\worksheet.py:1488\u001b[0m, in \u001b[0;36mWorksheet.write_column\u001b[1;34m(self, row, col, data, cell_format)\u001b[0m\n\u001b[0;32m   1474\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1475\u001b[0m \u001b[38;5;124;03mWrite a column of data starting from (row, col).\u001b[39;00m\n\u001b[0;32m   1476\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1485\u001b[0m \n\u001b[0;32m   1486\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m-> 1488\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1489\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error:\n\u001b[0;32m   1490\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m error\n",
      "File \u001b[1;32mc:\\Users\\SophieZIMMERMANN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xlsxwriter\\worksheet.py:514\u001b[0m, in \u001b[0;36mWorksheet._write\u001b[1;34m(self, row, col, *args)\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_boolean(row, col, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, Decimal, Fraction):\n\u001b[1;32m--> 514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_number\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_token_as_string(token, row, col, \u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\SophieZIMMERMANN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xlsxwriter\\worksheet.py:637\u001b[0m, in \u001b[0;36mWorksheet._write_number\u001b[1;34m(self, row, col, number, cell_format)\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_formula(row, col, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-1/0\u001b[39m\u001b[38;5;124m\"\u001b[39m, cell_format, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#DIV/0!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    636\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 637\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    638\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNAN/INF not supported in write_number() \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    639\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnan_inf_to_errors\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Workbook() option\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    640\u001b[0m         )\n\u001b[0;32m    642\u001b[0m \u001b[38;5;66;03m# Check that row and col are valid and store max and min values.\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_dimensions(row, col):\n",
      "\u001b[1;31mTypeError\u001b[0m: NAN/INF not supported in write_number() without 'nan_inf_to_errors' Workbook() option"
     ]
    }
   ],
   "source": [
    "if len(sectors)>0:\n",
    "    try:\n",
    "        if 8 in filtered_index:\n",
    "                dup_list = filtered_duplication\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        newVolumeSold(prs, sect_vsod_merged, position=posItr, parent=direct_parent['Sector'], child = 'Sector')\n",
    "        posItr += sect_vsod_count\n",
    "        ind +=1\n",
    "else:\n",
    "    ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244a0620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 300\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41024fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(segments)>0:\n",
    "    try:\n",
    "        if 8 in filtered_index:\n",
    "                dup_list = filtered_duplication\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        newVolumeSold(prs, seg_vsod_merged, position=posItr, parent=direct_parent['Segment'], child = 'Segment')\n",
    "        posItr += seg_vsod_count\n",
    "        ind +=1\n",
    "    \n",
    "else:\n",
    "    ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bc536a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 356\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451cdc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(subsegments)>0:\n",
    "    try:\n",
    "        if 8 in filtered_index:\n",
    "                dup_list = filtered_duplication\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        newVolumeSold(prs, subseg_vsod_merged, position=posItr, parent=direct_parent['SubSegment'], child = 'SubSegment')\n",
    "        posItr += subseg_vsod_count\n",
    "        ind+=1\n",
    "else:\n",
    "     ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b7472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 356\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2298d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(subcategories)>0:\n",
    "    try:\n",
    "        if 8 in filtered_index:\n",
    "                dup_list = filtered_duplication\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        newVolumeSold(prs, subcat_vsod_merged, position=posItr, parent=direct_parent['SubCategory'], child = 'SubCategory')\n",
    "        posItr += subcat_vsod_count\n",
    "        ind+=1\n",
    "else:\n",
    "     ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5677352e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 356\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee42400-58ae-4311-8ac7-9914c0ae666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 11\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(globals()[f\"modified_promotionBrands{slides_Period}\"],value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in globals()[f\"modified_promotionBrands{slides_Period}\"].items() if key in dict[key1]}\n",
    "        if filtered_dict:        \n",
    "            try:\n",
    "                if 9 in filtered_index:\n",
    "                        dup_list = filtered_duplication\n",
    "                        run_slide = True\n",
    "                else:\n",
    "                    run_slide = False\n",
    "            except NameError:\n",
    "                dup_list = duplication\n",
    "                run_slide = True\n",
    "\n",
    "            if run_slide:\n",
    "                PromoShare_vs_ValueShare(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                posItr += len(filtered_dict)\n",
    "    ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7b6a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 404\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569341f7-9b94-4bf5-9114-fe10a6d0cfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 12\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(newModifiedBrands,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in newModifiedBrands.items() if key in dict[key1]}\n",
    "        if filtered_dict:        \n",
    "            try:\n",
    "                if 10 in filtered_index:\n",
    "                        dup_list = filtered_duplication\n",
    "                        run_slide = True\n",
    "                else:\n",
    "                    run_slide = False\n",
    "            except NameError:\n",
    "                dup_list = duplication\n",
    "                run_slide = True\n",
    "\n",
    "            if run_slide:\n",
    "                PromoSalesTotalSize(prs,filtered_dict,dup_list[ind],threshold,position=sum(dup_list[:ind]))\n",
    "                posItr += len(filtered_dict)\n",
    "    ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4e2148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 446\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6331b0-3674-471a-8da0-d10719174ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 13\n",
    "if promo_type:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(PromoSalesTypes_data,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in PromoSalesTypes_data.items() if key in dict[key1]}\n",
    "            if filtered_dict:       \n",
    "                try:\n",
    "                    if 11 in filtered_index:\n",
    "                            dup_list = filtered_duplication\n",
    "                            run_slide = True\n",
    "                    else:\n",
    "                        run_slide = False\n",
    "                except NameError:\n",
    "                    dup_list = duplication\n",
    "                    run_slide = True\n",
    "\n",
    "                if run_slide:\n",
    "                    PromoSalesTypes(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                    posItr += len(filtered_dict)\n",
    "                    ind +=1\n",
    "else:\n",
    "    ind+=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5192201c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 446\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555338fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 14\n",
    "if feature_share:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(globals()[f\"modified_promotionBrands_share{slides_Period}\"],value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in globals()[f\"modified_promotionBrands_share{slides_Period}\"].items() if key in dict[key1]}\n",
    "            if filtered_dict:       \n",
    "                try:\n",
    "                    if 12 in filtered_index:\n",
    "                            dup_list = filtered_duplication\n",
    "                            run_slide = True\n",
    "                    else:\n",
    "                        run_slide = False\n",
    "                except NameError:\n",
    "                    dup_list = duplication\n",
    "                    run_slide = True\n",
    "\n",
    "                if run_slide:   \n",
    "                    featureShare(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                    posItr += len(filtered_dict)\n",
    "                    ind +=1\n",
    "else:\n",
    "    ind+=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c973d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 446\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ecb5b3-8308-43ec-b4aa-16c2e7b0797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# slide 15\n",
    "if display_share:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(globals()[f\"modified_promotionBrands_share{slides_Period}\"],value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in globals()[f\"modified_promotionBrands_share{slides_Period}\"].items() if key in dict[key1]}\n",
    "            if filtered_dict:        \n",
    "                try:\n",
    "                    if 13 in filtered_index:\n",
    "                            dup_list = filtered_duplication\n",
    "                            run_slide = True\n",
    "                    else:\n",
    "                        run_slide = False\n",
    "                except NameError:\n",
    "                    dup_list = duplication\n",
    "                    run_slide = True\n",
    "\n",
    "                if run_slide:   \n",
    "                    displayShare(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                    posItr += len(filtered_dict)\n",
    "                    ind +=1\n",
    "else:\n",
    "    ind+=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16eefd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 446\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ffadfa-5f94-4967-84f6-54c1d2ab7d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 16\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(modified_promotionEndOfWeek,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in modified_promotionEndOfWeek.items() if key in dict[key1]}\n",
    "        if filtered_dict:       \n",
    "            try:\n",
    "                if 14 in filtered_index:\n",
    "                        dup_list = filtered_duplication\n",
    "                        run_slide = True\n",
    "                else:\n",
    "                    run_slide = False\n",
    "            except NameError:\n",
    "                dup_list = duplication\n",
    "                run_slide = True\n",
    "\n",
    "            if run_slide:\n",
    "                PromoFrequency(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                posItr += len(filtered_dict)\n",
    "    ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84ad318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 592\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43caf10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if categories:\n",
    "    catFinal = sorted(splitDfsPromo(dfCategory,(client_manuf) ,genrateIndexList(catGroup[0])[0]))\n",
    "    catFinal = catFinal+sorted(splitDfsPromo(dfCategory,(client_brands) ,genrateIndexList(catGroup[0])[0]))\n",
    "    catFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f6fd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 592\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05117abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sectors:\n",
    "    secFinal = sorted(splitDfsPromo(dfSector,(client_manuf)  ,genrateIndexList(secGroup[0])[0]))\n",
    "    secFinal = secFinal + sorted(splitDfsPromo(dfSector,(client_brands)  ,genrateIndexList(secGroup[0])[0]))\n",
    "    secFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5855f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 592\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c788ee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if segments:\n",
    "    segFinal = sorted(splitDfsPromo(dfSegment,(client_manuf)  ,genrateIndexList(segGroup[0])[0]))\n",
    "    segFinal = segFinal+sorted(splitDfsPromo(dfSegment,(client_brands)  ,genrateIndexList(segGroup[0])[0]))\n",
    "    segFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889d3e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if subsegments:\n",
    "    subsegFinal = sorted(splitDfsPromo(dfSubSegment,(client_manuf)  ,genrateIndexList(subsegGroup[0])[0]))\n",
    "    subsegFinal = subsegFinal + sorted(splitDfsPromo(dfSubSegment,(client_brands)  ,genrateIndexList(subsegGroup[0])[0]))\n",
    "    subsegFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3153b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "if subcategories:\n",
    "    subcatFinal = sorted(splitDfsPromo(dfSubCategory,(client_manuf) ,genrateIndexList(subcatGroup[0])[0]))\n",
    "    subcatFinal = subcatFinal+sorted(splitDfsPromo(dfSubCategory,(client_brands) ,genrateIndexList(subcatGroup[0])[0]))\n",
    "    subcatFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5febe962-91f9-4b04-80a0-986f63399c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slide 17\n",
    "#split catGroup into Lists depends on num of charts \n",
    "# index1 = filtered_index\n",
    "# catGroupSplit = splitListpromo(dfCategory, catGroup, [i-14 for i in index1[ind]])\n",
    "values_to_check = {15, 16, 17,18}\n",
    "try:\n",
    "    index1 = filtered_index\n",
    "except NameError:\n",
    "    index1 = index\n",
    "try:\n",
    "    normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "    if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "            dup_list = filtered_duplication\n",
    "            index1= filtered_index\n",
    "            run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    index1 = index\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    catGroupSplit = splitListpromo(dfCategory, catGroup, [i-14 for i in index1[ind]])\n",
    "    promoSalesPerRetailer(prs,dfCategory,len(index1[ind]),catGroupSplit,position=sum(dup_list[:ind]))\n",
    "    posItr = sum(dup_list[:ind]) + len(index1[ind])\n",
    "ind+=1\n",
    "\n",
    "\n",
    "#split secGroup into Lists depends on num of charts \n",
    "if len(sectors) != 0:   \n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1= filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        index1 = index\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        secGroupSplit = splitListpromo(dfSector, secGroup, [i-14 for i in index1[ind]])\n",
    "        promoSalesPerRetailer(prs,dfSector,len(index1[ind]),secGroupSplit,position=posItr)\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n",
    "\n",
    "#split segGroup into Lists depends on num of charts \n",
    "if len(segments) != 0: \n",
    "    \n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1= filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        index1 = index\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        segGroupSplit = splitListpromo(dfSegment, segGroup, [i-14 for i in index1[ind]])\n",
    "        promoSalesPerRetailer(prs,dfSegment,len(index1[ind]),segGroupSplit,position=posItr)\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n",
    "\n",
    "#split subsegGroup into Lists depends on num of charts \n",
    "if len(subsegments) != 0:\n",
    "    subsegGroupSplit = splitListpromo(dfSubSegment, subsegGroup, [i-14 for i in index1[ind]])\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1= filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        index1 = index\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        promoSalesPerRetailer(prs,dfSubSegment,len(index1[ind]),subsegGroupSplit,position=posItr)\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n",
    "\n",
    "#split subcatGroup into Lists depends on num of charts \n",
    "if len(subcategories) != 0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1= filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        index1 = index\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        subcatGroupSplit = splitListpromo(dfSubCategory, subcatGroup, [i-14 for i in index1[ind]])\n",
    "        promoSalesPerRetailer(prs,dfSubCategory,len(index1[ind]),subcatGroupSplit,position=posItr)\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c0f9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf01c1-6ec8-405c-bb46-928310996eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 713\n"
     ]
    }
   ],
   "source": [
    "# slide 21\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(modified_valueUplift,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in modified_valueUplift.items() if key in dict[key1]}\n",
    "        if filtered_dict:\n",
    "            try:\n",
    "                if 19 in filtered_index:\n",
    "                        dup_list = filtered_duplication\n",
    "                        run_slide = True\n",
    "                else:\n",
    "                        run_slide = False\n",
    "            except NameError:\n",
    "                    dup_list = duplication\n",
    "                    run_slide = True \n",
    "\n",
    "            if run_slide:\n",
    "                valueUplift(prs,filtered_dict,dup_list[ind],position=posItr)\n",
    "                posItr += len(filtered_dict)\n",
    "    ind +=1\n",
    "print(ind,posItr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1031c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 1 713\n"
     ]
    }
   ],
   "source": [
    "print(ind, duplication[ind], posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e02f578",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_to_check = {20,21,22,23,24,25}\n",
    "if len(categories)>0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        seasonality(prs,dfCategory0, len(index1[ind]), categoryGroup0, position=posItr,slideby=\"Category\")\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec4ed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)>0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        seasonality(prs, dfSector0, len(index1[ind]), secGroup0, position=posItr,slideby=\"Sector\")\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c95329",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(segments)>0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        seasonality(prs, dfSegment0, len(index1[ind]), segGroup0, position=posItr,slideby=\"Segment\")\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfffb4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(subsegments) != 0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        seasonality(prs,dfSubSegment0,len(index1[ind]),subsegGroup0,position=posItr,slideby=\"SubSegment\")\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d74d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(subcategories) != 0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        seasonality(prs,dfSubCategory0,len(index1[ind]),subcatGroup0,position=posItr,slideby=\"SubCategory\")\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb5a7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737 89\n"
     ]
    }
   ],
   "source": [
    "print(posItr,ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e773cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date1 = pd.to_datetime(end_date)\n",
    "start_date1 = end_date1 - pd.DateOffset(months=12)\n",
    " \n",
    "# Generate all weekly periods (weekly ends, e.g., Sundays) between start and end\n",
    "week_ends = pd.date_range(start=start_date1, end=end_date1, freq='W-SUN')\n",
    " \n",
    "# Convert to list of dates (if needed)\n",
    "week_ends_list = week_ends.to_list()\n",
    "all_weeks_df = pd.DataFrame({'End of Week': week_ends_list})\n",
    "\n",
    "def add_all_weeks(data):\n",
    "    final_data ={}\n",
    "    for key,df in data.items():\n",
    "        df_full = all_weeks_df.merge(df, on='End of Week', how='left')\n",
    "        df_full.fillna(0, inplace=True)\n",
    "        final_data[key] = df_full\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab704be",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_dfCategory1 = add_all_weeks(modified_dfCategory1)\n",
    "modified_dfSector1 = add_all_weeks(modified_dfSector1)\n",
    "modified_dfSegment1 = add_all_weeks(modified_dfSegment1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b6cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_to_check = {26,27,28,29}\n",
    "try:\n",
    "    normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "    if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "            dup_list = filtered_duplication\n",
    "            index1 = filtered_index\n",
    "            run_slide = True\n",
    "    else:\n",
    "            run_slide = False\n",
    "except NameError:\n",
    "        dup_list = duplication\n",
    "        index1=index\n",
    "        run_slide = True \n",
    "\n",
    "if run_slide:\n",
    "        catGroup1Split = splitListpromo(modified_dfCategory1, catGroup1, [i-25 for i in index1[ind]])\n",
    "        Promotional_Frequency(prs,modified_dfCategory1,len(index1[ind]),catGroup1Split,position=posItr)\n",
    "        posItr +=len(catGroup1Split)\n",
    "ind+=1\n",
    "#Sector Replace\n",
    "if len(sectors) != 0: \n",
    "    \n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        secGroup1Split = splitListpromo(modified_dfSector1, secGroup1, [i-25 for i in index1[ind]])\n",
    "        Promotional_Frequency(prs,modified_dfSector1,len(index1[ind]),secGroup1Split,position=posItr)\n",
    "        posItr += len(secGroup1Split)\n",
    "ind+=1\n",
    "\n",
    "\n",
    "if len(segments) != 0: \n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 =  filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        segGroup1Split = splitListpromo(modified_dfSegment1, segGroup1, [i-25 for i in index1[ind]])\n",
    "        Promotional_Frequency(prs,modified_dfSegment1,len(index1[ind]),segGroup1Split,position=posItr)\n",
    "        posItr += len(segGroup1Split)\n",
    "ind+=1\n",
    "\n",
    "if len(subsegments) != 0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        subsegGroup1Split = splitListpromo(modified_dfSubSegment1, subsegGroup1, [i-25 for i in index1[ind]])\n",
    "        Promotional_Frequency(prs,modified_dfSubSegment1,len(index1[ind]),subsegGroup1Split,position=posItr)\n",
    "        posItr += len(subsegGroup1Split)\n",
    "ind+=1\n",
    "\n",
    "if len(subcategories) != 0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        subcatGroup1Split = splitListpromo(modified_dfSubCategory1, subcatGroup1, [i-25 for i in index[ind]])\n",
    "        Promotional_Frequency(prs,modified_dfSubCategory1,len(index1[ind]),subcatGroup1Split,position=posItr)\n",
    "        posItr += len(subcatGroup1Split)\n",
    "ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d3bb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 790\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39417e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "95\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "# slide 2 with no client brands\n",
    "try:\n",
    "    if 0 in filtered_index and 'Promo Evolution no client prio' in filtered_section_names:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(promotionsBrandNOTSortedTotalFinal,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in promotionsBrandNOTSortedTotalFinal.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                print(ind)\n",
    "                promoEvolutionNew(prs,filtered_dict,dup_list[ind],position=posItr)\n",
    "                posItr += len(filtered_dict)\n",
    "        ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb051d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 838\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42070784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 3 with no client brands\n",
    "try:\n",
    "    if 1 in filtered_index and 'VSOD Summary by Sector no client prio' in filtered_section_names:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(newpromotionsNotBrandsWithMarket,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in newpromotionsNotBrandsWithMarket.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                VSOD1(prs,filtered_dict,dup_list[ind],position=posItr)\n",
    "                posItr += len(filtered_dict)\n",
    "ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61072cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "854\n"
     ]
    }
   ],
   "source": [
    "print(posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 4 with no client brands\n",
    "try:\n",
    "    if 2 in filtered_index and 'Value uplift by retailer by brand no client prio' in filtered_section_names:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(concated,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in concated.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                valueUpliftRetailer_no(prs,filtered_dict,dup_list[ind],position=posItr)\n",
    "                posItr += len(filtered_dict)\n",
    "ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead65353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860\n"
     ]
    }
   ],
   "source": [
    "print(posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b3726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 11 with no client prio\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(globals()[f\"modified_promotionBrands{slides_Period}\"],value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in globals()[f\"modified_promotionBrands{slides_Period}\"].items() if key in dict[key1]}\n",
    "        if filtered_dict:        \n",
    "            try:\n",
    "                if 9 in filtered_index and 'Promo share vs Value Share no client prio' in filtered_section_names:\n",
    "                        dup_list = filtered_duplication\n",
    "                        run_slide = True\n",
    "                else:\n",
    "                    run_slide = False\n",
    "            except NameError:\n",
    "                dup_list = duplication\n",
    "                run_slide = True\n",
    "\n",
    "            if run_slide:\n",
    "                PromoShare_vs_ValueShare_no(prs,filtered_dict,dup_list[ind],position=posItr)\n",
    "                posItr += len(filtered_dict)\n",
    "    ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d61cb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "908\n"
     ]
    }
   ],
   "source": [
    "print(posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d694f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 908\n"
     ]
    }
   ],
   "source": [
    "print(ind, posItr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd77382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 12 with no client prio\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(newModifiedBrands,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in newModifiedBrands.items() if key in dict[key1]}\n",
    "        if filtered_dict:        \n",
    "            try:\n",
    "                if 10 in filtered_index and 'Promo Sales by total size no client prio' in filtered_section_names:\n",
    "                        dup_list = filtered_duplication\n",
    "                        run_slide = True\n",
    "                else:\n",
    "                    run_slide = False\n",
    "            except NameError:\n",
    "                dup_list = duplication\n",
    "                run_slide = True\n",
    "\n",
    "            if run_slide:\n",
    "                PromoSalesTotalSize_no(prs,filtered_dict,dup_list[ind],position=posItr)\n",
    "                posItr += len(filtered_dict)\n",
    "    ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3c723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 14 with no client prio\n",
    "if feature_share:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(globals()[f\"modified_promotionBrands_share{slides_Period}\"],value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in globals()[f\"modified_promotionBrands_share{slides_Period}\"].items() if key in dict[key1]}\n",
    "            if filtered_dict:       \n",
    "                try:\n",
    "                    if 12 in filtered_index and 'Feature Share vs Fair Share no client prio' in filtered_section_names:\n",
    "                            dup_list = filtered_duplication\n",
    "                            run_slide = True\n",
    "                    else:\n",
    "                        run_slide = False\n",
    "                except NameError:\n",
    "                    dup_list = duplication\n",
    "                    run_slide = True\n",
    "\n",
    "                if run_slide:   \n",
    "                    featureShare_no(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                    posItr += len(filtered_dict)\n",
    "        ind +=1\n",
    "else:\n",
    "    ind +=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbef8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# slide 15 with no client prio\n",
    "if display_share:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(globals()[f\"modified_promotionBrands_share{slides_Period}\"],value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in globals()[f\"modified_promotionBrands_share{slides_Period}\"].items() if key in dict[key1]}\n",
    "            if filtered_dict:        \n",
    "                try:\n",
    "                    if 13 in filtered_index and 'Display Share vs Fair Share no client prio' in filtered_section_names:\n",
    "                            dup_list = filtered_duplication\n",
    "                            run_slide = True\n",
    "                    else:\n",
    "                        run_slide = False\n",
    "                except NameError:\n",
    "                    dup_list = duplication\n",
    "                    run_slide = True\n",
    "\n",
    "                if run_slide:   \n",
    "                    displayShare_no(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                    posItr += len(filtered_dict)\n",
    "        ind+=1\n",
    "else:\n",
    "    ind+=5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217af932",
   "metadata": {},
   "source": [
    "## Output slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56e0982-087b-439b-a549-736abdbb54b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath=os.getcwd() + f\"\\\\Promotion output_{datetime.today().strftime(\"%d-%m\")}.pptx\"\n",
    "prs.save(outputPath)\n",
    "# # app = win32.Dispatch(\"PowerPoint.Application\")\n",
    "final=os.getcwd() +f\"\\\\Promotion output_{datetime.today().strftime(\"%d-%m\")}.pptx\"\n",
    "#open_chart_data_in_excel(final,outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae25476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
