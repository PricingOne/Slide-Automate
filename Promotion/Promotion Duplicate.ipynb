{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "15a454f5-c4e1-460c-a27d-40aa00dfcac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "slides_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ecc6d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "%run \"{os.path.dirname(os.getcwd())}\\general_functions\\generalFunctions.ipynb\" #container\n",
    "%run \"{os.getcwd()}\\Promotion Replacement Function.ipynb\" #container\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6999d128",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b5d5ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ali Salem\\Desktop\\Slide-Automate-1\\parameters.xlsx\n"
     ]
    }
   ],
   "source": [
    "filename = 'parameters.xlsx'\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Construct the full path to the file\n",
    "f_path = os.path.join(current_dir, filename)\n",
    "print(f_path)\n",
    "#xls = pd.ExcelFile(f_path)\n",
    "parm = pd.read_excel(f_path, sheet_name='Promotion')\n",
    "fields = dict(zip(parm['Field'],parm['Value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "26fd59b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = \"powerbi://api.powerbi.com/v1.0/myorg/\"+ fields['server']\n",
    "dataset_name = fields['f_name']\n",
    "f_name = os.getcwd()+\"/\"+fields['f_name']+\".xlsx\"\n",
    "\n",
    "client_manuf = list(set(fields['client_manuf'].split(','))-set(['']))\n",
    "client_brands = list(set(fields['client_brands'].split(','))-set(['']))\n",
    "\n",
    "decimals = fields['decimals']\n",
    "sign = fields['sign']\n",
    "currency = fields['currency']\n",
    "currency = ' '+ currency if sign.lower() == 'after' else  currency + ' ' \n",
    "\n",
    "categories = list(set(fields['categories'].split(','))-set(['']))\n",
    "sectors=list(set(fields['sectors'].split(','))-set(['']))\n",
    "segments=list(set(fields['segments'].split(','))-set(['']))\n",
    "subsegments=list(set(fields['subsegments'].split(','))-set(['']))\n",
    "subcategories=list(set(fields['subcategories'].split(','))-set(['']))\n",
    "\n",
    "national=fields['national']\n",
    "customareas=fields['customareas']\n",
    "areas = list(set(fields['areas'].split(','))-set(['']))+[customareas]\n",
    "\n",
    "regions_RET = list(set(fields['regions_RET'].split(','))-set(['']))\n",
    "channels_RET = list(set(fields['channels_RET'].split(','))-set(['']))\n",
    "market_RET=list(set(fields['market_RET'].split(','))-set(['']))\n",
    "\n",
    "regions_CHAN=list(set(fields['regions_CHAN'].split(','))-set(['']))\n",
    "channels_CHAN=list(set(fields['channels_CHAN'].split(','))-set(['']))\n",
    "market_CHAN=list(set(fields['market_CHAN'].split(','))-set(['']))\n",
    "\n",
    "regions_CUST=list(set(fields['regions_CUST'].split(','))-set(['']))\n",
    "channels_CUST=list(set(fields['channels_CUST'].split(','))-set(['']))\n",
    "market_CUST=list(set(fields['market_CUST'].split(','))-set(['']))\n",
    "\n",
    "data_source=fields['data_source']\n",
    "years=list(set(fields['years'].split(','))-set(['']))\n",
    "start_date = fields['start_date']\n",
    "end_date=fields['end_date']\n",
    "\n",
    "ManufOrTopC = fields['ManufOrTopC']\n",
    "BrandOrTopB = fields['BrandOrTopB']\n",
    "prodORitem = fields['prodORitem']\n",
    "\n",
    "percent = fields['percent']\n",
    "percentstr=fields['percentstr']\n",
    "\n",
    "National=[\"NATIONAL\"]if national else []\n",
    "subcatg_parent = fields['subcatg_parent']\n",
    "subcatg_parent_list = segments\n",
    "promo_col = list(set(fields['promo_col'].split(','))-set(['']))\n",
    "selectedBrands = client_brands \n",
    "marketList = regions_RET + channels_RET + market_RET + regions_CHAN + channels_CHAN + market_CHAN \n",
    "notInScope = []\n",
    "OpenEditData=fields['OpenEditData']\n",
    "normalized = fields['normalized']\n",
    "promo_type = fields['promo_type']\n",
    "display_share = fields['display_share']\n",
    "feature_share = fields['feature_share']\n",
    "slides_Period = fields['slides_Period']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9c6195f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_parent = {\"Sector\":\"Category\",\n",
    "                \"Segment\":\"Sector\",\n",
    "                \"SubSegment\":\"Segment\", \n",
    "                \"SubCategory\":\"Segment\"}\n",
    "Scope = {\n",
    "    \"Category\": categories,\n",
    "    \"Sector\": sectors,\n",
    "    \"Segment\": segments,\n",
    "    \"Subsegment\": subsegments,\n",
    "    \"Subcategory\": subcategories\n",
    "}\n",
    "suffixes = [\"Category\", \"Sector\", \"Segment\",'SubSegment', 'SubCategory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2a25d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "defaults = ast.literal_eval(\"{\" + fields['defaults'] + \"}\")\n",
    "marketList = regions_RET + channels_RET + market_RET + regions_CHAN + channels_CHAN + market_CHAN + regions_CUST + channels_CUST + market_CUST\n",
    "categoryList=categories +sectors+segments+subsegments+subcategories\n",
    "# defaults = {\n",
    "#     'Manual Shave Men': 6.69,'Disposables': 7.98,\"System\" : 5.03,\"Razors\" : 2.80,\"Refills\" : 6.58\n",
    "# }\n",
    "diff_market_value = {\n",
    "}\n",
    "\n",
    "def totalsize (lis,defaultdic,diffmarketdic=[]):\n",
    "\n",
    "    max_total_size = {\n",
    "    f\"{category} | {market}\": diff_market_value.get(market.upper(), {}).get(category, defaults[category])\n",
    "    for market in lis\n",
    "    for category in defaults\n",
    "    }\n",
    "\n",
    "    return max_total_size  \n",
    "\n",
    "max_total_size=totalsize(marketList,defaults,diff_market_value)\n",
    "\n",
    "custom_colors = [\n",
    "    RGBColor(91, 159, 153),    # Darker teal\n",
    "    RGBColor(131, 199, 193),   # Brighter medium teal\n",
    "    RGBColor(168, 216, 212),   # Original light teal\n",
    "    RGBColor(198, 236, 232),   # Very light teal\n",
    "    RGBColor(111, 179, 173),\n",
    "    RGBColor(121, 189, 183)\n",
    "]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "06b6fbff-4bd3-4c15-8d5d-f3b65886bc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized = True\n",
    "# promo_type = False\n",
    "# display_share = True  # True if Available\n",
    "# feature_share = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "86ff0039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ManufOrTopC =\"Top Companies\"\n",
    "# BrandOrTopB = \"Top Brands\"\n",
    "# prodORitem=\"Business Name\"\n",
    "\n",
    "# client_manuf = [\"Bel\"]\n",
    "# client_brands = [\"Kiri\", \"La Vache Qui Rit\", \"Boursin\"]\n",
    "\n",
    "# categories = [\"Total Fromage\"]\n",
    "# sectors = [\"Soft Cheese\", \"Aperitif\"]\n",
    "# segments = [\"Enfant\", \"Frais A Tartiner\", \"Salade\"]\n",
    "# subsegments= []\n",
    "# subcategories= []\n",
    "\n",
    "# decimals = 2\n",
    "# sign = \"After\"\n",
    "# currency = 'â‚¬'\n",
    "# currency = ' '+ currency if sign.lower() == 'after' else  currency + ' '\n",
    "\n",
    "# customareas=''\n",
    "# national = False\n",
    "# areas = [\"RETAILER\"]\n",
    "# regions_RET  =[\"Carrefour\", \"Intermarche\"]\n",
    "# channels_RET = [\"Carrefour Hyper + Drive\", \"Carrefour Supermarket + Drive\", \"Carrefour Proximite\", \"Intermarche Super\", \"Intermarche Hyper\", \"Intermarche Proxi\"]\n",
    "# market_RET = []\n",
    "\n",
    "# regions_CHAN = []\n",
    "# channels_CHAN = []\n",
    "# market_CHAN = []\n",
    "\n",
    "# regions_CUST = []\n",
    "# channels_CUST = []\n",
    "# market_CUST = []\n",
    "\n",
    "# data_source = \"DATA SOURCE: Trade Panel/Retailer Data | July 2025\"\n",
    "# years = ['2023', '2024', '2025']\n",
    "# slides_Period=\"P3M\"\n",
    "\n",
    "# subcatg_parent = \"Segment\"\n",
    "# subcatg_parent_list = segments\n",
    " \n",
    "# percent = 1000000\n",
    "# percentstr=\"'000 000\"\n",
    "# start_date = \"2022-08-01\"\t\n",
    "# end_date = \"2025-08-01\"\n",
    "\n",
    "# promo_col = []\n",
    "# selectedBrands = client_brands \n",
    "# marketList = regions_RET + channels_RET + market_RET + regions_CHAN + channels_CHAN + market_CHAN \n",
    "# notInScope = []\n",
    "# OpenEditData=True\n",
    "# direct_parent = {\"Sector\":\"Category\",\n",
    "#                 \"Segment\":\"Sector\",\n",
    "#                 \"SubSegment\":\"Segment\", \n",
    "#                 \"SubCategory\":\"Segment\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d93407ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# marketList = regions_RET + channels_RET + market_RET + regions_CHAN + channels_CHAN + market_CHAN + regions_CUST + channels_CUST + market_CUST\n",
    "# categoryList=categories +sectors+segments+subsegments+subcategories\n",
    "# defaults = {\n",
    "#     'Aperitif': 0.27,\n",
    "#     'Enfant': 0.35,\n",
    "#     \"Frais A Tartiner\" : 0.25,\n",
    "#     \"Ingredient A Chaud\" : 0.3,\n",
    "#     \"Salade\" : 0.28\n",
    "# }\n",
    "# diff_market_value = {\n",
    "\n",
    "# }\n",
    "\n",
    "# def totalsize (lis,defaultdic,diffmarketdic=[]):\n",
    "\n",
    "#     max_total_size = {\n",
    "#     f\"{category} | {market}\": diff_market_value.get(market.upper(), {}).get(category, defaults[category])\n",
    "#     for market in lis\n",
    "#     for category in defaults\n",
    "#     }\n",
    "\n",
    "#     return max_total_size  \n",
    "\n",
    "# max_total_size=totalsize(marketList,defaults,diff_market_value)\n",
    "\n",
    "# custom_colors = [\n",
    "#     RGBColor(91, 159, 153),    # Darker teal\n",
    "#     RGBColor(131, 199, 193),   # Brighter medium teal\n",
    "#     RGBColor(168, 216, 212),   # Original light teal\n",
    "#     RGBColor(198, 236, 232),   # Very light teal\n",
    "#     RGBColor(111, 179, 173),\n",
    "#     RGBColor(121, 189, 183)\n",
    "# ]\n",
    "# # custom_colors = [\n",
    "# #     RGBColor(111, 179, 173),  \n",
    "# #     RGBColor(121, 189, 183),  \n",
    "# #     RGBColor(168, 216, 212),  \n",
    "# #     RGBColor(178, 226, 222),\n",
    "# # ]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a8ab5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scope = {\n",
    "#     \"Category\": categories,\n",
    "#     \"Sector\": sectors,\n",
    "#     \"Segment\": segments,\n",
    "#     \"Subsegment\": subsegments,\n",
    "#     \"Subcategory\": subcategories\n",
    "# }\n",
    "# suffixes = [\"Category\", \"Sector\", \"Segment\",'SubSegment', 'SubCategory']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71fd5a3",
   "metadata": {},
   "source": [
    "## Reading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "461dc096-382d-4c3b-91c1-8610a7cd684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = {}\n",
    "datasets_path = os.getcwd()+\"/Promotion Datasets Test/\"\n",
    "datasets = os.listdir(datasets_path)\n",
    "for d in datasets:\n",
    "    with open(datasets_path+d, 'rb') as handle:\n",
    "        globals()[d.split('.')[0]] = pd.read_pickle(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707e341f",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c1c2b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[f\"modified_promotionBrands{slides_Period}\"] = cleaningData(globals()[f\"promotions_brands_{slides_Period}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "057130a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature_share & display_share:\n",
    "    globals()[f\"modified_promotionBrands_share{slides_Period}\"] = cleaningData_featureshare(globals()[f\"promotions_brands_{slides_Period}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "77d32fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[f\"modified_promotionBrands{slides_Period}_total\"] = cleaningdata_with_grand_total(globals()[f\"promotions_brands_{slides_Period}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8ad3da6e-fb47-4873-b875-bd146d89d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[f\"modified_promotionProducts{slides_Period}\"] = cleaningData(globals()[f\"promotions_products_{slides_Period}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c5159e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[f\"modified_promotionProducts{slides_Period}_updated\"] = {}\n",
    "for key, df in globals()[f\"modified_promotionProducts{slides_Period}\"].items():\n",
    "    df = df.copy()\n",
    "    df = df[df[f'{prodORitem}'] != '']\n",
    "    df = df[df['Promo Sales'] >= 10000]\n",
    "    df = df.sort_values(by='Promo Value', ascending=False).reset_index(drop=True)\n",
    "    if not df.empty:\n",
    "        globals()[f\"modified_promotionProducts{slides_Period}_updated\"][key] = df\n",
    "globals()[f\"modified_promotionProducts{slides_Period}_volumeuplift\"] = globals()[f\"modified_promotionProducts{slides_Period}_updated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b40a1e66-80f4-4dd0-9af8-a1a4e1cdc795",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_promotionEndOfWeek = cleaningData(promotions_EndOfWeek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c86f6a2a-90f7-40b1-8f9f-723f5578455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_valueUplift = cleaningData(value_uplift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7da7fc3d-461c-4a38-8ae2-8d19805e5a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "newModifiedBrands = cleaning13New(globals()[f\"promotions_brands_{slides_Period}\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4ae1fa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for each pivot call in a list of tuples:\n",
    "pivot_params = [\n",
    "    (Sector_client_VSOD, 'Top Brands', 'Sector_client_VSODNew'),\n",
    "    (Sector_manuf_VSOD, 'Top Companies', 'Sector_manuf_VSODNew'),\n",
    "    (Segment_client_VSOD, 'Top Brands', 'Segment_client_VSODNew'),\n",
    "    (Segment_manuf_VSOD, 'Top Companies', 'Segment_manuf_VSODNew'),\n",
    "    (SubSegment_client_VSOD, 'Top Brands', 'SubSegment_client_VSODNew'),\n",
    "    (SubSegment_manuf_VSOD, 'Top Companies', 'SubSegment_manuf_VSODNew'),\n",
    "    (SubCategory_client_VSOD, 'Top Brands', 'SubCategory_client_VSODNew'),\n",
    "    (SubCategory_manuf_VSOD, 'Top Companies', 'SubCategory_manuf_VSODNew')\n",
    "]\n",
    "\n",
    "# Prepare a dictionary to store results:\n",
    "pivot_results = {}\n",
    "\n",
    "for data_dict, pivot_col, result_name in pivot_params:\n",
    "    pivot_results[result_name] = dict_to_pivot_general(\n",
    "        data_dict=data_dict,\n",
    "        pivot_col=pivot_col,\n",
    "        value_col='VSOD',\n",
    "        aggfunc='sum',\n",
    "        fill_value=pd.NA\n",
    "    )\n",
    "\n",
    "# If you want to have these as separate variables in your workspace, you can unpack like:\n",
    "Sector_client_VSODNew = pivot_results['Sector_client_VSODNew']\n",
    "Sector_manuf_VSODNew = pivot_results['Sector_manuf_VSODNew']\n",
    "Segment_client_VSODNew = pivot_results['Segment_client_VSODNew']\n",
    "Segment_manuf_VSODNew = pivot_results['Segment_manuf_VSODNew']\n",
    "SubSegment_client_VSODNew = pivot_results['SubSegment_client_VSODNew']\n",
    "SubSegment_manuf_VSODNew = pivot_results['SubSegment_manuf_VSODNew']\n",
    "SubCategory_client_VSODNew = pivot_results['SubCategory_client_VSODNew']\n",
    "SubCategory_manuf_VSODNew = pivot_results['SubCategory_manuf_VSODNew']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d18ef6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors) >0:\n",
    "    a = Sector_VSOD\n",
    "    if len(Sector_client_VSODNew) >0:\n",
    "        b = cleaningData(Sector_client_VSODNew)\n",
    "        sect_vsod_merged = merging(b,a, col=[direct_parent[\"Sector\"],'Sector'])\n",
    "    else:\n",
    "        sect_vsod_merged = a\n",
    "    c = cleaningData(Sector_manuf_VSODNew)  \n",
    "    for key in sect_vsod_merged:\n",
    "        merged_df = pd.merge(sect_vsod_merged[key], c[key], on=[direct_parent[\"Sector\"],'Sector'], how='left')\n",
    "        if merged_df.shape[0]>0:\n",
    "            sect_vsod_merged[key] = merged_df    \n",
    "\n",
    "if len(segments) >0:\n",
    "    a = Segment_VSOD\n",
    "    if len(Segment_client_VSODNew) > 0:\n",
    "        b = cleaningData(Segment_client_VSODNew)\n",
    "        seg_vsod_merged = merging(a,b, col=[direct_parent[\"Segment\"],'Segment'])\n",
    "    else:\n",
    "        seg_vsod_merged = a\n",
    "    \n",
    "    c = cleaningData(Segment_manuf_VSODNew)\n",
    "    for key in seg_vsod_merged:\n",
    "        # Merge DataFrames based on 'Sector' column\n",
    "        merged_df = pd.merge(seg_vsod_merged[key], c[key], on=[direct_parent[\"Segment\"],'Segment'], how='left')\n",
    "        merged_df = merged_df.fillna(0)\n",
    "        if merged_df.shape[0]>0:\n",
    "            seg_vsod_merged[key] = merged_df    \n",
    "\n",
    "if len(subsegments) >0:\n",
    "    a = SubSegment_VSOD\n",
    "    if len(SubSegment_client_VSODNew) > 0 :\n",
    "        b = cleaningData(SubSegment_client_VSODNew)\n",
    "        subseg_vsod_merged = merging(a,b, col=[direct_parent[\"SubSegment\"],'SubSegment'])\n",
    "    else:\n",
    "        subseg_vsod_merged = a\n",
    "    c = cleaningData(SubSegment_manuf_VSOD)\n",
    "    for key in subseg_vsod_merged:\n",
    "        # Merge DataFrames based on 'Sector' column\n",
    "        merged_df = pd.merge(subseg_vsod_merged[key], c[key], on=[direct_parent[\"SubSegment\"],'SubSegment'], how='left')\n",
    "        merged_df = merged_df.fillna(0)\n",
    "        if merged_df.shape[0]>0:\n",
    "            subseg_vsod_merged[key] = merged_df    \n",
    "\n",
    "if len(subcategories) >0:\n",
    "    a = SubCategory_VSOD\n",
    "    if len(SubCategory_client_VSODNew) > 0 :\n",
    "        b = cleaningData(SubCategory_client_VSODNew)\n",
    "        subcat_vsod_merged = merging(a,b, col=[direct_parent[\"SubCategory\"],'SubCategory'])\n",
    "    else:\n",
    "        subcat_vsod_merged = a\n",
    "    c = cleaningData(SubCategory_manuf_VSODNew)\n",
    "    for key in subcat_vsod_merged:\n",
    "        # Merge DataFrames based on 'Sector' column\n",
    "        merged_df = pd.merge(subcat_vsod_merged[key], c[key], on=[direct_parent[\"SubCategory\"],'SubCategory'], how='left')\n",
    "        merged_df = merged_df.fillna(0)\n",
    "        if merged_df.shape[0]>0:\n",
    "            subcat_vsod_merged[key] = merged_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e97a11db",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=client_brands+client_manuf\n",
    "if len(sectors)!=0:\n",
    "    sect_vsod_merged=splitkeys(sect_vsod_merged,categories,parent=direct_parent['Sector'],clientlist=client)\n",
    "if len(segments)!=0:\n",
    "    seg_vsod_merged=splitkeys(seg_vsod_merged,sectors,parent=direct_parent['Segment'],clientlist=client)\n",
    "if len(subsegments)!=0:\n",
    "    subseg_vsod_merged=splitkeys(subseg_vsod_merged,segments,parent=direct_parent['SubSegment'],clientlist=client)\n",
    "if len(subcategories)!=0:\n",
    "    subcat_vsod_merged=splitkeys(subcat_vsod_merged,segments,parent=direct_parent['SubCategory'],clientlist=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b271ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors):\n",
    "    sect_vsod_count =0\n",
    "    for key,df in sect_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                sect_vsod_count +=1\n",
    "    sect_vsod_count = sect_vsod_count *len(categories)\n",
    " \n",
    "if len(segments):\n",
    "    seg_vsod_count =0\n",
    "    for key,df in seg_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                seg_vsod_count +=1\n",
    "    #seg_vsod_count = seg_vsod_count * len(sectors) \n",
    "    seg_vsod_count = seg_vsod_count           \n",
    " \n",
    "if len(subsegments) >0:\n",
    "    subseg_vsod_count =0\n",
    "    for key,df in subseg_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                subseg_vsod_count +=1\n",
    "    #subseg_vsod_count =subseg_vsod_count *len(segments)\n",
    "    subseg_vsod_count = subseg_vsod_count\n",
    " \n",
    "if len(subcategories) >0:\n",
    "    subcat_vsod_count =0\n",
    "    for key,df in subcat_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                subcat_vsod_count +=1\n",
    "    #subcat_vsod_count = subcat_vsod_count * len(subsegments)\n",
    "    subcat_vsod_count = subcat_vsod_count\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6dd04ba3-5570-4ad4-8d61-252872480a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "promotionsBrandSortedTotalFinal={}\n",
    "promotionsBrandSortedTotal=dfSort(globals()[f\"modified_promotionBrands{slides_Period}\"], client_brands, \"Top Brands\", num=8,salesCol='Promo Value')\n",
    "for key,df in promotionsBrandSortedTotal.items():\n",
    "     df_client = selectClientBrands(promotionsBrandSortedTotal[key],'Top Brands', 'Promo Value')\n",
    "     number_of_brands_needed = max(6 - len(df_client),0)\n",
    "     \n",
    "     df = df[~df['Top Brands'].isin(client_brands)]\n",
    "     df = df[~df['Top Brands'].str.contains('Others', case=False)]\n",
    "     \n",
    "     df = df.sort_values(by='Promo Value', ascending=False).head(number_of_brands_needed)\n",
    "     df = pd.concat([df, df_client], ignore_index=True)\n",
    "     df = df.sort_values(by='Promo Value', ascending=False).reset_index(drop=True)\n",
    "     df = df[~df['Top Brands'].str.contains('Grand Total', case=False)]\n",
    "     df = df[df['Value Share'] > 0.01]\n",
    "        \n",
    "     df['VSOD Evaluation vs YA'] = df['VSOD Evaluation vs YA'].astype(float)\n",
    "     df['Promo Value Uplift vs YA'] = df['Promo Value Uplift vs YA'].astype(float)\n",
    "     \n",
    "     if df.shape[0] >0:\n",
    "          promotionsBrandSortedTotalFinal[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e66555e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "promotionsBrandNOTSortedTotalFinal={}\n",
    "promotionsBrandNOTSortedTotalFinal=dfSort(globals()[f\"modified_promotionBrands{slides_Period}\"], client_brands, \"Top Brands\", num=8,salesCol='Promo Value')\n",
    "for key,df in globals()[f\"modified_promotionBrands{slides_Period}\"].items():\n",
    "     df = df.sort_values(by='Promo Value', ascending=False).reset_index(drop=True)\n",
    "     df = df[~df['Top Brands'].str.contains('Others', case=False)]\n",
    "     df = df[~df['Top Brands'].str.contains('Grand Total', case=False)]\n",
    "     df = df[df['Value Share'] > 0.01]\n",
    "     df['VSOD Evaluation vs YA'] = df['VSOD Evaluation vs YA'].astype(float)\n",
    "     df['Promo Value Uplift vs YA'] = df['Promo Value Uplift vs YA'].astype(float)\n",
    "     if df.shape[0] >0:\n",
    "          promotionsBrandNOTSortedTotalFinal[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "75e0e42f-2500-4d43-9ed2-2b5ac567a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedBrands_og = selectedBrands\n",
    "selectedBrands= selectedBrands + [\"Grand Total\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ab470824-4116-42ea-b87c-150650a1d61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "promotionsBrandsSelected={key:globals()[f\"modified_promotionBrands{slides_Period}_total\"][key][globals()[f\"modified_promotionBrands{slides_Period}_total\"][key]['Top Brands'].isin(selectedBrands)].sort_values(by='Promo Value',ascending=False) for key in globals()[f\"modified_promotionBrands{slides_Period}_total\"].keys()   if all(cat != key.split(' | ')[0] for cat in categories)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5deb8699",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in promotionsBrandsSelected:\n",
    "    grand_total_row = promotionsBrandsSelected[key].loc[promotionsBrandsSelected[key]['Top Brands'] == 'Grand Total']\n",
    "    sorted_df = promotionsBrandsSelected[key].loc[promotionsBrandsSelected[key]['Top Brands'] != 'Grand Total']\n",
    "    promotionsBrandsSelected[key] = pd.concat([grand_total_row, sorted_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bf5988c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedBrands = selectedBrands_og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6d4a6ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not including client brands\n",
    "promotionsNotBrandsSelected = {\n",
    "    key: globals()[f\"modified_promotionBrands{slides_Period}_total\"][key][\n",
    "        ~globals()[f\"modified_promotionBrands{slides_Period}_total\"][key]['Top Brands'].isin(selectedBrands)\n",
    "    ].sort_values(by='Value Share', ascending=False)\n",
    "    for key in globals()[f\"modified_promotionBrands{slides_Period}_total\"].keys()\n",
    "    if all(cat != key.split(' | ')[0] for cat in categories)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5825f852-d5a8-4717-863c-60bce7831474",
   "metadata": {},
   "outputs": [],
   "source": [
    "promotionsBrandsWithMarket=concatAttribute(promotionsBrandsSelected,marketList)\n",
    "promotionsBrandsWithMarket = fillingMissingBrands(promotionsBrandsWithMarket)\n",
    "promotionsNotBrandsWithMarket=concatAttribute(promotionsNotBrandsSelected,marketList)\n",
    "promotionsNotBrandsWithMarket = fillingMissingBrands(promotionsNotBrandsWithMarket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "762fb5e2-0b4d-442f-9531-040980af3115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_market(data, Scope):\n",
    "    final = {}\n",
    "    for k,df in data.items():\n",
    "        for key, value in Scope.items():\n",
    "            df_market = df[df['SOURCE'].isin(value)]\n",
    "            df_market = df_market.reset_index(drop=True)\n",
    "            if df_market.shape[0] >0:\n",
    "                final[k + ' | ' + value[0]] = df_market\n",
    "    return final        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b2a003a6-6da6-495c-a2d9-a9b0af5a7a88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newpromotionsBrandsWithMarket = split_market(promotionsBrandsWithMarket,Scope)\n",
    "newpromotionsNotBrandsWithMarket = split_market(promotionsNotBrandsWithMarket,Scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6e045f79-110e-4cb8-b237-b514151b9c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatAttributeNew(sorted):\n",
    "    \"\"\"\n",
    "    Concatenate DataFrames from a sorted dictionary based on exact matches of categories, sectors, segments,\n",
    "    subsegments, and subcategories. Adds a 'SOURCE' column to each DataFrame indicating its market.\n",
    "\n",
    "    Parameters:\n",
    "    sorted (dict): Dictionary with keys like 'category | sector | segment | brand' and values as DataFrames.\n",
    "    categories, sectors, segments, subsegments, subcategories (list): Lists of strings to match exactly.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary with matched group names as keys and concatenated DataFrames as values.\n",
    "    \"\"\"\n",
    "    # Combine all lists and preserve order without duplicates\n",
    "    lis = list(dict.fromkeys(categories + sectors + segments + subsegments + subcategories))\n",
    "\n",
    "    marketDic = defaultdict(list)\n",
    "    concatenatedDic = {}\n",
    "\n",
    "    for i in lis:\n",
    "        for key, df in sorted.items():\n",
    "            parts = key.split(' | ')\n",
    "            if i in parts:\n",
    "                # Determine market label\n",
    "        \n",
    "                market_label = parts[1]  # category\n",
    "\n",
    "                df = df.copy()  # Avoid modifying original\n",
    "                df['SOURCE'] = market_label\n",
    "                marketDic[i].append(df)\n",
    "\n",
    "        if marketDic[i]:\n",
    "            concatenatedDic[i] = pd.concat(marketDic[i], ignore_index=True)\n",
    "\n",
    "    return concatenatedDic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "28e29be2-2f65-4603-8858-1087e008b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "concated = concatAttributeNew(globals()[f\"modified_promotionBrands{slides_Period}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "84e39181",
   "metadata": {},
   "outputs": [],
   "source": [
    "concated1 = concatAttributeNew(globals()[f\"modified_promotionBrands_share{slides_Period}\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8b8c6fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[f\"new_modified_promotionProducts{slides_Period}\"] = filter_data(globals()[f\"modified_promotionProducts{slides_Period}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d5316486-6b68-430c-963f-11df7ef98c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top20clientonly = filter_data_Top(globals()[f\"modified_promotionProducts{slides_Period}\"])\n",
    "bottom20clientonly = filter_data_Bot(globals()[f\"modified_promotionProducts{slides_Period}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4f3e9198-c36a-4544-8a00-92a1e2ab89cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promotionsEndOfWeekCleaning(promotions_EndOfWeek, notInScope, col='Top Brands'):\n",
    "    promotionsEndOfWeek = {}\n",
    "    for key, value in promotions_EndOfWeek.items():\n",
    "        df = value.copy()\n",
    "        if df.shape[0] != 0:\n",
    "            modified_key = key\n",
    "            flag = False if any(element in modified_key for element in notInScope) else True\n",
    "            if flag:\n",
    "                promotionsEndOfWeek[modified_key] = df[df[col] != 'Grand Total'].reset_index(drop=True).replace(np.nan, 0)\n",
    "        else:\n",
    "            print(key, ' Is empty')\n",
    "    \n",
    "    return promotionsEndOfWeek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c3bdd031-7086-48bc-b9b6-d9e09be82bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod=cleaningData(promotions_EndOfWeek)\n",
    "promotionsEndOfWeekCleaned=promotionsEndOfWeekCleaning(mod,notInScope,col='End of Week')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4e7408ac-109a-48e1-83ee-1f3acda454ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "brandMarketCategory = [key for key in promotionsEndOfWeekCleaned.keys() if any(cat in key.split(' | ')[0] for cat in categories )]\n",
    "if len(sectors) != 0:\n",
    "    brandMarketSector = [key for key in promotionsEndOfWeekCleaned.keys() if any(cat == key.split(' | ')[0] for cat in sectors )]\n",
    "if len(segments) != 0:\n",
    "    brandMarketSegment = [key for key in promotionsEndOfWeekCleaned.keys() if any(cat == key.split(' | ')[0] for cat in segments )]\n",
    "if len(subsegments) != 0:\n",
    "    brandMarketSubSegment = [key for key in promotionsEndOfWeekCleaned.keys() if any(cat == key.split(' | ')[0] for cat in subsegments )]\n",
    "if len(subcategories) != 0:\n",
    "    brandMarketSubCategory = [key for key in promotionsEndOfWeekCleaned.keys() if any(cat == key.split(' | ')[0] for cat in subcategories )]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "33070cde-4b18-410c-bf87-00d132014a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeDates(dfList, promotionsEndOfWeekCleaned):\n",
    "    # Create a list of unique brand-category combinations\n",
    "    brandCatList = sorted(set(key.split(' | ')[0] + ' | ' + key.split(' | ')[1] for key in dfList))\n",
    "    EndOfWeekcompletDate = {}\n",
    "    dfGroup = []\n",
    "    dic = defaultdict(int)\n",
    "    for key in brandCatList:\n",
    "        for name in dfList:\n",
    "            if (key.split(' | ')[0] == name.split(' | ')[0]) and (key.split(' | ')[1] == name.split(' | ')[1]):\n",
    "                dic[key] += 1\n",
    "                \n",
    "    # Iterate over unique brand-category combinations\n",
    "    for name in dic.keys():\n",
    "        # Get dataframe keys associated with the current brand-category combination\n",
    "        dfName = [key for key in dfList if name == (key.split(' | ')[0] + ' | ' + key.split(' | ')[1])]\n",
    "        uniqueDates = pd.concat([promotionsEndOfWeekCleaned[key] for key in dfName])[['End of Week']].drop_duplicates()\n",
    "        if uniqueDates.shape[0] > 0:\n",
    "            dfCompleteDates = {}\n",
    "            dfGroup.append(dfName)\n",
    "            for key in dfName:\n",
    "                EndOfWeekcompletDate[key] = pd.merge(uniqueDates, promotionsEndOfWeekCleaned[key], how='left').replace(np.nan, 0).sort_values(by='End of Week').reset_index(drop = True)\n",
    "    return EndOfWeekcompletDate, dfGroup, dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "26bde262-eab5-4afc-ab44-9c3658cb974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(categories) != 0:\n",
    "    dfCategory,catGroup,catDuplication=completeDates(brandMarketCategory,promotionsEndOfWeekCleaned)\n",
    "if len(sectors) != 0:\n",
    "    dfSector,secGroup,secDuplication=completeDates(brandMarketSector,promotionsEndOfWeekCleaned)\n",
    "if len(segments) != 0:\n",
    "    dfSegment,segGroup,segDuplication=completeDates(brandMarketSegment,promotionsEndOfWeekCleaned)\n",
    "if len(subsegments) != 0:\n",
    "    dfSubSegment,subsegGroup,subsegDuplication=completeDates(brandMarketSubSegment,promotionsEndOfWeekCleaned)\n",
    "if len(subcategories) != 0:\n",
    "    dfSubCategory,subcatGroup,subcatDuplication=completeDates(brandMarketSubCategory,promotionsEndOfWeekCleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4108f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors):\n",
    "    sect_vsod_count =0\n",
    "    for key,df in sect_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                sect_vsod_count +=1\n",
    "    sect_vsod_count = sect_vsod_count *len(categories)\n",
    " \n",
    "if len(segments):\n",
    "    seg_vsod_count =0\n",
    "    for key,df in seg_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                seg_vsod_count +=1\n",
    "    seg_vsod_count = seg_vsod_count           \n",
    " \n",
    "if len(subsegments) >0:\n",
    "    subseg_vsod_count =0\n",
    "    for key,df in subseg_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                subseg_vsod_count +=1\n",
    "    subseg_vsod_count = subseg_vsod_count\n",
    " \n",
    "if len(subcategories) >0:\n",
    "    subcat_vsod_count =0\n",
    "    for key,df in subcat_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                subcat_vsod_count +=1\n",
    "    subcat_vsod_count = subcat_vsod_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "43c6f94a-d00f-46ad-9011-678073e6bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PromoRet ={}\n",
    "if len(categories)!=0:\n",
    "    first_key, first_value = next(iter(catDuplication.items()))\n",
    "    PromoRet.update({first_key: first_value})\n",
    "if len(sectors)!=0:\n",
    "    sec_key, sec_value = next(iter(secDuplication.items()))\n",
    "    PromoRet.update({sec_key:sec_value})\n",
    "if len(segments)!=0:\n",
    "    third_key, third_value = next(iter(segDuplication.items()))\n",
    "    PromoRet.update({third_key: third_value})\n",
    "if len(subsegments)!=0:\n",
    "    fourth_key, fourth_value = next(iter(subsegDuplication.items()))\n",
    "    PromoRet.update({fourth_key:fourth_value})\n",
    "if len(subcategories)!=0:\n",
    "    fifth_key, fifth_value = next(iter(subcatDuplication.items()))\n",
    "    PromoRet.update({fifth_key:fifth_value })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a728a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "PromoSalesTypes_data = {}\n",
    "for key in brands_promo_type.keys():\n",
    "    df=brands_promo_type[key].copy()\n",
    "    df[\"Promo Sales\"] = pd.to_numeric(df[\"Promo Sales\"], errors=\"coerce\").fillna(0)\n",
    "    df[\"Value Share\"] = pd.to_numeric(df[\"Value Share\"], errors=\"coerce\").fillna(0)\n",
    "    df = df[df['Promo Type'].notna()]\n",
    "    brand_totals = df.groupby(\"Top Brands\")['Promo Sales'].sum()\n",
    "    df[\"Brand Total Sales\"] = df[\"Top Brands\"].map(brand_totals)\n",
    "    df[\"% Promo Sales\"] = df[\"Promo Sales\"] / df[\"Brand Total Sales\"]\n",
    "\n",
    "    df = df[~df['Top Brands'].str.contains('Others|Grand Total', case=False)]\n",
    "    df = df[df['Value Share'] > 0.01]\n",
    "    df = df[df['Promo Sales'] > 0]\n",
    "    # Select client brands and additional brands needed to make 10 brands\n",
    "    df_client = selectClientBrands(brands_promo_type[key],'Top Brands', 'Value Share')\n",
    "    comp_brand = df[~df['Top Brands'].isin(cb for cb in client_brands)].drop_duplicates(\"Top Brands\")\n",
    "    if not df_client.empty:\n",
    "        comp_brand = comp_brand.nlargest(10-df_client[\"Top Brands\"].nunique(), \"Value Share\")[\"Top Brands\"].to_list()\n",
    "        # Concatenate client brands and additional brands\n",
    "        df = df[df[\"Top Brands\"].isin(comp_brand + client_brands)]\n",
    "        df = df.reset_index(drop=True)\n",
    "        df = df.sort_values(\"Value Share\", ascending=False).reset_index(drop=True)\n",
    "        df = df[~df['Promo Type'].fillna('').str.contains('NONE/PL|Undefined|Nan', na=False)]\n",
    "        # print(comp_brand)\n",
    "        if df.shape[0]:\n",
    "            PromoSalesTypes_data[key] =df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "88c1ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lis = []\n",
    "cat_lis = []\n",
    "if categories:\n",
    "    for i in range(len(catGroup)):\n",
    "        cat_lis += genrateIndexList(catGroup[i], chartIndex=14, chartCount=4)[0]\n",
    "    final_lis.append(cat_lis)\n",
    "else:\n",
    "    final_lis.append([])\n",
    "\n",
    "sec_lis = []\n",
    "if sectors:\n",
    "    for i in range(len(secGroup)):\n",
    "        sec_lis += genrateIndexList(secGroup[i], chartIndex=14, chartCount=4)[0]\n",
    "    final_lis.append(sec_lis)\n",
    "else:\n",
    "    final_lis.append([])\n",
    "\n",
    "seg_lis=[]\n",
    "if segments:\n",
    "    for i in range(len(segGroup)):\n",
    "        seg_lis += genrateIndexList(segGroup[i], chartIndex=14, chartCount=4)[0]\n",
    "    final_lis.append(seg_lis)\n",
    "\n",
    "else:\n",
    "    final_lis.append([])\n",
    "\n",
    "subseg_lis =[]\n",
    "if subsegments:\n",
    "    for i in range(len(subsegGroup)):\n",
    "        subseg_lis +=  genrateIndexList(subsegGroup[i], chartIndex=14, chartCount=4)[0]\n",
    "    final_lis.append(subseg_lis)\n",
    "else:\n",
    "    final_lis.append([])\n",
    "\n",
    "subcat_lis =[]\n",
    "if subcategories:\n",
    "    for i in range(len(subcatGroup)):\n",
    "        subcat_lis +=  genrateIndexList(subcatGroup[i], chartIndex=14, chartCount=4)[0]\n",
    "    final_lis.append(subcat_lis)\n",
    "else:\n",
    "    final_lis.append([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd4fa9",
   "metadata": {},
   "source": [
    "### New Slide 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "db1737be",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_month_year=MonthYear_clean(Category_MonthYear,column='Category')\n",
    "sector_month_year = MonthYear_clean(Sector_MonthYear,column='Sector')\n",
    "segment_month_year = MonthYear_clean(Segment_MonthYear,column='Segment')\n",
    "subcat_month_year = MonthYear_clean(SubCategory_MonthYear,column='SubCategory')\n",
    "subseg_month_year = MonthYear_clean(SubSegment_MonthYear,column='SubSegment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6ac48172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_month_year(data, column):\n",
    "    final_month_year ={}\n",
    "    for key,df in data.items():\n",
    "        for sec in df[column].unique():\n",
    "            newkey = key + ' | ' + sec\n",
    "            new_df = df[df[column] == sec].reset_index(drop=True)\n",
    "            if new_df.shape[0] > 0:\n",
    "                final_month_year[newkey] = new_df\n",
    "    return final_month_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "265d60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_month_year1=split_month_year(category_month_year,'Category')\n",
    "sector_month_year1 = split_month_year(sector_month_year,'Sector')\n",
    "segment_month_year1 = split_month_year(segment_month_year,'Segment')\n",
    "subseg_month_year1 = split_month_year(subseg_month_year,'SubSegment')\n",
    "subcat_month_year1 = split_month_year(subcat_month_year,'SubCategory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b92a3b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_year1 = {}\n",
    "month_year1.update(sector_month_year1)\n",
    "month_year1.update(segment_month_year1)\n",
    "month_year1.update(subcat_month_year1)\n",
    "month_year1.update(subseg_month_year1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a94833af",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandMarketCategory = [key for key in category_month_year1.keys() if any(cat == key.split(' | ')[2]  for cat in categories )]\n",
    "if len(sectors) != 0:\n",
    "    brandMarketSector = [key for key in sector_month_year1.keys() if any(cat == key.split(' | ')[2]  for cat in sectors )]\n",
    "if len(segments) != 0:\n",
    "    brandMarketSegment = [key for key in segment_month_year1.keys() if any(cat == key.split(' | ')[2]  for cat in segments )]\n",
    "if len(subsegments) != 0:\n",
    "    brandMarketSubSegment = [key for key in subseg_month_year1.keys() if any(cat == key.split(' | ')[2] for cat in subsegments )]\n",
    "if len(subcategories) != 0:\n",
    "    brandMarketSubCategory = [key for key in subcat_month_year1.keys() if any(cat == key.split(' | ')[2] for cat in subcategories )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "17cb72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeDates1(dfList, promotionsEndOfWeekCleaned,column=\"Sector\"):\n",
    "    brandCatList = sorted(set(key.split(' | ')[0]  for key in dfList))\n",
    "    EndOfWeekcompletDate = {}\n",
    "    dfGroup = []\n",
    "    dic = defaultdict(int)\n",
    "    for key in brandCatList:\n",
    "        for name in dfList:\n",
    "            if (key.split(' | ')[0] == name.split(' | ')[0]):\n",
    "                \n",
    "                dic[key] += 1\n",
    "    for name in dic.keys():\n",
    "\n",
    "        if column == \"Sector\" :\n",
    "            dfName = [key for key in dfList if name == key.split(' | ')[0] and len(name.split(' | ')) == 1]\n",
    "        else:\n",
    "            dfName = [key for key in dfList if name == key.split(' | ')[0]  ]\n",
    "        uniqueDates = pd.concat([promotionsEndOfWeekCleaned[key] for key in dfName])[['MonthYear']].drop_duplicates()\n",
    "        dfCompleteDates = {}\n",
    "        dfGroup.append(dfName)\n",
    "        for key in dfName:\n",
    "            EndOfWeekcompletDate[key] = pd.merge(uniqueDates, promotionsEndOfWeekCleaned[key], how='left')#.replace(np.nan, 0)\n",
    "            column = EndOfWeekcompletDate[key].columns[1]\n",
    "            year = EndOfWeekcompletDate[key].columns[3]\n",
    "            monthyear = EndOfWeekcompletDate[key].columns[0]\n",
    "            EndOfWeekcompletDate[key][column] = EndOfWeekcompletDate[key][column].fillna(method='ffill')      \n",
    "            EndOfWeekcompletDate[key][year] = pd.to_datetime(EndOfWeekcompletDate[key][monthyear], format='%b-%y').dt.year\n",
    "            EndOfWeekcompletDate[key] = EndOfWeekcompletDate[key].fillna(0)\n",
    "    return EndOfWeekcompletDate, dfGroup, dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3b1814ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCategory0,categoryGroup0,categoryDuplication0=completeDates1(brandMarketCategory,category_month_year1,column=\"Category\")\n",
    "if len(sectors) != 0:\n",
    "    dfSector0,secGroup0,secDuplication0=completeDates1(brandMarketSector,sector_month_year1,column=\"Sector\")\n",
    "if len(segments) != 0:\n",
    "    dfSegment0,segGroup0,segDuplication0=completeDates1(brandMarketSegment,segment_month_year1,column=\"Segment\")\n",
    "if len(subsegments) != 0:\n",
    "    dfSubSegment0,subsegGroup0,subsegDuplication0=completeDates1(brandMarketSubSegment,subseg_month_year1,column=\"Subsegment\")\n",
    "if len(subcategories) != 0:\n",
    "    dfSubCategory0,subcatGroup0,subcatDuplication0=completeDates1(brandMarketSubCategory,subcat_month_year1,column=\"Subcategory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "55074d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryGroup0=groupingkeys(categoryGroup0)\n",
    "if len(sectors) != 0:\n",
    "    secGroup0=groupingkeys(secGroup0)\n",
    "if len(segments) != 0:\n",
    "    segGroup0=groupingkeys(segGroup0)\n",
    "if len(subsegments) != 0:\n",
    "    subsegGroup0=groupingkeys(subsegGroup0)\n",
    "if len(subcategories) != 0:\n",
    "    subcatGroup0=groupingkeys(subcatGroup0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "94eb5ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20, 20, 20, 20, 20, 20, 20, 20], [21, 21, 21, 21, 21, 21, 21, 21]]\n",
      "[[20, 20, 20, 20, 20, 20, 20, 20], [21, 21, 21, 21, 21, 21, 21, 21], [22, 22, 22, 22, 22, 22, 22, 22]]\n",
      "[[20, 20, 20, 20, 20, 20, 20, 20], [21, 21, 21, 21, 21, 21, 21, 21], [22, 22, 22, 22, 22, 22, 22, 22], []]\n"
     ]
    }
   ],
   "source": [
    "final_lis0 = []\n",
    "category_lis = []\n",
    "if categories:\n",
    "    for i in range(len(categoryGroup0)):\n",
    "        category_lis += genrateIndexList(categoryGroup0[i], chartIndex=19, chartCount=6)[0]\n",
    "final_lis0.append(category_lis)  # Append empty list if sectors is False\n",
    "\n",
    "sec_lis = []\n",
    "if sectors:\n",
    "    for i in range(len(secGroup0)):\n",
    "        sec_lis += genrateIndexList(secGroup0[i], chartIndex=19, chartCount=6)[0]\n",
    "final_lis0.append(sec_lis)  # Append empty list if sectors is False\n",
    "print(final_lis0)\n",
    "\n",
    "seg_lis = []\n",
    "if segments:\n",
    "    for i in range(len(segGroup0)):\n",
    "        seg_lis += genrateIndexList(segGroup0[i], chartIndex=19, chartCount=6)[0]\n",
    "final_lis0.append(seg_lis)  # Append empty list if segments is False\n",
    "print(final_lis0)\n",
    "\n",
    "subseg_lis = []\n",
    "if subsegments:\n",
    "    for i in range(len(subsegGroup0)):\n",
    "        subseg_lis += genrateIndexList(subsegGroup0[i], chartIndex=19, chartCount=6)[0]\n",
    "final_lis0.append(subseg_lis)  # Append empty list if subsegments is False\n",
    "print(final_lis0)\n",
    "\n",
    "subcat_lis = []\n",
    "if subcategories:\n",
    "    for i in range(len(subcatGroup0)):\n",
    "        subcat_lis += genrateIndexList(subcatGroup0[i], chartIndex=19, chartCount=6)[0]\n",
    "final_lis0.append(subcat_lis)  # Append empty list if subcategories is False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc50143",
   "metadata": {},
   "source": [
    "### New slide 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3653fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[f\"modified_endofweek_{slides_Period}\"] = {}\n",
    "past_12_months = pd.date_range(end=end_date , periods=12, freq='M').strftime('%b-%y').tolist()\n",
    "for key in modified_promotionEndOfWeek.keys():\n",
    "    df=modified_promotionEndOfWeek[key].copy()\n",
    "    df['End of Week'] = pd.to_datetime(df['End of Week'])\n",
    "    filtered_df = df[df['End of Week'].dt.strftime('%b-%y').isin(past_12_months)]\n",
    "    if filtered_df.shape[0] >0:\n",
    "        globals()[f\"modified_endofweek_{slides_Period}\"][key] = filtered_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "06d18d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandMarketCategory= [key for key in globals()[f\"modified_endofweek_{slides_Period}\"].keys() if any(cat in key.split(' | ')[0] for cat in categories )]\n",
    "if len(sectors) != 0:\n",
    "    brandMarketSector = [key for key in globals()[f\"modified_endofweek_{slides_Period}\"].keys() if any(cat == key.split(' | ')[0] for cat in sectors )]\n",
    "if len(segments) != 0:\n",
    "    brandMarketSegment = [key for key in globals()[f\"modified_endofweek_{slides_Period}\"].keys() if any(cat == key.split(' | ')[0] for cat in segments )]\n",
    "if len(subsegments) != 0:\n",
    "    brandMarketSubSegment = [key for key in globals()[f\"modified_endofweek_{slides_Period}\"].keys() if any(cat == key.split(' | ')[0] for cat in subsegments )]\n",
    "if len(subcategories) != 0:\n",
    "    brandMarketSubCategory = [key for key in globals()[f\"modified_endofweek_{slides_Period}\"].keys() if any(cat == key.split(' | ')[0] for cat in subcategories )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3ace0ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(categories) != 0:\n",
    "    dfCategory1,catGroup1,catDuplication1=completeDates(brandMarketCategory,globals()[f\"modified_endofweek_{slides_Period}\"])\n",
    "if len(sectors) != 0:\n",
    "    dfSector1,secGroup1,secDuplication1=completeDates(brandMarketSector,globals()[f\"modified_endofweek_{slides_Period}\"])\n",
    "if len(segments) != 0:\n",
    "    dfSegment1,segGroup1,segDuplication1=completeDates(brandMarketSegment,globals()[f\"modified_endofweek_{slides_Period}\"])\n",
    "if len(subsegments) != 0:\n",
    "    dfSubSegment1,subsegGroup1,subsegDuplication1=completeDates(brandMarketSubSegment,globals()[f\"modified_endofweek_{slides_Period}\"])\n",
    "if len(subcategories) != 0:\n",
    "    dfSubCategory1,subcatGroup1,subcatDuplication1=completeDates(brandMarketSubCategory,globals()[f\"modified_endofweek_{slides_Period}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8479ede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promofrequencyclean(data):        \n",
    "        modified_dfCategory1 = {}\n",
    "        for k in data.keys():\n",
    "                chart_df=data[k].copy()\n",
    "                chart_df['Weekly VSOD'] = np.where((chart_df['VSOD']>.2)&(chart_df['Value Uplift (v. base) Normalized'] != ''),1,None)\n",
    "                chart_df['try'] = 0\n",
    "                chart_df['New Uplift'] = 0\n",
    "                chart_df['try'] = np.where((chart_df['Value Uplift (v. base) Normalized']>=2),1.8,chart_df['Value Uplift (v. base) Normalized'])\n",
    "                chart_df['New Uplift'] = np.where((chart_df['Weekly VSOD']==1)&(chart_df['Value Uplift (v. base) Normalized']>0.05),chart_df['try'],None)\n",
    "                if not chart_df['Weekly VSOD'].isnull().all():\n",
    "                        modified_dfCategory1[k]= chart_df \n",
    "        return modified_dfCategory1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9ad97599",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(categories)!=0: \n",
    "    modified_dfCategory1=promofrequencyclean(dfCategory1)\n",
    "if len(sectors)!=0: \n",
    "    modified_dfSector1=promofrequencyclean(dfSector1)\n",
    "if len(segments)!=0: \n",
    "    modified_dfSegment1=promofrequencyclean(dfSegment1)\n",
    "if len(subsegments)!=0: \n",
    "    modified_dfSubSegment1=promofrequencyclean(dfSubSegment1)\n",
    "if len(subcategories)!=0: \n",
    "    modified_dfSubCategory1=promofrequencyclean(dfSubCategory1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2f0aae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandMarketCategory= [key for key in modified_dfCategory1.keys() if any(cat in key.split(' | ')[0] for cat in categories )]\n",
    "if len(sectors) != 0:\n",
    "    brandMarketSector = [key for key in modified_dfSector1.keys() if any(cat == key.split(' | ')[0] for cat in sectors )]\n",
    "if len(segments) != 0:\n",
    "    brandMarketSegment = [key for key in modified_dfSegment1.keys() if any(cat == key.split(' | ')[0] for cat in segments )]\n",
    "if len(subsegments) != 0:\n",
    "    brandMarketSubSegment = [key for key in modified_dfSubSegment1.keys() if any(cat == key.split(' | ')[0] for cat in subsegments )]\n",
    "if len(subcategories) != 0:\n",
    "    brandMarketSubCategory = [key for key in modified_dfSubCategory1.keys() if any(cat == key.split(' | ')[0] for cat in subcategories )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "31f3763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(categories) != 0:\n",
    "    dfCategory1,catGroup1,catDuplication1=completeDates(brandMarketCategory,globals()[f\"modified_endofweek_{slides_Period}\"])\n",
    "if len(sectors) != 0:\n",
    "    dfSector1,secGroup1,secDuplication1=completeDates(brandMarketSector,globals()[f\"modified_endofweek_{slides_Period}\"])\n",
    "if len(segments) != 0:\n",
    "    dfSegment1,segGroup1,segDuplication1=completeDates(brandMarketSegment,globals()[f\"modified_endofweek_{slides_Period}\"])\n",
    "if len(subsegments) != 0:\n",
    "    dfSubSegment1,subsegGroup1,subsegDuplication1=completeDates(brandMarketSubSegment,globals()[f\"modified_endofweek_{slides_Period}\"])\n",
    "if len(subcategories) != 0:\n",
    "    dfSubCategory1,subcatGroup1,subcatDuplication1=completeDates(brandMarketSubCategory,globals()[f\"modified_endofweek_{slides_Period}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c2bbe9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_region(data):\n",
    "    # Define categories for grouping\n",
    "    market_groups = {\n",
    "        \"RETAILER_REGIONS\": regions_RET,\n",
    "        \"RETAILER_CHANNELS\": channels_RET,\n",
    "        \"RETAILER_MARKET\": market_RET,\n",
    "        \"CHANNEL_REGIONS\": regions_CHAN,\n",
    "        \"CHANNEL_CHANNELS\": channels_CHAN,\n",
    "        \"CHANNEL_MARKET\": market_CHAN,\n",
    "        f\"{customareas}_REGIONS\": regions_CUST,\n",
    "        f\"{customareas}_CHANNELS\": channels_CUST,\n",
    "        f\"{customareas}_MARKET\": market_CUST,\n",
    "    }\n",
    "    result = []\n",
    "    for sublist in data:\n",
    "        for category, keywords in market_groups.items():\n",
    "            # Filter items matching the current category\n",
    "            base_category = category.split(\"_\")[0]\n",
    "\n",
    "            group = [\n",
    "                f\"{item} | {base_category}\" for item in sublist if item.split(\" | \")[-1] in keywords\n",
    "            ]\n",
    "            if group:  # Append only non-empty groups\n",
    "                result.append(group)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "016f5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(categories)>0:\n",
    "    catGroup1 = group_by_region(catGroup1)\n",
    "if len(sectors)>0:\n",
    "    secGroup1 = group_by_region(secGroup1)\n",
    "if len(segments)>0:\n",
    "    segGroup1 = group_by_region(segGroup1)\n",
    "if len(subsegments)>0:\n",
    "    subsegGroup1 = group_by_region(subsegGroup1)\n",
    "if len(subcategories)>0:\n",
    "    subcatGroup1 = group_by_region(subcatGroup1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "95b943e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lis1 = []\n",
    "cat_lis = []\n",
    "if categories:\n",
    "    for i in range(len(catGroup1)):\n",
    "        cat_lis += genrateIndexList(catGroup1[i], chartIndex=25, chartCount=4)[0]\n",
    "    final_lis1.append(cat_lis)\n",
    "else:\n",
    "    final_lis1.append([])\n",
    "\n",
    "sec_lis = []\n",
    "if sectors:\n",
    "    for i in range(len(secGroup1)):\n",
    "        sec_lis += genrateIndexList(secGroup1[i], chartIndex=25, chartCount=4)[0]\n",
    "    final_lis1.append(sec_lis)\n",
    "else:\n",
    "    final_lis1.append([])\n",
    "\n",
    "seg_lis=[]\n",
    "if segments:\n",
    "    for i in range(len(segGroup1)):\n",
    "        seg_lis += genrateIndexList(segGroup1[i], chartIndex=25, chartCount=4)[0]\n",
    "    final_lis1.append(seg_lis)\n",
    "\n",
    "else:\n",
    "    final_lis1.append([])\n",
    "\n",
    "subseg_lis =[]\n",
    "if subsegments:\n",
    "    for i in range(len(subsegGroup1)):\n",
    "        subseg_lis +=  genrateIndexList(subsegGroup1[i], chartIndex=25, chartCount=4)[0]\n",
    "    final_lis1.append(subseg_lis)\n",
    "else:\n",
    "    final_lis1.append([])\n",
    "\n",
    "subcat_lis =[]\n",
    "if subcategories:\n",
    "    for i in range(len(subcatGroup1)):\n",
    "        subcat_lis +=  genrateIndexList(subcatGroup1[i], chartIndex=25, chartCount=4)[0]\n",
    "    final_lis1.append(subcat_lis)\n",
    "else:\n",
    "    final_lis1.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "21faef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "retailer=regions_RET+channels_RET+market_RET\n",
    "channels=regions_CHAN+channels_CHAN+channels_CHAN\n",
    "customarea=regions_CUST+channels_CUST+market_CUST\n",
    "def addarea(modified_dfCategory1,retailer,market=\"RETAILER\"):\n",
    "    keys_to_modify = [k for k in modified_dfCategory1.keys() if k.split(\" | \")[-1] in retailer]\n",
    "    for k in keys_to_modify:\n",
    "        new_key = k + \" | \"+ market\n",
    "        modified_dfCategory1[new_key] = modified_dfCategory1[k]  \n",
    "        del modified_dfCategory1[k]       \n",
    "    return modified_dfCategory1      \n",
    "if len(categories)>0:            \n",
    "    modified_dfCategory1=addarea(modified_dfCategory1,retailer,market=\"RETAILER\")\n",
    "    modified_dfCategory1=addarea(modified_dfCategory1,channels,market=\"CHANNELS\")\n",
    "    modified_dfCategory1=addarea(modified_dfCategory1,customarea,market=f\"{customareas}\")\n",
    "\n",
    "if len(sectors)>0:            \n",
    "    modified_dfSector1=addarea(modified_dfSector1,retailer,market=\"RETAILER\")\n",
    "    modified_dfSector1=addarea(modified_dfSector1,channels,market=\"CHANNELS\")\n",
    "    modified_dfSector1=addarea(modified_dfSector1,customarea,market=f\"{customareas}\")\n",
    "if len(segments)>0:            \n",
    "    modified_dfSegment1=addarea(modified_dfSegment1,retailer,market=\"RETAILER\")\n",
    "    modified_dfSegment1=addarea(modified_dfSegment1,channels,market=\"CHANNELS\")\n",
    "    modified_dfSegment1=addarea(modified_dfSegment1,customarea,market=f\"{customareas}\")\n",
    "if len(subsegments)>0:            \n",
    "    modified_dfSubSegment1=addarea(modified_dfSubSegment1,retailer,market=\"RETAILER\")\n",
    "    modified_dfSubSegment1=addarea(modified_dfSubSegment1,channels,market=\"CHANNELS\")\n",
    "    modified_dfSubSegment1=addarea(modified_dfSubSegment1,customarea,market=f\"{customareas}\")\n",
    "if len(subcategories)>0:            \n",
    "    modified_dfSubCategory1=addarea(modified_dfSubCategory1,retailer,market=\"RETAILER\")\n",
    "    modified_dfSubCategory1=addarea(modified_dfSubCategory1,channels,market=\"CHANNELS\")\n",
    "    modified_dfSubCategory1=addarea(modified_dfSubCategory1,customarea,market=f\"{customareas}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ec5211df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in list(globals()[f\"modified_promotionBrands{slides_Period}\"].keys()):  # Convert to list to avoid runtime errors\n",
    "    df = globals()[f\"modified_promotionBrands{slides_Period}\"][k].copy()\n",
    "    # Filter rows based on 'Top Brands'\n",
    "    df = df[~df['Top Brands'].str.contains('Others', case=False, na=False)]\n",
    "    df = df[~df['Top Brands'].str.contains('Grand Total', case=False, na=False)]\n",
    "    df = df[df['Value Share'] > 0.01]\n",
    "    if not df.empty:\n",
    "        globals()[f\"modified_promotionBrands{slides_Period}\"][k] = df\n",
    "    else:\n",
    "        del globals()[f\"modified_promotionBrands{slides_Period}\"][k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "25d54fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in list(globals()[f\"modified_promotionBrands_share{slides_Period}\"].keys()):  # Convert to list to avoid runtime errors\n",
    "    df = globals()[f\"modified_promotionBrands_share{slides_Period}\"][k].copy()\n",
    "    # Filter rows based on 'Top Brands'\n",
    "    df = df[~df['Top Brands'].str.contains('Others', case=False, na=False)]\n",
    "    df = df[~df['Top Brands'].str.contains('Grand Total', case=False, na=False)]\n",
    "    df = df[df['Value Share'] > 0.01]\n",
    "    if not df.empty:\n",
    "        globals()[f\"modified_promotionBrands_share{slides_Period}\"][k] = df\n",
    "    else:\n",
    "        del globals()[f\"modified_promotionBrands_share{slides_Period}\"][k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ee2a74",
   "metadata": {},
   "source": [
    "\n",
    "## Slide duplication: index, duplication and section names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ceca67f7-038d-44e1-98aa-cbc9a32d8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [*[0]*5,\n",
    "         #*[1]*5,\n",
    "         *[1]*5,\n",
    "         *[2]*5,\n",
    "         *[3]*5,\n",
    "         *[4]*5,\n",
    "         *[5]*5,\n",
    "         *[6]*5,\n",
    "         *[7]*5,\n",
    "         *[8]*4,\n",
    "         *[9]*5,\n",
    "         *[10]*5,\n",
    "         *[11]*5,\n",
    "         *[12]*5,\n",
    "         *[13]*5,\n",
    "         *[14]*5,\n",
    "         *final_lis,\n",
    "         *[19]*5,\n",
    "         *final_lis0,\n",
    "         *final_lis1,\n",
    "         *[0]*5,\n",
    "         *[1]*5,\n",
    "         *[2]*5,\n",
    "         *[9]*5,\n",
    "         *[10]*5,\n",
    "        #  *[11]*5,\n",
    "         *[12]*5,\n",
    "         *[13]*5\n",
    "         #*[14]*5\n",
    "        ]\n",
    "duplication = combine_duplications(Scope,count_df,[#modified_promotionBrandsP12M, #0\n",
    "                                                   promotionsBrandSortedTotalFinal, #1\n",
    "                                                   newpromotionsNotBrandsWithMarket, #2\n",
    "                                                   concated, #3\n",
    "                                                   globals()[f\"modified_promotionProducts{slides_Period}_volumeuplift\"], #4\n",
    "                                                   globals()[f\"new_modified_promotionProducts{slides_Period}\"], #5\n",
    "                                                   globals()[f\"new_modified_promotionProducts{slides_Period}\"], #6\n",
    "                                                   top20clientonly, #7\n",
    "                                                   bottom20clientonly,#8\n",
    "                                                   globals()[f\"modified_promotionBrands{slides_Period}\"], #10\n",
    "                                                   newModifiedBrands, #11\n",
    "                                                   PromoSalesTypes_data if promo_type else None,#12\n",
    "                                                   globals()[f\"modified_promotionBrands_share{slides_Period}\"] if feature_share else None, #13\n",
    "                                                   globals()[f\"modified_promotionBrands_share{slides_Period}\"] if display_share else None, #14\n",
    "                                                   modified_promotionEndOfWeek,#15\n",
    "                                                   PromoRet, #16-19\n",
    "                                                   modified_valueUplift, #20\n",
    "                                                   #month_year1,#21\n",
    "                                                   #modified_endofweek_P12M, #22\n",
    "                                                   #modified_promotionBrandsP12M, #0 with no client\n",
    "                                                   promotionsBrandNOTSortedTotalFinal, #1 with no client\n",
    "                                                   newpromotionsNotBrandsWithMarket, #2 with no client\n",
    "                                                   concated, #3 with no client\n",
    "                                                   globals()[f\"modified_promotionBrands{slides_Period}\"], # 10 with no client\n",
    "                                                   newModifiedBrands, #11 with no client\n",
    "                                                   #PromoSalesTypes_data if promo_type else None,#12  with no client\n",
    "                                                   globals()[f\"modified_promotionBrands_share{slides_Period}\"] if feature_share else None, #13  with no client\n",
    "                                                   globals()[f\"modified_promotionBrands_share{slides_Period}\"] if display_share else None #14 with no client\n",
    "                                                  ])\n",
    "section_names = [#\"Promo Value Sale\",#0\n",
    "                 \"Promo Evolution\", #1\n",
    "                 \"VSOD Summary by Sector\" , #2\n",
    "                 \"Value uplift by retailer by brand\", #3 \n",
    "                 \"Volume Uplift vs discount depth\",#4\n",
    "                 \"Value Uplift vs Promo Efficiency Quadrant\", #5\n",
    "                 \"Top 20 promotions\", #6\n",
    "                 \"Top 20 promotions CLIENT ONLY\", #7\n",
    "                 \"Bottom 20 promotions CLIENT ONLY\", #8\n",
    "                 \"Promo share vs Value Share\", #10\n",
    "                 \"Promo Sales by total size\",#11\n",
    "                 \"Promo Sales by promo type\", #12\n",
    "                 \"Feature Share vs Fair Share\", #13\n",
    "                 \"Display Share vs Fair Share\", #14\n",
    "                 \"Promo Frequency learnings\", #15\n",
    "                 \"Promo sales per retailer\", #16-19\n",
    "                 \"Value Uplift vs discount depth\" ,#20\n",
    "                 #\"Seasonality Index\",#21\n",
    "                 #\"Promotional Frequency Analysis\", #22\n",
    "                 #\"Promo Value Sale no client prio\",\n",
    "                 \"Promo Evolution no client prio\",\n",
    "                 \"VSOD Summary by Sector no client prio\",\n",
    "                 \"Value uplift by retailer by brand no client prio\",\n",
    "                \"Promo share vs Value Share no client prio\", #10\n",
    "                 \"Promo Sales by total size no client prio\",#11\n",
    "                 #\"Promo Sales by promo type no client prio\", #12\n",
    "                 \"Feature Share vs Fair Share no client prio\", #13\n",
    "                 \"Display Share vs Fair Share no client prio\" #14\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "#duplication.insert(89, 0)\n",
    "\n",
    "if len(sectors) > 0:\n",
    "       #duplication.insert(45,(len(client_manuf)+len(client_brands))*len(categories)* len(marketList))\n",
    "       duplication.insert(40, sect_vsod_count)\n",
    "if len(segments) > 0:\n",
    "        #duplication.insert(46,(len(client_manuf)+len(client_brands))*len(sectors)* len(marketList)) \n",
    "         duplication.insert(41, seg_vsod_count)\n",
    " \n",
    "else:\n",
    "    duplication.insert(41,0)  \n",
    "  \n",
    "if len(subsegments) > 0:\n",
    "        #duplication.insert(47,(len(client_manuf)+len(client_brands))*len(segments)* len(marketList))\n",
    "        duplication.insert(42, subseg_vsod_count)\n",
    "\n",
    "else:\n",
    "    duplication.insert(42,0)\n",
    "\n",
    "if len(subcategories) > 0:\n",
    "        #duplication.insert(48,(len(client_manuf)+len(client_brands))*len(segments)* len(marketList))\n",
    "        duplication.insert(43, subcat_vsod_count)\n",
    "\n",
    "else:\n",
    "    duplication.insert(43,0)\n",
    "\n",
    "\n",
    "duplication.insert(84,1)\n",
    "duplication.insert(85, 1)\n",
    "duplication.insert(86, 1)\n",
    "duplication.insert(87, 1)\n",
    "duplication.insert(88, 0)\n",
    "duplication.insert(89, 1)\n",
    "duplication.insert(90, 1)\n",
    "duplication.insert(91, 1)\n",
    "duplication.insert(92, 1)\n",
    "duplication.insert(93, 0)\n",
    "\n",
    "section_names = [f\"{name} {suffix}\" for name in section_names for suffix in suffixes]\n",
    "\n",
    "section_names.insert(40,'Volume Sold on Deal Sector')\n",
    "section_names.insert(41,'Volume Sold on Deal Segment')\n",
    "section_names.insert(42,'Volume Sold on Deal SubSegment')\n",
    "section_names.insert(43,'Volume Sold on Deal SubCategory')\n",
    "\n",
    "section_names.insert(84,'Seasonality Index Category')\n",
    "section_names.insert(85,'Seasonality Index Sector')\n",
    "section_names.insert(86,'Seasonality Index Segment')\n",
    "section_names.insert(87,'Seasonality Index Subsegment')\n",
    "section_names.insert(88,'Seasonality Index Subcategory')\n",
    "\n",
    "section_names.insert(89,'Promotional Frequency Analysis Category')\n",
    "section_names.insert(90,'Promotional Frequency Analysis Sector')\n",
    "section_names.insert(91,'Promotional Frequency Analysis Segment')\n",
    "section_names.insert(92,'Promotional Frequency Analysis Subsegment')\n",
    "section_names.insert(93,'Promotional Frequency Analysis Subcategory')\n",
    "#section_names.insert(94,'Promotional Frequency Analysis Subcategory')\n",
    "\n",
    "duplication[77]=1\n",
    "#index = [i for i in index if i != []]\n",
    "# duplication = [i for i in duplication if i != []]\n",
    "#\n",
    "\n",
    "path = os.getcwd() + '//Promotion base.pptx'\n",
    "new_pre = os.getcwd() + '//slide duplicated.pptx'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19bbcf3",
   "metadata": {},
   "source": [
    "### Deck 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1a93e125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 8, 8, 8, 8, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, [18, 18, 18, 18, 18, 18, 18, 18], [18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18], [18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 16, 18, 18, 18, 18], [], [], 19, 19, 19, 19, 19, [20, 20, 20, 20, 20, 20, 20, 20], [21, 21, 21, 21, 21, 21, 21, 21], [22, 22, 22, 22, 22, 22, 22, 22], [], [], [27, 29, 26, 27, 29, 26, 27, 29, 26, 27, 29, 26], [27, 29, 26, 27, 29, 26, 27, 29, 26, 27, 29, 26, 27, 29, 26, 27, 29, 26], [27, 29, 26, 27, 29, 26, 27, 29, 26, 27, 29, 26, 27, 29, 26, 27, 29, 27, 29, 26, 27, 29, 26], [], [], 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13]\n",
      "[7, 14, 21, 0, 0, 0, 8, 8, 0, 0, 1, 2, 3, 0, 0, 7, 14, 21, 0, 0, 7, 14, 19, 0, 0, 7, 14, 19, 0, 0, 7, 14, 18, 0, 0, 7, 14, 18, 0, 0, 28, 56, 0, 0, 8, 16, 24, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 48, 66, 0, 0, 1, 1, 1, 1, 0, 21, 28, 35, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 8, 16, 24, 0, 0, 0, 8, 8, 0, 0, 1, 2, 3, 0, 0, 8, 16, 24, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['Promo Evolution Category', 'Promo Evolution Sector', 'Promo Evolution Segment', 'Promo Evolution SubSegment', 'Promo Evolution SubCategory', 'VSOD Summary by Sector Category', 'VSOD Summary by Sector Sector', 'VSOD Summary by Sector Segment', 'VSOD Summary by Sector SubSegment', 'VSOD Summary by Sector SubCategory', 'Value uplift by retailer by brand Category', 'Value uplift by retailer by brand Sector', 'Value uplift by retailer by brand Segment', 'Value uplift by retailer by brand SubSegment', 'Value uplift by retailer by brand SubCategory', 'Volume Uplift vs discount depth Category', 'Volume Uplift vs discount depth Sector', 'Volume Uplift vs discount depth Segment', 'Volume Uplift vs discount depth SubSegment', 'Volume Uplift vs discount depth SubCategory', 'Value Uplift vs Promo Efficiency Quadrant Category', 'Value Uplift vs Promo Efficiency Quadrant Sector', 'Value Uplift vs Promo Efficiency Quadrant Segment', 'Value Uplift vs Promo Efficiency Quadrant SubSegment', 'Value Uplift vs Promo Efficiency Quadrant SubCategory', 'Top 20 promotions Category', 'Top 20 promotions Sector', 'Top 20 promotions Segment', 'Top 20 promotions SubSegment', 'Top 20 promotions SubCategory', 'Top 20 promotions CLIENT ONLY Category', 'Top 20 promotions CLIENT ONLY Sector', 'Top 20 promotions CLIENT ONLY Segment', 'Top 20 promotions CLIENT ONLY SubSegment', 'Top 20 promotions CLIENT ONLY SubCategory', 'Bottom 20 promotions CLIENT ONLY Category', 'Bottom 20 promotions CLIENT ONLY Sector', 'Bottom 20 promotions CLIENT ONLY Segment', 'Bottom 20 promotions CLIENT ONLY SubSegment', 'Bottom 20 promotions CLIENT ONLY SubCategory', 'Volume Sold on Deal Sector', 'Volume Sold on Deal Segment', 'Volume Sold on Deal SubSegment', 'Volume Sold on Deal SubCategory', 'Promo share vs Value Share Category', 'Promo share vs Value Share Sector', 'Promo share vs Value Share Segment', 'Promo share vs Value Share SubSegment', 'Promo share vs Value Share SubCategory', 'Promo Sales by total size Category', 'Promo Sales by total size Sector', 'Promo Sales by total size Segment', 'Promo Sales by total size SubSegment', 'Promo Sales by total size SubCategory', 'Promo Sales by promo type Category', 'Promo Sales by promo type Sector', 'Promo Sales by promo type Segment', 'Promo Sales by promo type SubSegment', 'Promo Sales by promo type SubCategory', 'Feature Share vs Fair Share Category', 'Feature Share vs Fair Share Sector', 'Feature Share vs Fair Share Segment', 'Feature Share vs Fair Share SubSegment', 'Feature Share vs Fair Share SubCategory', 'Display Share vs Fair Share Category', 'Display Share vs Fair Share Sector', 'Display Share vs Fair Share Segment', 'Display Share vs Fair Share SubSegment', 'Display Share vs Fair Share SubCategory', 'Promo Frequency learnings Category', 'Promo Frequency learnings Sector', 'Promo Frequency learnings Segment', 'Promo Frequency learnings SubSegment', 'Promo Frequency learnings SubCategory', 'Promo sales per retailer Category', 'Promo sales per retailer Sector', 'Promo sales per retailer Segment', 'Promo sales per retailer SubSegment', 'Promo sales per retailer SubCategory', 'Value Uplift vs discount depth Category', 'Value Uplift vs discount depth Sector', 'Value Uplift vs discount depth Segment', 'Value Uplift vs discount depth SubSegment', 'Value Uplift vs discount depth SubCategory', 'Seasonality Index Category', 'Seasonality Index Sector', 'Seasonality Index Segment', 'Seasonality Index Subsegment', 'Seasonality Index Subcategory', 'Promotional Frequency Analysis Category', 'Promotional Frequency Analysis Sector', 'Promotional Frequency Analysis Segment', 'Promotional Frequency Analysis Subsegment', 'Promotional Frequency Analysis Subcategory', 'Promo Evolution no client prio Category', 'Promo Evolution no client prio Sector', 'Promo Evolution no client prio Segment', 'Promo Evolution no client prio SubSegment', 'Promo Evolution no client prio SubCategory', 'VSOD Summary by Sector no client prio Category', 'VSOD Summary by Sector no client prio Sector', 'VSOD Summary by Sector no client prio Segment', 'VSOD Summary by Sector no client prio SubSegment', 'VSOD Summary by Sector no client prio SubCategory', 'Value uplift by retailer by brand no client prio Category', 'Value uplift by retailer by brand no client prio Sector', 'Value uplift by retailer by brand no client prio Segment', 'Value uplift by retailer by brand no client prio SubSegment', 'Value uplift by retailer by brand no client prio SubCategory', 'Promo share vs Value Share no client prio Category', 'Promo share vs Value Share no client prio Sector', 'Promo share vs Value Share no client prio Segment', 'Promo share vs Value Share no client prio SubSegment', 'Promo share vs Value Share no client prio SubCategory', 'Promo Sales by total size no client prio Category', 'Promo Sales by total size no client prio Sector', 'Promo Sales by total size no client prio Segment', 'Promo Sales by total size no client prio SubSegment', 'Promo Sales by total size no client prio SubCategory', 'Feature Share vs Fair Share no client prio Category', 'Feature Share vs Fair Share no client prio Sector', 'Feature Share vs Fair Share no client prio Segment', 'Feature Share vs Fair Share no client prio SubSegment', 'Feature Share vs Fair Share no client prio SubCategory', 'Display Share vs Fair Share no client prio Category', 'Display Share vs Fair Share no client prio Sector', 'Display Share vs Fair Share no client prio Segment', 'Display Share vs Fair Share no client prio SubSegment', 'Display Share vs Fair Share no client prio SubCategory']\n",
      "129\n",
      "129\n",
      "129\n",
      "[[18, 18, 18, 18, 18, 18, 18, 18], [18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18], [18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 16, 18, 18, 18, 18], [], []]\n",
      "[[27, 29, 26, 27, 29, 26, 27, 29, 26, 27, 29, 26], [27, 29, 26, 27, 29, 26, 27, 29, 26, 27, 29, 26, 27, 29, 26, 27, 29, 26], [27, 29, 26, 27, 29, 26, 27, 29, 26, 27, 29, 26, 27, 29, 26, 27, 29, 27, 29, 26, 27, 29, 26], [], []]\n",
      "756\n"
     ]
    }
   ],
   "source": [
    "print(index)\n",
    "print(duplication)\n",
    "print(section_names)\n",
    "print(len(index))\n",
    "print(len(duplication))\n",
    "print(len(section_names))\n",
    "print(final_lis)\n",
    "print(final_lis1)\n",
    "print(sum(duplication))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "474f4496",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m     slideDuplication(filtered_index,filtered_duplication,filtered_section_names,path,new_pre)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mslideDuplication\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43mduplication\u001b[49m\u001b[43m,\u001b[49m\u001b[43msection_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnew_pre\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10908\\612993193.py:46\u001b[0m, in \u001b[0;36mslideDuplication\u001b[1;34m(index, duplication, section_names, path, new_pre)\u001b[0m\n\u001b[0;32m     44\u001b[0m             duplicated_slide \u001b[38;5;241m=\u001b[39m slide\u001b[38;5;241m.\u001b[39mDuplicate()\n\u001b[0;32m     45\u001b[0m             duplicated_slide\u001b[38;5;241m.\u001b[39mMoveTo(presentation\u001b[38;5;241m.\u001b[39mSlides\u001b[38;5;241m.\u001b[39mCount)\n\u001b[1;32m---> 46\u001b[0m         lis\u001b[38;5;241m.\u001b[39mappend(\u001b[43mpresentation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSlides\u001b[49m\u001b[38;5;241m.\u001b[39mcount\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mduplication[i])\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Add sections to the new presentation\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(lis)):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\win32com\\client\\dynamic.py:626\u001b[0m, in \u001b[0;36mCDispatch.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    625\u001b[0m     debug_attr_print(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOLE returned \u001b[39m\u001b[38;5;124m\"\u001b[39m, ret)\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_good_object_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;66;03m# no where else to look.\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_username_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\win32com\\client\\dynamic.py:398\u001b[0m, in \u001b[0;36mCDispatch._get_good_object_\u001b[1;34m(self, ob, userName, ReturnCLSID)\u001b[0m\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m    390\u001b[0m         \u001b[38;5;28mmap\u001b[39m(\n\u001b[0;32m    391\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m o, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, oun\u001b[38;5;241m=\u001b[39muserName, rc\u001b[38;5;241m=\u001b[39mReturnCLSID: s\u001b[38;5;241m.\u001b[39m_get_good_single_object_(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    395\u001b[0m         )\n\u001b[0;32m    396\u001b[0m     )\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_good_single_object_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mob\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\win32com\\client\\dynamic.py:372\u001b[0m, in \u001b[0;36mCDispatch._get_good_single_object_\u001b[1;34m(self, ob, userName, ReturnCLSID)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_good_single_object_\u001b[39m(\u001b[38;5;28mself\u001b[39m, ob, userName\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ReturnCLSID\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ob, PyIDispatchType):\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;66;03m# make a new instance of (probably this) class.\u001b[39;00m\n\u001b[1;32m--> 372\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap_dispatch_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mReturnCLSID\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ob, PyIUnknownType):\n\u001b[0;32m    374\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\win32com\\client\\__init__.py:155\u001b[0m, in \u001b[0;36mCDispatch._wrap_dispatch_\u001b[1;34m(self, ob, userName, returnCLSID)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_wrap_dispatch_\u001b[39m(\u001b[38;5;28mself\u001b[39m, ob, userName\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, returnCLSID\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturnCLSID\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\win32com\\client\\__init__.py:115\u001b[0m, in \u001b[0;36mDispatch\u001b[1;34m(dispatch, userName, resultCLSID, typeinfo, clsctx)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a Dispatch based COM object.\"\"\"\u001b[39;00m\n\u001b[0;32m    114\u001b[0m dispatch, userName \u001b[38;5;241m=\u001b[39m dynamic\u001b[38;5;241m.\u001b[39m_GetGoodDispatchAndUserName(dispatch, userName, clsctx)\n\u001b[1;32m--> 115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__WrapDispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdispatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresultCLSID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypeinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclsctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclsctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\win32com\\client\\__init__.py:37\u001b[0m, in \u001b[0;36m__WrapDispatch\u001b[1;34m(dispatch, userName, resultCLSID, typeinfo, clsctx, WrapperClass)\u001b[0m\n\u001b[0;32m     33\u001b[0m     typeinfo \u001b[38;5;241m=\u001b[39m dispatch\u001b[38;5;241m.\u001b[39mGetTypeInfo()\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m     35\u001b[0m         typeinfo \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     ):  \u001b[38;5;66;03m# Some objects return NULL, some raise exceptions...\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m         resultCLSID \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mtypeinfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGetTypeAttr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pythoncom\u001b[38;5;241m.\u001b[39mcom_error, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if len(slides_name) >0:\n",
    "    indices = [i for i, s in enumerate(section_names) if any(sub.lower() in s.lower() for sub in slides_name)]\n",
    "    filtered_section_names = [section_names[i] for i in indices]\n",
    "    filtered_duplication = [duplication[i] for i in indices]\n",
    "    filtered_index = [index[i] for i in indices]\n",
    "    slideDuplication(filtered_index,filtered_duplication,filtered_section_names,path,new_pre)\n",
    "else:\n",
    "    slideDuplication(index,duplication,section_names,path,new_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b830c75f",
   "metadata": {},
   "source": [
    "## Replace duplicated slides with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78376167-8225-4f4f-af41-cd366f3e2273",
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = Presentation(new_pre)\n",
    "posItr = 0\n",
    "ind =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a49aea0-21ff-4bf4-9427-d2f7a6b8a2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 2\n",
    "try:\n",
    "    if 0 in filtered_index:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(promotionsBrandSortedTotalFinal,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in promotionsBrandSortedTotalFinal.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                \n",
    "                promoEvolutionNew(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6850ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 18\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd4fcae-6d85-4244-82e5-9a19f05b6bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 3\n",
    "try:\n",
    "    if 1 in filtered_index:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(newpromotionsBrandsWithMarket,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in newpromotionsBrandsWithMarket.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                VSOD1(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92914c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 22\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8dc777-7e02-4573-b8f9-000bb04fcdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 4\n",
    "try:\n",
    "    if 2 in filtered_index:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(concated,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in concated.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                valueUpliftRetailer(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27312e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 28\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8ee2a2-5cdf-41f3-ad8a-95fb9baacc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 5\n",
    "try:\n",
    "    if 3 in filtered_index:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(globals()[f\"modified_promotionProducts{slides_Period}_volumeuplift\"],value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in globals()[f\"modified_promotionProducts{slides_Period}_volumeuplift\"].items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                VolumeUplift(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0b667f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 46\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f24f2e-b093-4fe6-8605-1ef06f69e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 6\n",
    "try:\n",
    "    if 4 in filtered_index:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(globals()[f\"new_modified_promotionProducts{slides_Period}\"],value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in globals()[f\"new_modified_promotionProducts{slides_Period}\"].items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                ValueUpliftvsPromoEfficiencyQuadrant(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569c3cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 64\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba714fd4-a9da-45d9-9eb0-1a1889324bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 7\n",
    "try:\n",
    "    if 5 in filtered_index:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(globals()[f\"new_modified_promotionProducts{slides_Period}\"],value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in globals()[f\"new_modified_promotionProducts{slides_Period}\"].items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                top20(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477805d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 82\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df90b497-4ca3-4467-9965-3eeba68fef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 8\n",
    "try:\n",
    "    if 6 in filtered_index:\n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(top20clientonly,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in top20clientonly.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                top20Client(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e578ca09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 99\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4108f604-685c-4fd8-aab4-5c66967a67ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 9\n",
    "try:\n",
    "    if 7 in filtered_index:\n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(bottom20clientonly,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in bottom20clientonly.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                bot20Client(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16765a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 116\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762a2079",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)>0:\n",
    "    try:\n",
    "        if 8 in filtered_index:\n",
    "                dup_list = filtered_duplication\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        newVolumeSold(prs, sect_vsod_merged, position=posItr, parent=direct_parent['Sector'], child = 'Sector')\n",
    "        posItr += sect_vsod_count\n",
    "        ind +=1\n",
    "else:\n",
    "    ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244a0620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 127\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41024fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(segments)>0:\n",
    "    try:\n",
    "        if 8 in filtered_index:\n",
    "                dup_list = filtered_duplication\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        newVolumeSold(prs, seg_vsod_merged, position=posItr, parent=direct_parent['Segment'], child = 'Segment')\n",
    "        posItr += seg_vsod_count\n",
    "        ind +=1\n",
    "    \n",
    "else:\n",
    "    ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bc536a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 149\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451cdc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(subsegments)>0:\n",
    "    try:\n",
    "        if 8 in filtered_index:\n",
    "                dup_list = filtered_duplication\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        newVolumeSold(prs, subseg_vsod_merged, position=posItr, parent=direct_parent['SubSegment'], child = 'SubSegment')\n",
    "        posItr += subseg_vsod_count\n",
    "        ind+=1\n",
    "else:\n",
    "     ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b7472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 149\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2298d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(subcategories)>0:\n",
    "    try:\n",
    "        if 8 in filtered_index:\n",
    "                dup_list = filtered_duplication\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        newVolumeSold(prs, subcat_vsod_merged, position=posItr, parent=direct_parent['SubCategory'], child = 'SubCategory')\n",
    "        posItr += subcat_vsod_count\n",
    "        ind+=1\n",
    "else:\n",
    "     ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5677352e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 149\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee42400-58ae-4311-8ac7-9914c0ae666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 11\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(globals()[f\"modified_promotionBrands{slides_Period}\"],value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in globals()[f\"modified_promotionBrands{slides_Period}\"].items() if key in dict[key1]}\n",
    "        if filtered_dict:        \n",
    "            try:\n",
    "                if 9 in filtered_index:\n",
    "                        dup_list = filtered_duplication\n",
    "                        run_slide = True\n",
    "                else:\n",
    "                    run_slide = False\n",
    "            except NameError:\n",
    "                dup_list = duplication\n",
    "                run_slide = True\n",
    "\n",
    "            if run_slide:\n",
    "                PromoShare_vs_ValueShare(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                posItr += len(filtered_dict)\n",
    "    ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7b6a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 167\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569341f7-9b94-4bf5-9114-fe10a6d0cfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 12\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(newModifiedBrands,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in newModifiedBrands.items() if key in dict[key1]}\n",
    "        if filtered_dict:        \n",
    "            try:\n",
    "                if 10 in filtered_index:\n",
    "                        dup_list = filtered_duplication\n",
    "                        run_slide = True\n",
    "                else:\n",
    "                    run_slide = False\n",
    "            except NameError:\n",
    "                dup_list = duplication\n",
    "                run_slide = True\n",
    "\n",
    "            if run_slide:\n",
    "                PromoSalesTotalSize(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                posItr += len(filtered_dict)\n",
    "    ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4e2148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 173\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6331b0-3674-471a-8da0-d10719174ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 13\n",
    "if promo_type:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(PromoSalesTypes_data,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in PromoSalesTypes_data.items() if key in dict[key1]}\n",
    "            if filtered_dict:       \n",
    "                try:\n",
    "                    if 11 in filtered_index:\n",
    "                            dup_list = filtered_duplication\n",
    "                            run_slide = True\n",
    "                    else:\n",
    "                        run_slide = False\n",
    "                except NameError:\n",
    "                    dup_list = duplication\n",
    "                    run_slide = True\n",
    "\n",
    "                if run_slide:\n",
    "                    PromoSalesTypes(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                    posItr += len(filtered_dict)\n",
    "                    ind +=1\n",
    "else:\n",
    "    ind+=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5192201c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 173\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555338fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 14\n",
    "if feature_share:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(globals()[f\"modified_promotionBrands_share{slides_Period}\"],value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in globals()[f\"modified_promotionBrands_share{slides_Period}\"].items() if key in dict[key1]}\n",
    "            if filtered_dict:       \n",
    "                try:\n",
    "                    if 12 in filtered_index:\n",
    "                            dup_list = filtered_duplication\n",
    "                            run_slide = True\n",
    "                    else:\n",
    "                        run_slide = False\n",
    "                except NameError:\n",
    "                    dup_list = duplication\n",
    "                    run_slide = True\n",
    "\n",
    "                if run_slide:   \n",
    "                    featureShare(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                    posItr += len(filtered_dict)\n",
    "                    ind +=1\n",
    "else:\n",
    "    ind+=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c973d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 173\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ecb5b3-8308-43ec-b4aa-16c2e7b0797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# slide 15\n",
    "if display_share:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(globals()[f\"modified_promotionBrands_share{slides_Period}\"],value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in globals()[f\"modified_promotionBrands_share{slides_Period}\"].items() if key in dict[key1]}\n",
    "            if filtered_dict:        \n",
    "                try:\n",
    "                    if 13 in filtered_index:\n",
    "                            dup_list = filtered_duplication\n",
    "                            run_slide = True\n",
    "                    else:\n",
    "                        run_slide = False\n",
    "                except NameError:\n",
    "                    dup_list = duplication\n",
    "                    run_slide = True\n",
    "\n",
    "                if run_slide:   \n",
    "                    displayShare(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                    posItr += len(filtered_dict)\n",
    "                    ind +=1\n",
    "else:\n",
    "    ind+=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16eefd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 173\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ffadfa-5f94-4967-84f6-54c1d2ab7d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 16\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(modified_promotionEndOfWeek,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in modified_promotionEndOfWeek.items() if key in dict[key1]}\n",
    "        if filtered_dict:       \n",
    "            try:\n",
    "                if 14 in filtered_index:\n",
    "                        dup_list = filtered_duplication\n",
    "                        run_slide = True\n",
    "                else:\n",
    "                    run_slide = False\n",
    "            except NameError:\n",
    "                dup_list = duplication\n",
    "                run_slide = True\n",
    "\n",
    "            if run_slide:\n",
    "                PromoFrequency(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                posItr += len(filtered_dict)\n",
    "    ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84ad318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 228\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43caf10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if categories:\n",
    "    catFinal = sorted(splitDfsPromo(dfCategory,(client_manuf) ,genrateIndexList(catGroup[0])[0]))\n",
    "    catFinal = catFinal+sorted(splitDfsPromo(dfCategory,(client_brands) ,genrateIndexList(catGroup[0])[0]))\n",
    "    catFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f6fd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 228\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05117abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sectors:\n",
    "    secFinal = sorted(splitDfsPromo(dfSector,(client_manuf)  ,genrateIndexList(secGroup[0])[0]))\n",
    "    secFinal = secFinal + sorted(splitDfsPromo(dfSector,(client_brands)  ,genrateIndexList(secGroup[0])[0]))\n",
    "    secFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5855f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 228\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c788ee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if segments:\n",
    "    segFinal = sorted(splitDfsPromo(dfSegment,(client_manuf)  ,genrateIndexList(segGroup[0])[0]))\n",
    "    segFinal = segFinal+sorted(splitDfsPromo(dfSegment,(client_brands)  ,genrateIndexList(segGroup[0])[0]))\n",
    "    segFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889d3e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if subsegments:\n",
    "    subsegFinal = sorted(splitDfsPromo(dfSubSegment,(client_manuf)  ,genrateIndexList(subsegGroup[0])[0]))\n",
    "    subsegFinal = subsegFinal + sorted(splitDfsPromo(dfSubSegment,(client_brands)  ,genrateIndexList(subsegGroup[0])[0]))\n",
    "    subsegFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3153b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "if subcategories:\n",
    "    subcatFinal = sorted(splitDfsPromo(dfSubCategory,(client_manuf) ,genrateIndexList(subcatGroup[0])[0]))\n",
    "    subcatFinal = subcatFinal+sorted(splitDfsPromo(dfSubCategory,(client_brands) ,genrateIndexList(subcatGroup[0])[0]))\n",
    "    subcatFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5febe962-91f9-4b04-80a0-986f63399c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slide 17\n",
    "#split catGroup into Lists depends on num of charts \n",
    "# index1 = filtered_index\n",
    "# catGroupSplit = splitListpromo(dfCategory, catGroup, [i-14 for i in index1[ind]])\n",
    "values_to_check = {15, 16, 17,18}\n",
    "try:\n",
    "    index1 = filtered_index\n",
    "except NameError:\n",
    "    index1 = index\n",
    "try:\n",
    "    normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "    if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "            dup_list = filtered_duplication\n",
    "            index1= filtered_index\n",
    "            run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    index1 = index\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    catGroupSplit = splitListpromo(dfCategory, catGroup, [i-14 for i in index1[ind]])\n",
    "    promoSalesPerRetailer(prs,dfCategory,len(index1[ind]),catGroupSplit,position=sum(dup_list[:ind]))\n",
    "    posItr = sum(dup_list[:ind]) + len(index1[ind])\n",
    "ind+=1\n",
    "\n",
    "\n",
    "#split secGroup into Lists depends on num of charts \n",
    "if len(sectors) != 0:   \n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1= filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        index1 = index\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        secGroupSplit = splitListpromo(dfSector, secGroup, [i-14 for i in index1[ind]])\n",
    "        promoSalesPerRetailer(prs,dfSector,len(index1[ind]),secGroupSplit,position=posItr)\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n",
    "\n",
    "#split segGroup into Lists depends on num of charts \n",
    "if len(segments) != 0: \n",
    "    \n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1= filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        index1 = index\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        segGroupSplit = splitListpromo(dfSegment, segGroup, [i-14 for i in index1[ind]])\n",
    "        promoSalesPerRetailer(prs,dfSegment,len(index1[ind]),segGroupSplit,position=posItr)\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n",
    "\n",
    "#split subsegGroup into Lists depends on num of charts \n",
    "if len(subsegments) != 0:\n",
    "    subsegGroupSplit = splitListpromo(dfSubSegment, subsegGroup, [i-14 for i in index1[ind]])\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1= filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        index1 = index\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        promoSalesPerRetailer(prs,dfSubSegment,len(index1[ind]),subsegGroupSplit,position=posItr)\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n",
    "\n",
    "#split subcatGroup into Lists depends on num of charts \n",
    "if len(subcategories) != 0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1= filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        index1 = index\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        subcatGroupSplit = splitListpromo(dfSubCategory, subcatGroup, [i-14 for i in index1[ind]])\n",
    "        promoSalesPerRetailer(prs,dfSubCategory,len(index1[ind]),subcatGroupSplit,position=posItr)\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c0f9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf01c1-6ec8-405c-bb46-928310996eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 281\n"
     ]
    }
   ],
   "source": [
    "# slide 21\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(modified_valueUplift,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in modified_valueUplift.items() if key in dict[key1]}\n",
    "        if filtered_dict:\n",
    "            try:\n",
    "                if 19 in filtered_index:\n",
    "                        dup_list = filtered_duplication\n",
    "                        run_slide = True\n",
    "                else:\n",
    "                        run_slide = False\n",
    "            except NameError:\n",
    "                    dup_list = duplication\n",
    "                    run_slide = True \n",
    "\n",
    "            if run_slide:\n",
    "                valueUplift(prs,filtered_dict,dup_list[ind],position=posItr)\n",
    "                posItr += len(filtered_dict)\n",
    "    ind +=1\n",
    "print(ind,posItr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1031c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 1 281\n"
     ]
    }
   ],
   "source": [
    "print(ind, duplication[ind], posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e02f578",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_to_check = {20,21,22,23,24,25}\n",
    "if len(categories)>0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        seasonality(prs,dfCategory0, len(index1[ind]), categoryGroup0, position=posItr,slideby=\"Category\")\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec4ed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)>0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        seasonality(prs, dfSector0, len(index1[ind]), secGroup0, position=posItr,slideby=\"Sector\")\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c95329",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(segments)>0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        seasonality(prs, dfSegment0, len(index1[ind]), segGroup0, position=posItr,slideby=\"Segment\")\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfffb4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(subsegments) != 0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        seasonality(prs,dfSubSegment0,len(index1[ind]),subsegGroup0,position=posItr,slideby=\"SubSegment\")\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d74d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(subcategories) != 0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        seasonality(prs,dfSubCategory0,len(index1[ind]),subcatGroup0,position=posItr,slideby=\"SubCategory\")\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43fdd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(index[ind]), ind, duplication[ind], posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb5a7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293 89\n"
     ]
    }
   ],
   "source": [
    "print(posItr,ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e773cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date1 = pd.to_datetime(end_date)\n",
    "start_date1 = end_date1 - pd.DateOffset(months=12)\n",
    " \n",
    "# Generate all weekly periods (weekly ends, e.g., Sundays) between start and end\n",
    "week_ends = pd.date_range(start=start_date1, end=end_date1, freq='W-SUN')\n",
    " \n",
    "# Convert to list of dates (if needed)\n",
    "week_ends_list = week_ends.to_list()\n",
    "all_weeks_df = pd.DataFrame({'End of Week': week_ends_list})\n",
    "\n",
    "def add_all_weeks(data):\n",
    "    final_data ={}\n",
    "    for key,df in data.items():\n",
    "        df_full = all_weeks_df.merge(df, on='End of Week', how='left')\n",
    "        df_full.fillna(0, inplace=True)\n",
    "        final_data[key] = df_full\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab704be",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_dfCategory1 = add_all_weeks(modified_dfCategory1)\n",
    "modified_dfSector1 = add_all_weeks(modified_dfSector1)\n",
    "modified_dfSegment1 = add_all_weeks(modified_dfSegment1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b6cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_to_check = {26,27,28,29}\n",
    "try:\n",
    "    normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "    if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "            dup_list = filtered_duplication\n",
    "            index1 = filtered_index\n",
    "            run_slide = True\n",
    "    else:\n",
    "            run_slide = False\n",
    "except NameError:\n",
    "        dup_list = duplication\n",
    "        index1=index\n",
    "        run_slide = True \n",
    "\n",
    "if run_slide:\n",
    "        catGroup1Split = splitListpromo(modified_dfCategory1, catGroup1, [i-25 for i in index1[ind]])\n",
    "        Promotional_Frequency(prs,modified_dfCategory1,len(index1[ind]),catGroup1Split,position=posItr)\n",
    "        posItr +=len(catGroup1Split)\n",
    "ind+=1\n",
    "#Sector Replace\n",
    "if len(sectors) != 0: \n",
    "    \n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        secGroup1Split = splitListpromo(modified_dfSector1, secGroup1, [i-25 for i in index1[ind]])\n",
    "        Promotional_Frequency(prs,modified_dfSector1,len(index1[ind]),secGroup1Split,position=posItr)\n",
    "        posItr += len(secGroup1Split)\n",
    "ind+=1\n",
    "\n",
    "\n",
    "if len(segments) != 0: \n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 =  filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        segGroup1Split = splitListpromo(modified_dfSegment1, segGroup1, [i-25 for i in index1[ind]])\n",
    "        Promotional_Frequency(prs,modified_dfSegment1,len(index1[ind]),segGroup1Split,position=posItr)\n",
    "        posItr += len(segGroup1Split)\n",
    "ind+=1\n",
    "\n",
    "if len(subsegments) != 0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        subsegGroup1Split = splitListpromo(modified_dfSubSegment1, subsegGroup1, [i-25 for i in index1[ind]])\n",
    "        Promotional_Frequency(prs,modified_dfSubSegment1,len(index1[ind]),subsegGroup1Split,position=posItr)\n",
    "        posItr += len(subsegGroup1Split)\n",
    "ind+=1\n",
    "\n",
    "if len(subcategories) != 0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        subcatGroup1Split = splitListpromo(modified_dfSubCategory1, subcatGroup1, [i-25 for i in index[ind]])\n",
    "        Promotional_Frequency(prs,modified_dfSubCategory1,len(index1[ind]),subcatGroup1Split,position=posItr)\n",
    "        posItr += len(subcatGroup1Split)\n",
    "ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d3bb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 313\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39417e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 {'Manual Shave Men | NATIONAL':           Top Brands Total Size  Promo Value  VSOD  VSOD IYA  Value Share  \\\n",
      "0           Gillette          0  143085956.0  0.18     0.900     0.629098   \n",
      "1             Schick          0   26769558.0  0.25     0.833     0.074329   \n",
      "2                Bic          0   23459418.0  0.17     1.000     0.082169   \n",
      "3            Harry's          0   15085039.0  0.09     0.900     0.119603   \n",
      "4  Dollar Shave Club          0    6818844.0  0.23     1.278     0.020083   \n",
      "5             Pbg Pl          0    4797053.0  0.15     0.882     0.023870   \n",
      "7             Equate          0    1535761.0  0.06     6.000     0.022702   \n",
      "\n",
      "   Promo Share  Value Uplift (v. base) Normalized  \\\n",
      "0     0.627470                           0.141828   \n",
      "1     0.117392                           0.261002   \n",
      "2     0.102876                           0.099026   \n",
      "3     0.066152                          -0.246168   \n",
      "4     0.029902                           0.097395   \n",
      "5     0.021036                          -0.022815   \n",
      "7     0.006735                           0.095595   \n",
      "\n",
      "   Value Uplift Normalized IYA  Volume Uplift (v. Base) Normalized  \\\n",
      "0                     1.419834                            0.362951   \n",
      "1                     1.687592                            0.411159   \n",
      "2                     0.436079                            0.606503   \n",
      "3                     1.634749                            0.161471   \n",
      "4                    -2.332660                            0.247958   \n",
      "5                     0.932237                            0.057936   \n",
      "7                    -0.944654                            0.521427   \n",
      "\n",
      "   Volume Uplift Normalized IYA  Promo Value Uplift vs YA  \\\n",
      "0                      0.744143                  0.419834   \n",
      "1                      1.170913                  0.687592   \n",
      "2                      0.777980                 -0.563921   \n",
      "3                      0.946202                  0.634749   \n",
      "4                      0.828793                 -3.332660   \n",
      "5                      0.788081                 -0.067763   \n",
      "7                      7.637433                 -1.944654   \n",
      "\n",
      "   VSOD Evaluation vs YA  \n",
      "0                 -0.100  \n",
      "1                 -0.167  \n",
      "2                  0.000  \n",
      "3                 -0.100  \n",
      "4                  0.278  \n",
      "5                 -0.118  \n",
      "7                  5.000  , \"Manual Shave Men | Sam's Corp\":   Top Brands Total Size  Promo Value  VSOD  VSOD IYA  Value Share  \\\n",
      "0   Gillette          0   43905953.0  0.56     1.077     0.891791   \n",
      "1     Schick          0    4369441.0  0.52     1.576     0.103288   \n",
      "\n",
      "   Promo Share  Value Uplift (v. base) Normalized  \\\n",
      "0     0.905079                           0.247417   \n",
      "1     0.090072                           0.173835   \n",
      "\n",
      "   Value Uplift Normalized IYA  Volume Uplift (v. Base) Normalized  \\\n",
      "0                     1.193796                            0.393060   \n",
      "1                     1.145476                            0.456876   \n",
      "\n",
      "   Volume Uplift Normalized IYA  Promo Value Uplift vs YA  \\\n",
      "0                      1.203565                  0.193796   \n",
      "1                      1.245059                  0.145476   \n",
      "\n",
      "   VSOD Evaluation vs YA  \n",
      "0                  0.077  \n",
      "1                  0.576  , 'Manual Shave Men | Walmart':           Top Brands Total Size  Promo Value  VSOD  VSOD IYA  Value Share  \\\n",
      "0           Gillette          0   10656802.0  0.02     1.000     0.564837   \n",
      "1             Schick          0    6271015.0  0.16     0.571     0.068500   \n",
      "2                Bic          0    4603854.0  0.09     1.125     0.105536   \n",
      "3  Dollar Shave Club          0    1929113.0  0.14     1.556     0.025977   \n",
      "4             Equate          0    1471589.0  0.06     6.000     0.070658   \n",
      "5          Comfort 3          0     773970.0  0.15     7.500     0.010605   \n",
      "6            Harry's          0     423667.0  0.01     0.200     0.141628   \n",
      "7      Van Der Hagen          0       9544.0  0.00     0.000     0.011982   \n",
      "\n",
      "   Promo Share  Value Uplift (v. base) Normalized  \\\n",
      "0     0.407651                           0.292995   \n",
      "1     0.239883                           0.609421   \n",
      "2     0.176110                           1.593176   \n",
      "3     0.073794                          -0.028190   \n",
      "4     0.056292                          -0.001943   \n",
      "5     0.029606                           0.092435   \n",
      "6     0.016206                           0.120824   \n",
      "7     0.000365                           0.232000   \n",
      "\n",
      "   Value Uplift Normalized IYA  Volume Uplift (v. Base) Normalized  \\\n",
      "0                     1.866496                            0.770448   \n",
      "1                     0.450794                            2.432800   \n",
      "2                     1.430619                            2.011768   \n",
      "3                     0.521685                            0.063617   \n",
      "4                     0.021766                            0.209700   \n",
      "5                    -0.370431                            0.217708   \n",
      "6                     0.265099                            0.190045   \n",
      "7                     2.825114                            0.853846   \n",
      "\n",
      "   Volume Uplift Normalized IYA  Promo Value Uplift vs YA  \\\n",
      "0                      0.874139                  0.866496   \n",
      "1                      1.772117                 -0.549206   \n",
      "2                      1.022027                  0.430619   \n",
      "3                      0.234462                 -0.478315   \n",
      "4                     13.244178                 -0.978234   \n",
      "5                      2.246496                 -1.370431   \n",
      "6                      0.387794                 -0.734901   \n",
      "7                      7.980848                  1.825114   \n",
      "\n",
      "   VSOD Evaluation vs YA  \n",
      "0                  0.000  \n",
      "1                 -0.429  \n",
      "2                  0.125  \n",
      "3                  0.556  \n",
      "4                  5.000  \n",
      "5                  6.500  \n",
      "6                 -0.800  \n",
      "7                  0.000  }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 {'Disposables | NATIONAL':       Top Brands Total Size  Promo Value  VSOD  VSOD IYA  Value Share  \\\n",
      "0       Gillette          0   33043709.0  0.17     0.810     0.537116   \n",
      "1            Bic          0   16421284.0  0.14     0.933     0.186744   \n",
      "2         Schick          0   14898816.0  0.24     0.774     0.141365   \n",
      "3         Pbg Pl          0    2975511.0  0.15     0.938     0.050226   \n",
      "4         Equate          0    1200169.0  0.06     6.000     0.054119   \n",
      "5  Private Label          0    1109307.0  0.13     0.591     0.017440   \n",
      "\n",
      "   Promo Share  Value Uplift (v. base) Normalized  \\\n",
      "0     0.469491                           0.015707   \n",
      "1     0.233316                           0.040989   \n",
      "2     0.211685                           0.174840   \n",
      "3     0.042277                          -0.037681   \n",
      "4     0.017052                           0.298436   \n",
      "5     0.015761                          -0.045648   \n",
      "\n",
      "   Value Uplift Normalized IYA  Volume Uplift (v. Base) Normalized  \\\n",
      "0                     0.066720                            0.232537   \n",
      "1                     0.339680                            0.333969   \n",
      "2                     0.845996                            0.357263   \n",
      "3                     1.067775                            0.050018   \n",
      "4                    -9.829105                            0.549108   \n",
      "5                     0.458691                            0.050909   \n",
      "\n",
      "   Volume Uplift Normalized IYA  Promo Value Uplift vs YA  \\\n",
      "0                      0.391349                 -0.933280   \n",
      "1                      0.891099                 -0.660320   \n",
      "2                      1.165698                 -0.154004   \n",
      "3                      0.673529                  0.067775   \n",
      "4                     15.932251                -10.829105   \n",
      "5                      0.678234                 -0.541309   \n",
      "\n",
      "   VSOD Evaluation vs YA  \n",
      "0                 -0.190  \n",
      "1                 -0.067  \n",
      "2                 -0.226  \n",
      "3                 -0.062  \n",
      "4                  5.000  \n",
      "5                 -0.409  , 'System | NATIONAL':           Top Brands Total Size  Promo Value  VSOD  VSOD IYA  Value Share  \\\n",
      "0           Gillette          0  110042247.0  0.19     1.000     0.668457   \n",
      "1            Harry's          0   14929308.0  0.09     1.125     0.168549   \n",
      "2             Schick          0   11870742.0  0.26     1.040     0.045644   \n",
      "3                Bic          0    7038134.0  0.28     0.966     0.037422   \n",
      "4  Dollar Shave Club          0    6818844.0  0.23     1.278     0.028677   \n",
      "5          Comfort 3          0    2903740.0  0.29     1.706     0.010340   \n",
      "6             Pbg Pl          0    1821542.0  0.15     0.833     0.012592   \n",
      "8      Van Der Hagen          0     475252.0  0.03     0.750     0.010064   \n",
      "\n",
      "   Promo Share  Value Uplift (v. base) Normalized  \\\n",
      "0     0.697997                           0.181952   \n",
      "1     0.094696                          -0.258276   \n",
      "2     0.075296                           0.376247   \n",
      "3     0.044643                           0.371717   \n",
      "4     0.043252                           0.097395   \n",
      "5     0.018418                           0.125485   \n",
      "6     0.011554                           0.003108   \n",
      "8     0.003015                           0.037232   \n",
      "\n",
      "   Value Uplift Normalized IYA  Volume Uplift (v. Base) Normalized  \\\n",
      "0                     2.992810                            0.507395   \n",
      "1                     1.238355                            0.111350   \n",
      "2                     4.923038                            0.581492   \n",
      "3                     0.516291                            1.370369   \n",
      "4                    -2.332660                            0.247958   \n",
      "5                     0.314593                            0.445845   \n",
      "6                    -0.804799                            0.087177   \n",
      "8                    -0.206925                            0.409455   \n",
      "\n",
      "   Volume Uplift Normalized IYA  Promo Value Uplift vs YA  \\\n",
      "0                      1.319860                  1.992810   \n",
      "1                      2.883433                  0.238355   \n",
      "2                      1.040385                  3.923038   \n",
      "3                      0.631258                 -0.483709   \n",
      "4                      0.828793                 -3.332660   \n",
      "5                      0.507469                 -0.685407   \n",
      "6                      1.229632                 -1.804799   \n",
      "8                      2.205027                 -1.206925   \n",
      "\n",
      "   VSOD Evaluation vs YA  \n",
      "0                  0.000  \n",
      "1                  0.125  \n",
      "2                  0.040  \n",
      "3                 -0.034  \n",
      "4                  0.278  \n",
      "5                  0.706  \n",
      "6                 -0.167  \n",
      "8                 -0.250  , \"Disposables | Sam's Corp\":   Top Brands Total Size  Promo Value  VSOD  VSOD IYA  Value Share  \\\n",
      "0   Gillette          0    6669320.0  0.52     1.182     0.580606   \n",
      "1     Schick          0    4369441.0  0.52     1.576     0.400337   \n",
      "2        Bic          0     234920.0  0.60     1.304     0.019057   \n",
      "\n",
      "   Promo Share  Value Uplift (v. base) Normalized  \\\n",
      "0     0.591583                           0.233682   \n",
      "1     0.387579                           0.173835   \n",
      "2     0.020838                           0.340102   \n",
      "\n",
      "   Value Uplift Normalized IYA  Volume Uplift (v. Base) Normalized  \\\n",
      "0                     1.937369                            0.362030   \n",
      "1                     1.145476                            0.456876   \n",
      "2                     1.560829                            0.606036   \n",
      "\n",
      "   Volume Uplift Normalized IYA  Promo Value Uplift vs YA  \\\n",
      "0                      1.486442                  0.937369   \n",
      "1                      1.245059                  0.145476   \n",
      "2                      1.804135                  0.560829   \n",
      "\n",
      "   VSOD Evaluation vs YA  \n",
      "0                  0.182  \n",
      "1                  0.576  \n",
      "2                  0.304  , \"System | Sam's Corp\":   Top Brands Total Size  Promo Value  VSOD  VSOD IYA  Value Share  \\\n",
      "0   Gillette          0   37236633.0  0.58       1.0     0.999993   \n",
      "\n",
      "   Promo Share  Value Uplift (v. base) Normalized  \\\n",
      "0     0.999992                           0.250026   \n",
      "\n",
      "   Value Uplift Normalized IYA  Volume Uplift (v. Base) Normalized  \\\n",
      "0                     1.139951                            0.417379   \n",
      "\n",
      "   Volume Uplift Normalized IYA  Promo Value Uplift vs YA  \\\n",
      "0                       1.11676                  0.139951   \n",
      "\n",
      "   VSOD Evaluation vs YA  \n",
      "0                    0.0  , 'Disposables | Walmart':   Top Brands Total Size  Promo Value  VSOD  VSOD IYA  Value Share  \\\n",
      "0     Schick          0    2238318.0  0.11     0.379     0.118084   \n",
      "1        Bic          0    1716107.0  0.03     0.750     0.184538   \n",
      "2     Equate          0    1141177.0  0.06     6.000     0.153282   \n",
      "3   Gillette          0     355493.0  0.00     0.000     0.540824   \n",
      "\n",
      "   Promo Share  Value Uplift (v. base) Normalized  \\\n",
      "0     0.410574                           1.499192   \n",
      "1     0.314785                           0.963125   \n",
      "2     0.209326                           0.085956   \n",
      "3     0.065208                          -0.242084   \n",
      "\n",
      "   Value Uplift Normalized IYA  Volume Uplift (v. Base) Normalized  \\\n",
      "0                     1.305431                            3.866902   \n",
      "1                    24.129196                            1.142939   \n",
      "2                    -2.814192                            0.202683   \n",
      "3                    -0.109294                            0.088200   \n",
      "\n",
      "   Volume Uplift Normalized IYA  Promo Value Uplift vs YA  \\\n",
      "0                      3.243660                  0.305431   \n",
      "1                      4.496019                 23.129196   \n",
      "2                    -27.332868                 -3.814192   \n",
      "3                      0.025051                 -1.109294   \n",
      "\n",
      "   VSOD Evaluation vs YA  \n",
      "0                 -0.621  \n",
      "1                 -0.250  \n",
      "2                  5.000  \n",
      "3                  0.000  , 'System | Walmart':           Top Brands Total Size  Promo Value  VSOD  VSOD IYA  Value Share  \\\n",
      "0           Gillette          0   10301309.0  0.06     2.000     0.576628   \n",
      "1             Schick          0    4032697.0  0.30     1.429     0.044153   \n",
      "2                Bic          0    2887747.0  0.25     1.087     0.066744   \n",
      "3  Dollar Shave Club          0    1929113.0  0.14     1.556     0.038733   \n",
      "4          Comfort 3          0     773970.0  0.15     7.500     0.015813   \n",
      "5            Harry's          0     423082.0  0.01     0.333     0.209564   \n",
      "6             Equate          0     330412.0  0.05     1.667     0.030088   \n",
      "7      Van Der Hagen          0       9544.0  0.00     0.000     0.017865   \n",
      "\n",
      "   Promo Share  Value Uplift (v. base) Normalized  \\\n",
      "0     0.497882                           0.310248   \n",
      "1     0.194908                           0.206276   \n",
      "2     0.139570                           2.165946   \n",
      "3     0.093238                          -0.028190   \n",
      "4     0.037407                           0.092435   \n",
      "5     0.020448                           0.140564   \n",
      "6     0.015969                          -0.093488   \n",
      "7     0.000461                           0.232000   \n",
      "\n",
      "   Value Uplift Normalized IYA  Volume Uplift (v. Base) Normalized  \\\n",
      "0                     9.266581                            0.819963   \n",
      "1                     0.111860                            0.904217   \n",
      "2                     0.814690                            2.440891   \n",
      "3                     0.521685                            0.063617   \n",
      "4                    -0.370431                            0.217708   \n",
      "5                     0.229596                            0.215569   \n",
      "6                     0.179197                            0.280547   \n",
      "7                     2.825114                            0.853846   \n",
      "\n",
      "   Volume Uplift Normalized IYA  Promo Value Uplift vs YA  \\\n",
      "0                      2.071592                  8.266581   \n",
      "1                      0.336842                 -0.888140   \n",
      "2                      0.611580                 -0.185310   \n",
      "3                      0.234462                 -0.478315   \n",
      "4                      2.246496                 -1.370431   \n",
      "5                      0.248508                 -0.770404   \n",
      "6                      1.637732                 -0.820803   \n",
      "7                      7.980848                  1.825114   \n",
      "\n",
      "   VSOD Evaluation vs YA  \n",
      "0                  1.000  \n",
      "1                  0.429  \n",
      "2                  0.087  \n",
      "3                  0.556  \n",
      "4                  6.500  \n",
      "5                 -0.667  \n",
      "6                  0.667  \n",
      "7                  0.000  }\n",
      "96 {'Disposables | NATIONAL':       Top Brands Total Size  Promo Value  VSOD  VSOD IYA  Value Share  \\\n",
      "0       Gillette          0   33043709.0  0.17     0.810     0.537116   \n",
      "1            Bic          0   16421284.0  0.14     0.933     0.186744   \n",
      "2         Schick          0   14898816.0  0.24     0.774     0.141365   \n",
      "3         Pbg Pl          0    2975511.0  0.15     0.938     0.050226   \n",
      "4         Equate          0    1200169.0  0.06     6.000     0.054119   \n",
      "5  Private Label          0    1109307.0  0.13     0.591     0.017440   \n",
      "\n",
      "   Promo Share  Value Uplift (v. base) Normalized  \\\n",
      "0     0.469491                           0.015707   \n",
      "1     0.233316                           0.040989   \n",
      "2     0.211685                           0.174840   \n",
      "3     0.042277                          -0.037681   \n",
      "4     0.017052                           0.298436   \n",
      "5     0.015761                          -0.045648   \n",
      "\n",
      "   Value Uplift Normalized IYA  Volume Uplift (v. Base) Normalized  \\\n",
      "0                     0.066720                            0.232537   \n",
      "1                     0.339680                            0.333969   \n",
      "2                     0.845996                            0.357263   \n",
      "3                     1.067775                            0.050018   \n",
      "4                    -9.829105                            0.549108   \n",
      "5                     0.458691                            0.050909   \n",
      "\n",
      "   Volume Uplift Normalized IYA  Promo Value Uplift vs YA  \\\n",
      "0                      0.391349                 -0.933280   \n",
      "1                      0.891099                 -0.660320   \n",
      "2                      1.165698                 -0.154004   \n",
      "3                      0.673529                  0.067775   \n",
      "4                     15.932251                -10.829105   \n",
      "5                      0.678234                 -0.541309   \n",
      "\n",
      "   VSOD Evaluation vs YA  \n",
      "0                 -0.190  \n",
      "1                 -0.067  \n",
      "2                 -0.226  \n",
      "3                 -0.062  \n",
      "4                  5.000  \n",
      "5                 -0.409  , 'Refills | NATIONAL':           Top Brands Total Size  Promo Value  VSOD  VSOD IYA  Value Share  \\\n",
      "0           Gillette          0   72254455.0  0.19     1.000     0.729228   \n",
      "1            Harry's          0    9314819.0  0.08     1.143     0.169263   \n",
      "2             Schick          0    6817010.0  0.25     1.250     0.041806   \n",
      "3  Dollar Shave Club          0    3561871.0  0.22     1.294     0.025075   \n",
      "4             Pbg Pl          0    1165364.0  0.18     1.059     0.010437   \n",
      "6             Equate          0     284558.0  0.06     2.000     0.011029   \n",
      "\n",
      "   Promo Share  Value Uplift (v. base) Normalized  \\\n",
      "0     0.766134                           0.135104   \n",
      "1     0.098768                          -0.191602   \n",
      "2     0.072283                          -0.041517   \n",
      "3     0.037768                          -0.005011   \n",
      "4     0.012357                           0.009362   \n",
      "6     0.003017                          -0.104575   \n",
      "\n",
      "   Value Uplift Normalized IYA  Volume Uplift (v. Base) Normalized  \\\n",
      "0                     1.646628                            0.449445   \n",
      "1                     0.000000                            0.151115   \n",
      "2                     0.286167                            0.251527   \n",
      "3                     0.026392                            0.095924   \n",
      "4                    -0.564187                            0.100872   \n",
      "6                     0.179229                            0.267685   \n",
      "\n",
      "   Volume Uplift Normalized IYA  Promo Value Uplift vs YA  \\\n",
      "0                      1.304609                  0.646628   \n",
      "1                      0.000000                  0.000000   \n",
      "2                      0.923156                 -0.713833   \n",
      "3                      0.512147                 -0.973608   \n",
      "4                      1.864472                 -1.564187   \n",
      "6                      0.920153                 -0.820771   \n",
      "\n",
      "   VSOD Evaluation vs YA  \n",
      "0                  0.000  \n",
      "1                  0.143  \n",
      "2                  0.250  \n",
      "3                  0.294  \n",
      "4                  0.059  \n",
      "6                  1.000  , 'Razors | NATIONAL':           Top Brands Total Size  Promo Value  VSOD  VSOD IYA  Value Share  \\\n",
      "0           Gillette          0   37683633.0  0.20     1.053     0.652173   \n",
      "1            Harry's          0    5614489.0  0.10     0.909     0.195959   \n",
      "2             Schick          0    5051536.0  0.27     0.750     0.061361   \n",
      "3  Dollar Shave Club          0    3256973.0  0.26     1.368     0.041041   \n",
      "4             Pbg Pl          0     481453.0  0.15     1.000     0.011541   \n",
      "5      Van Der Hagen          0     324080.0  0.06     0.667     0.019430   \n",
      "\n",
      "   Promo Share  Value Uplift (v. base) Normalized  \\\n",
      "0     0.709650                           0.258825   \n",
      "1     0.105731                          -0.326989   \n",
      "2     0.095129                           0.896341   \n",
      "3     0.061335                           0.186674   \n",
      "4     0.009067                           0.023234   \n",
      "5     0.006103                           0.068579   \n",
      "\n",
      "   Value Uplift Normalized IYA  Volume Uplift (v. Base) Normalized  \\\n",
      "0                    10.617111                            0.729781   \n",
      "1                     1.567818                            0.036748   \n",
      "2                     3.360945                            1.158988   \n",
      "3                     1.973461                            0.517650   \n",
      "4                     0.512324                            0.129487   \n",
      "5                    -0.405066                            0.572287   \n",
      "\n",
      "   Volume Uplift Normalized IYA  Promo Value Uplift vs YA  \\\n",
      "0                      1.289194                  9.617111   \n",
      "1                      0.951587                  0.567818   \n",
      "2                      1.310714                  2.360945   \n",
      "3                      1.007740                  0.973461   \n",
      "4                      0.755879                 -0.487676   \n",
      "5                      3.108446                 -1.405066   \n",
      "\n",
      "   VSOD Evaluation vs YA  \n",
      "0                  0.053  \n",
      "1                 -0.091  \n",
      "2                 -0.250  \n",
      "3                  0.368  \n",
      "4                  0.000  \n",
      "5                 -0.333  , \"Disposables | Sam's Corp\":   Top Brands Total Size  Promo Value  VSOD  VSOD IYA  Value Share  \\\n",
      "0   Gillette          0    6669320.0  0.52     1.182     0.580606   \n",
      "1     Schick          0    4369441.0  0.52     1.576     0.400337   \n",
      "2        Bic          0     234920.0  0.60     1.304     0.019057   \n",
      "\n",
      "   Promo Share  Value Uplift (v. base) Normalized  \\\n",
      "0     0.591583                           0.233682   \n",
      "1     0.387579                           0.173835   \n",
      "2     0.020838                           0.340102   \n",
      "\n",
      "   Value Uplift Normalized IYA  Volume Uplift (v. Base) Normalized  \\\n",
      "0                     1.937369                            0.362030   \n",
      "1                     1.145476                            0.456876   \n",
      "2                     1.560829                            0.606036   \n",
      "\n",
      "   Volume Uplift Normalized IYA  Promo Value Uplift vs YA  \\\n",
      "0                      1.486442                  0.937369   \n",
      "1                      1.245059                  0.145476   \n",
      "2                      1.804135                  0.560829   \n",
      "\n",
      "   VSOD Evaluation vs YA  \n",
      "0                  0.182  \n",
      "1                  0.576  \n",
      "2                  0.304  , \"Refills | Sam's Corp\":   Top Brands Total Size  Promo Value  VSOD  VSOD IYA  Value Share  \\\n",
      "0   Gillette          0   30554877.0  0.58     0.983          1.0   \n",
      "\n",
      "   Promo Share  Value Uplift (v. base) Normalized  \\\n",
      "0          1.0                           0.274952   \n",
      "\n",
      "   Value Uplift Normalized IYA  Volume Uplift (v. Base) Normalized  \\\n",
      "0                     1.350311                            0.418865   \n",
      "\n",
      "   Volume Uplift Normalized IYA  Promo Value Uplift vs YA  \\\n",
      "0                      1.170109                  0.350311   \n",
      "\n",
      "   VSOD Evaluation vs YA  \n",
      "0                 -0.017  , \"Razors | Sam's Corp\":   Top Brands Total Size  Promo Value  VSOD  VSOD IYA  Value Share  \\\n",
      "0   Gillette          0    6681756.0   0.6     1.132     0.999974   \n",
      "\n",
      "   Promo Share  Value Uplift (v. base) Normalized  \\\n",
      "0     0.999955                           0.149434   \n",
      "\n",
      "   Value Uplift Normalized IYA  Volume Uplift (v. Base) Normalized  \\\n",
      "0                      0.47401                             0.40799   \n",
      "\n",
      "   Volume Uplift Normalized IYA  Promo Value Uplift vs YA  \\\n",
      "0                      0.777627                  -0.52599   \n",
      "\n",
      "   VSOD Evaluation vs YA  \n",
      "0                  0.132  , 'Disposables | Walmart':   Top Brands Total Size  Promo Value  VSOD  VSOD IYA  Value Share  \\\n",
      "0     Schick          0    2238318.0  0.11     0.379     0.118084   \n",
      "1        Bic          0    1716107.0  0.03     0.750     0.184538   \n",
      "2     Equate          0    1141177.0  0.06     6.000     0.153282   \n",
      "3   Gillette          0     355493.0  0.00     0.000     0.540824   \n",
      "\n",
      "   Promo Share  Value Uplift (v. base) Normalized  \\\n",
      "0     0.410574                           1.499192   \n",
      "1     0.314785                           0.963125   \n",
      "2     0.209326                           0.085956   \n",
      "3     0.065208                          -0.242084   \n",
      "\n",
      "   Value Uplift Normalized IYA  Volume Uplift (v. Base) Normalized  \\\n",
      "0                     1.305431                            3.866902   \n",
      "1                    24.129196                            1.142939   \n",
      "2                    -2.814192                            0.202683   \n",
      "3                    -0.109294                            0.088200   \n",
      "\n",
      "   Volume Uplift Normalized IYA  Promo Value Uplift vs YA  \\\n",
      "0                      3.243660                  0.305431   \n",
      "1                      4.496019                 23.129196   \n",
      "2                    -27.332868                 -3.814192   \n",
      "3                      0.025051                 -1.109294   \n",
      "\n",
      "   VSOD Evaluation vs YA  \n",
      "0                 -0.621  \n",
      "1                 -0.250  \n",
      "2                  5.000  \n",
      "3                  0.000  , 'Refills | Walmart':           Top Brands Total Size  Promo Value  VSOD  VSOD IYA  Value Share  \\\n",
      "0           Gillette          0    4081396.0  0.04     2.000     0.617099   \n",
      "1             Schick          0    2362391.0  0.29     2.071     0.046231   \n",
      "2  Dollar Shave Club          0    1029606.0  0.13     1.444     0.040291   \n",
      "3             Equate          0     279376.0  0.06     2.000     0.039221   \n",
      "4            Harry's          0     271146.0  0.01     1.000     0.243415   \n",
      "5      Van Der Hagen          0       1171.0  0.00     0.000     0.013513   \n",
      "\n",
      "   Promo Share  Value Uplift (v. base) Normalized  \\\n",
      "0     0.508517                          -0.115531   \n",
      "1     0.294339                          -0.015668   \n",
      "2     0.128283                          -0.051663   \n",
      "3     0.034809                          -0.087636   \n",
      "4     0.033783                           0.000000   \n",
      "5     0.000146                           0.360595   \n",
      "\n",
      "   Value Uplift Normalized IYA  Volume Uplift (v. Base) Normalized  \\\n",
      "0                    -4.395059                            0.117348   \n",
      "1                    -0.033013                            0.266870   \n",
      "2                     0.335485                            0.046799   \n",
      "3                     0.171214                            0.301177   \n",
      "4                     0.000000                            0.000000   \n",
      "5                    -3.094775                            0.932773   \n",
      "\n",
      "   Volume Uplift Normalized IYA  Promo Value Uplift vs YA  \\\n",
      "0                      0.611366                 -5.395059   \n",
      "1                      0.265045                 -1.033013   \n",
      "2                      0.220439                 -0.664515   \n",
      "3                      1.668760                 -0.828786   \n",
      "4                      0.000000                  0.000000   \n",
      "5                     13.646125                 -4.094775   \n",
      "\n",
      "   VSOD Evaluation vs YA  \n",
      "0                  1.000  \n",
      "1                  1.071  \n",
      "2                  0.444  \n",
      "3                  1.000  \n",
      "4                  0.000  \n",
      "5                  0.000  , 'Razors | Walmart':           Top Brands Total Size  Promo Value  VSOD  VSOD IYA  Value Share  \\\n",
      "0           Gillette          0    6219904.0  0.10     2.000     0.648459   \n",
      "1             Schick          0    1670207.0  0.33     0.825     0.051430   \n",
      "2  Dollar Shave Club          0     899507.0  0.18     2.250     0.045584   \n",
      "3            Harry's          0     151936.0  0.01     0.111     0.202241   \n",
      "4             Equate          0      51036.0  0.02     1.000     0.021574   \n",
      "5      Van Der Hagen          0       8373.0  0.00     0.000     0.029880   \n",
      "\n",
      "   Promo Share  Value Uplift (v. base) Normalized  \\\n",
      "0     0.690919                           0.785659   \n",
      "1     0.185530                           0.833865   \n",
      "2     0.099919                           0.001162   \n",
      "3     0.016877                           0.140564   \n",
      "4     0.005669                          -0.142388   \n",
      "5     0.000930                          -0.094340   \n",
      "\n",
      "   Value Uplift Normalized IYA  Volume Uplift (v. Base) Normalized  \\\n",
      "0                    15.699998                            2.431585   \n",
      "1                     0.245352                            3.414762   \n",
      "2                     0.010043                            0.106447   \n",
      "3                     0.239045                            0.215569   \n",
      "4                     0.235341                           -0.088755   \n",
      "5                    -0.100444                            0.000000   \n",
      "\n",
      "   Volume Uplift Normalized IYA  Promo Value Uplift vs YA  \\\n",
      "0                      2.217179                 14.699998   \n",
      "1                      0.643290                 -0.754648   \n",
      "2                      0.220652                 -0.989957   \n",
      "3                      0.271219                 -0.760955   \n",
      "4                     -2.977671                 -0.764659   \n",
      "5                      0.000000                 -1.100444   \n",
      "\n",
      "   VSOD Evaluation vs YA  \n",
      "0                  1.000  \n",
      "1                 -0.175  \n",
      "2                  1.250  \n",
      "3                 -0.889  \n",
      "4                  0.000  \n",
      "5                  0.000  }\n"
     ]
    }
   ],
   "source": [
    "# slide 2 with no client brands\n",
    "try:\n",
    "    if 0 in filtered_index and 'Promo Evolution no client prio' in filtered_section_names:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(promotionsBrandNOTSortedTotalFinal,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in promotionsBrandNOTSortedTotalFinal.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                print(ind)\n",
    "                promoEvolutionNew(prs,filtered_dict,dup_list[ind],position=posItr)\n",
    "                posItr += len(filtered_dict)\n",
    "        ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb051d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 331\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42070784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 3 with no client brands\n",
    "try:\n",
    "    if 1 in filtered_index and 'VSOD Summary by Sector no client prio' in filtered_section_names:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(newpromotionsNotBrandsWithMarket,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in newpromotionsNotBrandsWithMarket.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                VSOD1(prs,filtered_dict,dup_list[ind],position=posItr)\n",
    "                posItr += len(filtered_dict)\n",
    "ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61072cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335\n"
     ]
    }
   ],
   "source": [
    "print(posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 4 with no client brands\n",
    "try:\n",
    "    if 2 in filtered_index and 'Value uplift by retailer by brand no client prio' in filtered_section_names:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(concated,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in concated.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                valueUpliftRetailer_no(prs,filtered_dict,dup_list[ind],position=posItr)\n",
    "                posItr += len(filtered_dict)\n",
    "ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead65353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341\n"
     ]
    }
   ],
   "source": [
    "print(posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b3726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 11 with no client prio\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(globals()[f\"modified_promotionBrands{slides_Period}\"],value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in globals()[f\"modified_promotionBrands{slides_Period}\"].items() if key in dict[key1]}\n",
    "        if filtered_dict:        \n",
    "            try:\n",
    "                if 9 in filtered_index and 'Promo share vs Value Share no client prio' in filtered_section_names:\n",
    "                        dup_list = filtered_duplication\n",
    "                        run_slide = True\n",
    "                else:\n",
    "                    run_slide = False\n",
    "            except NameError:\n",
    "                dup_list = duplication\n",
    "                run_slide = True\n",
    "\n",
    "            if run_slide:\n",
    "                PromoShare_vs_ValueShare_no(prs,filtered_dict,dup_list[ind],position=posItr)\n",
    "                posItr += len(filtered_dict)\n",
    "    ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d61cb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "print(posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d694f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 359\n"
     ]
    }
   ],
   "source": [
    "print(ind, posItr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd77382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 12 with no client prio\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(newModifiedBrands,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in newModifiedBrands.items() if key in dict[key1]}\n",
    "        if filtered_dict:        \n",
    "            try:\n",
    "                if 10 in filtered_index and 'Promo Sales by total size no client prio' in filtered_section_names:\n",
    "                        dup_list = filtered_duplication\n",
    "                        run_slide = True\n",
    "                else:\n",
    "                    run_slide = False\n",
    "            except NameError:\n",
    "                dup_list = duplication\n",
    "                run_slide = True\n",
    "\n",
    "            if run_slide:\n",
    "                PromoSalesTotalSize_no(prs,filtered_dict,dup_list[ind],position=posItr)\n",
    "                posItr += len(filtered_dict)\n",
    "    ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3c723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 14 with no client prio\n",
    "if feature_share:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(globals()[f\"modified_promotionBrands_share{slides_Period}\"],value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in globals()[f\"modified_promotionBrands_share{slides_Period}\"].items() if key in dict[key1]}\n",
    "            if filtered_dict:       \n",
    "                try:\n",
    "                    if 12 in filtered_index and 'Feature Share vs Fair Share no client prio' in filtered_section_names:\n",
    "                            dup_list = filtered_duplication\n",
    "                            run_slide = True\n",
    "                    else:\n",
    "                        run_slide = False\n",
    "                except NameError:\n",
    "                    dup_list = duplication\n",
    "                    run_slide = True\n",
    "\n",
    "                if run_slide:   \n",
    "                    featureShare_no(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                    posItr += len(filtered_dict)\n",
    "        ind +=1\n",
    "else:\n",
    "    ind +=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbef8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# slide 15 with no client prio\n",
    "if display_share:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(globals()[f\"modified_promotionBrands_share{slides_Period}\"],value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in globals()[f\"modified_promotionBrands_share{slides_Period}\"].items() if key in dict[key1]}\n",
    "            if filtered_dict:        \n",
    "                try:\n",
    "                    if 13 in filtered_index and 'Display Share vs Fair Share no client prio' in filtered_section_names:\n",
    "                            dup_list = filtered_duplication\n",
    "                            run_slide = True\n",
    "                    else:\n",
    "                        run_slide = False\n",
    "                except NameError:\n",
    "                    dup_list = duplication\n",
    "                    run_slide = True\n",
    "\n",
    "                if run_slide:   \n",
    "                    displayShare_no(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                    posItr += len(filtered_dict)\n",
    "        ind+=1\n",
    "else:\n",
    "    ind+=5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217af932",
   "metadata": {},
   "source": [
    "## Output slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56e0982-087b-439b-a549-736abdbb54b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slide 23: Opened Excel workbook: Book1\n",
      "Slide 24: Opened Excel workbook: Book1\n"
     ]
    }
   ],
   "source": [
    "outputPath=os.getcwd() + f\"\\\\Promotion {client_manuf[0]}.pptx\"\n",
    "prs.save(outputPath)\n",
    "# app = win32.Dispatch(\"PowerPoint.Application\")\n",
    "final=os.getcwd() +f\"\\\\Promotion {client_manuf[0]}.pptx\"\n",
    "#open_chart_data_in_excel(final,outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae25476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
