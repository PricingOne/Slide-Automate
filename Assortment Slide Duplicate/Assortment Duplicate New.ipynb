{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e2c6689",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"..\\general_functions\\generalFunctions.ipynb\"\n",
    "%run \"..\\Assortment Slide Duplicate\\Assortment Replacement Function New.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20a6c146",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_manuf =[\"Bel\"]\n",
    "client_brands = [\"Kiri\",\"La Vache Qui Rit\",\"Boursin\"]\n",
    "\n",
    "decimals = 2\n",
    "sign = \"After\"\n",
    "currency = '€'\n",
    "currency = ' '+ currency if sign.lower() == 'after' else  currency + ' '\n",
    "\n",
    "prodORitem = \"Item\"\n",
    "prodORitemfields= prodORitem\n",
    "categories = [\"Total Fromage\"]\n",
    "sectors = [\"Soft Cheese\",\"Aperitif\",\"Ingredient A Chaud\"]\n",
    "segments = [\"Enfant\",\"Frais A Tartiner\",\"Salade\"]\n",
    "subsegments= []\n",
    "subcategories= []\n",
    "\n",
    "national = False\n",
    "customareas= \"\"\n",
    "areas = [\"RETAILER\"]\n",
    "\t\t\t\t\t\n",
    "regions_RET  = [\"Carrefour\",\"Intermarche\"]\n",
    "channels_RET = [\"Carrefour Hyper + Drive\",\"Carrefour Supermarket + Drive\",\"Carrefour Proximite\",\"Intermarche Super\",\"Intermarche Hyper\",\"Intermarche Proxi\"]\n",
    "market_RET = []\n",
    " \n",
    "regions_CHAN = []\n",
    "channels_CHAN = []\n",
    "market_CHAN = []\n",
    "\n",
    "regions_REG = []\n",
    "channels_REG = []\n",
    "market_REG = []\n",
    "\n",
    "regions_CUST = []\n",
    "channels_CUST = []\n",
    "market_CUST = []\n",
    "\n",
    "data_source = \"DATA SOURCE: Trade Panel/Retailer Data | July 2025\"\n",
    "years = {2023,2024,2025}\n",
    "ManufOrTopC =\"Top Companies\"\n",
    "BrandOrTopB = \"Top Brands\"\n",
    "end_date = \"2025-08-01\"\n",
    "\n",
    "unit = \"‘000000s\"\n",
    "unitDeviation = 1000000\n",
    "\n",
    "OpenEditData=True\n",
    "RunManuf= False\n",
    "Runwithoutclientorder= False\n",
    "\n",
    "client_brands_competitor = client_brands \n",
    "valueToReplace = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e1d68cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = {}\n",
    "datasets_path = os.getcwd()+\"/Assortment Datasets NewEX/\"\n",
    "datasets = os.listdir(datasets_path)\n",
    "for d in datasets:\n",
    "    with open(datasets_path+d, 'rb') as handle:\n",
    "        globals()[d.split('.')[0]] = pd.read_pickle(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "392c7030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixAssortmentCleaning(assortment, cumulativeShare,slideby=\"Top Brands\",lis=\"\"):\n",
    "    # Initialize dictionaries to store modified data\n",
    "    cumulativeShareModifiedBrand = {}\n",
    "    assortmentModified = {}\n",
    "    assortmentModifiedBrand = {}\n",
    "    assortmentModifiedTotal = {}\n",
    "    assortmentClient = {}\n",
    "\n",
    "    # Process cumulative share data\n",
    "    for key, value in cumulativeShare.items():\n",
    "        dfcumulative=cumulativeShare[key].copy()\n",
    "        # dfcumulative=DetectHeader(dfcumulative)\n",
    "        if dfcumulative.shape[0] != 0:  # If the dataframe is not empty\n",
    "            newKey = key\n",
    "            cumulativeShareModifiedBrand[newKey] = dfcumulative.replace(np.nan, 0)  # Replace NaNs with 0 and store\n",
    "\n",
    "    # Process assortment data\n",
    "    for key, value in assortment.items():\n",
    "        df=assortment[key].copy()\n",
    "\n",
    "        # df=DetectHeader(df)\n",
    "        df[slideby] = df[slideby].ffill()  # Forward fill 'Top Brands' column\n",
    "\n",
    "        # Replace specific values in 'Top Brands' as per 'valueToReplace' dictionary\n",
    "        for val, replacer in valueToReplace.items():\n",
    "            df[slideby] = df[slideby].str.replace(val, replacer)\n",
    "        \n",
    "        dfBrand = df[~df[slideby].str.contains('Total')]  # Filter out rows containing 'Total' in 'Top Brands'\n",
    "        dfTotal = df[df[slideby].str.contains('Total') & (df[slideby] != 'Grand Total')].reset_index(drop=True)\n",
    "        dfTotal[slideby] = dfTotal[slideby].str.replace(' Total', '')  # Adjust 'Top Brands' column for total rows\n",
    "\n",
    "        if df.shape[0] != 0:  # If the dataframe is not empty\n",
    "            newKey = key\n",
    "\n",
    "            # Process client-specific data for each brand\n",
    "            for brand in lis:\n",
    "\n",
    "                if df[df[slideby] == brand].shape[0] > 0:  # Check if brand data exists in dataframe\n",
    "\n",
    "                    #assortmentClient[newKey + ' | ' + brand] = df[df['Top Brands'] == brand].replace(np.nan, 0)\n",
    "                    brand_df = df[df[slideby] == brand].replace(np.nan, 0) \n",
    "                    brand_df = brand_df.sort_values(by='Value Share', ascending = False)\n",
    "                    brand_df['Value Share Rescale'] = brand_df['Value Share'] / sum(brand_df['Value Share'])\n",
    "                    brand_df['Cumulative Share'] = brand_df['Value Share Rescale'].cumsum()\n",
    "                    brand_df = brand_df[brand_df[\"WD\"] != 0]\n",
    "                    #brand_df['Final Cumlative Share'] = 100 - brand_df['Cumlative Share']*100\n",
    "                    assortmentClient[newKey + ' | ' + brand] = brand_df.merge(\n",
    "                        cumulativeShareModifiedBrand[newKey], how='left', on= prodORitem\n",
    "                    )\n",
    "                    #assortmentClient[newKey + ' | ' + brand] = assortmentClient[newKey + ' | ' + brand].merge(\n",
    "                    #    cumulativeShareModifiedBrand[newKey], how='left', on= prodORitem\n",
    "                    #)            \n",
    "            # Store modified data for total, brand, and overall assortment\n",
    "            assortmentModified[newKey] = df.replace(np.nan, 0)\n",
    "            assortmentModifiedBrand[newKey] = dfBrand.replace(np.nan, 0)\n",
    "            assortmentModifiedBrand[newKey] = assortmentModifiedBrand[newKey][assortmentModifiedBrand[newKey][\"WD\"] != 0]\n",
    "            assortmentModifiedBrand[newKey] = assortmentModifiedBrand[newKey].merge(\n",
    "                cumulativeShareModifiedBrand[newKey], how='left', on=prodORitem\n",
    "            )\n",
    "            \n",
    "            assortmentModifiedTotal[newKey] = dfTotal.replace(np.nan, 0)\n",
    "    \n",
    "    return assortmentModifiedBrand, assortmentModifiedTotal, assortmentClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b064fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "assortmentBrand,assortmentTotal,assortmentClient=mixAssortmentCleaning(assortment,cumulative_share,slideby=f'{BrandOrTopB}',lis=client_brands_competitor)\n",
    "dropemptydf(assortmentBrand)\n",
    "assortmentmanuf,assortmentTotalmanuf,assortmentClientmanuf=mixAssortmentCleaning(assortment_manuf,cumulative_share,slideby=f'{ManufOrTopC}',lis=client_manuf)\n",
    "dropemptydf(assortmentmanuf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "480f5169",
   "metadata": {},
   "outputs": [],
   "source": [
    "assortmentClientManufAppend= assortmentClientmanuf\n",
    "assortmentClientManufAppend.update(assortmentClient)\n",
    "dropemptydf(assortmentClientManufAppend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5af95e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cleans and processes assortment for brand-specific analysis.\n",
    "\n",
    "Args:\n",
    "assortmentbybrand (dict): Dictionary containing assortment data by brand.\n",
    "\n",
    "Returns:\n",
    "tuple: \n",
    "   - assortmentModifiedBrand (dict): Dictionary containing cleaned and modified assortment data by brand for slide 1\n",
    "\"\"\"\n",
    "\n",
    "# Initialize dictionaries to store modified data\n",
    "assortmentbybrandfinal = {}\n",
    "# Process assortment data\n",
    "for key, value in assortmentbybrand.items():\n",
    "   df=assortmentbybrand[key].copy()\n",
    "   # df=DetectHeader(df)\n",
    "   if BrandOrTopB != \"Top Brands\":\n",
    "      df= df.rename(columns={\"Brand\":\"Top Brands\"})\n",
    "   # Replace specific values in 'Top Brands' as per 'valueToReplace' dictionary\n",
    "   for val, replacer in valueToReplace.items():\n",
    "      df['Top Brands'] = df['Top Brands'].str.replace(val, replacer)\n",
    "   \n",
    "   dfBrand = df[df['Top Brands'] != 'Grand Total'].reset_index(drop=True)\n",
    "   if dfBrand.shape[0] != 0:  # If the dataframe is not empty\n",
    "      assortmentbybrandfinal[key] = dfBrand.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83cac88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cleans and processes assortment for brand-specific analysis.\n",
    "\n",
    "Args:\n",
    "assortmentbybrand (dict): Dictionary containing assortment data by brand.\n",
    "\n",
    "Returns:\n",
    "tuple: \n",
    "   - assortmentModifiedBrand (dict): Dictionary containing cleaned and modified assortment data by brand for slide 1\n",
    "\"\"\"\n",
    "\n",
    "# Initialize dictionaries to store modified data\n",
    "assortmentbymanufFinal = {}\n",
    "# Process assortment data\n",
    "for key, value in assortmentbymanuf.items():\n",
    "   df=assortmentbymanuf[key].copy()\n",
    "   # df=DetectHeader(df)\n",
    "   dfManuf = df[df[ManufOrTopC] != 'Grand Total'].reset_index(drop=True)\n",
    "   dfManuf = dfManuf[dfManuf[ManufOrTopC] != 'All Others'].reset_index(drop=True)\n",
    "   if dfManuf.shape[0] != 0:  # If the dataframe is not empty\n",
    "         assortmentbymanufFinal[key] = dfManuf.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "898cbe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assortmentBrandSorted= dfSort(assortmentbybrandfinal, client_brands, 'Top Brands', num=10,salesCol='Value Share')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d1e8a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "assortmentManufSorted= dfSort(assortmentbymanufFinal, [], ManufOrTopC, num=10,salesCol='Value Share')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77e3bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assortmentBrandNOTSorted= dfSort(assortmentbybrandfinal, [], 'Top Brands', num=10,salesCol='Value Share')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a73f10f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assortmentTotalSorted= dfSort(assortmentTotal, client_brands, 'Top Brands', num=10,salesCol='Value Share')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f3f41a",
   "metadata": {},
   "source": [
    "### Slide 3,4 cumulative share Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6505e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulativeShareCleaningTopPercent(assortment, cumulativeShare, percent=0.5):\n",
    "    \"\"\"\n",
    "    Cleans and processes assortment and cumulative share data, filtering out the top percentage of products.\n",
    "    \n",
    "    Args:\n",
    "    assortment (dict): Dictionary containing assortment data.\n",
    "    cumulativeShare (dict): Dictionary containing cumulative share data.\n",
    "    percent (float): The top cumulative product share percentage threshold to filter by (default is 0.5).\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing the cleaned and processed data for the top percentage of products.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize dictionaries to store modified data\n",
    "    assortmentModified = {}\n",
    "    assortmentModifiedBrand = {}\n",
    "    topPercent = {}\n",
    "    cumulativeShareModifiedBrand = {}\n",
    "\n",
    "    # Process cumulative share data\n",
    "    for key, value in cumulativeShare.items():\n",
    "        dfcumulative=cumulativeShare[key].copy()\n",
    "        # dfcumulative=DetectHeader(dfcumulative)\n",
    "        if dfcumulative.shape[0] != 0:  # If the dataframe is not empty\n",
    "            newKey = key\n",
    "            cumulativeShareModifiedBrand[newKey] = dfcumulative.replace(np.nan, 0)  # Replace NaNs with 0 and store\n",
    "\n",
    "    # Process assortment data\n",
    "    for key, value in assortment.items():\n",
    "        df=assortment[key].copy()\n",
    "        # df=DetectHeader(df)\n",
    "        if BrandOrTopB != \"Top Brands\":\n",
    "            df= df.rename(columns={\"Brand\":\"Top Brands\"})\n",
    "        df['Top Brands'] = df['Top Brands'].ffill()  # Forward fill 'Top Brands' column\n",
    "        \n",
    "        # Replace specific values in 'Top Brands' as per 'valueToReplace' dictionary\n",
    "        for val, replacer in valueToReplace.items():\n",
    "            df['Top Brands'] = df['Top Brands'].str.replace(val, replacer)\n",
    "        \n",
    "        dfBrand = df[~df['Top Brands'].str.contains('Total')]  # Filter out rows containing 'Total' in 'Top Brands'\n",
    "        \n",
    "        if df.shape[0] != 0:  # If the dataframe is not empty\n",
    "            newKey = key\n",
    "\n",
    "            # Store modified data for overall and brand-specific assortment\n",
    "            assortmentModified[newKey] = df.replace(np.nan, 0)\n",
    "            assortmentModifiedBrand[newKey] = dfBrand.replace(np.nan, 0)\n",
    "            assortmentModifiedBrand[newKey] = assortmentModifiedBrand[newKey].merge(\n",
    "                cumulativeShareModifiedBrand[newKey], how='left', on=prodORitem\n",
    "            )\n",
    "            \n",
    "            # Filter and store data for products within the specified cumulative share percentage\n",
    "            # if (assortmentModifiedBrand[newKey][assortmentModifiedBrand[newKey]['Cumulative '+prodORitem+' Share'] <= percent].shape[0] > 0):\n",
    "            \n",
    "            topPercent[newKey] = assortmentModifiedBrand[newKey]\n",
    "\n",
    "    return topPercent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "678533cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulativeShareTop50 = cumulativeShareCleaningTopPercent(assortment,cumulative_share, percent =0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8af5ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulativeShareAll = cumulativeShareCleaningTopPercent(assortment,cumulative_share, percent =100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a25a7a",
   "metadata": {},
   "source": [
    "### Slide 6,7 SKU Productivity Analysis Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "011064e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def productivityAnalysisCleaning(assortmentModifiedBrand):\n",
    "    \"\"\"\n",
    "    Cleans and filters the assortment data for client brands based on specific criteria.\n",
    "    \n",
    "    Args:\n",
    "    assortmentModifiedBrand (dict): Dictionary containing modified assortment data by brand.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing the cleaned and filtered data for each client brand.\n",
    "    \"\"\"\n",
    "    \n",
    "    assortmentClientBrand = {}  # Initialize a dictionary to store the cleaned data for client brands\n",
    "    \n",
    "    # Iterate over the modified assortment data\n",
    "    for key, value in assortmentModifiedBrand.items():\n",
    "        # Filter the dataframe for client brands with Net Sales >= 1000 and WD not equal to 0\n",
    "        df = value[(value['Top Brands'].isin(client_brands)) & (value['Net Sales'] >= 1000)]\n",
    "        df = df[df['WD'] != 0]\n",
    "        \n",
    "        # If the filtered dataframe is not empty\n",
    "        if df.shape[0] != 0:\n",
    "            # Iterate over each client brand\n",
    "            for brand in client_brands:\n",
    "                # If the brand exists in the filtered dataframe\n",
    "                if df[df['Top Brands'] == brand].shape[0] > 0:\n",
    "                    # Store the filtered data in the dictionary with a combined key of original key and brand name\n",
    "                    assortmentClientBrand[key + ' | ' + brand] = df[df['Top Brands'] == brand]\n",
    "    \n",
    "    return assortmentClientBrand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0d89d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "assortmentClientBrand=productivityAnalysisCleaning(assortmentBrand)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ae52e2",
   "metadata": {},
   "source": [
    "## New Slide "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a5aef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_brand(brands):\n",
    "    new_brands ={}\n",
    "    for key, df in brands.items():\n",
    "        if df.shape[0] != 0:  \n",
    "            new_brands[key] =df.replace(np.nan, -1)  \n",
    "    return new_brands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "000adaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_manuf(manuf):\n",
    "    new_manuf ={}\n",
    "    for key, df in manuf.items():\n",
    "        if df.shape[0] != 0:  \n",
    "            # newKey = key\n",
    "            # if key.split(' | ')[0] not in categories:  \n",
    "            #     newKey = key.split(' | ')[1] + ' | ' + key.split(' | ')[0]\n",
    "            new_manuf[key] = df.replace(np.nan, -1)  \n",
    "    return new_manuf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80e9da24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_total(total):\n",
    "    new_total ={}\n",
    "    for key, df in total.items():\n",
    "        # new_df = DetectHeader(df)\n",
    "        if df.shape[0] != 0:\n",
    "            new_df = df.drop(['SKU Share', 'Value Share'], axis=1)\n",
    "            new_total[key] = new_df.replace(np.nan, -1) \n",
    "    return new_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22f5a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_total_brand(total, brand, column,scope):\n",
    "    brand_total ={}\n",
    "    for key in brand.keys():\n",
    "        market = key.split(' | ')[1]\n",
    "        for small_key in total.keys():\n",
    "            if market == small_key:\n",
    "                # print(market, small_key, key)\n",
    "                df = pd.merge(total[small_key], brand[key], how = 'left',on=column,suffixes=('_total', '_brand')).replace(np.nan,0)\n",
    "                print(df.columns)\n",
    "                df['Fair Share'] = df.apply(lambda x: ((x['Av No SKUs_brand'] / x['SKU Share']) * x['Value Share'] if x['SKU Share'] != 0 else 0), axis=1)\n",
    "                df ['Listing Opportunity'] = df['Fair Share'].astype(float).round(0) - df['Av No SKUs_brand'].astype(float).round(0)\n",
    "                grand_row = df[df[column] == 'Grand Total']\n",
    "                other_rows = df[df[column].isin(scope)]\n",
    "                df = pd.concat([grand_row, other_rows], ignore_index=True)\n",
    "                if df.shape[0] > 0:\n",
    "                    brand_total[key] = df\n",
    "\n",
    "    return brand_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beff195c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Sector', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n",
      "Index(['Segment', 'Av No SKUs_total', 'Av No SKUs_brand', 'SKU Share',\n",
      "       'Value Share'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "if len(sectors) > 0:\n",
    "    Sector_brands = clean_brand(Sector_dfs_brands)\n",
    "    Sector_manuf = clean_manuf(Sector_dfs_manuf)\n",
    "    Sector_total = clean_total(Sector_dfs_total)\n",
    "    Sector_brand_total = merge_total_brand(Sector_total, Sector_brands, 'Sector',sectors)\n",
    "    Sector_manuf_total = merge_total_brand(Sector_total, Sector_manuf, 'Sector',sectors)\n",
    "    final_Sector = Sector_manuf_total | Sector_brand_total\n",
    "\n",
    "\n",
    "if len(segments) > 0:\n",
    "    Segment_brands = clean_brand(Segment_dfs_brands)\n",
    "    Segment_manuf = clean_manuf(Segment_dfs_manuf)\n",
    "    Segment_total = clean_total(Segment_dfs_total)\n",
    "    Segment_brand_total = merge_total_brand(Segment_total, Segment_brands, 'Segment',segments)\n",
    "    Segment_manuf_total = merge_total_brand(Segment_total, Segment_manuf, 'Segment',segments)\n",
    "    final_Segment = Segment_manuf_total | Segment_brand_total\n",
    "\n",
    "\n",
    "if len(subcategories) > 0:\n",
    "    SubCategory_brands = clean_brand(SubCategory_dfs_brands)\n",
    "    SubCategory_manuf = clean_manuf(SubCategory_dfs_manuf)\n",
    "    SubCategory_total = clean_total(SubCategory_dfs_total)\n",
    "    SubCategory_brand_total = merge_total_brand(SubCategory_total, SubCategory_brands, 'SubCategory',subcategories)\n",
    "    SubCategory_manuf_total = merge_total_brand(SubCategory_total, SubCategory_manuf, 'SubCategory',subcategories)\n",
    "    final_SubCategory = SubCategory_manuf_total | SubCategory_brand_total\n",
    "\n",
    "\n",
    "if len(subsegments) > 0:\n",
    "    Subsegment_brands = clean_brand(SubSegment_dfs_brands)\n",
    "    Subsegment_manuf = clean_manuf(SubSegment_dfs_manuf)\n",
    "    Subsegment_total = clean_total(SubSegment_dfs_total)\n",
    "    Subsegment_brand_total = merge_total_brand(Subsegment_total, Subsegment_brands,'SubSegment',subsegments)\n",
    "    Subsegment_manuf_total = merge_total_brand(Subsegment_total, Subsegment_manuf,'SubSegment',subsegments)\n",
    "    final_Subsegment = Subsegment_manuf_total | Subsegment_brand_total\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1236c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [0,0 if RunManuf else None,1,3,4,5 if len(client_brands)>0 else None,6 if len(client_brands)>0 else None, *[7]*((1 if sectors else 0) + (1 if segments else 0) + (1 if subsegments else 0) + (1 if subcategories else 0)),0 if Runwithoutclientorder else None]\n",
    "        #  2 if len(client_brands)>0 else None ##TOP%CUM\n",
    "index = [x for x in index if x is not None]\n",
    "\n",
    "duplication = [len(assortmentBrandSorted.keys()),len(assortmentManufSorted.keys()) if RunManuf else None,len(assortmentBrand.keys()),len(assortmentClientManufAppend.keys()) if len(client_brands) >0 else None,len(assortmentBrand.keys()) , len(assortmentClientBrand.keys()) if len(client_brands)>0 else None , len(assortmentClientBrand.keys()) if len(client_brands)>0 else None,\n",
    "            #    len(cumulativeShareTop50.keys()), ##TOP%CUM\n",
    "               len(final_Sector.keys()) if len(sectors) >0 else None, len(final_Segment.keys()) if len(segments) > 0 else None, len(final_SubCategory.keys()) if len(subcategories) >0 else None, len(final_Subsegment.keys()) if len(subsegments) > 0 else None ,len(assortmentBrandNOTSorted.keys()) if Runwithoutclientorder else None]\n",
    "duplication = [x for x in duplication if x is not None]\n",
    "\n",
    "section_names = [\"SKU Share By Brand\",\"SKU Share by Manuf\" if RunManuf else None,\"Cumulative Product Shares\",\"Manuf Cumulative Product Share\" if len(client_brands) >0 else None,\"Top 20 cumulative share\",\"SKU Productivity Analysis with TM%\" if len(client_brands)>0 else None, \"SKU Productivity Analysis with WD\" if len(client_brands)>0  else None,\n",
    "                 #\"Top 50% cumulative share\",##TOP%CUM\n",
    "                 \"Sectors Fair Share\" if len(sectors) > 0 else None, \"Segments Fair Share\" if len(segments) > 0 else None, \"SubCategory Fair Share\" if len(subcategories) > 0 else None, \"SubSegment Fair Share\" if len(subsegments) > 0 else None,\"SKU Share By Brand no client prio\" if Runwithoutclientorder else None ]\n",
    "section_names = [x for x in section_names if x is not None]\n",
    "\n",
    "path = os.getcwd() + '//Assortment base Oct 2024.pptx'\n",
    "new_pre = os.getcwd() + '//slide duplicated.pptx'\n",
    "\n",
    "\n",
    "length = len(duplication)\n",
    "for i in reversed(range(length)):\n",
    "    if duplication[i]==0:\n",
    "        del duplication[i]\n",
    "        del index[i]\n",
    "        del section_names[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "059c9266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[0, 1, 3, 4, 5, 6, 7, 7]\n",
      "8\n",
      "[56, 56, 166, 56, 108, 108, 32, 32]\n",
      "8\n",
      "['SKU Share By Brand', 'Cumulative Product Shares', 'Manuf Cumulative Product Share', 'Top 20 cumulative share', 'SKU Productivity Analysis with TM%', 'SKU Productivity Analysis with WD', 'Sectors Fair Share', 'Segments Fair Share']\n"
     ]
    }
   ],
   "source": [
    "print(len(index))\n",
    "print(index)\n",
    "print(len(duplication))\n",
    "print(duplication)\n",
    "print(len(section_names))\n",
    "print(section_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d86274b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "614"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(duplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7333dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pythoncom\n",
    "import win32com.client as win32\n",
    "\n",
    "def slideDuplication(index=[0,1], duplication=[1,1], section_names=[''], path='', new_pre=''):\n",
    "    \"\"\"\n",
    "    Duplicate slides in a PowerPoint presentation.\n",
    "\n",
    "    Parameters:\n",
    "    - index (list): List of slide indices (0-based) to duplicate.\n",
    "    - duplication (list): List specifying the number of times each slide should be duplicated.\n",
    "    - section_names (list): List of names for sections to be added.\n",
    "    - path (str): Path to the PowerPoint presentation file.\n",
    "    - new_pre (str): Path to save the duplicated presentation.\n",
    "\n",
    "    Returns:\n",
    "    - str: A message indicating success or failure.\n",
    "    \"\"\"\n",
    "    # Check lengths\n",
    "    if not (len(index) == len(duplication) == len(section_names)):\n",
    "        return 'The Index list must have the same length as Duplication and Section names'\n",
    "\n",
    "    lis = []\n",
    "\n",
    "    pythoncom.CoInitialize()\n",
    "    app = win32.Dispatch(\"PowerPoint.Application\")\n",
    "    presentation = app.Presentations.Open(path, WithWindow=False)\n",
    "\n",
    "    try:\n",
    "        for i in range(len(index)):\n",
    "            if isinstance(index[i], list):\n",
    "                # List of slide indices\n",
    "                for num_duplicate in range(duplication[i]):\n",
    "                    for k in index[i]:\n",
    "                        slide = presentation.Slides.Item(k + 1)  # ✅ convert 0-based to 1-based\n",
    "                        duplicated_slide = slide.Duplicate()\n",
    "                        duplicated_slide.MoveTo(presentation.Slides.Count)\n",
    "                lis.append(presentation.Slides.Count + 1 - (duplication[i] * len(index[i])))\n",
    "            else:\n",
    "                # Single slide index\n",
    "                slide = presentation.Slides.Item(index[i] + 1)  # ✅ convert 0-based to 1-based\n",
    "                for num_duplicate in range(duplication[i]):\n",
    "                    duplicated_slide = slide.Duplicate()\n",
    "                    duplicated_slide.MoveTo(presentation.Slides.Count)\n",
    "                lis.append(presentation.Slides.Count + 1 - duplication[i])\n",
    "\n",
    "        # Add sections\n",
    "        for j in range(len(lis)):\n",
    "            if duplication[j] != 0:\n",
    "                presentation.SectionProperties.AddBeforeSlide(lis[j], section_names[j])\n",
    "\n",
    "        # Delete the default first section if exists\n",
    "        if presentation.SectionProperties.Count > 0:\n",
    "            presentation.SectionProperties.Delete(1, True)\n",
    "\n",
    "        presentation.SaveAs(new_pre)\n",
    "        return f\"Presentation saved to {new_pre}\"\n",
    "\n",
    "    finally:\n",
    "        presentation.Close()\n",
    "        app.Quit()\n",
    "        pythoncom.CoUninitialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b89c034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Presentation saved to c:\\\\Users\\\\aleaa\\\\Documents\\\\Slide-Automate\\\\Assortment Slide Duplicate//slide duplicated.pptx'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slideDuplication(index,duplication,section_names,path,new_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6e08c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = Presentation(new_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e09a89",
   "metadata": {},
   "source": [
    "### Slide 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b16811e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "posItr = 0\n",
    "ind=0\n",
    "SkuShareByBrand(prs,assortmentBrandSorted,duplication[ind],BrandOrTopB,position=posItr)\n",
    "posItr +=len(assortmentBrandSorted)\n",
    "ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5bfee105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 1\n"
     ]
    }
   ],
   "source": [
    "print(posItr,ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1df971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RunManuf:\n",
    "    SkuShareByBrand(prs,assortmentManufSorted,duplication[ind],ManufOrTopC,position=posItr)\n",
    "    posItr += len(assortmentManufSorted)\n",
    "    ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dabb97e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 1\n"
     ]
    }
   ],
   "source": [
    "print(posItr,ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15768e88",
   "metadata": {},
   "source": [
    "### Slide 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a04b676",
   "metadata": {},
   "outputs": [],
   "source": [
    "CumulativeProductShare(prodORitemfields,prs,assortmentBrand,duplication[ind],position=posItr)\n",
    "posItr+= len(assortmentBrand)\n",
    "ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59bcb85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 2\n"
     ]
    }
   ],
   "source": [
    "print(posItr,ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fd077f",
   "metadata": {},
   "source": [
    "### Slide 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3912b3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulativeTop50(prodORitem,prs, cumulativeShareTop50,duplication[ind],position=posItr)\n",
    "# posItr +=len(cumulativeShareTop50)\n",
    "# ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2908c907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 2\n"
     ]
    }
   ],
   "source": [
    "print(posItr,ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d2dea5",
   "metadata": {},
   "source": [
    "### Slide 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6fcb1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(client_brands)>0:\n",
    "    brandCumulativeProductShare(prodORitem,prodORitemfields,prs,assortmentClientManufAppend,duplication[ind],position=posItr)\n",
    "    posItr +=len(assortmentClientManufAppend)\n",
    "    ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06b377f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278 3\n"
     ]
    }
   ],
   "source": [
    "print(posItr,ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c25e9a",
   "metadata": {},
   "source": [
    "### Slide 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af7c2695",
   "metadata": {},
   "outputs": [],
   "source": [
    "top20CumulativeShare(prodORitem,prodORitemfields,prs,assortmentBrand,duplication[ind],client_brands, position=posItr)\n",
    "posItr+= len(assortmentBrand)\n",
    "ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6565deb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334 4\n"
     ]
    }
   ],
   "source": [
    "print(posItr,ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bfbadf",
   "metadata": {},
   "source": [
    "### Slide 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a20fc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(client_brands)>0 and len(assortmentClientBrand.keys())>0:\n",
    "    SKUProductivityAnalysis(prodORitem,prodORitemfields,prs,assortmentClientBrand,duplication[ind],position=posItr)\n",
    "    posItr += len(assortmentClientBrand)\n",
    "    ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9751cc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442 5\n"
     ]
    }
   ],
   "source": [
    "print(posItr,ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c83b4a2",
   "metadata": {},
   "source": [
    "### Slide 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "47db71f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(client_brands)>0 and len(assortmentClientBrand.keys())>0:\n",
    "    SKUWithWD(prodORitem,prodORitemfields,prs,assortmentClientBrand,duplication[ind],position=posItr)\n",
    "    posItr += len(assortmentClientBrand)\n",
    "    ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d428f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550 6\n"
     ]
    }
   ],
   "source": [
    "print(posItr,ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535bff0b",
   "metadata": {},
   "source": [
    "### Slide 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "219a1941",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if len(sectors)>0:\n",
    "    fair_share(final_Sector,prs ,scope ='Sector', position=posItr,category = categories[0])\n",
    "    posItr += len(final_Sector)\n",
    "    ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f3a3546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(segments)>0:\n",
    "    fair_share(final_Segment,prs ,scope='Segment', position=posItr,category =categories[0])\n",
    "    posItr += len(final_Segment)\n",
    "    ind+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "23cfbb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(subcategories)>0:\n",
    "    fair_share(final_SubCategory,prs ,scope='SubCategory', position=posItr,category =categories[0])\n",
    "    posItr += len(final_SubCategory)\n",
    "    ind+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6e831e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(subsegments)>0:\n",
    "    fair_share(final_Subsegment,prs ,scope='SubSegment', position=posItr,category =categories[0])\n",
    "    posItr += len(final_Subsegment)\n",
    "    ind+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71926fb",
   "metadata": {},
   "source": [
    "### Slide 1 without forcing client brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e1f84829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614 8\n"
     ]
    }
   ],
   "source": [
    "print(posItr,ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "776c0826",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Runwithoutclientorder: SkuShareByBrand(prs,assortmentBrandNOTSorted,duplication[ind],BrandOrTopB,position=posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a9ccb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath=os.getcwd() + f\"\\\\Mix and assortment output_{datetime.today().strftime(\"%d-%m\")}.pptx\"\n",
    "# prs.save(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a5ed5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_chart_data_in_excel(pptx_path, output_pptx_path=None, OpenEditData=True):\n",
    "    \"\"\"Open PowerPoint, detect charts, and (optionally) open their Excel data workbooks.\"\"\"\n",
    "    if not OpenEditData:\n",
    "        print(\"Stopping the script as 'OpenEditData' is set to False.\")\n",
    "        return None\n",
    "\n",
    "    pythoncom.CoInitialize()\n",
    "\n",
    "    powerpoint = safe_dispatch(\"PowerPoint.Application\")\n",
    "    powerpoint.DisplayAlerts = False\n",
    "\n",
    "    excel = safe_dispatch(\"Excel.Application\")\n",
    "    excel.Visible = False\n",
    "    excel.DisplayAlerts = False\n",
    "\n",
    "    workbooks = []\n",
    "\n",
    "    # Open the PowerPoint file (hidden window)\n",
    "    ppt_pres = powerpoint.Presentations.Open(pptx_path, WithWindow=False)\n",
    "\n",
    "    try:\n",
    "        for slide in ppt_pres.Slides:\n",
    "            slide_index = slide.SlideIndex\n",
    "            for shape in slide.Shapes:\n",
    "                if getattr(shape, \"HasChart\", False):\n",
    "                    chart = shape.Chart\n",
    "                    if chart.ChartType in [15, -4169]:\n",
    "                        try:\n",
    "                            chart_data = chart.ChartData\n",
    "                            workbook = chart_data.Workbook\n",
    "                            workbook.Application.Visible = False\n",
    "                            workbooks.append(workbook)\n",
    "                            print(f\"Slide {slide_index}: Found chart with workbook: {workbook.FullName}\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Slide {slide_index}: Failed to open chart data → {e}\")\n",
    "\n",
    "        if output_pptx_path:\n",
    "            ppt_pres.SaveAs(output_pptx_path)\n",
    "\n",
    "        # return presentation object so slideDuplication can use it\n",
    "        return ppt_pres\n",
    "\n",
    "    finally:\n",
    "        for wb in workbooks:\n",
    "            try:\n",
    "                wb.Close(SaveChanges=False)\n",
    "            except Exception:\n",
    "                pass\n",
    "        pythoncom.CoUninitialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e82b1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slide 335: Found chart with workbook: Book1\n",
      "Slide 336: Found chart with workbook: Book1\n",
      "Slide 337: Found chart with workbook: Book1\n",
      "Slide 338: Found chart with workbook: Book1\n",
      "Slide 339: Found chart with workbook: Book1\n",
      "Slide 340: Found chart with workbook: Book1\n",
      "Slide 341: Found chart with workbook: Book1\n",
      "Slide 342: Found chart with workbook: Book1\n",
      "Slide 343: Found chart with workbook: Book1\n",
      "Slide 344: Found chart with workbook: Book1\n",
      "Slide 345: Found chart with workbook: Book1\n",
      "Slide 346: Found chart with workbook: Book1\n",
      "Slide 347: Found chart with workbook: Book1\n",
      "Slide 348: Found chart with workbook: Book1\n",
      "Slide 349: Found chart with workbook: Book1\n",
      "Slide 350: Found chart with workbook: Book1\n",
      "Slide 351: Found chart with workbook: Book1\n",
      "Slide 352: Found chart with workbook: Book1\n",
      "Slide 353: Found chart with workbook: Book1\n",
      "Slide 354: Found chart with workbook: Book1\n",
      "Slide 355: Found chart with workbook: Book1\n",
      "Slide 356: Found chart with workbook: Book1\n",
      "Slide 357: Found chart with workbook: Book1\n",
      "Slide 358: Found chart with workbook: Book1\n",
      "Slide 359: Found chart with workbook: Book1\n",
      "Slide 360: Found chart with workbook: Book1\n",
      "Slide 361: Found chart with workbook: Book1\n",
      "Slide 362: Found chart with workbook: Book1\n",
      "Slide 363: Found chart with workbook: Book1\n",
      "Slide 364: Found chart with workbook: Book1\n",
      "Slide 365: Found chart with workbook: Book1\n",
      "Slide 366: Found chart with workbook: Book1\n",
      "Slide 367: Found chart with workbook: Book1\n",
      "Slide 368: Found chart with workbook: Book1\n",
      "Slide 369: Found chart with workbook: Book1\n",
      "Slide 370: Found chart with workbook: Book1\n",
      "Slide 371: Found chart with workbook: Book1\n",
      "Slide 372: Found chart with workbook: Book1\n",
      "Slide 373: Found chart with workbook: Book1\n",
      "Slide 374: Found chart with workbook: Book1\n",
      "Slide 375: Found chart with workbook: Book1\n",
      "Slide 376: Found chart with workbook: Book1\n",
      "Slide 377: Found chart with workbook: Book1\n",
      "Slide 378: Found chart with workbook: Book1\n",
      "Slide 379: Found chart with workbook: Book1\n",
      "Slide 380: Found chart with workbook: Book1\n",
      "Slide 381: Found chart with workbook: Book1\n",
      "Slide 382: Found chart with workbook: Book1\n",
      "Slide 383: Found chart with workbook: Book1\n",
      "Slide 384: Found chart with workbook: Book1\n",
      "Slide 385: Found chart with workbook: Book1\n",
      "Slide 386: Found chart with workbook: Book1\n",
      "Slide 387: Found chart with workbook: Book1\n",
      "Slide 388: Found chart with workbook: Book1\n",
      "Slide 389: Found chart with workbook: Book1\n",
      "Slide 390: Found chart with workbook: Book1\n",
      "Slide 391: Found chart with workbook: Book1\n",
      "Slide 392: Found chart with workbook: Book1\n",
      "Slide 393: Found chart with workbook: Book1\n",
      "Slide 394: Found chart with workbook: Book1\n",
      "Slide 395: Found chart with workbook: Book1\n",
      "Slide 396: Found chart with workbook: Book1\n",
      "Slide 397: Found chart with workbook: Book1\n",
      "Slide 398: Found chart with workbook: Book1\n",
      "Slide 399: Found chart with workbook: Book1\n",
      "Slide 400: Found chart with workbook: Book1\n",
      "Slide 401: Found chart with workbook: Book1\n",
      "Slide 402: Found chart with workbook: Book1\n",
      "Slide 403: Found chart with workbook: Book1\n",
      "Slide 404: Found chart with workbook: Book1\n",
      "Slide 405: Found chart with workbook: Book1\n",
      "Slide 406: Found chart with workbook: Book1\n",
      "Slide 407: Found chart with workbook: Book1\n",
      "Slide 408: Found chart with workbook: Book1\n",
      "Slide 409: Found chart with workbook: Book1\n",
      "Slide 410: Found chart with workbook: Book1\n",
      "Slide 411: Found chart with workbook: Book1\n",
      "Slide 412: Found chart with workbook: Book1\n",
      "Slide 413: Found chart with workbook: Book1\n",
      "Slide 414: Found chart with workbook: Book1\n",
      "Slide 415: Found chart with workbook: Book1\n",
      "Slide 416: Found chart with workbook: Book1\n",
      "Slide 417: Found chart with workbook: Book1\n",
      "Slide 418: Found chart with workbook: Book1\n",
      "Slide 419: Found chart with workbook: Book1\n",
      "Slide 420: Found chart with workbook: Book1\n",
      "Slide 421: Found chart with workbook: Book1\n",
      "Slide 422: Found chart with workbook: Book1\n",
      "Slide 423: Found chart with workbook: Book1\n"
     ]
    }
   ],
   "source": [
    "final=os.getcwd() + f\"\\\\Mix and assortment output_{datetime.today().strftime(\"%d-%m\")}.pptx\"\n",
    "pptx_path = outputPath  # Replace with the actual path to your PPTX file\n",
    "output_pptx_path=final\n",
    "open_chart_data_in_excel(pptx_path,output_pptx_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dcb2f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
