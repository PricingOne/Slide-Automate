{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"..\\general_functions\\generalFunctions.ipynb\"\n",
    "%run \"..\\Financials Slide Duplicate\\Financials Replacement Function.ipynb\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries & reading pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "themePath = os.getcwd()+\"\\Theme1.thmx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_manuf = [\"Ecb\"] \n",
    "client_brands = [\"Isana Ecb\"] \n",
    " \n",
    "decimals = 2\n",
    "sign = \"After\"\n",
    "currency = 'â‚¬'\n",
    "currency = ' '+ currency if sign.lower() == 'after' else  currency + ' '\n",
    " \n",
    "prodORitem = \"Product\"\n",
    "categories =[\"Female Shaving\"]\n",
    "sectors = []\n",
    "segments = [\"Female Dispo\",\"Female Blades\",\"Female Razor\"]\n",
    "subsegments= []\n",
    "subcategories= [\"Female 1-Blade\",\"Female 2-Blade\",\"Female 3-Blade\",\"Female 4-Blade\",\"Female 5-Blade\",\"Female 6-Blade\",\"Female Double Edge\"]\n",
    "\n",
    "national = False\n",
    "customareas= \"\"\n",
    "areas = [\"RETAILER\"] \n",
    "\n",
    "regions_RET  = [\"Rossmann\"]\n",
    "channels_RET = []\n",
    "market_RET = []\n",
    "\n",
    "regions_CHAN = []\n",
    "channels_CHAN = []\n",
    "market_CHAN = []\n",
    " \n",
    "regions_CUST = []\n",
    "channels_CUST = []\n",
    "market_CUST = []\n",
    "\n",
    "\n",
    "data_source = \"DATA SOURCE: Trade Panel/Retailer Data | Jan 2025\"\n",
    "\n",
    "end_date = \"2025-02-01\"\n",
    "\n",
    "OpenEditData=True\n",
    "ManufOrTopC =\"Top Companies\"\n",
    "BrandOrTopB=\"Top Brands\"\n",
    "\n",
    "percent = 100000\n",
    "percentstr=\"'00 000\"\n",
    "### OpenEditData is a parameter (run open excel cell or not )\n",
    "OpenEditData=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "national = ['National'] if \"NATIONAL\" in areas else []\n",
    "retailers = regions_RET + channels_RET + market_RET\n",
    "channels = regions_CHAN + channels_CHAN + market_CHAN\n",
    "cust = regions_CUST + channels_CUST + market_CUST\n",
    "area=national+retailers+channels+cust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleaa\\Documents\\Slide-Automate\\Financials Slide Duplicate\\Financials Datasets-Female ECB\\\n"
     ]
    }
   ],
   "source": [
    "loaded_data = {}\n",
    "\n",
    "datasets_path = os.getcwd()+\"\\\\\"\"Financials Datasets-Female ECB\"\"\\\\\"\n",
    "print(datasets_path)\n",
    "\n",
    "datasets = os.listdir(datasets_path)\n",
    "for dataset in datasets:\n",
    "    file_path = os.path.join(datasets_path, dataset)\n",
    "    with open(file_path, 'rb') as handle:\n",
    "        globals()[dataset.split('.')[0]] = pd.read_pickle(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacement functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide1: Mix Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_brand_P12M_dfs={}\n",
    "for k in brands_client_dfs.keys():\n",
    "    t=brands_client_dfs[k].copy()\n",
    "    t=DetectHeader(t)\n",
    "    t=t[:-1]\n",
    "    t['Value Sales IYA'] = t['Value Sales IYA'].astype(float).fillna(-199)\n",
    "    t=t.fillna(0)\n",
    "    t = t[t['Net Sales'].astype(float) >= 1000]\n",
    "    total= t[(t['Top Brands'].str.contains( ' Total')) & ~(t['Top Brands'].isin(['Grand Total','All Others Total'])) & ~(t['Top Brands'].isin([i+' Total' for i in client_brands]))]\n",
    "    if not t.empty and len(t['Top Brands']) != 1:\n",
    "        modified_brand_P12M_dfs[k]=t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Market "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_RET_CHAN_POS(dataframes,regions, channels, markets):\n",
    "    modified_regions = {}\n",
    "    modified_channels = {}\n",
    "    modified_markets = {}\n",
    "    dya = {}\n",
    "\n",
    "    for k in dataframes.keys():\n",
    "        t = dataframes[k].copy()\n",
    "        # t.columns = t.iloc[cut_df-1]\n",
    "        # t = t.iloc[cut_df:]\n",
    "        t=DetectHeader(t)\n",
    "\n",
    "        t = t[t[\"Net Sales\"].astype(float)>=1000]\n",
    "        t['Value Sales IYA'] =t['Value Sales IYA'].astype(float).fillna(-199) \n",
    "\n",
    "        level_check = set([\"Region\", \"Channel\", \"Market\"])\n",
    "        existant_cols = list(set(t.columns)&level_check)\n",
    "\n",
    "        decider_dic = {\"Region\": regions, \"Channel\":channels, \"Market\":markets}\n",
    "        grand_tot = t[t[t.columns[0]] == 'Grand Total'] \n",
    "        dya[k] = grand_tot\n",
    "\n",
    "        if len(existant_cols) == 1:\n",
    "            df = t[t[t.columns[0]].isin(decider_dic[existant_cols[0]])]\n",
    "            if not df.empty:\n",
    "                if df.columns[0] == \"Region\":\n",
    "                    modified_regions[k] = df\n",
    "                if df.columns[0] == \"Channel\":\n",
    "                    modified_channels[k] = df\n",
    "                if df.columns[0] == \"Market\":\n",
    "                    modified_markets[k] = df\n",
    "\n",
    "        elif len(existant_cols) == 2:\n",
    "            levels_rank = {\"Region\":1, \"Channel\":2, \"Market\":3}\n",
    "            existant_cols = sorted(existant_cols, key=lambda x: levels_rank[x])\n",
    "            t_child = t[t[existant_cols[1]].isin(decider_dic[existant_cols[1]])].drop(columns = [existant_cols[0]])\n",
    "            t_parent = t[t[existant_cols[0]].isin([i + \" Total\" for i in decider_dic[existant_cols[0]]])].drop(columns = [existant_cols[1]])\n",
    "            t_parent[existant_cols[0]] = t_parent[existant_cols[0]].str.replace(\" Total\", \"\").str.strip()\n",
    "            for df in [t_child, t_parent]:\n",
    "                if not df.empty:\n",
    "                    if df.columns[0] == \"Region\":\n",
    "                        modified_regions[k] = df\n",
    "                    if df.columns[0] == \"Channel\":\n",
    "                        modified_channels[k] = df\n",
    "                    if df.columns[0] == \"Market\":\n",
    "                        modified_markets[k] = df\n",
    "            \n",
    "\n",
    "        else:\n",
    "            levels_rank = {\"Region\":1, \"Channel\":2, \"Market\":3}\n",
    "            existant_cols = sorted(existant_cols, key=lambda x: levels_rank[x])\n",
    "            t_market = t[t[existant_cols[2]].isin(decider_dic[existant_cols[2]])].drop(columns = [existant_cols[0],existant_cols[1]])\n",
    "            t_channel = t[t[existant_cols[1]].isin([i + \" Total\" for i in decider_dic[existant_cols[1]]])].drop(columns = [existant_cols[0],existant_cols[2]])\n",
    "            t_channel[existant_cols[1]] = t_channel[existant_cols[1]].str.replace(\" Total\", \"\").str.strip()\n",
    "            t_region = t[t[existant_cols[0]].isin([i + \" Total\" for i in decider_dic[existant_cols[0]]])].drop(columns = [existant_cols[1],existant_cols[2]])\n",
    "            t_region[existant_cols[0]] = t_region[existant_cols[0]].str.replace(\" Total\", \"\").str.strip()\n",
    "            if not t_region.empty:\n",
    "                modified_regions[k] = t_region\n",
    "            if not t_channel.empty:\n",
    "                modified_channels[k] = t_channel\n",
    "            if not t_market.empty:\n",
    "                modified_markets[k] = t_market\n",
    "            \n",
    "    return modified_regions, modified_channels, modified_markets, dya\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_retailer_regions = {}\n",
    "modified_retailer_channels = {}\n",
    "modified_retailer_markets = {}\n",
    "\n",
    "modified_channels_regions = {}\n",
    "modified_channels_channels = {}\n",
    "modified_channels_markets = {}\n",
    "\n",
    "modified_cust_regions = {}\n",
    "modified_cust_channels = {}\n",
    "modified_cust_markets = {}\n",
    "\n",
    "dya_retailer={}\n",
    "dya_channel={}\n",
    "dya_cust = {}\n",
    "\n",
    "#**********Retailer*********\n",
    "if len(retailers)!=0:\n",
    "    modified_retailer_regions, modified_retailer_channels, modified_retailer_markets, dya_retailer = process_RET_CHAN_POS(retailers_P12M_dfs, regions_RET, channels_RET, market_RET)\n",
    "# *********Channels**********\n",
    "if len(channels)!=0:\n",
    "    modified_channels_regions, modified_channels_channels, modified_channels_markets, dya_channel = process_RET_CHAN_POS(channel_P12M_dfs, regions_CHAN, channels_CHAN, market_CHAN)\n",
    "#********POS****************\n",
    "if len(cust)!=0: \n",
    "    modified_cust_regions, modified_cust_channels, modified_cust_markets, dya_cust = process_RET_CHAN_POS(cust_P12M_dfs, regions_CUST, channels_CUST, market_CUST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Sector/Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MixAnalysisCleaning(inputdic):\n",
    "    modifieddic={}\n",
    "    for k in inputdic.keys():\n",
    "        t=inputdic[k].copy()\n",
    "        t=DetectHeader(t)\n",
    "        t=t[:-1]\n",
    "        t['Value Sales IYA'] =t['Value Sales IYA'].astype(float).fillna(-199)\n",
    "        t=t.fillna(0)\n",
    "        t=t[t[\"Net Sales\"]>=1000]\n",
    "        if not t.empty:\n",
    "            modifieddic[k]=t\n",
    "    return modifieddic   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)!=0:\n",
    "    modified_sectors_P12M_mix_analysis_dfs=MixAnalysisCleaning(Sector_P12M_client_dfs)\n",
    "if len(segments)!=0:\n",
    "    modified_segment_P12M_mix_analysis_dfs=MixAnalysisCleaning(Segment_P12M_client_dfs)\n",
    "if len(subsegments)!=0:\n",
    "    modified_subsegment_P12M_mix_analysis_dfs=MixAnalysisCleaning(SubSegment_P12M_client_dfs)\n",
    "if len(subcategories)!=0:\n",
    "    modified_subcategory_P12M_mix_analysis_dfs=MixAnalysisCleaning(SubCategory_P12M_client_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide2: Trade Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TradeMarginCleaning(inputdic,scope=\"\"):\n",
    "    modifieddic={}\n",
    "    for k in inputdic.keys():\n",
    "        t = inputdic[k].copy()\n",
    "        t=DetectHeader(t)\n",
    "        t[scope] = t[scope].replace('Grand Total', 'Total')\n",
    "        t=t.replace(np.nan,0)\n",
    "        if not t.empty:\n",
    "            modifieddic[k]=t\n",
    "    return modifieddic   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)!=0:\n",
    "    modified_sector_Trade_Margin_dfs=TradeMarginCleaning(Sector_P12M_client_dfs,scope=\"Sector\")\n",
    "if len(segments)!=0:\n",
    "    modified_segment_Trade_Margin_dfs=TradeMarginCleaning(Segment_P12M_client_dfs,scope=\"Segment\")\n",
    "\n",
    "if len(subsegments)!=0:\n",
    "    modified_subsegment_Trade_Margin_dfs=TradeMarginCleaning(SubSegment_P12M_client_dfs,scope=\"SubSegment\")\n",
    "\n",
    "if len(subcategories)!=0:\n",
    "    modified_subcategory_Trade_Margin_dfs=TradeMarginCleaning(SubCategory_P12M_client_dfs,scope=\"SubCategory\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sector KPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(data,lis, Scope =\"Sector\"):\n",
    "    final ={}\n",
    "    for key, df in data.items():\n",
    "        df=DetectHeader(df)\n",
    "        df.fillna(0,inplace = True)\n",
    "        df = df.reset_index(drop=True)\n",
    "        df =df[df['Net Sales'] > 1000]\n",
    "        df=df[df[Scope].isin(lis) ]\n",
    "\n",
    "        df = df[~df[Scope].str.contains('Grand Total', case=False)]\n",
    "        if df.shape[0] !=0:\n",
    "            if 'National' in key:\n",
    "                new_key = key.split(' | ')[0] + ' | ' + key.split(' | ')[2] +' | ' + key.split(' | ')[1]\n",
    "            else:\n",
    "                new_key = key\n",
    "            final[new_key] = df\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(data1,data2, Scope = \"Sector\"):\n",
    "    final = {}\n",
    "    for key in data1.keys():\n",
    "        if key in data2.keys():\n",
    "            final[key] = pd.merge(data1[key], data2[key], on = Scope, suffixes= (\"_P12M\", \"_P3M\"))\n",
    "            df = final[key]\n",
    "            df = df[~df[Scope].str.contains('Total', case=False)]\n",
    "            df =df[df['Net Sales_P3M'] > 1000]\n",
    "            \n",
    "            df = df.sort_values('Rate of Sales_P3M', ascending=False).reset_index(drop =True)\n",
    "            \n",
    "            \n",
    "            if df.shape[0]>0:\n",
    "                final[key] = df\n",
    "            \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_sector_P12M = {}\n",
    "modified_sector_P3M ={}\n",
    "merged_data_sector ={}\n",
    "if len(sectors)!=0:\n",
    "    modified_sector_P12M  = clean(Sector_P12M_client_dfs,sectors, \"Sector\")\n",
    "    modified_sector_P3M  = clean(Sector_P3M_client_dfs,sectors, \"Sector\")\n",
    "    merged_data_sector = merge_data(modified_sector_P12M,modified_sector_P3M, \"Sector\")\n",
    "\n",
    "\n",
    "modified_segment_P12M ={}\n",
    "modified_segment_P3M ={}\n",
    "merged_data_segment ={}\n",
    "if len(segments)!=0:\n",
    "    modified_segment_P12M  = clean(Segment_P12M_client_dfs,segments, \"Segment\")\n",
    "    modified_segment_P3M  = clean(Segment_P3M_client_dfs,segments, \"Segment\")\n",
    "    merged_data_segment = merge_data(modified_segment_P12M,modified_segment_P3M, \"Segment\")\n",
    "\n",
    "modified_subsegment_P12M ={}\n",
    "modified_subsegment_P3M ={}\n",
    "merged_data_subsegment ={}\n",
    "if len(subsegments)!=0:\n",
    "    modified_subsegment_P12M  = clean(SubSegment_P12M_client_dfs,subsegments, \"SubSegment\")\n",
    "    modified_subsegment_P3M  = clean(SubSegment_P3M_client_dfs,subsegments, \"SubSegment\")\n",
    "    merged_data_subsegment = merge_data(modified_subsegment_P12M,modified_subsegment_P3M, \"SubSegment\")\n",
    "\n",
    "modified_subcategory_P12M = {}\n",
    "modified_subcategory_P3M ={}\n",
    "merged_data_subcategory ={}\n",
    "if len(subcategories)!=0:\n",
    "    modified_subcategory_P12M  = clean(SubCategory_P12M_client_dfs,subcategories, \"SubCategory\")\n",
    "    modified_subcategory_P3M  = clean(SubCategory_P3M_client_dfs,subcategories, \"SubCategory\")\n",
    "    merged_data_subcategory = merge_data(modified_subcategory_P12M,modified_subcategory_P3M, \"SubCategory\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide 4: SKU KPIs Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By_Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_product_P12M_dfs={}\n",
    "modified_product_P3M_dfs={}\n",
    "modified_product_dfs = {}\n",
    "\n",
    "#P3M\n",
    "for k in product_P3M_dfs.keys():\n",
    "    t=product_P3M_dfs[k].copy()\n",
    "    t=DetectHeader(t)\n",
    "    t=t[:-1]\n",
    "    t['Top Brands']=t['Top Brands'].ffill()\n",
    "    t = t[~t[\"Top Brands\"].str.contains(' Total')]\n",
    "    df = t[t['Top Brands'].isin(client_brands)]\n",
    "    df = df.fillna(0)\n",
    "    df = df[df['Net Sales'] > 1000]\n",
    "    if not df.empty:\n",
    "        modified_product_P3M_dfs[k] = df\n",
    "\n",
    "#P12M\n",
    "for k in product_P12M_dfs.keys():\n",
    "    t=product_P12M_dfs[k].copy()\n",
    "    t=DetectHeader(t)\n",
    "    t=t[:-1]\n",
    "    t['Top Brands']=t['Top Brands'].ffill()\n",
    "    t = t[~t[\"Top Brands\"].str.contains(' Total')]\n",
    "    df = t[t['Top Brands'].isin(client_brands)]\n",
    "    df = df.fillna(0)\n",
    "    df['Net Sales'] = df['Net Sales'].astype(float)\n",
    "    df = df[df['Net Sales'] > 1000]\n",
    "    # df = df.nlargest(15, 'Net Sales')\n",
    "    if not df.empty:\n",
    "        modified_product_P12M_dfs[k] = df\n",
    "\n",
    "\n",
    "missing_keys = [k for k in modified_product_P12M_dfs.keys() if k not in modified_product_P3M_dfs]\n",
    "for k in missing_keys:\n",
    "    modified_product_P3M_dfs[k] = pd.DataFrame(columns=modified_product_P12M_dfs[k].columns)\n",
    "\n",
    "for k in modified_product_P12M_dfs.keys():\n",
    "    p12m_df = modified_product_P12M_dfs[k].copy()\n",
    "    p12m_df = p12m_df.nlargest(15, 'Net Sales')\n",
    "    p3m_df = modified_product_P3M_dfs[k].copy()\n",
    "    comb = pd.merge(p12m_df,p3m_df, how = 'left',on = [\"Top Brands\",f'{prodORitem}'], suffixes = (\"_P12M\", \"_P3M\"))\n",
    "    comb = comb.sort_values(by=f'{prodORitem} Sales Rate_P3M', ascending=False)\n",
    "    # Compute Sales Rate Ix\n",
    "    first_value = comb[f'{prodORitem} Sales Rate_P3M'].iloc[0]\n",
    "    comb['Sales Rate Ix'] = (comb[f'{prodORitem} Sales Rate_P3M'] / first_value)\n",
    "    modified_product_dfs[k] = comb.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By_Brand \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_brand_product_P3M_dfs={}\n",
    "modified_brand_product_P12M_dfs={}\n",
    "modified_brand_product_dfs={}\n",
    "\n",
    "###P3M\n",
    "for k in modified_product_P3M_dfs.keys():\n",
    "        t = modified_product_P3M_dfs[k].copy()\n",
    "        for brand in client_brands:\n",
    "            df = t[t['Top Brands'] == brand]\n",
    "            new_key = f\"{brand} | {k}\"\n",
    "            manuf = client_manuf[0].strip().lower()\n",
    "            parts = [part.strip() for part in new_key.split('|') if part.strip().lower() != manuf]\n",
    "            new_key = ' | '.join(parts)\n",
    "            if not df.empty :\n",
    "                modified_brand_product_P3M_dfs[new_key] = df  \n",
    "\n",
    "\n",
    "###P12M    \n",
    "for k in modified_product_P12M_dfs.keys():\n",
    "        t = modified_product_P12M_dfs[k].copy()\n",
    "        for brand in client_brands:\n",
    "            df = t[t['Top Brands'] == brand]\n",
    "            new_key = f\"{brand} | {k}\"\n",
    "            manuf = client_manuf[0].strip().lower()\n",
    "            parts = [part.strip() for part in new_key.split('|') if part.strip().lower() != manuf]\n",
    "            new_key = ' | '.join(parts)\n",
    "            \n",
    "            if not df.empty :\n",
    "                modified_brand_product_P12M_dfs[new_key] = df    \n",
    "\n",
    "\n",
    "missing_keys = [k for k in modified_brand_product_P12M_dfs.keys() if k not in modified_brand_product_P3M_dfs]\n",
    "for k in missing_keys:\n",
    "    modified_brand_product_P3M_dfs[k] = pd.DataFrame(columns=modified_brand_product_P12M_dfs[k].columns)\n",
    "\n",
    "for k in modified_brand_product_P12M_dfs.keys():\n",
    "    p12m_df = modified_brand_product_P12M_dfs[k].copy()\n",
    "    p12m_df = p12m_df.nlargest(15, 'Net Sales')\n",
    "    p3m_df = modified_brand_product_P3M_dfs[k].copy()\n",
    "    comb = pd.merge(p12m_df,p3m_df, how = 'left',on = [\"Top Brands\",f'{prodORitem}'], suffixes = (\"_P12M\", \"_P3M\"))\n",
    "    \n",
    "    comb = comb.sort_values(by=f'{prodORitem} Sales Rate_P3M', ascending=False)\n",
    "    # Compute Sales Rate Ix\n",
    "    first_value = comb[f'{prodORitem} Sales Rate_P3M'].iloc[0]\n",
    "    comb['Sales Rate Ix'] = (comb[f'{prodORitem} Sales Rate_P3M'] / first_value)\n",
    "    modified_brand_product_dfs[k] = comb.fillna(0)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide 5_Mix Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixMatrixClean(data):\n",
    "    final ={}\n",
    "    for key, val in data.items():\n",
    "        df=val.copy()\n",
    "        columnsNum = df.loc[df['Unnamed: 1']=='Values'].index[0]+1\n",
    "        df.columns = df.iloc[columnsNum]\n",
    "        df = df.iloc[columnsNum+1:].reset_index(drop=True)\n",
    "        if df.shape[0] !=0:\n",
    "            if 'National' in key:\n",
    "                new_key = ' | '.join([key.split(' | ')[0],key.split(' | ')[2],key.split(' | ')[1]])\n",
    "            else:\n",
    "                new_key = key\n",
    "\n",
    "            df.fillna(0,inplace = True)\n",
    "            df['Source'] = new_key.split(' | ')[2]\n",
    "\n",
    "            final[new_key] = df.sort_values(by='Value Sales',ascending=False)\n",
    "    #         final[new_key] = df.sort_values(by='Value Sales',ascending=False)\n",
    "    sortOrder=final[new_key][final[new_key].columns[0]].unique()\n",
    "\n",
    "    # print(sortOrder,final[new_key].columns[0])\n",
    "    for key,val in final.items():\n",
    "        val['order']=val[val.columns[0]].replace(dict(zip(sortOrder,range(len(sortOrder)))))\n",
    "        final[key]=val\n",
    "\n",
    "\n",
    "\n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)!=0:\n",
    "    sector_P12M_modified = mixMatrixClean(Sector_P12M_client_dfs)\n",
    "if len(segments)!=0:\n",
    "    segment_P12M_modified = mixMatrixClean(Segment_P12M_client_dfs)\n",
    "if len(subcategories)!=0:\n",
    "    subCat_P12M_modified = mixMatrixClean(SubCategory_P12M_client_dfs)\n",
    "if len(subsegments)!=0:\n",
    "    subSeg_P12M_modified = mixMatrixClean(SubSegment_P12M_client_dfs)\n",
    "    \n",
    "    \n",
    "secRetailerDf,segRetailerDf,subCatRetailerDf,subSegRetailerDf,brandsRetailerDf={},{},{},{},{}\n",
    "secChannelDf,segChannelDf,subCatChannelDf,subSegChannelDf,brandsChannelDf={},{},{},{},{}\n",
    "secCustDf,segCustDf,subCatCustDf,subSegCustDf,brandsCustDf={},{},{},{},{}\n",
    "\n",
    "for key,retailerList in {'region':['National'] if national else []+regions_RET,'channel':['National'] if national else []+channels_RET,'market':['National'] if national else []+market_RET}.items():\n",
    "    if len(sectors)!=0:secRetailerDf[key] = {key: sector_P12M_modified[key] for key in sector_P12M_modified.keys()  if (key.split(' | ')[2] in retailerList)}\n",
    "    if len(segments)!=0:segRetailerDf[key] = {key: segment_P12M_modified[key] for key in segment_P12M_modified.keys()  if (key.split(' | ')[2] in retailerList)}\n",
    "    if len(subcategories)!=0:subCatRetailerDf[key] = {key: subCat_P12M_modified[key] for key in subCat_P12M_modified.keys()  if (key.split(' | ')[2] in retailerList)}\n",
    "    if len(subsegments)!=0:subSegRetailerDf[key] = {key: subSeg_P12M_modified[key] for key in subSeg_P12M_modified.keys()  if (key.split(' | ')[2] in retailerList)}\n",
    "\n",
    "for key,channelList in {'region':['National'] if national else []+regions_CHAN,'channel':['National'] if national else []+channels_CHAN,'market':['National'] if national else []+market_CHAN}.items():\n",
    "    if len(sectors)!=0:secChannelDf[key] = {key: sector_P12M_modified[key] for key in sector_P12M_modified.keys()  if (key.split(' | ')[2] in channelList)}\n",
    "    if len(segments)!=0:segChannelDf[key] = {key: segment_P12M_modified[key] for key in segment_P12M_modified.keys()  if (key.split(' | ')[2] in channelList)}\n",
    "    if len(subcategories)!=0:subCatChannelDf[key] = {key: subCat_P12M_modified[key] for key in subCat_P12M_modified.keys()  if (key.split(' | ')[2] in channelList)}\n",
    "    if len(subsegments)!=0:subSegChannelDf[key] = {key: subSeg_P12M_modified[key] for key in subSeg_P12M_modified.keys()  if (key.split(' | ')[2] in channelList)}\n",
    "\n",
    "for key,custList in {'region':['National'] if national else []+regions_CUST,'channel':['National'] if national else []+channels_CUST,'market':['National'] if national else []+market_CUST}.items():\n",
    "    if len(sectors)!=0:secCustDf[key] = {key: sector_P12M_modified[key] for key in sector_P12M_modified.keys()  if (key.split(' | ')[2] in custList)}\n",
    "    if len(segments)!=0:segCustDf[key] = {key: segment_P12M_modified[key] for key in segment_P12M_modified.keys()  if (key.split(' | ')[2] in custList)}\n",
    "    if len(subcategories)!=0:subCatCustDf[key] = {key: subCat_P12M_modified[key] for key in subCat_P12M_modified.keys()  if (key.split(' | ')[2] in custList)}\n",
    "    if len(subsegments)!=0:subSegCustDf[key] = {key: subSeg_P12M_modified[key] for key in subSeg_P12M_modified.keys()  if (key.split(' | ')[2] in custList)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "secRetailerClient,segRetailerClient,subCatRetailerClient,subSegRetailerClient={},{},{},{}\n",
    "secChannelClient,segChannelClient,subCatChannelClient,subSegChannelClient={},{},{},{}\n",
    "secCustClient,segCustClient,subCatCustClient,subSegCustClient={},{},{},{}\n",
    "\n",
    "\n",
    "def clientAgg(dic):\n",
    "\n",
    "    clients={}\n",
    "    for marketLevel in ['region','channel','market']:\n",
    "        for manuf in client_manuf:\n",
    "            keys = [dic[marketLevel][key] for key in dic[marketLevel].keys() if manuf in key.split(' | ')]\n",
    "            if keys:\n",
    "                clients[manuf+' | '+marketLevel]=pd.concat(keys).reset_index(drop = True)\n",
    "    return clients\n",
    "\n",
    "if len(sectors)!=0:secRetailerClient = clientAgg(secRetailerDf)\n",
    "if len(segments)!=0:segRetailerClient = clientAgg(segRetailerDf)\n",
    "if len(subcategories)!=0:subCatRetailerClient = clientAgg(subCatRetailerDf)\n",
    "if len(subsegments)!=0:subSegRetailerClient = clientAgg(subSegRetailerDf)\n",
    "\n",
    "if len(sectors)!=0:secChannelClient = clientAgg(secChannelDf)\n",
    "if len(segments)!=0:segChannelClient = clientAgg(segChannelDf)\n",
    "if len(subcategories)!=0:subCatChannelClient = clientAgg(subCatChannelDf)\n",
    "if len(subsegments)!=0:subSegChannelClient = clientAgg(subSegChannelDf)\n",
    "\n",
    "if len(sectors)!=0:secCustClient = clientAgg(secCustDf)\n",
    "if len(segments)!=0:segCustClient = clientAgg(segCustDf)\n",
    "if len(subcategories)!=0:subCatCustClient = clientAgg(subCatCustDf)\n",
    "if len(subsegments)!=0:subSegCustClient = clientAgg(subSegCustDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0, 0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retailerDuplication = sum([len(secRetailerClient)+len(segRetailerClient)+len(subCatRetailerClient)+len(subSegRetailerClient)])\n",
    "channelDuplication = sum([len(secChannelClient)+len(segChannelClient)+len(subCatChannelClient)+len(subSegChannelClient)])\n",
    "custDuplication = sum([len(secCustClient)+len(segCustClient)+len(subCatCustClient)+len(subSegCustClient)])\n",
    "retailerDuplication,channelDuplication,custDuplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillMissingValue(dfToFill):\n",
    "    for key,val in dfToFill.items():\n",
    "        colToFill = val.columns[0]\n",
    "        uniqueValue = val[~val[colToFill].str.contains('Total')][colToFill].unique()\n",
    "        dfLis = []\n",
    "        for source in val['Source'].unique():\n",
    "            df = val[val.Source==source]\n",
    "            missingValue = list(set(uniqueValue) - set(df[~df[colToFill].str.contains('Total')][colToFill].unique()))\n",
    "            missingValue = pd.DataFrame({colToFill: missingValue,'Source':source})\n",
    "            val = pd.concat([val, missingValue]).replace(np.nan,0).reset_index(drop=True)\n",
    "            \n",
    "        ## Value Identifier on the avg or national value for the color schema on replacement\n",
    "        if 'National' in val['Source'].unique():\n",
    "            val['Net Total'] = val[(val.Source=='National')&(val[colToFill].str.contains('Total'))]['Net Sales/Kg'].iloc[0]\n",
    "            val['GM Total'] = val[(val.Source=='National')&(val[colToFill].str.contains('Total'))]['Gross Margin %'].iloc[0]\n",
    "        else:\n",
    "            val['Net Total'] = val[(val[colToFill].str.contains('Total'))]['Net Sales/Kg'].sum()/val[(val[colToFill].str.contains('Total'))]['Net Sales/Kg'].count()\n",
    "            val['GM Total'] = val[(val[colToFill].str.contains('Total'))]['Gross Margin %'].sum()/val[(val[colToFill].str.contains('Total'))]['Gross Margin %'].count()\n",
    "        dfToFill[key]=val\n",
    "        \n",
    "    return dfToFill\n",
    "                            \n",
    "retailerDic = {'Sec':secRetailerClient,'Seg':segRetailerClient,'SubSeg':subSegRetailerClient,'SubCat':subCatRetailerClient}\n",
    "channelDic = {'Sec':secChannelClient,'Seg':segChannelClient,'SubSeg':subSegChannelClient,'SubCat':subCatChannelClient}\n",
    "custDic = {'Sec':secCustClient,'Seg':segCustClient,'SubSeg':subSegCustClient,'SubCat':subCatCustClient}\n",
    "\n",
    "for key,val in retailerDic.items():\n",
    "    retailerDic[key] = fillMissingValue(val)\n",
    "for key,val in channelDic.items():\n",
    "    channelDic[key] = fillMissingValue(val)\n",
    "for key,val in custDic.items():\n",
    "    custDic[key] = fillMissingValue(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLide6: MixMatrix ByBrand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixMatrixbybrandClean(data):\n",
    "    final = {}\n",
    "    for key, val in data.items():\n",
    "        df = val.copy()\n",
    "        df = DetectHeader(df)\n",
    "       \n",
    "        if df.shape[0] != 0:\n",
    "            new_key = key\n",
    "           \n",
    "            df.fillna(0, inplace=True)\n",
    "            if categories[0] in key.split(' | ')[0]:\n",
    "                df['Source'] = new_key.split(' | ')[0]\n",
    "            else:\n",
    "                df['Source'] = new_key.split(' | ')[2]\n",
    "            # Sort the DataFrame by 'Value Sales'\n",
    "            final[new_key] = df.sort_values(by='Value Sales', ascending=False)\n",
    "            # Generate sort order based on sorted unique values of the first column\n",
    "            sortOrder = final[new_key][final[new_key].columns[0]].unique()\n",
    "            # Apply the sort order to the current DataFrame\n",
    "            final[new_key]['order'] = final[new_key][final[new_key].columns[0]].replace(dict(zip(sortOrder, range(len(sortOrder)))))\n",
    " \n",
    "    return final\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillMissingValue(dfToFill):\n",
    "    for key,val in dfToFill.items():\n",
    "        colToFill = val.columns[0]\n",
    "        uniqueValue = val[~val[colToFill].str.contains('Total')][colToFill].unique()\n",
    "        dfLis = []\n",
    "        for source in val['Source'].unique():\n",
    "            df = val[val.Source==source]\n",
    "            missingValue = list(set(uniqueValue) - set(df[~df[colToFill].str.contains('Total')][colToFill].unique()))\n",
    "            missingValue = pd.DataFrame({colToFill: missingValue,'Source':source})\n",
    "            val = pd.concat([val, missingValue]).replace(np.nan,0).reset_index(drop=True)\n",
    "            \n",
    "        ## Value Identifier on the avg or national value for the color schema on replacement\n",
    "            val['Net Total'] = val[(val[colToFill].str.contains('Total'))]['Net Sales/Kg'].sum()/val[(val[colToFill].str.contains('Total'))]['Net Sales/Kg'].count()\n",
    "            val['GM Total'] = val[(val[colToFill].str.contains('Total'))]['Gross Margin %'].sum()/val[(val[colToFill].str.contains('Total'))]['Gross Margin %'].count()\n",
    "        dfToFill[key]=val\n",
    "        \n",
    "    return dfToFill\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat,sec,seg,subseg,subcat \n",
    "secbrand,segbrand,subsegbrand,subcatbrand = {},{},{},{}\n",
    "for key in brands_client_dfs.keys():\n",
    "    key_split = key.split(' | ')\n",
    "    if len(sectors) != 0 and len(key_split) > 2 and key_split[2] in sectors or key_split[0] in categories  :secbrand[key] = brands_client_dfs[key]\n",
    "    if len(segments) != 0 and len(key_split) > 2 and key_split[2] in segments or key_split[0] in categories:segbrand[key] = brands_client_dfs[key]\n",
    "    if len(subsegments) != 0 and len(key_split) > 2 and key_split[2] in subsegments or key_split[0] in categories:subsegbrand[key] = brands_client_dfs[key]\n",
    "    if len(subcategories) != 0 and len(key_split) > 2 and key_split[2] in subcategories or key_split[0] in categories:subcatbrand[key] = brands_client_dfs[key]\n",
    " \n",
    "if len(sectors) != 0:\n",
    "        sec_dfclean=mixMatrixbybrandClean(secbrand)\n",
    "        sectorbybrand=fillMissingValue(sec_dfclean)\n",
    "if len(segments) != 0:\n",
    "        seg_dfclean=mixMatrixbybrandClean(segbrand)\n",
    "        segmentbybrand=fillMissingValue(seg_dfclean)\n",
    "\n",
    "if len(subsegments) != 0: \n",
    "        subseg_dfclean=mixMatrixbybrandClean(subsegbrand)\n",
    "        subsegmentbybrand=fillMissingValue(subseg_dfclean)\n",
    "\n",
    "if len(subcategories) != 0:\n",
    "       subcat_dfclean=mixMatrixbybrandClean(subcatbrand)\n",
    "       subcategorybybrand=fillMissingValue(subcat_dfclean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatdf(dic,area):\n",
    "    final = {}\n",
    "\n",
    "    for key_part in area:\n",
    "        print(key_part)\n",
    "        aligned_dfs = []\n",
    "\n",
    "        # Filter and align DataFrames for the current area\n",
    "        for key, df in dic.items():\n",
    "            key_parts = key.split(\" | \")  # Split key into parts based on \" | \"\n",
    "            # print(key_parts)\n",
    "            if key_part in key_parts:  # Check if the key includes the area (e.g., \"NATIONAL\")\n",
    "                # print(key)\n",
    "                # Set 'Top Brands' as index for alignment, reindex to ensure all brands are present\n",
    "                area_brands = pd.concat([df['Top Brands'] for key, df in dic.items() if key_part in key]).unique()\n",
    "                aligned_df = df.set_index('Top Brands').reindex(area_brands).reset_index()\n",
    "                aligned_df['Source'] = aligned_df['Source'].ffill()  # Track the source of the data\n",
    "                aligned_df = aligned_df.fillna(0)  # Fill missing values with 0\n",
    "                aligned_df.rename(columns={\"Top Brands\": client_manuf[0]}, inplace=True)\n",
    "                aligned_dfs.append(aligned_df)\n",
    "\n",
    "        if aligned_dfs:  # Ensure there's at least one DataFrame to concatenate\n",
    "            final_df = pd.concat(aligned_dfs, ignore_index=True)\n",
    "            final[key_part] = final_df  # Store the concatenated DataFrame in the final dictionary\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rossmann\n",
      "Rossmann\n"
     ]
    }
   ],
   "source": [
    "if len(sectors)!=0:\n",
    "    secfinaldic=concatdf(sectorbybrand,area)\n",
    "if len(segments)!=0:\n",
    "    segfinaldic=concatdf(segmentbybrand,area)\n",
    "if len(subsegments)!=0:\n",
    "    subsegfinaldic=concatdf(subsegmentbybrand,area)\n",
    "if len(subcategories)!=0:\n",
    "    subcatfinaldic=concatdf(subcategorybybrand,area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide7:Sector Spending Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Spending Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanProducts(data):\n",
    "    final ={}\n",
    "    for key, df in data.items():\n",
    "        df=DetectHeader(df)\n",
    "        df['Top Brands'] = df['Top Brands'].replace(0, np.nan)\n",
    "        df['Top Brands'] = df['Top Brands'].fillna(method = 'ffill')\n",
    "        df = df[~df['Top Brands'].str.contains('Total', case=False)]\n",
    "        df.fillna(0,inplace = True)\n",
    "        df = df[df['Net Sales']>1000]\n",
    "        # df = df[df['Top Brands'].isin(client_brands)]\n",
    "        df = df.sort_values(by= 'Net Sales', ascending=False)\n",
    "        df =df.head(12)\n",
    "        df = df.reset_index(drop=True)\n",
    "        if df.shape[0] !=0:\n",
    "            if 'National' in key:\n",
    "                new_key = key.split(' | ')[0] + ' | ' + key.split(' | ')[2] +' | ' + key.split(' | ')[1]\n",
    "            else:\n",
    "                new_key = key\n",
    "            final[new_key] = df\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_products_p12m = cleanProducts(product_P12M_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_products_p12m_brand ={}\n",
    "for key, df in modified_brand_product_P12M_dfs.items():\n",
    "    df['Top Brands'] = df['Top Brands'].replace(0, np.nan)\n",
    "    df['Top Brands'] = df['Top Brands'].fillna(method = 'ffill')\n",
    "    df = df[~df['Top Brands'].str.contains('Total', case=False)]\n",
    "    df.fillna(0,inplace = True)\n",
    "    df = df[df['Net Sales']>1000]\n",
    "    df = df[df['Top Brands'].isin(client_brands)]\n",
    "    df = df.sort_values(by= 'Net Sales', ascending=False)\n",
    "    df =df.head(12)\n",
    "    df = df.reset_index(drop=True)\n",
    "    if df.shape[0] !=0:\n",
    "        if 'National' in key:\n",
    "            new_key = key.split(' | ')[0] + ' | ' + key.split(' | ')[2] +' | ' + key.split(' | ')[1]\n",
    "        else:\n",
    "            new_key = key\n",
    "        modified_products_p12m_brand[new_key] = df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKU Profitability Slide 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "###P12M\n",
    "modified_product_sec_seg_P12M_dfs = {}\n",
    "\n",
    "for k in product_P12M_dfs.keys():\n",
    "    t=product_P12M_dfs[k].copy()\n",
    "    t=DetectHeader(t)\n",
    "    t=t[:-1]\n",
    "    t['Value Sales IYA'] =t['Value Sales IYA'].astype(float).fillna(-199)\n",
    "    t['Net Sales'] =t['Net Sales'].astype(float).fillna(0)\n",
    "    t['Net Sales/Kg'] =t['Net Sales/Kg'].astype(float).fillna(0)\n",
    "\n",
    "    t['Gross Margin %'] =t['Gross Margin %'].astype(float).fillna(0)\n",
    "\n",
    "    t['Top Brands']=t['Top Brands'].ffill()\n",
    "    total= t[(t['Top Brands'].str.contains( ' Total')) & ~(t['Top Brands'].isin(['Grand Total','All Others Total'])) & ~(t['Top Brands'].isin([i+' Total' for i in client_brands]))]\n",
    "    df = t[t['Top Brands'].isin(client_brands)]\n",
    "    df[f'{prodORitem} Sales Rate'] = df[f'{prodORitem} Sales Rate'].fillna(0)\n",
    "    df = df[df['Net Sales'] >= 1000]\n",
    "    if (not df.empty):\n",
    "        modified_product_sec_seg_P12M_dfs[k] = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide9: Trade margin table vs Competition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By client and competitor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_df_excluding_total(df, Inscope=\"\"):\n",
    "    df = df.fillna(0)\n",
    "    total_row = df[df[f'{ManufOrTopC}'] == 'Total']\n",
    "    df = df[df[f'{ManufOrTopC}'] != 'Total']\n",
    "    df = df.sort_values(by=[Inscope], ascending=[True]).reset_index(drop=True)\n",
    "    df = pd.concat([df, total_row]).reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def split_client_copetitor(dictionary,client_dictionary,competitor_dictionary,Inscope=\"\"):\n",
    "    for k in dictionary.keys():\n",
    "        t = dictionary[k].copy()\n",
    "        t=DetectHeader(t)\n",
    "        t=t[:-1]\n",
    "        t[f'{ManufOrTopC}'] = t[f'{ManufOrTopC}'].ffill()\n",
    "        t[Inscope]=t[Inscope].fillna(t[f'{ManufOrTopC}'])\n",
    "        t['Net Sales'] = t['Net Sales'].astype(float)\n",
    "        total_entries = t[(t[f'{ManufOrTopC}'].str.contains(' Total')) & ~(t[f'{ManufOrTopC}'].isin(['Grand Total',\"All Others Total\"])) & ~(t[f'{ManufOrTopC}'].isin([i+' Total' for i in client_manuf]))]\n",
    "        total_entries['Value Share'] = total_entries['Value Share'].astype(float)\n",
    "        total_entries = total_entries.nlargest(1,columns=\"Value Share\")    \n",
    "        comp_lis = list(total_entries[f'{ManufOrTopC}'].str.replace(\" Total\",'').str.strip())\n",
    "        dc = (t[t[f'{ManufOrTopC}'].isin(client_manuf) | t[f'{ManufOrTopC}'].isin([i + \" Total\" for i in client_manuf])]).replace([i + \" Total\" for i in client_manuf],\"Total\")\n",
    "        df = (t[t[f'{ManufOrTopC}'].isin(comp_lis) | t[f'{ManufOrTopC}'].isin([i + \" Total\" for i in comp_lis])]).replace([i + \" Total\" for i in comp_lis],\"Total\")\n",
    "        \n",
    "        dc = dc[dc['Net Sales'] > 1000]\n",
    "        unique_scope = dc[Inscope].unique().tolist()\n",
    "\n",
    "        df = df[df[Inscope].isin(unique_scope)]\n",
    "\n",
    "        for subcat in unique_scope:\n",
    "            if (subcat not in df[Inscope].values) & (subcat!=\"\"):\n",
    "                df = pd.concat([df, pd.DataFrame({f'{ManufOrTopC}': [df[f'{ManufOrTopC}'].unique()[0]], Inscope: [subcat]})])\n",
    "\n",
    "\n",
    "        dc = sort_df_excluding_total(dc, Inscope)\n",
    "        df = sort_df_excluding_total(df, Inscope)\n",
    "\n",
    "        if not dc.empty:\n",
    "            client_dictionary[k]=dc\n",
    "        if not df.empty:\n",
    "            competitor_dictionary[k]=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Sector_Cleaning \n",
    "client_manuf_sector_dfs_new = {}\n",
    "top_competitor_manuf_sector_dfs_new = {}\n",
    "if len(sectors)!=0:\n",
    "    split_client_copetitor(manuf_Sector_dfs,client_manuf_sector_dfs_new,top_competitor_manuf_sector_dfs_new,Inscope=\"Sector\")\n",
    "\n",
    "####Segment_Cleaning\n",
    "client_manuf_segment_dfs_new = {}\n",
    "top_competitor_manuf_segment_dfs_new = {}\n",
    "if len(segments)!=0:\n",
    "    split_client_copetitor(manuf_Segment_dfs,client_manuf_segment_dfs_new,top_competitor_manuf_segment_dfs_new,Inscope=\"Segment\")\n",
    "\n",
    "####SubSegment_Cleaning\n",
    "client_manuf_subsegment_dfs_new = {}\n",
    "top_competitor_manuf_subsegment_dfs_new = {}\n",
    "if len(subsegments)!=0:\n",
    "    split_client_copetitor(manuf_SubSegment_dfs,client_manuf_subsegment_dfs_new,top_competitor_manuf_subsegment_dfs_new,Inscope=\"SubSegment\")\n",
    "\n",
    "####SubCategory_Cleaning\n",
    "client_manuf_subcategory_dfs_new = {}\n",
    "top_competitor_manuf_subcategory_dfs_new = {}\n",
    "if len(subcategories)!=0:\n",
    "    split_client_copetitor(manuf_SubCategory_dfs,client_manuf_subcategory_dfs_new,top_competitor_manuf_subcategory_dfs_new,Inscope=\"SubCategory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# duplication part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [\n",
    "    *[0]*((1 if len(client_brands)>1 else 0)+(1 if regions_RET else 0)+(1 if channels_RET else 0)+(1 if market_RET else 0)\n",
    "          +(1 if regions_CHAN else 0)+(1 if channels_CHAN else 0)+(1 if market_CHAN else 0)\n",
    "          +(1 if regions_CUST else 0)+(1 if channels_CUST else 0)+(1 if market_CUST else 0)\n",
    "          +(1 if sectors else 0)+(1 if segments else 0)+(1 if subsegments else 0)+(1 if subcategories else 0)+(1 if len(client_brands)>0 else 0)),\n",
    "          \n",
    "    *[1]*((1 if sectors else 0)+(1 if segments else 0)+(1 if subsegments else 0)+(1 if subcategories else 0)),\n",
    "    *[2]*((1 if sectors else 0)+(1 if segments else 0)+(1 if subsegments else 0)+(1 if subcategories else 0)),\n",
    "    *[3]*((1 if len(client_brands)>0 else 0)+(1 if len(client_brands)>0 else 0)),\n",
    "    *[4]*((1 if retailerDuplication !=0 else 0)+(1 if channelDuplication !=0 else 0 )+(1 if custDuplication !=0 else 0 )),\n",
    "    *[5]*((1 if sectors else 0)+(1 if segments else 0)+(1 if subsegments else 0)+(1 if subcategories else 0)),\n",
    "    *[6]*((1 if sectors else 0)+(1 if segments else 0)+(1 if subsegments else 0)+(1 if subcategories else 0)), \n",
    "    *[7]*(1 if len(client_brands)>0 else 0),\n",
    "    *[8]*( 1 if len(client_brands)>0 else 0),\n",
    "    *[9]*((1 if sectors else 0)+(1 if segments else 0)+(1 if subsegments else 0)+(1 if subcategories else 0))\n",
    "          ]\n",
    "\n",
    "\n",
    "# slide 0\n",
    "duplication_1=[(len(modified_brand_P12M_dfs.keys()) if len(client_brands)>1 else 0)]\n",
    "duplication_2 = [len(modified_retailer_regions.keys()) if len(regions_RET)>0 else 0, len(modified_retailer_channels) if len(channels_RET)>0 else 0, len(modified_retailer_markets) if len(market_RET)>0 else 0,\n",
    "                 len(modified_channels_regions.keys()) if len(regions_CHAN)>0 else 0, len(modified_channels_channels) if len(channels_CHAN)>0 else 0, len(modified_channels_markets) if len(market_CHAN) >0 else 0,\n",
    "                 len(modified_cust_regions.keys()) if len(regions_CUST)>0 else 0, (len(modified_cust_channels) if len(channels_CUST)>0 else 0), (len(modified_cust_markets) if len(market_CUST)>0 else 0)] \n",
    "\n",
    "duplication_3 = [(len(modified_sectors_P12M_mix_analysis_dfs.keys()) if len(sectors)>0 else 0), (len(modified_segment_P12M_mix_analysis_dfs.keys()) if len(segments)>0 else 0), (len(modified_subsegment_P12M_mix_analysis_dfs) if len(subsegments)>0 else 0), (len(modified_subcategory_P12M_mix_analysis_dfs) if len(subcategories)>0 else 0)]\n",
    "\n",
    "duplication_4 = [len(modified_product_sec_seg_P12M_dfs.keys())]\n",
    "\n",
    "# Slide 1\n",
    "duplication_5 = [(len(modified_sector_Trade_Margin_dfs.keys()) if len(sectors)!=0 else 0), (len(modified_segment_Trade_Margin_dfs.keys()) if len(segments)!=0 else 0), (len(modified_subsegment_Trade_Margin_dfs) if len(subsegments)!=0 else 0), (len(modified_subcategory_Trade_Margin_dfs) if len(subcategories)!=0 else 0)]\n",
    "\n",
    "#Slide 2\n",
    "duplication_6 = [(len(merged_data_sector.keys()) if len(sectors)!=0 else 0), (len(merged_data_segment.keys()) if len(segments)!=0 else 0), (len(merged_data_subsegment) if len(subsegments)!=0 else 0), (len(merged_data_subcategory) if len(subcategories)!=0 else 0)]\n",
    "\n",
    "# Slide 3\n",
    "duplication_7 = [len(modified_product_dfs.keys()),len(modified_brand_product_dfs.keys())]\n",
    "#slide 4\n",
    "duplication_8 = [retailerDuplication,channelDuplication,custDuplication]\n",
    "\n",
    "# Slide 5\n",
    "duplication_9=[(len(secfinaldic.keys())if len(sectors)!=0 else 0),(len(segfinaldic.keys())if len(segments)!=0 else 0),(len(subsegfinaldic.keys())if len(subsegments)!=0 else 0),(len(subcatfinaldic.keys())if len(subcategories)!=0 else 0)]\n",
    "\n",
    "# Slide 5\n",
    "duplication_10 = [(len(modified_sector_P12M.keys()) if len(sectors)!=0 else 0), (len(modified_segment_P12M.keys()) if len(segments)!=0 else 0), (len(modified_subsegment_P12M) if len(subsegments)!=0 else 0), (len(modified_subcategory_P12M) if len(subcategories)!=0 else 0)]\n",
    "combinedmanufbranddfpool=modified_products_p12m\n",
    "combinedmanufbranddfpool.update(modified_products_p12m_brand)\n",
    "# Slide 6\n",
    "duplication_11 = [len(combinedmanufbranddfpool)]\n",
    "\n",
    "# Slide 7 \n",
    "duplication_12 = [len(modified_product_P12M_dfs) + len(modified_brand_product_P12M_dfs)]\n",
    "\n",
    "# Slide 8\n",
    "duplication_13 = [(len(client_manuf_sector_dfs_new.keys()) if len(sectors)!=0 else 0), (len(client_manuf_segment_dfs_new.keys()) if len(segments)!=0 else 0), (len(client_manuf_subsegment_dfs_new) if len(subsegments)!=0 else 0), (len(client_manuf_subcategory_dfs_new) if len(subcategories)!=0 else 0)]\n",
    "\n",
    "\n",
    "duplication = duplication_1 + duplication_2 + duplication_3 + duplication_4 + duplication_5 + duplication_6 + duplication_7 + duplication_8+duplication_9 + duplication_10 + duplication_11+duplication_12+duplication_13\n",
    "\n",
    "duplication = [item for item in duplication if item !=0]\n",
    "\n",
    "section_1 = ([\"Mix Analysis by brand\"] if len(client_brands)>1 else [])\n",
    "section_2 = ([\"Mix Analysis by Retailer for Region\"] if len(regions_RET)!=0 else [])+ ([\"Mix Analysis by Retailer for Channel\"] if len(channels_RET)!=0 else [])+ ([\"Mix Analysis by Retailer for Market\"] if len(market_RET)!=0 else [])+([\"Mix Analysis by Channel for Region\"] if len(regions_CHAN)!=0 else [])+ ([\"Mix Analysis by Channel for Channel\"] if len(channels_CHAN)!=0 else [])+ ([\"Mix Analysis by Channel for Market\"] if len(market_CHAN)!=0 else [])+([f\"Mix Analysis by {customareas} for Region\"] if len(regions_CUST)!=0 else [])+ ([f\"Mix Analysis by {customareas} for Channel\"] if len(channels_CUST)!=0 else [])+ ([f\"Mix Analysis by {customareas} for Market\"] if len(market_CUST)!=0 else [])\n",
    "section_3 = ([\"Mix Analysis by Sector\"] if len(sectors)!=0 else [])+ ([\"Mix Analysis by Segment\"] if len(segments)!=0 else [])+ ([\"Mix Analysis by SubSegment\"] if len(subsegments)!=0 else [])+ ([\"Mix Analysis by SubCategory\"] if len(subcategories)!=0 else [])\n",
    "section_4 = [\"Mix Analysis by\"+ f'{prodORitem}' if len(client_brands)>0 else []]\n",
    "\n",
    "section_5 = ([\"Trade Margin Analysis by Sector\"] if len(sectors)!=0 else [])+ ([\"Trade Margin Analysis by Segment\"] if len(segments)!=0 else [])+ ([\"Trade Margin Analysis by SubSegment\"] if len(subsegments)!=0 else [])+([\"Trade Margin Analysis by SubCategory\"] if len(subcategories)!=0 else [])\n",
    "\n",
    "section_6 = ([\"Sector KPI\"] if len(sectors)!=0 else [])+ ([\"Segment KPI\"] if len(segments)!=0 else [])+ ([\"SubSegment KPI\"] if len(subsegments)!=0 else [])+ ([\"SubCategory KPI\"] if len(subcategories)!=0 else [])\n",
    "\n",
    "section_7 = (\"SKU KPIs Summary By Manufacture\" if len(client_brands)>0 else [],\"SKU KPIs Summary By Brand\" if len(client_brands)>0 else [])\n",
    "\n",
    "section_8 = ['Mix Matrix By Retailer'if retailerDuplication != 0 else[] ,'Mix Matrix By Channel'if channelDuplication != 0 else[],'Mix Matrix By Custom Region'if custDuplication != 0 else[]]#,*section_names_slide4]#*section_names_slide3,*section_names_slide4]\n",
    "\n",
    "section_9=[\"Mix Matrix By Brands by Sector\" if len(sectors)!=0 else [],\"Mix Matrix By Brands by Segment\" if len(segments)!=0 else [],\"Mix Matrix By Brands by SubSegment\"if len(subsegments)!=0 else [],\"Mix Matrix By Brands by SubCategory\"if len(subcategories)!=0 else []]\n",
    "\n",
    "section_10 = ([\"Sector Spending Pool\"] if len(sectors)!=0 else [])+ ([\"Segment Spending Pool\"] if len(segments)!=0 else [])+ ([\"SubSegment Spending Pool\"] if len(subsegments)!=0 else [])+ ([\"SubCategory Spending Pool\"] if len(subcategories)!=0 else [])\n",
    "\n",
    "section_11 = ([\"Product Spending Pool\"] if len(client_brands)>0 else [])\n",
    "\n",
    "section_12 = [(\"SKU Profitability\" if len(client_brands)>0 else [])]\n",
    "\n",
    "section_13 = ([\"Trade Margin Table By Sector\"] if len(sectors)!=0 else [])+ ([\"Trade Margin Table By Segment\"] if len(segments)!=0 else [])+ ([\"Trade Margin Table By SubSegment\"] if len(subsegments)!=0 else [])+ ([\"Trade Margin Table By SubCategory\"] if len(subcategories)!=0 else [])\n",
    "\n",
    "section_names = [*section_1 , *section_2 , *section_3 , *section_4 , *section_5 , *section_6 , *section_7 , *section_8, *section_9 , *section_10 , *section_11,*section_12,*section_13]\n",
    "\n",
    "section_names = [item for item in section_names if item !=[]]\n",
    " \n",
    "\n",
    "path = os.getcwd() + \"\\Financials base.pptx\"\n",
    "new_pre = os.getcwd() + '\\Financials Slide Duplicate.pptx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Segment KPI', 'SubCategory KPI']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplication_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Female Shaving | Ecb | Rossmann': 2     SubCategory  Value Sales_P12M  Value Sales IYA_P12M  \\\n",
       " 0  Female 3-Blade           2170369              1.067287   \n",
       " 1  Female 4-Blade           2211467              1.015908   \n",
       " 2  Female 2-Blade            882311              0.845082   \n",
       " 3  Female 5-Blade            291171              0.000000   \n",
       " \n",
       " 2  Trade Margin %_P12M  Trade Margin % DYA_P12M  Net Sales_P12M  \\\n",
       " 0               0.2521                 0.005931    1.364137e+06   \n",
       " 1               0.1775                -0.012058    1.528460e+06   \n",
       " 2               0.1388                -0.023184    6.266382e+05   \n",
       " 3               0.3438                 0.000000    1.605714e+05   \n",
       " \n",
       " 2  Net Sales/Kg_P12M  Gross Profit/Kg_P12M  Gross Margin %_P12M  \\\n",
       " 0             0.1490                0.0292               0.1956   \n",
       " 1             1.5630                0.7814               0.4999   \n",
       " 2             0.0802               -0.0133              -0.1654   \n",
       " 3             1.2825                0.4882               0.3807   \n",
       " \n",
       " 2  Trade Profit IYA_P12M  ...  Gross Margin %_P3M  Trade Profit IYA_P3M  \\\n",
       " 0                  1.093  ...              0.1417                 1.059   \n",
       " 1                  0.951  ...              0.5303                 0.950   \n",
       " 2                  0.711  ...             -0.2427                 0.535   \n",
       " 3                  0.000  ...              0.3995                 0.000   \n",
       " \n",
       " 2  VSOD IYA_P3M  Av Price/KG_P3M  VAT/Kg_P3M  Total COGS/Kg_P3M  \\\n",
       " 0             0           0.2373    0.037885            -0.1286   \n",
       " 1             0           2.1800    0.348068            -0.7012   \n",
       " 2             0           0.1135    0.018154            -0.1000   \n",
       " 3             0           2.3428    0.374067            -0.7693   \n",
       " \n",
       " 2  Trade Profit/Kg_P3M  Rate of Sales_P3M  WD_P3M  Total WoB %_P3M  \n",
       " 0               0.0495            5071.16       1           0.4302  \n",
       " 1               0.3390            4240.28       1           0.3597  \n",
       " 2               0.0150            1614.70       1           0.1370  \n",
       " 3               0.6876             860.76       1           0.0730  \n",
       " \n",
       " [4 rows x 35 columns]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_subcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 1, 1, 2, 2, 3, 3, 4, 5, 5, 6, 6, 7, 8, 9, 9]\n",
      "[8, 1, 1, 8, 1, 1, 1, 1, 8, 8, 2, 1, 1, 1, 1, 16, 16, 1, 1]\n",
      "['Mix Analysis by Retailer for Region', 'Mix Analysis by Segment', 'Mix Analysis by SubCategory', 'Mix Analysis byProduct', 'Trade Margin Analysis by Segment', 'Trade Margin Analysis by SubCategory', 'Segment KPI', 'SubCategory KPI', 'SKU KPIs Summary By Manufacture', 'SKU KPIs Summary By Brand', 'Mix Matrix By Retailer', 'Mix Matrix By Brands by Segment', 'Mix Matrix By Brands by SubCategory', 'Segment Spending Pool', 'SubCategory Spending Pool', 'Product Spending Pool', 'SKU Profitability', 'Trade Margin Table By Segment', 'Trade Margin Table By SubCategory']\n",
      "19\n",
      "19\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print(index)\n",
    "print(duplication)\n",
    "print(section_names)\n",
    "print(len(index))\n",
    "print(len(duplication))                   \n",
    "print(len(section_names))\n",
    "# print(sum(duplication))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "slideDuplication(index,duplication,section_names,path,new_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_position(end):\n",
    "    return sum(duplication[i] * (1 if isinstance(index[i], int) else len(index[i])) for i in range(end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = Presentation(new_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0\n",
    "if len(client_brands)>1:\n",
    "    Mixanalysis(prs,modified_brand_P12M_dfs,duplication[p],Inscop='Brand',position = calculate_position(p),label_col='Top Brands')\n",
    "    p+=1\n",
    "if len(regions_RET)!=0:\n",
    "    Mixanalysis(prs,modified_retailer_regions,duplication[p],Inscop='Retailer',position = calculate_position(p),label_col='Region')\n",
    "    p+=1\n",
    "if len(channels_RET)!=0:\n",
    "    Mixanalysis(prs,modified_retailer_channels,duplication[p],Inscop='Retailer',position = calculate_position(p),label_col='Channel')\n",
    "    p+=1\n",
    "if len(market_RET)!=0:\n",
    "    Mixanalysis(prs,modified_retailer_markets,duplication[p],Inscop='Retailer',position = calculate_position(p),label_col='Market')\n",
    "    p+=1\n",
    "\n",
    "if len(regions_CHAN)!=0:\n",
    "    Mixanalysis(prs,modified_channels_regions,duplication[p],Inscop='Channel',position = calculate_position(p),label_col='Region')\n",
    "    p+=1\n",
    "if len(channels_CHAN)!=0:\n",
    "    Mixanalysis(prs,modified_channels_channels,duplication[p],Inscop='Channel',position = calculate_position(p),label_col='Channel')\n",
    "    p+=1\n",
    "if len(market_CHAN)!=0:\n",
    "    Mixanalysis(prs,modified_channels_markets,duplication[p],Inscop='Channel',position = calculate_position(p),label_col='Market')\n",
    "    p+=1\n",
    "\n",
    "if len(regions_CUST)!=0:\n",
    "    Mixanalysis(prs,modified_cust_regions,duplication[p],Inscop=f\"{customareas}\",position = calculate_position(p),label_col='Region')\n",
    "    p+=1\n",
    "if len(channels_CUST)!=0:\n",
    "    Mixanalysis(prs,modified_cust_channels,duplication[p],Inscop=f\"{customareas}\",position = calculate_position(p),label_col='Channel')\n",
    "    p+=1\n",
    "if len(market_CUST)!=0:\n",
    "    Mixanalysis(prs,modified_cust_markets,duplication[p],Inscop=f\"{customareas}\",position = calculate_position(p),label_col='Market')\n",
    "    p+=1\n",
    "\n",
    "if len(sectors)!=0:\n",
    "    Mixanalysis(prs,modified_sectors_P12M_mix_analysis_dfs,duplication[p],Inscop='Sector',position = calculate_position(p),label_col='Sector')\n",
    "    p+=1\n",
    "if len(segments)!=0:         \n",
    "    Mixanalysis(prs,modified_segment_P12M_mix_analysis_dfs,duplication[p],Inscop=\"Segment\",position = calculate_position(p),label_col=\"Segment\")\n",
    "    p+=1\n",
    "if len(subsegments)!=0:\n",
    "    Mixanalysis(prs,modified_subsegment_P12M_mix_analysis_dfs,duplication[p],Inscop=\"SubSegment\",position = calculate_position(p),label_col=\"SubSegment\")\n",
    "    p+=1\n",
    "if len(subcategories)!=0:\n",
    "    Mixanalysis(prs,modified_subcategory_P12M_mix_analysis_dfs,duplication[p],Inscop=\"SubCategory\",position = calculate_position(p),label_col=\"SubCategory\")\n",
    "    p+=1\n",
    "\n",
    "if len(client_brands)>0:\n",
    "    Mixanalysis(prs,modified_product_sec_seg_P12M_dfs,duplication[p],Inscop=f'{prodORitem}',position = calculate_position(p),label_col=f'{prodORitem}')\n",
    "    p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)!=0:\n",
    "    TradeMargin(prs,modified_sector_Trade_Margin_dfs,duplication[p],position = calculate_position(p),InScope='Sector')\n",
    "    p+=1\n",
    "if len(segments)!=0:\n",
    "    TradeMargin(prs,modified_segment_Trade_Margin_dfs,duplication[p],position = calculate_position(p),InScope=\"Segment\")\n",
    "    p+=1\n",
    "if len(subsegments)!=0:\n",
    "    TradeMargin(prs,modified_subsegment_Trade_Margin_dfs,duplication[p],position = calculate_position(p),InScope=\"SubSegment\")\n",
    "    p+=1\n",
    "if len(subcategories)!=0:\n",
    "    TradeMargin(prs,modified_subcategory_Trade_Margin_dfs,duplication[p],position = calculate_position(p),InScope=\"SubCategory\")\n",
    "    p+=1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)!=0:\n",
    "    sectorKPI(prs, merged_data_sector, duplication[p], position=calculate_position(p),Scope= \"Sector\")\n",
    "    p+=1\n",
    "if len(segments)!=0:\n",
    "    sectorKPI(prs, merged_data_segment, duplication[p], position=calculate_position(p),Scope= \"Segment\")\n",
    "    p+=1\n",
    "\n",
    "if len(subsegments)!=0:\n",
    "    sectorKPI(prs, merged_data_subsegment, duplication[p], position=calculate_position(p),Scope= \"SubSegment\")\n",
    "    p+=1\n",
    "\n",
    "if len(subcategories)!=0:\n",
    "    sectorKPI(prs, merged_data_subcategory, duplication[p], position=calculate_position(p),Scope= \"SubCategory\") \n",
    "    p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(client_brands)>0:\n",
    "    SkuKpis(prs,modified_product_dfs,duplication[p],position = calculate_position(p))\n",
    "    p+=1\n",
    "    SkuKpis(prs,modified_brand_product_dfs,duplication[p],position = calculate_position(p))\n",
    "    p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixMatrix(prs,dfs,position = 0,topbrans=False,slideby=\"\"):\n",
    "    \n",
    "    for slidenum,key in enumerate(dfs.keys()):\n",
    "        shapes = prs.slides[slidenum+position].shapes\n",
    "        tables, charts = createTableAndChart(shapes)\n",
    "        if slideby==\"bybrand\":\n",
    "            title_num = get_shape_number(shapes,\"Mix Matrix | Weight of Business (WoB) vs. Net Sales per kg (NS/kg) and Gross Margin (GM%) | National | P12M\")\n",
    "            data_source_num = get_shape_number(shapes,\"Data Source l Client P&L\")\n",
    "            shapes[4].text = data_source\n",
    "            shapes[5].text = shapes[5].text.replace('National',key)\n",
    "\n",
    "        else:\n",
    "            title_num = get_shape_number(shapes,\"Mix Matrix | Weight of Business (WoB) vs. Net Sales per kg (NS/kg) and Gross Margin (GM%) | Client | P12M\")\n",
    "            data_source_num = get_shape_number(shapes,\"Data Source l Client P&L\")\n",
    "            shapes[4].text = data_source\n",
    "            \n",
    "            if topbrans==False:\n",
    "                shapes[5].text = shapes[5].text.replace('Client',key.split(' | ')[1])\n",
    "            else:\n",
    "                shapes[5].text = shapes[5].text.replace('Client',client_manuf[0])\n",
    "    \n",
    "        shapes[5].text_frame.paragraphs[0].font.size = Pt(12)\n",
    "        shapes[5].text_frame.paragraphs[0].font.name = 'Nexa (Headings)'\n",
    "\n",
    "        df = dfs[key].reset_index(drop=True)\n",
    "        col = df.columns[0]\n",
    "        table = tables[0].table\n",
    "        \n",
    "        num_rows_to_remove = int(len(table.rows) - ((df.shape[0]/df.Source.nunique())*2 + 1))\n",
    "        table = removeRowFromTable(table,num_rows_to_remove,rowToExclude=1,height=Inches(3.88))\n",
    "\n",
    "        num_cols_to_remove = int(len(table.columns) - ((df.Source.nunique())*2 + 1))\n",
    "        table = col_cell_remove(table, num_cols_to_remove)\n",
    "\n",
    "        for row_num, row in enumerate(table.rows):\n",
    "\n",
    "            for col_num, cell in enumerate(row.cells):\n",
    "\n",
    "                if row_num==0:\n",
    "                    if col_num % 2!=0:\n",
    "                        cell.text=df.Source.unique()[col_num//2]\n",
    "                        cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                        cell.text_frame.paragraphs[0].font.size = Pt(10)\n",
    "                        cell.text_frame.paragraphs[0].font.bold = True\n",
    "                        cell.text_frame.paragraphs[0].font.color.rgb = RGBColor(87,85,85)\n",
    "                        cell.text_frame.paragraphs[0].font.name = 'Nexa Bold'\n",
    "\n",
    "                elif row_num %2 !=0:\n",
    "                    if col_num == 0:\n",
    "                        cell.text=df[col].unique()[row_num//2].replace('Grand Total',col + ' Total')\n",
    "                        cell.text_frame.paragraphs[0].alignment = PP_ALIGN.LEFT\n",
    "                        cell.text_frame.paragraphs[0].font.size = Pt(10)\n",
    "                        cell.text_frame.paragraphs[0].font.name = 'Nexa Bold'\n",
    "                        cell.text_frame.paragraphs[0].font.bold = False\n",
    "\n",
    "                    elif col_num%2 !=0:\n",
    "                        df1=df[df.Source ==df.Source.unique()[col_num//2]].reset_index(drop=True)\n",
    "                        cell.text = 'Wob = '+str(int(round(df1['Total WoB %'].iloc[(row_num//2)]*100,0)))+'%'\n",
    "\n",
    "                        cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                        cell.text_frame.paragraphs[0].font.size = Pt(8)\n",
    "                        cell.text_frame.paragraphs[0].font.bold = False\n",
    "                        cell.text_frame.paragraphs[0].font.name = 'Nexa Bold'\n",
    "\n",
    "                        if (col_num!= 1) & (row_num!=1):\n",
    "                            cell.text_frame.paragraphs[0].font.name = 'Nexa Bold'\n",
    "                            cell.text_frame.paragraphs[0].font.bold = True\n",
    "\n",
    "\n",
    "                else:\n",
    "                    if col_num!=0:\n",
    "\n",
    "                        if col_num%2!=0:\n",
    "                            df1=df[df.Source ==df.Source.unique()[col_num//2]].reset_index(drop=True)\n",
    "\n",
    "                            value =format_number(df1['Net Sales/Kg'].iloc[(row_num//2)-1], use_decimals=True, decimals=decimals, use_apostrophes=False, currency_symbol=currency.strip(), currency_before=True if sign.lower=='before' else False)\n",
    "                            value = '' if float(value.split(' ')[0])==0 else value\n",
    "\n",
    "                            cell.text = 'NS/KG'+'\\n'+str(value)\n",
    "                            cell.fill.solid()\n",
    "                            div = (df1['Net Sales/Kg'].iloc[(row_num//2)-1]/df1['Net Total'].replace(0,1).iloc[0])*100\n",
    "                            cell.fill.fore_color.rgb= RGBColor(255,191,191) if div<80 else RGBColor(203,234,231) if div >120 else RGBColor(242,242,242)\n",
    "\n",
    "\n",
    "                        else:\n",
    "                            cell.text = 'GM%'+'\\n'+str(int(round(df1['Gross Margin %'].iloc[(row_num//2)-1]*100,0)))+'%'\n",
    "                            div = (df1['Gross Margin %'].iloc[(row_num//2)-1]/df1['GM Total'].replace(0,1).iloc[0])*100\n",
    "                            cell.fill.fore_color.rgb= RGBColor(255,191,191) if div<80 else RGBColor(203,234,231) if div >120 else RGBColor(242,242,242)\n",
    "\n",
    "                        style_name='Nexa Book (Body)' #if (col_num not in [1,2]) & (row_num!=2) else 'Nexa Bold'\n",
    "                        for cell_style in cell.text_frame.paragraphs:\n",
    "                            cell_style.alignment = PP_ALIGN.CENTER\n",
    "                            cell_style.font.size = Pt(8)\n",
    "                            cell_style.font.bold = False\n",
    "                            cell_style.font.name = style_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "# mixMatrix(prs,secretailerTotal,position = 0)\n",
    "pos = calculate_position(p)\n",
    "if retailerDuplication!=0:\n",
    "    for key,val in retailerDic.items():\n",
    "        if val:\n",
    "            mixMatrix(prs,val,position = pos)\n",
    "            print(pos)\n",
    "\n",
    "            pos +=len(retailerDic[key].keys())\n",
    "\n",
    "    p+=1        \n",
    "if channelDuplication!=0:\n",
    "    for key,val in channelDic.items():\n",
    "        if val:\n",
    "            mixMatrix(prs,val,position = pos)\n",
    "            pos +=len(channelDic[key].keys())\n",
    "    p+=1       \n",
    "if custDuplication!=0:\n",
    "    for key,val in custDic.items():\n",
    "        if val:\n",
    "            mixMatrix(prs,val,position = pos)\n",
    "            pos +=len(custDic[key].keys())\n",
    "    p+=1        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = calculate_position(p)\n",
    "if len(sectors)!=0:\n",
    "    mixMatrix(prs,secfinaldic,position = calculate_position(p),slideby=\"bybrand\")\n",
    "    p+=1\n",
    "if len(segments)!=0:\n",
    "    mixMatrix(prs,segfinaldic,position = calculate_position(p),slideby=\"bybrand\")\n",
    "    p+=1\n",
    "if len(subsegments)!=0:\n",
    "    mixMatrix(prs,subsegfinaldic,position = calculate_position(p),slideby=\"bybrand\")\n",
    "    p+=1\n",
    "if len(subcategories)!=0:\n",
    "    mixMatrix(prs,subcatfinaldic,position = calculate_position(p),slideby=\"bybrand\")\n",
    "    p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "if len(sectors)!=0:\n",
    "    sectorSpendingPool(prs, modified_sector_P12M,duplication[p], position =calculate_position(p),Scope= \"Sector\")\n",
    "    p+=1\n",
    "\n",
    "if len(segments)!=0:\n",
    "    sectorSpendingPool(prs, modified_segment_P12M,duplication[p], position =calculate_position(p),Scope=\"Segment\")\n",
    "    p+=1\n",
    "\n",
    "if len(subsegments)!=0:\n",
    "    sectorSpendingPool(prs, modified_subsegment_P12M,duplication[p], position =calculate_position(p),Scope=\"SubSegment\")\n",
    "    p+=1\n",
    "\n",
    "if len(subcategories)!=0:\n",
    "    sectorSpendingPool(prs, modified_subcategory_P12M,duplication[p], position =calculate_position(p),Scope= \"SubCategory\")    \n",
    "    p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(client_brands)>0:\n",
    "    combinedmanufbranddfpool=modified_products_p12m\n",
    "    combinedmanufbranddfpool.update(modified_products_p12m_brand)\n",
    "    productSpendingPool(prs,combinedmanufbranddfpool, duplication[p], position= calculate_position(p))\n",
    "    p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(client_brands)>0:\n",
    "    combinedmanufbranddf=modified_product_P12M_dfs\n",
    "    combinedmanufbranddf.update(modified_brand_product_P12M_dfs)\n",
    "    SKUProfitability(prs,combinedmanufbranddf,duplication[p],position = calculate_position(p))\n",
    "    p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)!=0:\n",
    "    TradeMarginTable(prs,client_manuf_sector_dfs_new,top_competitor_manuf_sector_dfs_new,duplication[p],position = calculate_position(p),Inscope=\"Sector\")\n",
    "    p+=1\n",
    "if len(segments)!=0:  \n",
    "    TradeMarginTable(prs,client_manuf_segment_dfs_new,top_competitor_manuf_segment_dfs_new,duplication[p],position = calculate_position(p),Inscope=\"Segment\")\n",
    "    p+=1\n",
    "if len(subsegments)!=0:  \n",
    "    TradeMarginTable(prs,client_manuf_subsegment_dfs_new,top_competitor_manuf_subsegment_dfs_new,duplication[p],position = calculate_position(p),Inscope=\"SubSegment\")\n",
    "    p+=1   \n",
    "if len(subcategories)!=0:  \n",
    "    TradeMarginTable(prs,client_manuf_subcategory_dfs_new,top_competitor_manuf_subcategory_dfs_new,duplication[p],position = calculate_position(p),Inscope=\"SubCategory\")\n",
    "    p+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath=os.getcwd() +\"\\\\FinalOutput\"+f\"\\\\Financials_Output_{datetime.today().strftime(\"%d-%m\")}.pptx\"\n",
    "prs.save(outputPath)\n",
    "# app = win32.Dispatch(\"PowerPoint.Application\")/\n",
    "# presentation = app.Presentations.Open(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=os.getcwd() +\"\\\\FinalOutput\"+f\"\\\\Financials_Output_{datetime.today().strftime(\"%d-%m\")}.pptx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slide 1: Opened Excel workbook: Book1\n",
      "Slide 2: Opened Excel workbook: Book1\n",
      "Slide 3: Opened Excel workbook: Book1\n",
      "Slide 4: Opened Excel workbook: Book1\n",
      "Slide 5: Opened Excel workbook: Book1\n",
      "Slide 6: Opened Excel workbook: Book1\n",
      "Slide 7: Opened Excel workbook: Book1\n",
      "Slide 8: Opened Excel workbook: Book1\n",
      "Slide 9: Opened Excel workbook: Book1\n",
      "Slide 10: Opened Excel workbook: Book1\n",
      "Slide 11: Opened Excel workbook: Book1\n",
      "Slide 12: Opened Excel workbook: Book1\n",
      "Slide 13: Opened Excel workbook: Book1\n",
      "Slide 14: Opened Excel workbook: Book1\n",
      "Slide 15: Opened Excel workbook: Book1\n",
      "Slide 16: Opened Excel workbook: Book1\n",
      "Slide 17: Opened Excel workbook: Book1\n",
      "Slide 18: Opened Excel workbook: Book1\n",
      "Slide 61: Opened Excel workbook: Book1\n",
      "Slide 62: Opened Excel workbook: Book1\n",
      "Slide 63: Opened Excel workbook: Book1\n",
      "Slide 64: Opened Excel workbook: Book1\n",
      "Slide 65: Opened Excel workbook: Book1\n",
      "Slide 66: Opened Excel workbook: Book1\n",
      "Slide 67: Opened Excel workbook: Book1\n",
      "Slide 68: Opened Excel workbook: Book1\n",
      "Slide 69: Opened Excel workbook: Book1\n",
      "Slide 70: Opened Excel workbook: Book1\n",
      "Slide 71: Opened Excel workbook: Book1\n",
      "Slide 72: Opened Excel workbook: Book1\n",
      "Slide 73: Opened Excel workbook: Book1\n",
      "Slide 74: Opened Excel workbook: Book1\n",
      "Slide 75: Opened Excel workbook: Book1\n",
      "Slide 76: Opened Excel workbook: Book1\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "pptx_path = outputPath  # Replace with the actual path to your PPTX file\n",
    "output_pptx_path=final\n",
    "open_chart_data_in_excel(pptx_path,output_pptx_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
